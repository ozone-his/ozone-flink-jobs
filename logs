[INFO] Scanning for projects...
[WARNING] The POM for org.eclipse.m2e:lifecycle-mapping:jar:1.0.0 is invalid, transitive dependencies (if any) will not be available, enable debug logging for more details
[WARNING] Failed to retrieve plugin descriptor for org.eclipse.m2e:lifecycle-mapping:1.0.0: Plugin org.eclipse.m2e:lifecycle-mapping:1.0.0 or one of its dependencies could not be resolved: Failed to read artifact descriptor for org.eclipse.m2e:lifecycle-mapping:jar:1.0.0
[INFO] 
[INFO] ----------------------< com.ozonehis:flink-jobs >-----------------------
[INFO] Building Ozone ETL Pipelines 2.2.0-SNAPSHOT
[INFO] --------------------------------[ jar ]---------------------------------
[WARNING] The POM for org.eclipse.m2e:lifecycle-mapping:jar:1.0.0 is invalid, transitive dependencies (if any) will not be available, enable debug logging for more details
[WARNING] Failed to retrieve plugin descriptor for org.eclipse.m2e:lifecycle-mapping:1.0.0: Plugin org.eclipse.m2e:lifecycle-mapping:1.0.0 or one of its dependencies could not be resolved: Failed to read artifact descriptor for org.eclipse.m2e:lifecycle-mapping:jar:1.0.0
[INFO] 
[INFO] --- maven-resources-plugin:2.6:resources (default-resources) @ flink-jobs ---
[INFO] Using 'UTF-8' encoding to copy filtered resources.
[INFO] Copying 2 resources
[INFO] 
[INFO] --- maven-compiler-plugin:3.1:compile (default-compile) @ flink-jobs ---
[INFO] Nothing to compile - all classes are up to date
[INFO] 
[INFO] --- formatter-maven-plugin:2.10.0:format (default) @ flink-jobs ---
[INFO] Using 'UTF-8' encoding to format source files.
[INFO] Number of files to be formatted: 27
[INFO] Successfully formatted:          0 file(s)
[INFO] Fail to format:                  0 file(s)
[INFO] Skipped:                         27 file(s)
[INFO] Read only skipped:               0 file(s)
[INFO] Approximate time taken:          0s
[INFO] 
[INFO] --- exec-maven-plugin:3.1.0:java (default-cli) @ flink-jobs ---
INFO  - TaskExecutorResourceUtils  - The configuration option taskmanager.cpu.cores required for local execution is not set, setting it to the maximal possible value.
INFO  - TaskExecutorResourceUtils  - The configuration option taskmanager.memory.task.heap.size required for local execution is not set, setting it to the maximal possible value.
INFO  - TaskExecutorResourceUtils  - The configuration option taskmanager.memory.task.off-heap.size required for local execution is not set, setting it to the maximal possible value.
INFO  - TaskExecutorResourceUtils  - The configuration option taskmanager.memory.managed.size required for local execution is not set, setting it to its default value 128 mb.
INFO  - MiniCluster                - Starting Flink Mini Cluster
INFO  - MiniCluster                - Starting Metrics Registry
INFO  - MetricRegistryImpl         - No metrics reporter configured, no metrics will be exposed/reported.
INFO  - MiniCluster                - Starting RPC Service(s)
INFO  - AkkaRpcServiceUtils        - Trying to start local actor system
INFO  - Slf4jLogger                - Slf4jLogger started
INFO  - AkkaRpcServiceUtils        - Actor system started at akka://flink
INFO  - AkkaRpcServiceUtils        - Trying to start local actor system
INFO  - Slf4jLogger                - Slf4jLogger started
INFO  - AkkaRpcServiceUtils        - Actor system started at akka://flink-metrics
INFO  - AkkaRpcService             - Starting RPC endpoint for org.apache.flink.runtime.metrics.dump.MetricQueryService at akka://flink-metrics/user/rpc/MetricQueryService .
INFO  - aultDelegationTokenManager - Loading delegation token providers
INFO  - pFSDelegationTokenProvider - Hadoop FS is not available (not packaged with this application): NoClassDefFoundError : "org/apache/hadoop/hdfs/HdfsConfiguration".
INFO  - aultDelegationTokenManager - Delegation token provider hadoopfs loaded and initialized
INFO  - aultDelegationTokenManager - Delegation token provider hbase loaded and initialized
INFO  - aultDelegationTokenManager - Delegation token providers loaded successfully
INFO  - ionTokenReceiverRepository - Loading delegation token receivers
INFO  - ionTokenReceiverRepository - Delegation token receiver hadoopfs loaded and initialized
INFO  - ionTokenReceiverRepository - Delegation token receiver hbase loaded and initialized
INFO  - ionTokenReceiverRepository - Delegation token receivers loaded successfully
INFO  - aultDelegationTokenManager - Checking provider and receiver instances consistency
INFO  - aultDelegationTokenManager - Provider and receiver instances are consistent
INFO  - aultDelegationTokenManager - Obtaining delegation tokens
INFO  - aultDelegationTokenManager - Delegation tokens obtained successfully
WARN  - aultDelegationTokenManager - No tokens obtained so skipping notifications
INFO  - ionTokenReceiverRepository - Loading delegation token receivers
INFO  - ionTokenReceiverRepository - Delegation token receiver hadoopfs loaded and initialized
INFO  - ionTokenReceiverRepository - Delegation token receiver hbase loaded and initialized
INFO  - ionTokenReceiverRepository - Delegation token receivers loaded successfully
WARN  - Configuration              - Config uses deprecated configuration key 'high-availability' instead of proper key 'high-availability.type'
WARN  - Configuration              - Config uses deprecated configuration key 'high-availability' instead of proper key 'high-availability.type'
WARN  - Configuration              - Config uses deprecated configuration key 'high-availability' instead of proper key 'high-availability.type'
INFO  - ZooKeeperUtils             - Enforcing default ACL for ZK connections
INFO  - ZooKeeperUtils             - Using '/flink/default' as Zookeeper namespace.
INFO  - CuratorFrameworkImpl       - Starting
INFO  - ZooKeeper                  - Client environment:zookeeper.version=3.7.1-a2fb57c55f8e59cdd76c34b357ad5181df1258d5, built on 2022-05-07 06:45 UTC
INFO  - ZooKeeper                  - Client environment:host.name=192.168.1.167
INFO  - ZooKeeper                  - Client environment:java.version=11.0.18
INFO  - ZooKeeper                  - Client environment:java.vendor=Azul Systems, Inc.
INFO  - ZooKeeper                  - Client environment:java.home=/Users/emmanuelnyachoke/.sdkman/candidates/java/11.0.18-zulu/zulu-11.jdk/Contents/Home
INFO  - ZooKeeper                  - Client environment:java.class.path=/Users/emmanuelnyachoke/.sdkman/candidates/maven/current/boot/plexus-classworlds-2.6.0.jar
INFO  - ZooKeeper                  - Client environment:java.library.path=/Users/emmanuelnyachoke/Library/Java/Extensions:/Library/Java/Extensions:/Network/Library/Java/Extensions:/System/Library/Java/Extensions:/usr/lib/java:.
INFO  - ZooKeeper                  - Client environment:java.io.tmpdir=/var/folders/tj/cy4bltm12r7cm83r69vcgwgm0000gn/T/
INFO  - ZooKeeper                  - Client environment:java.compiler=<NA>
INFO  - ZooKeeper                  - Client environment:os.name=Mac OS X
INFO  - ZooKeeper                  - Client environment:os.arch=aarch64
INFO  - ZooKeeper                  - Client environment:os.version=13.5.2
INFO  - ZooKeeper                  - Client environment:user.name=emmanuelnyachoke
INFO  - ZooKeeper                  - Client environment:user.home=/Users/emmanuelnyachoke
INFO  - ZooKeeper                  - Client environment:user.dir=/Users/emmanuelnyachoke/Code/Mekom/ozone-flink-jobs
INFO  - ZooKeeper                  - Client environment:os.memory.free=207MB
INFO  - ZooKeeper                  - Client environment:os.memory.max=4096MB
INFO  - ZooKeeper                  - Client environment:os.memory.total=256MB
INFO  - ZooKeeper                  - Initiating client connection, connectString=localhost:2181 sessionTimeout=60000 watcher=org.apache.flink.shaded.curator5.org.apache.curator.ConnectionState@7b4f3608
INFO  - X509Util                   - Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation
INFO  - ClientCnxnSocket           - jute.maxbuffer value is 1048575 Bytes
INFO  - ClientCnxn                 - zookeeper.request.timeout value is 0. feature enabled=false
INFO  - CuratorFrameworkImpl       - Default schema
INFO  - ClientCnxn                 - Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181.
INFO  - ClientCnxn                 - SASL config status: Will not attempt to authenticate using SASL (unknown error)
INFO  - ClientCnxn                 - Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:52170, server: localhost/0:0:0:0:0:0:0:1:2181
INFO  - ClientCnxn                 - Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, session id = 0x10009b90d4f0000, negotiated timeout = 40000
INFO  - ConnectionStateManager     - State change: CONNECTED
INFO  - EnsembleTracker            - New config event received: {}
INFO  - EnsembleTracker            - New config event received: {}
INFO  - BlobServer                 - Created BLOB server storage directory /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/blobStorage
INFO  - BlobServer                 - Started BLOB server at 0.0.0.0:52172 - max concurrent requests: 50 - max backlog: 1000
INFO  - PermanentBlobCache         - Created BLOB cache storage directory /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/blobStorage
INFO  - TransientBlobCache         - Created BLOB cache storage directory /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/blobStorage
INFO  - MiniCluster                - Starting 1 TaskManager(s)
INFO  - TaskManagerRunner          - Starting TaskManager with ResourceID: 586b9eac-aa0b-41ab-ae70-a614854e7a0e
INFO  - TaskManagerServices        - Temporary file directory '/tmp/temp': total 926 GB, usable 289 GB (31.21% usable)
INFO  - IOManager                  - Created a new FileChannelManager for spilling of task related data to disk (joins, sorting, ...). Used directories:
	/tmp/temp/flink-io-0a6171ae-115d-46c8-b026-e3b045c9f5b5
INFO  - leEnvironmentConfiguration - Ignoring old (but still present) network buffer configuration via taskmanager.network.numberOfBuffers.
INFO  - NettyShuffleServiceFactory - Created a new FileChannelManager for storing result partitions of BLOCKING shuffles. Used directories:
	/tmp/temp/flink-netty-shuffle-4e00509b-807d-4def-a026-d6b1537f3cc6
INFO  - NetworkBufferPool          - Allocated 64 MB for network buffer pool (number of memory segments: 2048, bytes per segment: 32768).
INFO  - NettyShuffleEnvironment    - Starting the network environment and its components.
INFO  - KvStateService             - Starting the kvState service and its components.
INFO  - Configuration              - Config uses fallback configuration key 'akka.ask.timeout' instead of key 'taskmanager.slot.timeout'
INFO  - AkkaRpcService             - Starting RPC endpoint for org.apache.flink.runtime.taskexecutor.TaskExecutor at akka://flink/user/rpc/taskmanager_0 .
INFO  - aultLeaderRetrievalService - Starting DefaultLeaderRetrievalService with ZookeeperLeaderRetrievalDriver{connectionInformationPath='/resource_manager/connection_info'}.
INFO  - DefaultJobLeaderService    - Start job leader service.
INFO  - FileCache                  - User file cache uses directory /tmp/temp/flink-dist-cache-0f0b7a0a-0f03-46cd-a3fc-212aab11e3af
INFO  - DispatcherRestEndpoint     - Starting rest endpoint.
WARN  - WebMonitorUtils            - Log file environment variable 'log.file' is not set.
WARN  - WebMonitorUtils            - JobManager log files are unavailable in the web dashboard. Log file location not found in environment variable 'log.file' or configuration key 'web.log.path'.
INFO  - DispatcherRestEndpoint     - Rest endpoint listening at localhost:8081
INFO  - faultLeaderElectionService - Starting DefaultLeaderElectionService with org.apache.flink.runtime.leaderelection.MultipleComponentLeaderElectionDriverAdapter@490842e3.
INFO  - DispatcherRestEndpoint     - Web frontend listening at http://localhost:8081.
INFO  - DispatcherRestEndpoint     - http://localhost:8081 was granted leadership with leaderSessionID=3a82a6ce-fb62-4610-b46c-7fb86bd673d4
INFO  - faultLeaderElectionService - Starting DefaultLeaderElectionService with org.apache.flink.runtime.leaderelection.MultipleComponentLeaderElectionDriverAdapter@34e098bb.
INFO  - ResourceManagerServiceImpl - Starting resource manager service.
INFO  - faultLeaderElectionService - Starting DefaultLeaderElectionService with org.apache.flink.runtime.leaderelection.MultipleComponentLeaderElectionDriverAdapter@251106c5.
INFO  - aultLeaderRetrievalService - Starting DefaultLeaderRetrievalService with ZookeeperLeaderRetrievalDriver{connectionInformationPath='/resource_manager/connection_info'}.
INFO  - aultLeaderRetrievalService - Starting DefaultLeaderRetrievalService with ZookeeperLeaderRetrievalDriver{connectionInformationPath='/dispatcher/connection_info'}.
INFO  - aultLeaderRetrievalService - Starting DefaultLeaderRetrievalService with ZookeeperLeaderRetrievalDriver{connectionInformationPath='/resource_manager/connection_info'}.
INFO  - aultLeaderRetrievalService - Starting DefaultLeaderRetrievalService with ZookeeperLeaderRetrievalDriver{connectionInformationPath='/dispatcher/connection_info'}.
INFO  - aultLeaderRetrievalService - Starting DefaultLeaderRetrievalService with ZookeeperLeaderRetrievalDriver{connectionInformationPath='/rest_server/connection_info'}.
INFO  - MiniCluster                - Flink Mini Cluster started successfully
INFO  - DefaultDispatcherRunner    - DefaultDispatcherRunner was granted leadership with leader id 3a82a6ce-fb62-4610-b46c-7fb86bd673d4. Creating new DispatcherLeaderProcess.
INFO  - ionDispatcherLeaderProcess - Start SessionDispatcherLeaderProcess.
INFO  - FileSystemJobResultStore   - Creating highly available job result storage directory at /tmp/flink/ha/job-result-store/default
INFO  - ResourceManagerServiceImpl - Resource manager service is granted leadership with session id 3a82a6ce-fb62-4610-b46c-7fb86bd673d4.
INFO  - FileSystemJobResultStore   - Created highly available job result storage directory at /tmp/flink/ha/job-result-store/default
INFO  - ionDispatcherLeaderProcess - Recover all persisted job graphs that are not finished, yet.
INFO  - DefaultJobGraphStore       - Retrieved job ids [] from ZooKeeperStateHandleStore{namespace='flink/default/jobgraphs'}
INFO  - ionDispatcherLeaderProcess - Successfully recovered 0 persisted job graphs.
INFO  - AkkaRpcService             - Starting RPC endpoint for org.apache.flink.runtime.resourcemanager.StandaloneResourceManager at akka://flink/user/rpc/resourcemanager_1 .
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - AkkaRpcService             - Starting RPC endpoint for org.apache.flink.runtime.dispatcher.StandaloneDispatcher at akka://flink/user/rpc/dispatcher_2 .
INFO  - StandaloneResourceManager  - Starting the resource manager.
INFO  - aultDelegationTokenManager - Starting tokens update task
WARN  - aultDelegationTokenManager - No tokens obtained so skipping notifications
WARN  - aultDelegationTokenManager - Tokens update task not started because either no tokens obtained or none of the tokens specified its renewal date
INFO  - TaskExecutor               - Connecting to ResourceManager akka://flink/user/rpc/resourcemanager_1(b46c7fb86bd673d43a82a6cefb624610).
INFO  - TaskExecutor               - Resolved ResourceManager address, beginning registration
INFO  - StandaloneResourceManager  - Registering TaskManager with ResourceID 586b9eac-aa0b-41ab-ae70-a614854e7a0e (akka://flink/user/rpc/taskmanager_0) at ResourceManager
INFO  - TaskExecutor               - Successful registration at resource manager akka://flink/user/rpc/resourcemanager_1 under registration id 43a2b9639a4eed3af09e10b5321c6277.
INFO  - AbstractJdbcCatalog        - Catalog analytics established connection to jdbc:postgresql://localhost:5432/analytics
WARN  - Configuration              - Config uses deprecated configuration key 'high-availability' instead of proper key 'high-availability.type'
INFO  - ZooKeeperUtils             - Enforcing default ACL for ZK connections
INFO  - ZooKeeperUtils             - Using '/flink/default' as Zookeeper namespace.
INFO  - CuratorFrameworkImpl       - Starting
INFO  - ZooKeeper                  - Initiating client connection, connectString=localhost:2181 sessionTimeout=60000 watcher=org.apache.flink.shaded.curator5.org.apache.curator.ConnectionState@6fde4f4f
INFO  - ClientCnxnSocket           - jute.maxbuffer value is 1048575 Bytes
INFO  - ClientCnxn                 - zookeeper.request.timeout value is 0. feature enabled=false
INFO  - CuratorFrameworkImpl       - Default schema
INFO  - aultLeaderRetrievalService - Starting DefaultLeaderRetrievalService with ZookeeperLeaderRetrievalDriver{connectionInformationPath='/leader/rest_server/connection_info'}.
INFO  - ClientCnxn                 - Opening socket connection to server localhost/127.0.0.1:2181.
INFO  - ClientCnxn                 - SASL config status: Will not attempt to authenticate using SASL (unknown error)
INFO  - ClientCnxn                 - Socket connection established, initiating session, client: /127.0.0.1:52180, server: localhost/127.0.0.1:2181
INFO  - RestClusterClient          - Submitting job 'insert-into_analytics.analytics.appointments' (30b4315f4dce6b8b0d1d34062dbea1c2).
INFO  - ClientCnxn                 - Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x10009b90d4f0001, negotiated timeout = 40000
INFO  - ConnectionStateManager     - State change: CONNECTED
INFO  - EnsembleTracker            - New config event received: {}
INFO  - EnsembleTracker            - New config event received: {}
INFO  - StandaloneDispatcher       - Received JobGraph submission 'insert-into_analytics.analytics.appointments' (30b4315f4dce6b8b0d1d34062dbea1c2).
INFO  - StandaloneDispatcher       - Submitting job 'insert-into_analytics.analytics.appointments' (30b4315f4dce6b8b0d1d34062dbea1c2).
INFO  - DefaultJobGraphStore       - Added JobGraph(jobId: 30b4315f4dce6b8b0d1d34062dbea1c2) to ZooKeeperStateHandleStore{namespace='flink/default/jobgraphs'}.
INFO  - faultLeaderElectionService - Starting DefaultLeaderElectionService with org.apache.flink.runtime.leaderelection.MultipleComponentLeaderElectionDriverAdapter@44fd1b4c.
INFO  - terServiceLeadershipRunner - JobMasterServiceLeadershipRunner for job 30b4315f4dce6b8b0d1d34062dbea1c2 was granted leadership with leader id 3a82a6ce-fb62-4610-b46c-7fb86bd673d4. Creating new JobMasterServiceProcess.
INFO  - AkkaRpcService             - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/rpc/jobmanager_3 .
INFO  - RestClusterClient          - Successfully submitted job 'insert-into_analytics.analytics.appointments' (30b4315f4dce6b8b0d1d34062dbea1c2) to 'http://localhost:8081'.
INFO  - JobMaster                  - Initializing job 'insert-into_analytics.analytics.appointments' (30b4315f4dce6b8b0d1d34062dbea1c2).
INFO  - JobMaster                  - Using restart back off time strategy ExponentialDelayRestartBackoffTimeStrategy(initialBackoffMS=1000, maxBackoffMS=300000, backoffMultiplier=2.0, resetBackoffThresholdMS=3600000, jitterFactor=0.1, currentBackoffMS=1000, lastFailureTimestamp=0) for insert-into_analytics.analytics.appointments (30b4315f4dce6b8b0d1d34062dbea1c2).
INFO  - pletedCheckpointStoreUtils - Recovering checkpoints from ZooKeeperStateHandleStore{namespace='flink/default/jobs/30b4315f4dce6b8b0d1d34062dbea1c2/checkpoints'}.
INFO  - pletedCheckpointStoreUtils - Found 0 checkpoints in ZooKeeperStateHandleStore{namespace='flink/default/jobs/30b4315f4dce6b8b0d1d34062dbea1c2/checkpoints'}.
INFO  - pletedCheckpointStoreUtils - Trying to fetch 0 checkpoints from storage.
INFO  - ZooKeeperUtils             - Initialized DefaultCompletedCheckpointStore in 'ZooKeeperStateHandleStore{namespace='flink/default/jobs/30b4315f4dce6b8b0d1d34062dbea1c2/checkpoints'}' with /checkpoints.
INFO  - ExecutionGraph             - Created execution graph 5d2b85ced63db2be7a46b4ce2f567a3c for job 30b4315f4dce6b8b0d1d34062dbea1c2.
INFO  - JobMaster                  - Running initialization on master for job insert-into_analytics.analytics.appointments (30b4315f4dce6b8b0d1d34062dbea1c2).
INFO  - JobMaster                  - Successfully ran initialization on master in 0 ms.
INFO  - DefaultExecutionTopology   - Built 1 new pipelined regions in 0 ms, total 1 pipelined regions currently.
INFO  - JobMaster                  - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - JobMaster                  - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - JobMaster                  - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - CheckpointCoordinator      - No checkpoint found during restore.
INFO  - JobMaster                  - Using failover strategy org.apache.flink.runtime.executiongraph.failover.flip1.RestartPipelinedRegionFailoverStrategy@567fc184 for insert-into_analytics.analytics.appointments (30b4315f4dce6b8b0d1d34062dbea1c2).
INFO  - aultLeaderRetrievalService - Starting DefaultLeaderRetrievalService with ZookeeperLeaderRetrievalDriver{connectionInformationPath='/resource_manager/connection_info'}.
INFO  - JobMaster                  - Starting execution of job 'insert-into_analytics.analytics.appointments' (30b4315f4dce6b8b0d1d34062dbea1c2) under job master id b46c7fb86bd673d43a82a6cefb624610.
INFO  - SourceCoordinator          - Starting split enumerator for source Source: patient_appointment[1].
INFO  - SourceCoordinator          - Starting split enumerator for source Source: patient_appointment_provider[15].
INFO  - SourceCoordinator          - Starting split enumerator for source Source: appointment_service[4].
INFO  - SourceCoordinator          - Starting split enumerator for source Source: appointment_service_type[9].
INFO  - JobMaster                  - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
INFO  - ExecutionGraph             - Job insert-into_analytics.analytics.appointments (30b4315f4dce6b8b0d1d34062dbea1c2) switched from state CREATED to RUNNING.
INFO  - ExecutionGraph             - Source: patient_appointment[1] -> Calc[2] (1/1) (5d2b85ced63db2be7a46b4ce2f567a3c_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to SCHEDULED.
INFO  - ExecutionGraph             - Source: appointment_service[4] -> Calc[5] (1/1) (5d2b85ced63db2be7a46b4ce2f567a3c_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) switched from CREATED to SCHEDULED.
INFO  - ExecutionGraph             - Source: appointment_service_type[9] -> Calc[10] (1/1) (5d2b85ced63db2be7a46b4ce2f567a3c_2963852293169ba90d9d1e7d6308db5c_0_0) switched from CREATED to SCHEDULED.
INFO  - ExecutionGraph             - Source: patient_appointment_provider[15] -> Calc[16] (1/1) (5d2b85ced63db2be7a46b4ce2f567a3c_1171dea6747ab509fdaefbe74f7195af_0_0) switched from CREATED to SCHEDULED.
INFO  - ExecutionGraph             - Join[7] (1/1) (5d2b85ced63db2be7a46b4ce2f567a3c_5caeaa5e379e7348564aaaaf5ae0d6a6_0_0) switched from CREATED to SCHEDULED.
INFO  - ExecutionGraph             - Join[12] -> Calc[13] (1/1) (5d2b85ced63db2be7a46b4ce2f567a3c_ccd2f3173f602e66f6767720952cb258_0_0) switched from CREATED to SCHEDULED.
INFO  - ExecutionGraph             - Join[18] -> Calc[19] -> ConstraintEnforcer[20] (1/1) (5d2b85ced63db2be7a46b4ce2f567a3c_23e521ac8efce918f328250afebbe45c_0_0) switched from CREATED to SCHEDULED.
INFO  - ExecutionGraph             - SinkMaterializer[20] -> Sink: appointments[20] (1/1) (5d2b85ced63db2be7a46b4ce2f567a3c_fd907ffb7425150fb379978eab0e6d37_0_0) switched from CREATED to SCHEDULED.
INFO  - JobMaster                  - Connecting to ResourceManager akka://flink/user/rpc/resourcemanager_1(b46c7fb86bd673d43a82a6cefb624610)
INFO  - AdminClientConfig          - AdminClientConfig values: 
	bootstrap.servers = [localhost:29092]
	client.dns.lookup = use_all_dns_ips
	client.id = flink-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

INFO  - AdminClientConfig          - AdminClientConfig values: 
	bootstrap.servers = [localhost:29092]
	client.dns.lookup = use_all_dns_ips
	client.id = flink-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

INFO  - AdminClientConfig          - AdminClientConfig values: 
	bootstrap.servers = [localhost:29092]
	client.dns.lookup = use_all_dns_ips
	client.id = flink-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

INFO  - JobMaster                  - Resolved ResourceManager address, beginning registration
INFO  - AdminClientConfig          - AdminClientConfig values: 
	bootstrap.servers = [localhost:29092]
	client.dns.lookup = use_all_dns_ips
	client.id = flink-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

INFO  - aultLeaderRetrievalService - Starting DefaultLeaderRetrievalService with ZookeeperLeaderRetrievalDriver{connectionInformationPath='/30b4315f4dce6b8b0d1d34062dbea1c2/connection_info'}.
INFO  - StandaloneResourceManager  - Registering job manager b46c7fb86bd673d43a82a6cefb624610@akka://flink/user/rpc/jobmanager_3 for job 30b4315f4dce6b8b0d1d34062dbea1c2.
INFO  - StandaloneResourceManager  - Registered job manager b46c7fb86bd673d43a82a6cefb624610@akka://flink/user/rpc/jobmanager_3 for job 30b4315f4dce6b8b0d1d34062dbea1c2.
INFO  - JobMaster                  - JobManager successfully registered at ResourceManager, leader id: b46c7fb86bd673d43a82a6cefb624610.
INFO  - DeclarativeSlotManager     - Received resource requirements from job 30b4315f4dce6b8b0d1d34062dbea1c2: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
WARN  - AdminClientConfig          - The configuration 'key.deserializer' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'key.deserializer' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'value.deserializer' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'key.deserializer' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'key.deserializer' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'value.deserializer' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'enable.auto.commit' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'value.deserializer' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'client.id.prefix' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'enable.auto.commit' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'value.deserializer' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'client.id.prefix' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'group.id' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'enable.auto.commit' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'group.id' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'enable.auto.commit' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'auto.offset.reset' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'client.id.prefix' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'group.id' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'auto.offset.reset' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'auto.offset.reset' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'client.id.prefix' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'group.id' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'auto.offset.reset' was supplied but isn't a known config.
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290629617
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - KafkaSourceEnumerator      - Starting the KafkaSourceEnumerator for consumer group flink without periodic partition discovery.
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290629617
WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.admin.client:type=app-info,id=flink-enumerator-admin-client
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.admin.KafkaAdminClient.<init>(KafkaAdminClient.java:597)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:539)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:478)
	at org.apache.kafka.clients.admin.Admin.create(Admin.java:133)
	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getKafkaAdminClient(KafkaSourceEnumerator.java:410)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.start(KafkaSourceEnumerator.java:151)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$start$1(SourceCoordinator.java:234)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$runInEventLoop$10(SourceCoordinator.java:458)
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290629617
INFO  - KafkaSourceEnumerator      - Starting the KafkaSourceEnumerator for consumer group flink without periodic partition discovery.
WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.admin.client:type=app-info,id=flink-enumerator-admin-client
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.admin.KafkaAdminClient.<init>(KafkaAdminClient.java:597)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:539)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:478)
	at org.apache.kafka.clients.admin.Admin.create(Admin.java:133)
	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getKafkaAdminClient(KafkaSourceEnumerator.java:410)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.start(KafkaSourceEnumerator.java:151)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$start$1(SourceCoordinator.java:234)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$runInEventLoop$10(SourceCoordinator.java:458)
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290629617
INFO  - KafkaSourceEnumerator      - Starting the KafkaSourceEnumerator for consumer group flink without periodic partition discovery.
WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.admin.client:type=app-info,id=flink-enumerator-admin-client
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.admin.KafkaAdminClient.<init>(KafkaAdminClient.java:597)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:539)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:478)
	at org.apache.kafka.clients.admin.Admin.create(Admin.java:133)
	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getKafkaAdminClient(KafkaSourceEnumerator.java:410)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.start(KafkaSourceEnumerator.java:151)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$start$1(SourceCoordinator.java:234)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$runInEventLoop$10(SourceCoordinator.java:458)
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
INFO  - KafkaSourceEnumerator      - Starting the KafkaSourceEnumerator for consumer group flink without periodic partition discovery.
INFO  - TaskExecutor               - Receive slot request cbd7a528c6d242da5dd3ec1eeb9e3f8a for job 30b4315f4dce6b8b0d1d34062dbea1c2 from resource manager with leader id b46c7fb86bd673d43a82a6cefb624610.
INFO  - TaskExecutor               - Allocated slot for cbd7a528c6d242da5dd3ec1eeb9e3f8a.
INFO  - DefaultJobLeaderService    - Add job 30b4315f4dce6b8b0d1d34062dbea1c2 for job leader monitoring.
INFO  - aultLeaderRetrievalService - Starting DefaultLeaderRetrievalService with ZookeeperLeaderRetrievalDriver{connectionInformationPath='/30b4315f4dce6b8b0d1d34062dbea1c2/connection_info'}.
INFO  - DefaultJobLeaderService    - Try to register at job manager akka://flink/user/rpc/jobmanager_3 with leader id 3a82a6ce-fb62-4610-b46c-7fb86bd673d4.
INFO  - DefaultJobLeaderService    - Resolved JobManager address, beginning registration
INFO  - DefaultJobLeaderService    - Successful registration at job manager akka://flink/user/rpc/jobmanager_3 for job 30b4315f4dce6b8b0d1d34062dbea1c2.
INFO  - TaskExecutor               - Establish JobManager connection for job 30b4315f4dce6b8b0d1d34062dbea1c2.
INFO  - TaskExecutor               - Offer reserved slots to the leader of job 30b4315f4dce6b8b0d1d34062dbea1c2.
INFO  - ExecutionGraph             - Source: patient_appointment[1] -> Calc[2] (1/1) (5d2b85ced63db2be7a46b4ce2f567a3c_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - ExecutionGraph             - Deploying Source: patient_appointment[1] -> Calc[2] (1/1) (attempt #0) with attempt id 5d2b85ced63db2be7a46b4ce2f567a3c_cbc357ccb763df2852fee8c4fc7d55f2_0_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id cbd7a528c6d242da5dd3ec1eeb9e3f8a
INFO  - ExecutionGraph             - Source: appointment_service[4] -> Calc[5] (1/1) (5d2b85ced63db2be7a46b4ce2f567a3c_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - ExecutionGraph             - Deploying Source: appointment_service[4] -> Calc[5] (1/1) (attempt #0) with attempt id 5d2b85ced63db2be7a46b4ce2f567a3c_6cdc5bb954874d922eaee11a8e7b5dd5_0_0 and vertex id 6cdc5bb954874d922eaee11a8e7b5dd5_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id cbd7a528c6d242da5dd3ec1eeb9e3f8a
INFO  - TaskSlotTableImpl          - Activate slot cbd7a528c6d242da5dd3ec1eeb9e3f8a.
INFO  - ExecutionGraph             - Source: appointment_service_type[9] -> Calc[10] (1/1) (5d2b85ced63db2be7a46b4ce2f567a3c_2963852293169ba90d9d1e7d6308db5c_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - ExecutionGraph             - Deploying Source: appointment_service_type[9] -> Calc[10] (1/1) (attempt #0) with attempt id 5d2b85ced63db2be7a46b4ce2f567a3c_2963852293169ba90d9d1e7d6308db5c_0_0 and vertex id 2963852293169ba90d9d1e7d6308db5c_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id cbd7a528c6d242da5dd3ec1eeb9e3f8a
INFO  - ExecutionGraph             - Source: patient_appointment_provider[15] -> Calc[16] (1/1) (5d2b85ced63db2be7a46b4ce2f567a3c_1171dea6747ab509fdaefbe74f7195af_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - ExecutionGraph             - Deploying Source: patient_appointment_provider[15] -> Calc[16] (1/1) (attempt #0) with attempt id 5d2b85ced63db2be7a46b4ce2f567a3c_1171dea6747ab509fdaefbe74f7195af_0_0 and vertex id 1171dea6747ab509fdaefbe74f7195af_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id cbd7a528c6d242da5dd3ec1eeb9e3f8a
INFO  - ExecutionGraph             - Join[7] (1/1) (5d2b85ced63db2be7a46b4ce2f567a3c_5caeaa5e379e7348564aaaaf5ae0d6a6_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - ExecutionGraph             - Deploying Join[7] (1/1) (attempt #0) with attempt id 5d2b85ced63db2be7a46b4ce2f567a3c_5caeaa5e379e7348564aaaaf5ae0d6a6_0_0 and vertex id 5caeaa5e379e7348564aaaaf5ae0d6a6_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id cbd7a528c6d242da5dd3ec1eeb9e3f8a
INFO  - ExecutionGraph             - Join[12] -> Calc[13] (1/1) (5d2b85ced63db2be7a46b4ce2f567a3c_ccd2f3173f602e66f6767720952cb258_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - ExecutionGraph             - Deploying Join[12] -> Calc[13] (1/1) (attempt #0) with attempt id 5d2b85ced63db2be7a46b4ce2f567a3c_ccd2f3173f602e66f6767720952cb258_0_0 and vertex id ccd2f3173f602e66f6767720952cb258_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id cbd7a528c6d242da5dd3ec1eeb9e3f8a
INFO  - ExecutionGraph             - Join[18] -> Calc[19] -> ConstraintEnforcer[20] (1/1) (5d2b85ced63db2be7a46b4ce2f567a3c_23e521ac8efce918f328250afebbe45c_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - ExecutionGraph             - Deploying Join[18] -> Calc[19] -> ConstraintEnforcer[20] (1/1) (attempt #0) with attempt id 5d2b85ced63db2be7a46b4ce2f567a3c_23e521ac8efce918f328250afebbe45c_0_0 and vertex id 23e521ac8efce918f328250afebbe45c_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id cbd7a528c6d242da5dd3ec1eeb9e3f8a
INFO  - ExecutionGraph             - SinkMaterializer[20] -> Sink: appointments[20] (1/1) (5d2b85ced63db2be7a46b4ce2f567a3c_fd907ffb7425150fb379978eab0e6d37_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - ExecutionGraph             - Deploying SinkMaterializer[20] -> Sink: appointments[20] (1/1) (attempt #0) with attempt id 5d2b85ced63db2be7a46b4ce2f567a3c_fd907ffb7425150fb379978eab0e6d37_0_0 and vertex id fd907ffb7425150fb379978eab0e6d37_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id cbd7a528c6d242da5dd3ec1eeb9e3f8a
INFO  - tateChangelogStorageLoader - StateChangelogStorageLoader initialized with shortcut names {memory}.
INFO  - tateChangelogStorageLoader - Creating a changelog storage with name 'memory'.
INFO  - tateExecutorFactoryManager - Creating the channel state executor factory for job id 30b4315f4dce6b8b0d1d34062dbea1c2
INFO  - TaskExecutor               - Received task Source: patient_appointment[1] -> Calc[2] (1/1)#0 (5d2b85ced63db2be7a46b4ce2f567a3c_cbc357ccb763df2852fee8c4fc7d55f2_0_0), deploy into slot with allocation id cbd7a528c6d242da5dd3ec1eeb9e3f8a.
INFO  - Task                       - Source: patient_appointment[1] -> Calc[2] (1/1)#0 (5d2b85ced63db2be7a46b4ce2f567a3c_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to DEPLOYING.
INFO  - Task                       - Loading JAR files for task Source: patient_appointment[1] -> Calc[2] (1/1)#0 (5d2b85ced63db2be7a46b4ce2f567a3c_cbc357ccb763df2852fee8c4fc7d55f2_0_0) [DEPLOYING].
INFO  - TaskSlotTableImpl          - Activate slot cbd7a528c6d242da5dd3ec1eeb9e3f8a.
INFO  - TaskExecutor               - Received task Source: appointment_service[4] -> Calc[5] (1/1)#0 (5d2b85ced63db2be7a46b4ce2f567a3c_6cdc5bb954874d922eaee11a8e7b5dd5_0_0), deploy into slot with allocation id cbd7a528c6d242da5dd3ec1eeb9e3f8a.
INFO  - Task                       - Source: appointment_service[4] -> Calc[5] (1/1)#0 (5d2b85ced63db2be7a46b4ce2f567a3c_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) switched from CREATED to DEPLOYING.
INFO  - Task                       - Loading JAR files for task Source: appointment_service[4] -> Calc[5] (1/1)#0 (5d2b85ced63db2be7a46b4ce2f567a3c_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) [DEPLOYING].
INFO  - TaskSlotTableImpl          - Activate slot cbd7a528c6d242da5dd3ec1eeb9e3f8a.
INFO  - TaskExecutor               - Received task Source: appointment_service_type[9] -> Calc[10] (1/1)#0 (5d2b85ced63db2be7a46b4ce2f567a3c_2963852293169ba90d9d1e7d6308db5c_0_0), deploy into slot with allocation id cbd7a528c6d242da5dd3ec1eeb9e3f8a.
INFO  - Task                       - Source: appointment_service_type[9] -> Calc[10] (1/1)#0 (5d2b85ced63db2be7a46b4ce2f567a3c_2963852293169ba90d9d1e7d6308db5c_0_0) switched from CREATED to DEPLOYING.
INFO  - Task                       - Loading JAR files for task Source: appointment_service_type[9] -> Calc[10] (1/1)#0 (5d2b85ced63db2be7a46b4ce2f567a3c_2963852293169ba90d9d1e7d6308db5c_0_0) [DEPLOYING].
INFO  - TaskSlotTableImpl          - Activate slot cbd7a528c6d242da5dd3ec1eeb9e3f8a.
INFO  - TaskExecutor               - Received task Source: patient_appointment_provider[15] -> Calc[16] (1/1)#0 (5d2b85ced63db2be7a46b4ce2f567a3c_1171dea6747ab509fdaefbe74f7195af_0_0), deploy into slot with allocation id cbd7a528c6d242da5dd3ec1eeb9e3f8a.
INFO  - Task                       - Source: patient_appointment_provider[15] -> Calc[16] (1/1)#0 (5d2b85ced63db2be7a46b4ce2f567a3c_1171dea6747ab509fdaefbe74f7195af_0_0) switched from CREATED to DEPLOYING.
INFO  - Task                       - Loading JAR files for task Source: patient_appointment_provider[15] -> Calc[16] (1/1)#0 (5d2b85ced63db2be7a46b4ce2f567a3c_1171dea6747ab509fdaefbe74f7195af_0_0) [DEPLOYING].
INFO  - TaskSlotTableImpl          - Activate slot cbd7a528c6d242da5dd3ec1eeb9e3f8a.
INFO  - TaskExecutor               - Received task Join[7] (1/1)#0 (5d2b85ced63db2be7a46b4ce2f567a3c_5caeaa5e379e7348564aaaaf5ae0d6a6_0_0), deploy into slot with allocation id cbd7a528c6d242da5dd3ec1eeb9e3f8a.
INFO  - Task                       - Join[7] (1/1)#0 (5d2b85ced63db2be7a46b4ce2f567a3c_5caeaa5e379e7348564aaaaf5ae0d6a6_0_0) switched from CREATED to DEPLOYING.
INFO  - Task                       - Loading JAR files for task Join[7] (1/1)#0 (5d2b85ced63db2be7a46b4ce2f567a3c_5caeaa5e379e7348564aaaaf5ae0d6a6_0_0) [DEPLOYING].
INFO  - TaskSlotTableImpl          - Activate slot cbd7a528c6d242da5dd3ec1eeb9e3f8a.
INFO  - TaskExecutor               - Received task Join[12] -> Calc[13] (1/1)#0 (5d2b85ced63db2be7a46b4ce2f567a3c_ccd2f3173f602e66f6767720952cb258_0_0), deploy into slot with allocation id cbd7a528c6d242da5dd3ec1eeb9e3f8a.
INFO  - Task                       - Join[12] -> Calc[13] (1/1)#0 (5d2b85ced63db2be7a46b4ce2f567a3c_ccd2f3173f602e66f6767720952cb258_0_0) switched from CREATED to DEPLOYING.
INFO  - Task                       - Loading JAR files for task Join[12] -> Calc[13] (1/1)#0 (5d2b85ced63db2be7a46b4ce2f567a3c_ccd2f3173f602e66f6767720952cb258_0_0) [DEPLOYING].
INFO  - TaskSlotTableImpl          - Activate slot cbd7a528c6d242da5dd3ec1eeb9e3f8a.
INFO  - TaskExecutor               - Received task Join[18] -> Calc[19] -> ConstraintEnforcer[20] (1/1)#0 (5d2b85ced63db2be7a46b4ce2f567a3c_23e521ac8efce918f328250afebbe45c_0_0), deploy into slot with allocation id cbd7a528c6d242da5dd3ec1eeb9e3f8a.
INFO  - TaskSlotTableImpl          - Activate slot cbd7a528c6d242da5dd3ec1eeb9e3f8a.
INFO  - Task                       - Join[18] -> Calc[19] -> ConstraintEnforcer[20] (1/1)#0 (5d2b85ced63db2be7a46b4ce2f567a3c_23e521ac8efce918f328250afebbe45c_0_0) switched from CREATED to DEPLOYING.
INFO  - Task                       - Loading JAR files for task Join[18] -> Calc[19] -> ConstraintEnforcer[20] (1/1)#0 (5d2b85ced63db2be7a46b4ce2f567a3c_23e521ac8efce918f328250afebbe45c_0_0) [DEPLOYING].
INFO  - TaskExecutor               - Received task SinkMaterializer[20] -> Sink: appointments[20] (1/1)#0 (5d2b85ced63db2be7a46b4ce2f567a3c_fd907ffb7425150fb379978eab0e6d37_0_0), deploy into slot with allocation id cbd7a528c6d242da5dd3ec1eeb9e3f8a.
INFO  - Task                       - SinkMaterializer[20] -> Sink: appointments[20] (1/1)#0 (5d2b85ced63db2be7a46b4ce2f567a3c_fd907ffb7425150fb379978eab0e6d37_0_0) switched from CREATED to DEPLOYING.
INFO  - Task                       - Loading JAR files for task SinkMaterializer[20] -> Sink: appointments[20] (1/1)#0 (5d2b85ced63db2be7a46b4ce2f567a3c_fd907ffb7425150fb379978eab0e6d37_0_0) [DEPLOYING].
INFO  - TaskSlotTableImpl          - Activate slot cbd7a528c6d242da5dd3ec1eeb9e3f8a.
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - Task                       - Source: patient_appointment_provider[15] -> Calc[16] (1/1)#0 (5d2b85ced63db2be7a46b4ce2f567a3c_1171dea6747ab509fdaefbe74f7195af_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - Task                       - Source: appointment_service[4] -> Calc[5] (1/1)#0 (5d2b85ced63db2be7a46b4ce2f567a3c_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - Task                       - Source: patient_appointment[1] -> Calc[2] (1/1)#0 (5d2b85ced63db2be7a46b4ce2f567a3c_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - Task                       - Source: appointment_service_type[9] -> Calc[10] (1/1)#0 (5d2b85ced63db2be7a46b4ce2f567a3c_2963852293169ba90d9d1e7d6308db5c_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - Task                       - SinkMaterializer[20] -> Sink: appointments[20] (1/1)#0 (5d2b85ced63db2be7a46b4ce2f567a3c_fd907ffb7425150fb379978eab0e6d37_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - Task                       - Join[18] -> Calc[19] -> ConstraintEnforcer[20] (1/1)#0 (5d2b85ced63db2be7a46b4ce2f567a3c_23e521ac8efce918f328250afebbe45c_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - Task                       - Join[7] (1/1)#0 (5d2b85ced63db2be7a46b4ce2f567a3c_5caeaa5e379e7348564aaaaf5ae0d6a6_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - Task                       - Join[12] -> Calc[13] (1/1)#0 (5d2b85ced63db2be7a46b4ce2f567a3c_ccd2f3173f602e66f6767720952cb258_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - ExecutionGraph             - Source: patient_appointment_provider[15] -> Calc[16] (1/1) (5d2b85ced63db2be7a46b4ce2f567a3c_1171dea6747ab509fdaefbe74f7195af_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - ExecutionGraph             - Source: appointment_service[4] -> Calc[5] (1/1) (5d2b85ced63db2be7a46b4ce2f567a3c_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - ExecutionGraph             - Source: patient_appointment[1] -> Calc[2] (1/1) (5d2b85ced63db2be7a46b4ce2f567a3c_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - ExecutionGraph             - Source: appointment_service_type[9] -> Calc[10] (1/1) (5d2b85ced63db2be7a46b4ce2f567a3c_2963852293169ba90d9d1e7d6308db5c_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - ExecutionGraph             - SinkMaterializer[20] -> Sink: appointments[20] (1/1) (5d2b85ced63db2be7a46b4ce2f567a3c_fd907ffb7425150fb379978eab0e6d37_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - ExecutionGraph             - Join[18] -> Calc[19] -> ConstraintEnforcer[20] (1/1) (5d2b85ced63db2be7a46b4ce2f567a3c_23e521ac8efce918f328250afebbe45c_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - ExecutionGraph             - Join[7] (1/1) (5d2b85ced63db2be7a46b4ce2f567a3c_5caeaa5e379e7348564aaaaf5ae0d6a6_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - ExecutionGraph             - Join[12] -> Calc[13] (1/1) (5d2b85ced63db2be7a46b4ce2f567a3c_ccd2f3173f602e66f6767720952cb258_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - aultLeaderRetrievalService - Stopping DefaultLeaderRetrievalService.
INFO  - eeperLeaderRetrievalDriver - Closing ZookeeperLeaderRetrievalDriver{connectionInformationPath='/leader/rest_server/connection_info'}.
INFO  - CuratorFrameworkImpl       - backgroundOperationsLoop exiting
INFO  - mbeddedRocksDBStateBackend - Attempting to load RocksDB native library and store it under '/tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp'
INFO  - SourceCoordinator          - Source Source: appointment_service[4] registering reader for parallel task 0 (#0) @ 
INFO  - SourceCoordinator          - Source Source: patient_appointment[1] registering reader for parallel task 0 (#0) @ 
INFO  - SourceCoordinator          - Source Source: appointment_service_type[9] registering reader for parallel task 0 (#0) @ 
INFO  - SourceCoordinator          - Source Source: patient_appointment_provider[15] registering reader for parallel task 0 (#0) @ 
INFO  - Task                       - Source: patient_appointment_provider[15] -> Calc[16] (1/1)#0 (5d2b85ced63db2be7a46b4ce2f567a3c_1171dea6747ab509fdaefbe74f7195af_0_0) switched from INITIALIZING to RUNNING.
INFO  - Task                       - Source: appointment_service_type[9] -> Calc[10] (1/1)#0 (5d2b85ced63db2be7a46b4ce2f567a3c_2963852293169ba90d9d1e7d6308db5c_0_0) switched from INITIALIZING to RUNNING.
INFO  - Task                       - Source: patient_appointment[1] -> Calc[2] (1/1)#0 (5d2b85ced63db2be7a46b4ce2f567a3c_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
INFO  - Task                       - Source: appointment_service[4] -> Calc[5] (1/1)#0 (5d2b85ced63db2be7a46b4ce2f567a3c_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) switched from INITIALIZING to RUNNING.
INFO  - ExecutionGraph             - Source: appointment_service_type[9] -> Calc[10] (1/1) (5d2b85ced63db2be7a46b4ce2f567a3c_2963852293169ba90d9d1e7d6308db5c_0_0) switched from INITIALIZING to RUNNING.
INFO  - ExecutionGraph             - Source: patient_appointment_provider[15] -> Calc[16] (1/1) (5d2b85ced63db2be7a46b4ce2f567a3c_1171dea6747ab509fdaefbe74f7195af_0_0) switched from INITIALIZING to RUNNING.
INFO  - ExecutionGraph             - Source: patient_appointment[1] -> Calc[2] (1/1) (5d2b85ced63db2be7a46b4ce2f567a3c_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
INFO  - ExecutionGraph             - Source: appointment_service[4] -> Calc[5] (1/1) (5d2b85ced63db2be7a46b4ce2f567a3c_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) switched from INITIALIZING to RUNNING.
INFO  - ZooKeeper                  - Session: 0x10009b90d4f0001 closed
INFO  - ClientCnxn                 - EventThread shut down for session: 0x10009b90d4f0001
INFO  - KafkaSourceEnumerator      - Discovered new partitions: [openmrs.openmrs.appointment_service_type-0]
INFO  - KafkaSourceEnumerator      - Discovered new partitions: [openmrs.openmrs.appointment_service-0]
INFO  - KafkaSourceEnumerator      - Discovered new partitions: [openmrs.openmrs.patient_appointment_provider-0]
INFO  - KafkaSourceEnumerator      - Discovered new partitions: [openmrs.openmrs.patient_appointment-0]
INFO  - KafkaSourceEnumerator      - Assigning splits to readers {0=[[Partition: openmrs.openmrs.patient_appointment_provider-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}
INFO  - KafkaSourceEnumerator      - Assigning splits to readers {0=[[Partition: openmrs.openmrs.appointment_service-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}
INFO  - KafkaSourceEnumerator      - Assigning splits to readers {0=[[Partition: openmrs.openmrs.appointment_service_type-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}
INFO  - KafkaSourceEnumerator      - Assigning splits to readers {0=[[Partition: openmrs.openmrs.patient_appointment-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}
INFO  - SourceReaderBase           - Adding split(s) to reader: [[Partition: openmrs.openmrs.appointment_service_type-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]
INFO  - SourceReaderBase           - Adding split(s) to reader: [[Partition: openmrs.openmrs.patient_appointment_provider-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]
INFO  - SourceReaderBase           - Adding split(s) to reader: [[Partition: openmrs.openmrs.appointment_service-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]
INFO  - SourceReaderBase           - Adding split(s) to reader: [[Partition: openmrs.openmrs.patient_appointment-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]
INFO  - ConsumerConfig             - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = flink-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

INFO  - ConsumerConfig             - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = flink-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

INFO  - ConsumerConfig             - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = flink-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

INFO  - ConsumerConfig             - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = flink-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

WARN  - ConsumerConfig             - The configuration 'client.id.prefix' was supplied but isn't a known config.
WARN  - ConsumerConfig             - The configuration 'client.id.prefix' was supplied but isn't a known config.
WARN  - ConsumerConfig             - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
WARN  - ConsumerConfig             - The configuration 'client.id.prefix' was supplied but isn't a known config.
INFO  - AppInfoParser              - Kafka version: 3.2.3
WARN  - ConsumerConfig             - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
WARN  - ConsumerConfig             - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
WARN  - ConsumerConfig             - The configuration 'client.id.prefix' was supplied but isn't a known config.
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290629936
WARN  - ConsumerConfig             - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290629937
WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.consumer:type=app-info,id=flink-0
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:816)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:666)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:647)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:627)
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.<init>(KafkaPartitionSplitReader.java:88)
	at org.apache.flink.connector.kafka.source.KafkaSource.lambda$createReader$1(KafkaSource.java:160)
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager.createSplitFetcher(SplitFetcherManager.java:196)
	at org.apache.flink.connector.base.source.reader.fetcher.SingleThreadFetcherManager.addSplits(SingleThreadFetcherManager.java:107)
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.addSplits(SourceReaderBase.java:242)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleAddSplitsEvent(SourceOperator.java:584)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleOperatorEvent(SourceOperator.java:561)
	at org.apache.flink.streaming.runtime.tasks.OperatorEventDispatcherImpl.dispatchEventToHandlers(OperatorEventDispatcherImpl.java:72)
	at org.apache.flink.streaming.runtime.tasks.RegularOperatorChain.dispatchOperatorEvent(RegularOperatorChain.java:80)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$dispatchOperatorEvent$20(StreamTask.java:1473)
	at org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$1.runThrowing(StreamTaskActionExecutor.java:50)
	at org.apache.flink.streaming.runtime.tasks.mailbox.Mail.run(Mail.java:90)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMail(MailboxProcessor.java:398)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMailsWhenDefaultActionUnavailable(MailboxProcessor.java:367)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMail(MailboxProcessor.java:352)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:229)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:839)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:788)
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:952)
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:931)
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:745)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:562)
	at java.base/java.lang.Thread.run(Thread.java:829)
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290629937
WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.consumer:type=app-info,id=flink-0
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:816)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:666)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:647)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:627)
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.<init>(KafkaPartitionSplitReader.java:88)
	at org.apache.flink.connector.kafka.source.KafkaSource.lambda$createReader$1(KafkaSource.java:160)
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager.createSplitFetcher(SplitFetcherManager.java:196)
	at org.apache.flink.connector.base.source.reader.fetcher.SingleThreadFetcherManager.addSplits(SingleThreadFetcherManager.java:107)
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.addSplits(SourceReaderBase.java:242)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleAddSplitsEvent(SourceOperator.java:584)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleOperatorEvent(SourceOperator.java:561)
	at org.apache.flink.streaming.runtime.tasks.OperatorEventDispatcherImpl.dispatchEventToHandlers(OperatorEventDispatcherImpl.java:72)
	at org.apache.flink.streaming.runtime.tasks.RegularOperatorChain.dispatchOperatorEvent(RegularOperatorChain.java:80)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$dispatchOperatorEvent$20(StreamTask.java:1473)
	at org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$1.runThrowing(StreamTaskActionExecutor.java:50)
	at org.apache.flink.streaming.runtime.tasks.mailbox.Mail.run(Mail.java:90)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMail(MailboxProcessor.java:398)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMailsWhenDefaultActionUnavailable(MailboxProcessor.java:367)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMail(MailboxProcessor.java:352)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:229)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:839)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:788)
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:952)
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:931)
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:745)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:562)
	at java.base/java.lang.Thread.run(Thread.java:829)
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290629937
WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.consumer:type=app-info,id=flink-0
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:816)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:666)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:647)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:627)
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.<init>(KafkaPartitionSplitReader.java:88)
	at org.apache.flink.connector.kafka.source.KafkaSource.lambda$createReader$1(KafkaSource.java:160)
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager.createSplitFetcher(SplitFetcherManager.java:196)
	at org.apache.flink.connector.base.source.reader.fetcher.SingleThreadFetcherManager.addSplits(SingleThreadFetcherManager.java:107)
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.addSplits(SourceReaderBase.java:242)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleAddSplitsEvent(SourceOperator.java:584)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleOperatorEvent(SourceOperator.java:561)
	at org.apache.flink.streaming.runtime.tasks.OperatorEventDispatcherImpl.dispatchEventToHandlers(OperatorEventDispatcherImpl.java:72)
	at org.apache.flink.streaming.runtime.tasks.RegularOperatorChain.dispatchOperatorEvent(RegularOperatorChain.java:80)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$dispatchOperatorEvent$20(StreamTask.java:1473)
	at org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$1.runThrowing(StreamTaskActionExecutor.java:50)
	at org.apache.flink.streaming.runtime.tasks.mailbox.Mail.run(Mail.java:90)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMail(MailboxProcessor.java:398)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMailsWhenDefaultActionUnavailable(MailboxProcessor.java:367)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMail(MailboxProcessor.java:352)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:229)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:839)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:788)
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:952)
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:931)
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:745)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:562)
	at java.base/java.lang.Thread.run(Thread.java:829)
INFO  - SplitFetcher               - Starting split fetcher 0
INFO  - SplitFetcher               - Starting split fetcher 0
INFO  - SplitFetcher               - Starting split fetcher 0
INFO  - SplitFetcher               - Starting split fetcher 0
INFO  - KafkaConsumer              - [Consumer clientId=flink-0, groupId=flink] Subscribed to partition(s): openmrs.openmrs.patient_appointment_provider-0
INFO  - KafkaConsumer              - [Consumer clientId=flink-0, groupId=flink] Subscribed to partition(s): openmrs.openmrs.appointment_service_type-0
INFO  - KafkaConsumer              - [Consumer clientId=flink-0, groupId=flink] Subscribed to partition(s): openmrs.openmrs.patient_appointment-0
INFO  - KafkaConsumer              - [Consumer clientId=flink-0, groupId=flink] Subscribed to partition(s): openmrs.openmrs.appointment_service-0
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Seeking to EARLIEST offset of partition openmrs.openmrs.patient_appointment_provider-0
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Seeking to EARLIEST offset of partition openmrs.openmrs.appointment_service-0
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Seeking to EARLIEST offset of partition openmrs.openmrs.appointment_service_type-0
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Seeking to EARLIEST offset of partition openmrs.openmrs.patient_appointment-0
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Resetting the last seen epoch of partition openmrs.openmrs.patient_appointment_provider-0 to 0 since the associated topicId changed from null to nPGab1zmTMabJQo8sKir7w
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Resetting the last seen epoch of partition openmrs.openmrs.appointment_service-0 to 0 since the associated topicId changed from null to qIOrkhtFTzGmXnBXBQT9_Q
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Resetting the last seen epoch of partition openmrs.openmrs.patient_appointment-0 to 0 since the associated topicId changed from null to eOBInG-kS3-tG_7HKwriUQ
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Resetting the last seen epoch of partition openmrs.openmrs.appointment_service_type-0 to 0 since the associated topicId changed from null to AQpXfWw1QpK5jiWb6tDAig
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Cluster ID: 5Yr1SIgYQz-b-dgRabWx4g
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Cluster ID: 5Yr1SIgYQz-b-dgRabWx4g
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Cluster ID: 5Yr1SIgYQz-b-dgRabWx4g
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Cluster ID: 5Yr1SIgYQz-b-dgRabWx4g
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Resetting offset for partition openmrs.openmrs.appointment_service_type-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:29092 (id: 1 rack: null)], epoch=0}}.
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Resetting offset for partition openmrs.openmrs.patient_appointment-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:29092 (id: 1 rack: null)], epoch=0}}.
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Resetting offset for partition openmrs.openmrs.appointment_service-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:29092 (id: 1 rack: null)], epoch=0}}.
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Resetting offset for partition openmrs.openmrs.patient_appointment_provider-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:29092 (id: 1 rack: null)], epoch=0}}.
WARN  - Configuration              - Config uses deprecated configuration key 'high-availability' instead of proper key 'high-availability.type'
INFO  - ZooKeeperUtils             - Enforcing default ACL for ZK connections
INFO  - ZooKeeperUtils             - Using '/flink/default' as Zookeeper namespace.
INFO  - CuratorFrameworkImpl       - Starting
INFO  - ZooKeeper                  - Initiating client connection, connectString=localhost:2181 sessionTimeout=60000 watcher=org.apache.flink.shaded.curator5.org.apache.curator.ConnectionState@2175be66
INFO  - ClientCnxnSocket           - jute.maxbuffer value is 1048575 Bytes
INFO  - ClientCnxn                 - zookeeper.request.timeout value is 0. feature enabled=false
INFO  - ClientCnxn                 - Opening socket connection to server localhost/127.0.0.1:2181.
INFO  - ClientCnxn                 - SASL config status: Will not attempt to authenticate using SASL (unknown error)
INFO  - CuratorFrameworkImpl       - Default schema
INFO  - aultLeaderRetrievalService - Starting DefaultLeaderRetrievalService with ZookeeperLeaderRetrievalDriver{connectionInformationPath='/leader/rest_server/connection_info'}.
INFO  - ClientCnxn                 - Socket connection established, initiating session, client: /127.0.0.1:52207, server: localhost/127.0.0.1:2181
INFO  - RestClusterClient          - Submitting job 'insert-into_analytics.analytics.orders' (1d1394375e4908f94ef8c8210cd9a417).
INFO  - ClientCnxn                 - Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x10009b90d4f0002, negotiated timeout = 40000
INFO  - ConnectionStateManager     - State change: CONNECTED
INFO  - EnsembleTracker            - New config event received: {}
INFO  - mbeddedRocksDBStateBackend - Successfully loaded RocksDB native library
INFO  - EnsembleTracker            - New config event received: {}
INFO  - mbeddedRocksDBStateBackend - Getting shared memory for RocksDB: shareScope=SLOT, managed=false
INFO  - mbeddedRocksDBStateBackend - Getting shared memory for RocksDB: shareScope=SLOT, managed=false
INFO  - mbeddedRocksDBStateBackend - Getting shared memory for RocksDB: shareScope=SLOT, managed=false
INFO  - mbeddedRocksDBStateBackend - Getting shared memory for RocksDB: shareScope=SLOT, managed=false
INFO  - mbeddedRocksDBStateBackend - Obtained shared RocksDB cache of size 6710886 bytes
INFO  - mbeddedRocksDBStateBackend - Obtained shared RocksDB cache of size 6710886 bytes
INFO  - mbeddedRocksDBStateBackend - Obtained shared RocksDB cache of size 6710886 bytes
INFO  - mbeddedRocksDBStateBackend - Obtained shared RocksDB cache of size 6710886 bytes
INFO  - DBKeyedStateBackendBuilder - Finished building RocksDB keyed state-backend at /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_30b4315f4dce6b8b0d1d34062dbea1c2_op_StreamingJoinOperator_ccd2f3173f602e66f6767720952cb258__1_1__uuid_cfa4b98b-4efd-446a-8002-5533645b412a.
INFO  - DBKeyedStateBackendBuilder - Finished building RocksDB keyed state-backend at /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_30b4315f4dce6b8b0d1d34062dbea1c2_op_StreamingJoinOperator_5caeaa5e379e7348564aaaaf5ae0d6a6__1_1__uuid_280b4c67-4fc0-49c2-a92a-f03f9639c840.
INFO  - DBKeyedStateBackendBuilder - Finished building RocksDB keyed state-backend at /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_30b4315f4dce6b8b0d1d34062dbea1c2_op_StreamingJoinOperator_23e521ac8efce918f328250afebbe45c__1_1__uuid_f640805e-7f52-4049-bba2-0dd6bfefef7f.
INFO  - DBKeyedStateBackendBuilder - Finished building RocksDB keyed state-backend at /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_30b4315f4dce6b8b0d1d34062dbea1c2_op_SinkUpsertMaterializer_fd907ffb7425150fb379978eab0e6d37__1_1__uuid_2c7989c6-a514-489a-aa40-81ea0801e938.
WARN  - RocksDBOperationUtils      - RocksDBStateBackend performance will be poor because of the current Flink memory configuration! RocksDB will flush memtable constantly, causing high IO and CPU. Typically the easiest fix is to increase task manager managed memory size. If running locally, see the parameter taskmanager.memory.managed.size. Details: arenaBlockSize 8388608 > mutableLimit 1957341 (writeBufferSize = 67108864, arenaBlockSizeConfigured = 0, defaultArenaBlockSize = 8388608, writeBufferManagerCapacity = 2236962)
WARN  - RocksDBOperationUtils      - RocksDBStateBackend performance will be poor because of the current Flink memory configuration! RocksDB will flush memtable constantly, causing high IO and CPU. Typically the easiest fix is to increase task manager managed memory size. If running locally, see the parameter taskmanager.memory.managed.size. Details: arenaBlockSize 8388608 > mutableLimit 1957341 (writeBufferSize = 67108864, arenaBlockSizeConfigured = 0, defaultArenaBlockSize = 8388608, writeBufferManagerCapacity = 2236962)
WARN  - RocksDBOperationUtils      - RocksDBStateBackend performance will be poor because of the current Flink memory configuration! RocksDB will flush memtable constantly, causing high IO and CPU. Typically the easiest fix is to increase task manager managed memory size. If running locally, see the parameter taskmanager.memory.managed.size. Details: arenaBlockSize 8388608 > mutableLimit 1957341 (writeBufferSize = 67108864, arenaBlockSizeConfigured = 0, defaultArenaBlockSize = 8388608, writeBufferManagerCapacity = 2236962)
WARN  - RocksDBOperationUtils      - RocksDBStateBackend performance will be poor because of the current Flink memory configuration! RocksDB will flush memtable constantly, causing high IO and CPU. Typically the easiest fix is to increase task manager managed memory size. If running locally, see the parameter taskmanager.memory.managed.size. Details: arenaBlockSize 8388608 > mutableLimit 1957341 (writeBufferSize = 67108864, arenaBlockSizeConfigured = 0, defaultArenaBlockSize = 8388608, writeBufferManagerCapacity = 2236962)
WARN  - RocksDBOperationUtils      - RocksDBStateBackend performance will be poor because of the current Flink memory configuration! RocksDB will flush memtable constantly, causing high IO and CPU. Typically the easiest fix is to increase task manager managed memory size. If running locally, see the parameter taskmanager.memory.managed.size. Details: arenaBlockSize 8388608 > mutableLimit 1957341 (writeBufferSize = 67108864, arenaBlockSizeConfigured = 0, defaultArenaBlockSize = 8388608, writeBufferManagerCapacity = 2236962)
WARN  - RocksDBOperationUtils      - RocksDBStateBackend performance will be poor because of the current Flink memory configuration! RocksDB will flush memtable constantly, causing high IO and CPU. Typically the easiest fix is to increase task manager managed memory size. If running locally, see the parameter taskmanager.memory.managed.size. Details: arenaBlockSize 8388608 > mutableLimit 1957341 (writeBufferSize = 67108864, arenaBlockSizeConfigured = 0, defaultArenaBlockSize = 8388608, writeBufferManagerCapacity = 2236962)
WARN  - RocksDBOperationUtils      - RocksDBStateBackend performance will be poor because of the current Flink memory configuration! RocksDB will flush memtable constantly, causing high IO and CPU. Typically the easiest fix is to increase task manager managed memory size. If running locally, see the parameter taskmanager.memory.managed.size. Details: arenaBlockSize 8388608 > mutableLimit 1957341 (writeBufferSize = 67108864, arenaBlockSizeConfigured = 0, defaultArenaBlockSize = 8388608, writeBufferManagerCapacity = 2236962)
INFO  - Task                       - SinkMaterializer[20] -> Sink: appointments[20] (1/1)#0 (5d2b85ced63db2be7a46b4ce2f567a3c_fd907ffb7425150fb379978eab0e6d37_0_0) switched from INITIALIZING to RUNNING.
INFO  - ExecutionGraph             - SinkMaterializer[20] -> Sink: appointments[20] (1/1) (5d2b85ced63db2be7a46b4ce2f567a3c_fd907ffb7425150fb379978eab0e6d37_0_0) switched from INITIALIZING to RUNNING.
INFO  - Task                       - Join[12] -> Calc[13] (1/1)#0 (5d2b85ced63db2be7a46b4ce2f567a3c_ccd2f3173f602e66f6767720952cb258_0_0) switched from INITIALIZING to RUNNING.
INFO  - Task                       - Join[18] -> Calc[19] -> ConstraintEnforcer[20] (1/1)#0 (5d2b85ced63db2be7a46b4ce2f567a3c_23e521ac8efce918f328250afebbe45c_0_0) switched from INITIALIZING to RUNNING.
INFO  - Task                       - Join[7] (1/1)#0 (5d2b85ced63db2be7a46b4ce2f567a3c_5caeaa5e379e7348564aaaaf5ae0d6a6_0_0) switched from INITIALIZING to RUNNING.
INFO  - ExecutionGraph             - Join[12] -> Calc[13] (1/1) (5d2b85ced63db2be7a46b4ce2f567a3c_ccd2f3173f602e66f6767720952cb258_0_0) switched from INITIALIZING to RUNNING.
INFO  - ExecutionGraph             - Join[18] -> Calc[19] -> ConstraintEnforcer[20] (1/1) (5d2b85ced63db2be7a46b4ce2f567a3c_23e521ac8efce918f328250afebbe45c_0_0) switched from INITIALIZING to RUNNING.
INFO  - ExecutionGraph             - Join[7] (1/1) (5d2b85ced63db2be7a46b4ce2f567a3c_5caeaa5e379e7348564aaaaf5ae0d6a6_0_0) switched from INITIALIZING to RUNNING.
INFO  - StandaloneDispatcher       - Received JobGraph submission 'insert-into_analytics.analytics.orders' (1d1394375e4908f94ef8c8210cd9a417).
INFO  - StandaloneDispatcher       - Submitting job 'insert-into_analytics.analytics.orders' (1d1394375e4908f94ef8c8210cd9a417).
INFO  - DefaultJobGraphStore       - Added JobGraph(jobId: 1d1394375e4908f94ef8c8210cd9a417) to ZooKeeperStateHandleStore{namespace='flink/default/jobgraphs'}.
INFO  - faultLeaderElectionService - Starting DefaultLeaderElectionService with org.apache.flink.runtime.leaderelection.MultipleComponentLeaderElectionDriverAdapter@7be47792.
INFO  - terServiceLeadershipRunner - JobMasterServiceLeadershipRunner for job 1d1394375e4908f94ef8c8210cd9a417 was granted leadership with leader id 3a82a6ce-fb62-4610-b46c-7fb86bd673d4. Creating new JobMasterServiceProcess.
INFO  - AkkaRpcService             - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/rpc/jobmanager_4 .
INFO  - JobMaster                  - Initializing job 'insert-into_analytics.analytics.orders' (1d1394375e4908f94ef8c8210cd9a417).
INFO  - RestClusterClient          - Successfully submitted job 'insert-into_analytics.analytics.orders' (1d1394375e4908f94ef8c8210cd9a417) to 'http://localhost:8081'.
INFO  - JobMaster                  - Using restart back off time strategy ExponentialDelayRestartBackoffTimeStrategy(initialBackoffMS=1000, maxBackoffMS=300000, backoffMultiplier=2.0, resetBackoffThresholdMS=3600000, jitterFactor=0.1, currentBackoffMS=1000, lastFailureTimestamp=0) for insert-into_analytics.analytics.orders (1d1394375e4908f94ef8c8210cd9a417).
INFO  - pletedCheckpointStoreUtils - Recovering checkpoints from ZooKeeperStateHandleStore{namespace='flink/default/jobs/1d1394375e4908f94ef8c8210cd9a417/checkpoints'}.
INFO  - pletedCheckpointStoreUtils - Found 0 checkpoints in ZooKeeperStateHandleStore{namespace='flink/default/jobs/1d1394375e4908f94ef8c8210cd9a417/checkpoints'}.
INFO  - pletedCheckpointStoreUtils - Trying to fetch 0 checkpoints from storage.
INFO  - ZooKeeperUtils             - Initialized DefaultCompletedCheckpointStore in 'ZooKeeperStateHandleStore{namespace='flink/default/jobs/1d1394375e4908f94ef8c8210cd9a417/checkpoints'}' with /checkpoints.
INFO  - ExecutionGraph             - Created execution graph a5db4d5da596a9c0b858e30fe60e5a2e for job 1d1394375e4908f94ef8c8210cd9a417.
INFO  - JobMaster                  - Running initialization on master for job insert-into_analytics.analytics.orders (1d1394375e4908f94ef8c8210cd9a417).
INFO  - JobMaster                  - Successfully ran initialization on master in 0 ms.
INFO  - DefaultExecutionTopology   - Built 1 new pipelined regions in 0 ms, total 1 pipelined regions currently.
INFO  - JobMaster                  - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - JobMaster                  - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - JobMaster                  - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - CheckpointCoordinator      - No checkpoint found during restore.
INFO  - JobMaster                  - Using failover strategy org.apache.flink.runtime.executiongraph.failover.flip1.RestartPipelinedRegionFailoverStrategy@5f031be3 for insert-into_analytics.analytics.orders (1d1394375e4908f94ef8c8210cd9a417).
INFO  - aultLeaderRetrievalService - Starting DefaultLeaderRetrievalService with ZookeeperLeaderRetrievalDriver{connectionInformationPath='/resource_manager/connection_info'}.
INFO  - JobMaster                  - Starting execution of job 'insert-into_analytics.analytics.orders' (1d1394375e4908f94ef8c8210cd9a417) under job master id b46c7fb86bd673d43a82a6cefb624610.
INFO  - SourceCoordinator          - Starting split enumerator for source Source: orders[21].
INFO  - SourceCoordinator          - Starting split enumerator for source Source: encounter[36].
INFO  - SourceCoordinator          - Starting split enumerator for source Source: encounter_type[42].
INFO  - SourceCoordinator          - Starting split enumerator for source Source: order_type[24].
INFO  - AdminClientConfig          - AdminClientConfig values: 
	bootstrap.servers = [localhost:29092]
	client.dns.lookup = use_all_dns_ips
	client.id = flink-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

INFO  - AdminClientConfig          - AdminClientConfig values: 
	bootstrap.servers = [localhost:29092]
	client.dns.lookup = use_all_dns_ips
	client.id = flink-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

INFO  - AdminClientConfig          - AdminClientConfig values: 
	bootstrap.servers = [localhost:29092]
	client.dns.lookup = use_all_dns_ips
	client.id = flink-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

INFO  - AdminClientConfig          - AdminClientConfig values: 
	bootstrap.servers = [localhost:29092]
	client.dns.lookup = use_all_dns_ips
	client.id = flink-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

INFO  - SourceCoordinator          - Starting split enumerator for source Source: care_setting[30].
INFO  - JobMaster                  - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
INFO  - ExecutionGraph             - Job insert-into_analytics.analytics.orders (1d1394375e4908f94ef8c8210cd9a417) switched from state CREATED to RUNNING.
INFO  - AdminClientConfig          - AdminClientConfig values: 
	bootstrap.servers = [localhost:29092]
	client.dns.lookup = use_all_dns_ips
	client.id = flink-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

INFO  - ExecutionGraph             - Source: orders[21] -> Calc[22] (1/1) (a5db4d5da596a9c0b858e30fe60e5a2e_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to SCHEDULED.
INFO  - ExecutionGraph             - Source: order_type[24] -> Calc[25] (1/1) (a5db4d5da596a9c0b858e30fe60e5a2e_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) switched from CREATED to SCHEDULED.
INFO  - ExecutionGraph             - Source: care_setting[30] -> Calc[31] (1/1) (a5db4d5da596a9c0b858e30fe60e5a2e_2963852293169ba90d9d1e7d6308db5c_0_0) switched from CREATED to SCHEDULED.
INFO  - ExecutionGraph             - Source: encounter[36] -> Calc[37] (1/1) (a5db4d5da596a9c0b858e30fe60e5a2e_1171dea6747ab509fdaefbe74f7195af_0_0) switched from CREATED to SCHEDULED.
INFO  - ExecutionGraph             - Source: encounter_type[42] -> Calc[43] (1/1) (a5db4d5da596a9c0b858e30fe60e5a2e_2fa5fc7df17f61cb0e1946288970d799_0_0) switched from CREATED to SCHEDULED.
INFO  - ExecutionGraph             - Join[27] -> Calc[28] (1/1) (a5db4d5da596a9c0b858e30fe60e5a2e_55d7dd5010de5a0cb7f3223050a51b73_0_0) switched from CREATED to SCHEDULED.
INFO  - ExecutionGraph             - Join[33] -> Calc[34] (1/1) (a5db4d5da596a9c0b858e30fe60e5a2e_2e54324c2d6d30259944e7ab21f8249d_0_0) switched from CREATED to SCHEDULED.
INFO  - ExecutionGraph             - Join[39] -> Calc[40] (1/1) (a5db4d5da596a9c0b858e30fe60e5a2e_ab06fe1c886f2b2a7030a8ed4a30b46a_0_0) switched from CREATED to SCHEDULED.
INFO  - ExecutionGraph             - Join[45] -> Calc[46] -> ConstraintEnforcer[47] (1/1) (a5db4d5da596a9c0b858e30fe60e5a2e_6d4fd8dcc30b46c08121fc16d7e07e79_0_0) switched from CREATED to SCHEDULED.
INFO  - ExecutionGraph             - SinkMaterializer[47] -> Sink: orders[47] (1/1) (a5db4d5da596a9c0b858e30fe60e5a2e_4595a980807a13db332f9917535d0424_0_0) switched from CREATED to SCHEDULED.
INFO  - JobMaster                  - Connecting to ResourceManager akka://flink/user/rpc/resourcemanager_1(b46c7fb86bd673d43a82a6cefb624610)
WARN  - AdminClientConfig          - The configuration 'key.deserializer' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'value.deserializer' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'enable.auto.commit' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'client.id.prefix' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'group.id' was supplied but isn't a known config.
INFO  - JobMaster                  - Resolved ResourceManager address, beginning registration
WARN  - AdminClientConfig          - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'auto.offset.reset' was supplied but isn't a known config.
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290630467
WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.admin.client:type=app-info,id=flink-enumerator-admin-client
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.admin.KafkaAdminClient.<init>(KafkaAdminClient.java:597)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:539)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:478)
	at org.apache.kafka.clients.admin.Admin.create(Admin.java:133)
	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getKafkaAdminClient(KafkaSourceEnumerator.java:410)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.start(KafkaSourceEnumerator.java:151)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$start$1(SourceCoordinator.java:234)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$runInEventLoop$10(SourceCoordinator.java:458)
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
WARN  - AdminClientConfig          - The configuration 'key.deserializer' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'value.deserializer' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'enable.auto.commit' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'client.id.prefix' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'group.id' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'auto.offset.reset' was supplied but isn't a known config.
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290630468
WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.admin.client:type=app-info,id=flink-enumerator-admin-client
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.admin.KafkaAdminClient.<init>(KafkaAdminClient.java:597)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:539)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:478)
	at org.apache.kafka.clients.admin.Admin.create(Admin.java:133)
	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getKafkaAdminClient(KafkaSourceEnumerator.java:410)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.start(KafkaSourceEnumerator.java:151)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$start$1(SourceCoordinator.java:234)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$runInEventLoop$10(SourceCoordinator.java:458)
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
WARN  - AdminClientConfig          - The configuration 'key.deserializer' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'value.deserializer' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'enable.auto.commit' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'client.id.prefix' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'group.id' was supplied but isn't a known config.
INFO  - KafkaSourceEnumerator      - Starting the KafkaSourceEnumerator for consumer group flink without periodic partition discovery.
INFO  - aultLeaderRetrievalService - Starting DefaultLeaderRetrievalService with ZookeeperLeaderRetrievalDriver{connectionInformationPath='/1d1394375e4908f94ef8c8210cd9a417/connection_info'}.
INFO  - StandaloneResourceManager  - Registering job manager b46c7fb86bd673d43a82a6cefb624610@akka://flink/user/rpc/jobmanager_4 for job 1d1394375e4908f94ef8c8210cd9a417.
WARN  - AdminClientConfig          - The configuration 'key.deserializer' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'value.deserializer' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'enable.auto.commit' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'client.id.prefix' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'group.id' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'auto.offset.reset' was supplied but isn't a known config.
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290630468
WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.admin.client:type=app-info,id=flink-enumerator-admin-client
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.admin.KafkaAdminClient.<init>(KafkaAdminClient.java:597)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:539)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:478)
	at org.apache.kafka.clients.admin.Admin.create(Admin.java:133)
	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getKafkaAdminClient(KafkaSourceEnumerator.java:410)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.start(KafkaSourceEnumerator.java:151)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$start$1(SourceCoordinator.java:234)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$runInEventLoop$10(SourceCoordinator.java:458)
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
WARN  - AdminClientConfig          - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'auto.offset.reset' was supplied but isn't a known config.
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290630470
WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.admin.client:type=app-info,id=flink-enumerator-admin-client
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.admin.KafkaAdminClient.<init>(KafkaAdminClient.java:597)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:539)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:478)
	at org.apache.kafka.clients.admin.Admin.create(Admin.java:133)
	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getKafkaAdminClient(KafkaSourceEnumerator.java:410)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.start(KafkaSourceEnumerator.java:151)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$start$1(SourceCoordinator.java:234)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$runInEventLoop$10(SourceCoordinator.java:458)
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
WARN  - AdminClientConfig          - The configuration 'key.deserializer' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'value.deserializer' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'enable.auto.commit' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'client.id.prefix' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'group.id' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'auto.offset.reset' was supplied but isn't a known config.
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290630470
WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.admin.client:type=app-info,id=flink-enumerator-admin-client
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.admin.KafkaAdminClient.<init>(KafkaAdminClient.java:597)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:539)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:478)
	at org.apache.kafka.clients.admin.Admin.create(Admin.java:133)
	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getKafkaAdminClient(KafkaSourceEnumerator.java:410)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.start(KafkaSourceEnumerator.java:151)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$start$1(SourceCoordinator.java:234)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$runInEventLoop$10(SourceCoordinator.java:458)
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
INFO  - KafkaSourceEnumerator      - Starting the KafkaSourceEnumerator for consumer group flink without periodic partition discovery.
INFO  - KafkaSourceEnumerator      - Starting the KafkaSourceEnumerator for consumer group flink without periodic partition discovery.
INFO  - KafkaSourceEnumerator      - Starting the KafkaSourceEnumerator for consumer group flink without periodic partition discovery.
INFO  - KafkaSourceEnumerator      - Starting the KafkaSourceEnumerator for consumer group flink without periodic partition discovery.
INFO  - KafkaSourceEnumerator      - Discovered new partitions: [openmrs.openmrs.care_setting-0]
INFO  - KafkaSourceEnumerator      - Discovered new partitions: [openmrs.openmrs.orders-0]
INFO  - KafkaSourceEnumerator      - Discovered new partitions: [openmrs.openmrs.encounter_type-0]
INFO  - KafkaSourceEnumerator      - Discovered new partitions: [openmrs.openmrs.encounter-0]
INFO  - KafkaSourceEnumerator      - Discovered new partitions: [openmrs.openmrs.order_type-0]
INFO  - StandaloneResourceManager  - Registered job manager b46c7fb86bd673d43a82a6cefb624610@akka://flink/user/rpc/jobmanager_4 for job 1d1394375e4908f94ef8c8210cd9a417.
INFO  - JobMaster                  - JobManager successfully registered at ResourceManager, leader id: b46c7fb86bd673d43a82a6cefb624610.
INFO  - DeclarativeSlotManager     - Received resource requirements from job 1d1394375e4908f94ef8c8210cd9a417: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
INFO  - TaskExecutor               - Receive slot request 3958974785a4365b6f3e7ad73e6888a1 for job 1d1394375e4908f94ef8c8210cd9a417 from resource manager with leader id b46c7fb86bd673d43a82a6cefb624610.
INFO  - TaskExecutor               - Allocated slot for 3958974785a4365b6f3e7ad73e6888a1.
INFO  - DefaultJobLeaderService    - Add job 1d1394375e4908f94ef8c8210cd9a417 for job leader monitoring.
INFO  - aultLeaderRetrievalService - Starting DefaultLeaderRetrievalService with ZookeeperLeaderRetrievalDriver{connectionInformationPath='/1d1394375e4908f94ef8c8210cd9a417/connection_info'}.
INFO  - DefaultJobLeaderService    - Try to register at job manager akka://flink/user/rpc/jobmanager_4 with leader id 3a82a6ce-fb62-4610-b46c-7fb86bd673d4.
INFO  - DefaultJobLeaderService    - Resolved JobManager address, beginning registration
INFO  - DefaultJobLeaderService    - Successful registration at job manager akka://flink/user/rpc/jobmanager_4 for job 1d1394375e4908f94ef8c8210cd9a417.
INFO  - TaskExecutor               - Establish JobManager connection for job 1d1394375e4908f94ef8c8210cd9a417.
INFO  - TaskExecutor               - Offer reserved slots to the leader of job 1d1394375e4908f94ef8c8210cd9a417.
INFO  - ExecutionGraph             - Source: orders[21] -> Calc[22] (1/1) (a5db4d5da596a9c0b858e30fe60e5a2e_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - ExecutionGraph             - Deploying Source: orders[21] -> Calc[22] (1/1) (attempt #0) with attempt id a5db4d5da596a9c0b858e30fe60e5a2e_cbc357ccb763df2852fee8c4fc7d55f2_0_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id 3958974785a4365b6f3e7ad73e6888a1
INFO  - ExecutionGraph             - Source: order_type[24] -> Calc[25] (1/1) (a5db4d5da596a9c0b858e30fe60e5a2e_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - ExecutionGraph             - Deploying Source: order_type[24] -> Calc[25] (1/1) (attempt #0) with attempt id a5db4d5da596a9c0b858e30fe60e5a2e_6cdc5bb954874d922eaee11a8e7b5dd5_0_0 and vertex id 6cdc5bb954874d922eaee11a8e7b5dd5_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id 3958974785a4365b6f3e7ad73e6888a1
INFO  - ExecutionGraph             - Source: care_setting[30] -> Calc[31] (1/1) (a5db4d5da596a9c0b858e30fe60e5a2e_2963852293169ba90d9d1e7d6308db5c_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - TaskSlotTableImpl          - Activate slot 3958974785a4365b6f3e7ad73e6888a1.
INFO  - ExecutionGraph             - Deploying Source: care_setting[30] -> Calc[31] (1/1) (attempt #0) with attempt id a5db4d5da596a9c0b858e30fe60e5a2e_2963852293169ba90d9d1e7d6308db5c_0_0 and vertex id 2963852293169ba90d9d1e7d6308db5c_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id 3958974785a4365b6f3e7ad73e6888a1
INFO  - ExecutionGraph             - Source: encounter[36] -> Calc[37] (1/1) (a5db4d5da596a9c0b858e30fe60e5a2e_1171dea6747ab509fdaefbe74f7195af_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - ExecutionGraph             - Deploying Source: encounter[36] -> Calc[37] (1/1) (attempt #0) with attempt id a5db4d5da596a9c0b858e30fe60e5a2e_1171dea6747ab509fdaefbe74f7195af_0_0 and vertex id 1171dea6747ab509fdaefbe74f7195af_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id 3958974785a4365b6f3e7ad73e6888a1
INFO  - ExecutionGraph             - Source: encounter_type[42] -> Calc[43] (1/1) (a5db4d5da596a9c0b858e30fe60e5a2e_2fa5fc7df17f61cb0e1946288970d799_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - ExecutionGraph             - Deploying Source: encounter_type[42] -> Calc[43] (1/1) (attempt #0) with attempt id a5db4d5da596a9c0b858e30fe60e5a2e_2fa5fc7df17f61cb0e1946288970d799_0_0 and vertex id 2fa5fc7df17f61cb0e1946288970d799_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id 3958974785a4365b6f3e7ad73e6888a1
INFO  - tateChangelogStorageLoader - Creating a changelog storage with name 'memory'.
INFO  - ExecutionGraph             - Join[27] -> Calc[28] (1/1) (a5db4d5da596a9c0b858e30fe60e5a2e_55d7dd5010de5a0cb7f3223050a51b73_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - tateExecutorFactoryManager - Creating the channel state executor factory for job id 1d1394375e4908f94ef8c8210cd9a417
INFO  - ExecutionGraph             - Deploying Join[27] -> Calc[28] (1/1) (attempt #0) with attempt id a5db4d5da596a9c0b858e30fe60e5a2e_55d7dd5010de5a0cb7f3223050a51b73_0_0 and vertex id 55d7dd5010de5a0cb7f3223050a51b73_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id 3958974785a4365b6f3e7ad73e6888a1
INFO  - TaskExecutor               - Received task Source: orders[21] -> Calc[22] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_cbc357ccb763df2852fee8c4fc7d55f2_0_0), deploy into slot with allocation id 3958974785a4365b6f3e7ad73e6888a1.
INFO  - Task                       - Source: orders[21] -> Calc[22] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to DEPLOYING.
INFO  - Task                       - Loading JAR files for task Source: orders[21] -> Calc[22] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_cbc357ccb763df2852fee8c4fc7d55f2_0_0) [DEPLOYING].
INFO  - TaskSlotTableImpl          - Activate slot 3958974785a4365b6f3e7ad73e6888a1.
INFO  - TaskExecutor               - Received task Source: order_type[24] -> Calc[25] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_6cdc5bb954874d922eaee11a8e7b5dd5_0_0), deploy into slot with allocation id 3958974785a4365b6f3e7ad73e6888a1.
INFO  - Task                       - Source: order_type[24] -> Calc[25] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) switched from CREATED to DEPLOYING.
INFO  - TaskSlotTableImpl          - Activate slot 3958974785a4365b6f3e7ad73e6888a1.
INFO  - TaskExecutor               - Received task Source: care_setting[30] -> Calc[31] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_2963852293169ba90d9d1e7d6308db5c_0_0), deploy into slot with allocation id 3958974785a4365b6f3e7ad73e6888a1.
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - ExecutionGraph             - Join[33] -> Calc[34] (1/1) (a5db4d5da596a9c0b858e30fe60e5a2e_2e54324c2d6d30259944e7ab21f8249d_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - ExecutionGraph             - Deploying Join[33] -> Calc[34] (1/1) (attempt #0) with attempt id a5db4d5da596a9c0b858e30fe60e5a2e_2e54324c2d6d30259944e7ab21f8249d_0_0 and vertex id 2e54324c2d6d30259944e7ab21f8249d_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id 3958974785a4365b6f3e7ad73e6888a1
INFO  - Task                       - Source: care_setting[30] -> Calc[31] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_2963852293169ba90d9d1e7d6308db5c_0_0) switched from CREATED to DEPLOYING.
INFO  - Task                       - Loading JAR files for task Source: care_setting[30] -> Calc[31] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_2963852293169ba90d9d1e7d6308db5c_0_0) [DEPLOYING].
INFO  - Task                       - Loading JAR files for task Source: order_type[24] -> Calc[25] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) [DEPLOYING].
INFO  - TaskSlotTableImpl          - Activate slot 3958974785a4365b6f3e7ad73e6888a1.
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - TaskExecutor               - Received task Source: encounter[36] -> Calc[37] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_1171dea6747ab509fdaefbe74f7195af_0_0), deploy into slot with allocation id 3958974785a4365b6f3e7ad73e6888a1.
INFO  - ExecutionGraph             - Join[39] -> Calc[40] (1/1) (a5db4d5da596a9c0b858e30fe60e5a2e_ab06fe1c886f2b2a7030a8ed4a30b46a_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - ExecutionGraph             - Deploying Join[39] -> Calc[40] (1/1) (attempt #0) with attempt id a5db4d5da596a9c0b858e30fe60e5a2e_ab06fe1c886f2b2a7030a8ed4a30b46a_0_0 and vertex id ab06fe1c886f2b2a7030a8ed4a30b46a_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id 3958974785a4365b6f3e7ad73e6888a1
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - Task                       - Source: encounter[36] -> Calc[37] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_1171dea6747ab509fdaefbe74f7195af_0_0) switched from CREATED to DEPLOYING.
INFO  - Task                       - Loading JAR files for task Source: encounter[36] -> Calc[37] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_1171dea6747ab509fdaefbe74f7195af_0_0) [DEPLOYING].
INFO  - TaskSlotTableImpl          - Activate slot 3958974785a4365b6f3e7ad73e6888a1.
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - TaskExecutor               - Received task Source: encounter_type[42] -> Calc[43] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_2fa5fc7df17f61cb0e1946288970d799_0_0), deploy into slot with allocation id 3958974785a4365b6f3e7ad73e6888a1.
INFO  - ExecutionGraph             - Join[45] -> Calc[46] -> ConstraintEnforcer[47] (1/1) (a5db4d5da596a9c0b858e30fe60e5a2e_6d4fd8dcc30b46c08121fc16d7e07e79_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - ExecutionGraph             - Deploying Join[45] -> Calc[46] -> ConstraintEnforcer[47] (1/1) (attempt #0) with attempt id a5db4d5da596a9c0b858e30fe60e5a2e_6d4fd8dcc30b46c08121fc16d7e07e79_0_0 and vertex id 6d4fd8dcc30b46c08121fc16d7e07e79_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id 3958974785a4365b6f3e7ad73e6888a1
INFO  - Task                       - Source: orders[21] -> Calc[22] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - ExecutionGraph             - SinkMaterializer[47] -> Sink: orders[47] (1/1) (a5db4d5da596a9c0b858e30fe60e5a2e_4595a980807a13db332f9917535d0424_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - Task                       - Source: encounter_type[42] -> Calc[43] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_2fa5fc7df17f61cb0e1946288970d799_0_0) switched from CREATED to DEPLOYING.
INFO  - TaskSlotTableImpl          - Activate slot 3958974785a4365b6f3e7ad73e6888a1.
INFO  - Task                       - Source: care_setting[30] -> Calc[31] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_2963852293169ba90d9d1e7d6308db5c_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - Task                       - Loading JAR files for task Source: encounter_type[42] -> Calc[43] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_2fa5fc7df17f61cb0e1946288970d799_0_0) [DEPLOYING].
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - ExecutionGraph             - Deploying SinkMaterializer[47] -> Sink: orders[47] (1/1) (attempt #0) with attempt id a5db4d5da596a9c0b858e30fe60e5a2e_4595a980807a13db332f9917535d0424_0_0 and vertex id 4595a980807a13db332f9917535d0424_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id 3958974785a4365b6f3e7ad73e6888a1
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - Task                       - Source: encounter[36] -> Calc[37] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_1171dea6747ab509fdaefbe74f7195af_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - TaskExecutor               - Received task Join[27] -> Calc[28] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_55d7dd5010de5a0cb7f3223050a51b73_0_0), deploy into slot with allocation id 3958974785a4365b6f3e7ad73e6888a1.
INFO  - ExecutionGraph             - Source: orders[21] -> Calc[22] (1/1) (a5db4d5da596a9c0b858e30fe60e5a2e_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - ExecutionGraph             - Source: care_setting[30] -> Calc[31] (1/1) (a5db4d5da596a9c0b858e30fe60e5a2e_2963852293169ba90d9d1e7d6308db5c_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - Task                       - Source: order_type[24] -> Calc[25] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - TaskSlotTableImpl          - Activate slot 3958974785a4365b6f3e7ad73e6888a1.
INFO  - ExecutionGraph             - Source: encounter[36] -> Calc[37] (1/1) (a5db4d5da596a9c0b858e30fe60e5a2e_1171dea6747ab509fdaefbe74f7195af_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - Task                       - Join[27] -> Calc[28] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_55d7dd5010de5a0cb7f3223050a51b73_0_0) switched from CREATED to DEPLOYING.
INFO  - Task                       - Loading JAR files for task Join[27] -> Calc[28] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_55d7dd5010de5a0cb7f3223050a51b73_0_0) [DEPLOYING].
INFO  - ExecutionGraph             - Source: order_type[24] -> Calc[25] (1/1) (a5db4d5da596a9c0b858e30fe60e5a2e_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - Task                       - Source: encounter_type[42] -> Calc[43] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_2fa5fc7df17f61cb0e1946288970d799_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - TaskExecutor               - Received task Join[33] -> Calc[34] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_2e54324c2d6d30259944e7ab21f8249d_0_0), deploy into slot with allocation id 3958974785a4365b6f3e7ad73e6888a1.
INFO  - ExecutionGraph             - Source: encounter_type[42] -> Calc[43] (1/1) (a5db4d5da596a9c0b858e30fe60e5a2e_2fa5fc7df17f61cb0e1946288970d799_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - Task                       - Join[33] -> Calc[34] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_2e54324c2d6d30259944e7ab21f8249d_0_0) switched from CREATED to DEPLOYING.
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - aultLeaderRetrievalService - Stopping DefaultLeaderRetrievalService.
INFO  - eeperLeaderRetrievalDriver - Closing ZookeeperLeaderRetrievalDriver{connectionInformationPath='/leader/rest_server/connection_info'}.
INFO  - TaskSlotTableImpl          - Activate slot 3958974785a4365b6f3e7ad73e6888a1.
INFO  - Task                       - Loading JAR files for task Join[33] -> Calc[34] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_2e54324c2d6d30259944e7ab21f8249d_0_0) [DEPLOYING].
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - CuratorFrameworkImpl       - backgroundOperationsLoop exiting
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - SourceCoordinator          - Source Source: care_setting[30] registering reader for parallel task 0 (#0) @ 
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - Task                       - Source: care_setting[30] -> Calc[31] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_2963852293169ba90d9d1e7d6308db5c_0_0) switched from INITIALIZING to RUNNING.
INFO  - Task                       - Source: encounter[36] -> Calc[37] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_1171dea6747ab509fdaefbe74f7195af_0_0) switched from INITIALIZING to RUNNING.
INFO  - SourceCoordinator          - Source Source: encounter[36] registering reader for parallel task 0 (#0) @ 
INFO  - KafkaSourceEnumerator      - Assigning splits to readers {0=[[Partition: openmrs.openmrs.encounter-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}
INFO  - ExecutionGraph             - Source: care_setting[30] -> Calc[31] (1/1) (a5db4d5da596a9c0b858e30fe60e5a2e_2963852293169ba90d9d1e7d6308db5c_0_0) switched from INITIALIZING to RUNNING.
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - TaskExecutor               - Received task Join[39] -> Calc[40] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_ab06fe1c886f2b2a7030a8ed4a30b46a_0_0), deploy into slot with allocation id 3958974785a4365b6f3e7ad73e6888a1.
INFO  - Task                       - Source: orders[21] -> Calc[22] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
INFO  - Task                       - Source: order_type[24] -> Calc[25] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) switched from INITIALIZING to RUNNING.
INFO  - Task                       - Source: encounter_type[42] -> Calc[43] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_2fa5fc7df17f61cb0e1946288970d799_0_0) switched from INITIALIZING to RUNNING.
INFO  - ExecutionGraph             - Source: encounter[36] -> Calc[37] (1/1) (a5db4d5da596a9c0b858e30fe60e5a2e_1171dea6747ab509fdaefbe74f7195af_0_0) switched from INITIALIZING to RUNNING.
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - KafkaSourceEnumerator      - Assigning splits to readers {0=[[Partition: openmrs.openmrs.care_setting-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}
INFO  - Task                       - Join[39] -> Calc[40] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_ab06fe1c886f2b2a7030a8ed4a30b46a_0_0) switched from CREATED to DEPLOYING.
INFO  - TaskSlotTableImpl          - Activate slot 3958974785a4365b6f3e7ad73e6888a1.
INFO  - Task                       - Loading JAR files for task Join[39] -> Calc[40] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_ab06fe1c886f2b2a7030a8ed4a30b46a_0_0) [DEPLOYING].
INFO  - SourceCoordinator          - Source Source: encounter_type[42] registering reader for parallel task 0 (#0) @ 
INFO  - Task                       - Join[27] -> Calc[28] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_55d7dd5010de5a0cb7f3223050a51b73_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - SourceCoordinator          - Source Source: order_type[24] registering reader for parallel task 0 (#0) @ 
INFO  - SourceCoordinator          - Source Source: orders[21] registering reader for parallel task 0 (#0) @ 
INFO  - KafkaSourceEnumerator      - Assigning splits to readers {0=[[Partition: openmrs.openmrs.order_type-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}
INFO  - KafkaSourceEnumerator      - Assigning splits to readers {0=[[Partition: openmrs.openmrs.orders-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}
INFO  - ExecutionGraph             - Source: orders[21] -> Calc[22] (1/1) (a5db4d5da596a9c0b858e30fe60e5a2e_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
INFO  - KafkaSourceEnumerator      - Assigning splits to readers {0=[[Partition: openmrs.openmrs.encounter_type-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}
INFO  - ExecutionGraph             - Source: order_type[24] -> Calc[25] (1/1) (a5db4d5da596a9c0b858e30fe60e5a2e_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) switched from INITIALIZING to RUNNING.
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - ExecutionGraph             - Source: encounter_type[42] -> Calc[43] (1/1) (a5db4d5da596a9c0b858e30fe60e5a2e_2fa5fc7df17f61cb0e1946288970d799_0_0) switched from INITIALIZING to RUNNING.
INFO  - Task                       - Join[33] -> Calc[34] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_2e54324c2d6d30259944e7ab21f8249d_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - ExecutionGraph             - Join[27] -> Calc[28] (1/1) (a5db4d5da596a9c0b858e30fe60e5a2e_55d7dd5010de5a0cb7f3223050a51b73_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - ExecutionGraph             - Join[33] -> Calc[34] (1/1) (a5db4d5da596a9c0b858e30fe60e5a2e_2e54324c2d6d30259944e7ab21f8249d_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - TaskExecutor               - Received task Join[45] -> Calc[46] -> ConstraintEnforcer[47] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_6d4fd8dcc30b46c08121fc16d7e07e79_0_0), deploy into slot with allocation id 3958974785a4365b6f3e7ad73e6888a1.
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - Task                       - Join[45] -> Calc[46] -> ConstraintEnforcer[47] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_6d4fd8dcc30b46c08121fc16d7e07e79_0_0) switched from CREATED to DEPLOYING.
INFO  - Task                       - Loading JAR files for task Join[45] -> Calc[46] -> ConstraintEnforcer[47] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_6d4fd8dcc30b46c08121fc16d7e07e79_0_0) [DEPLOYING].
INFO  - TaskSlotTableImpl          - Activate slot 3958974785a4365b6f3e7ad73e6888a1.
INFO  - Task                       - Join[39] -> Calc[40] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_ab06fe1c886f2b2a7030a8ed4a30b46a_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - ExecutionGraph             - Join[39] -> Calc[40] (1/1) (a5db4d5da596a9c0b858e30fe60e5a2e_ab06fe1c886f2b2a7030a8ed4a30b46a_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - TaskExecutor               - Received task SinkMaterializer[47] -> Sink: orders[47] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_4595a980807a13db332f9917535d0424_0_0), deploy into slot with allocation id 3958974785a4365b6f3e7ad73e6888a1.
INFO  - TaskSlotTableImpl          - Activate slot 3958974785a4365b6f3e7ad73e6888a1.
INFO  - Task                       - SinkMaterializer[47] -> Sink: orders[47] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_4595a980807a13db332f9917535d0424_0_0) switched from CREATED to DEPLOYING.
INFO  - Task                       - Loading JAR files for task SinkMaterializer[47] -> Sink: orders[47] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_4595a980807a13db332f9917535d0424_0_0) [DEPLOYING].
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - SourceReaderBase           - Adding split(s) to reader: [[Partition: openmrs.openmrs.encounter_type-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]
INFO  - SourceReaderBase           - Adding split(s) to reader: [[Partition: openmrs.openmrs.orders-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]
INFO  - SourceReaderBase           - Adding split(s) to reader: [[Partition: openmrs.openmrs.order_type-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]
INFO  - SourceReaderBase           - Adding split(s) to reader: [[Partition: openmrs.openmrs.care_setting-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]
INFO  - SourceReaderBase           - Adding split(s) to reader: [[Partition: openmrs.openmrs.encounter-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]
INFO  - ConsumerConfig             - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = flink-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

INFO  - ConsumerConfig             - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = flink-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

INFO  - mbeddedRocksDBStateBackend - Getting shared memory for RocksDB: shareScope=SLOT, managed=false
INFO  - mbeddedRocksDBStateBackend - Getting shared memory for RocksDB: shareScope=SLOT, managed=false
INFO  - ConsumerConfig             - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = flink-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

INFO  - ConsumerConfig             - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = flink-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

INFO  - Task                       - Join[45] -> Calc[46] -> ConstraintEnforcer[47] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_6d4fd8dcc30b46c08121fc16d7e07e79_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
WARN  - ConsumerConfig             - The configuration 'client.id.prefix' was supplied but isn't a known config.
WARN  - ConsumerConfig             - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290630629
WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.consumer:type=app-info,id=flink-0
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:816)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:666)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:647)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:627)
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.<init>(KafkaPartitionSplitReader.java:88)
	at org.apache.flink.connector.kafka.source.KafkaSource.lambda$createReader$1(KafkaSource.java:160)
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager.createSplitFetcher(SplitFetcherManager.java:196)
	at org.apache.flink.connector.base.source.reader.fetcher.SingleThreadFetcherManager.addSplits(SingleThreadFetcherManager.java:107)
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.addSplits(SourceReaderBase.java:242)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleAddSplitsEvent(SourceOperator.java:584)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleOperatorEvent(SourceOperator.java:561)
	at org.apache.flink.streaming.runtime.tasks.OperatorEventDispatcherImpl.dispatchEventToHandlers(OperatorEventDispatcherImpl.java:72)
	at org.apache.flink.streaming.runtime.tasks.RegularOperatorChain.dispatchOperatorEvent(RegularOperatorChain.java:80)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$dispatchOperatorEvent$20(StreamTask.java:1473)
	at org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$1.runThrowing(StreamTaskActionExecutor.java:50)
	at org.apache.flink.streaming.runtime.tasks.mailbox.Mail.run(Mail.java:90)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMail(MailboxProcessor.java:398)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMailsWhenDefaultActionUnavailable(MailboxProcessor.java:367)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMail(MailboxProcessor.java:352)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:229)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:839)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:788)
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:952)
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:931)
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:745)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:562)
	at java.base/java.lang.Thread.run(Thread.java:829)
WARN  - ConsumerConfig             - The configuration 'client.id.prefix' was supplied but isn't a known config.
WARN  - ConsumerConfig             - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290630630
WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.consumer:type=app-info,id=flink-0
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:816)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:666)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:647)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:627)
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.<init>(KafkaPartitionSplitReader.java:88)
	at org.apache.flink.connector.kafka.source.KafkaSource.lambda$createReader$1(KafkaSource.java:160)
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager.createSplitFetcher(SplitFetcherManager.java:196)
	at org.apache.flink.connector.base.source.reader.fetcher.SingleThreadFetcherManager.addSplits(SingleThreadFetcherManager.java:107)
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.addSplits(SourceReaderBase.java:242)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleAddSplitsEvent(SourceOperator.java:584)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleOperatorEvent(SourceOperator.java:561)
	at org.apache.flink.streaming.runtime.tasks.OperatorEventDispatcherImpl.dispatchEventToHandlers(OperatorEventDispatcherImpl.java:72)
	at org.apache.flink.streaming.runtime.tasks.RegularOperatorChain.dispatchOperatorEvent(RegularOperatorChain.java:80)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$dispatchOperatorEvent$20(StreamTask.java:1473)
	at org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$1.runThrowing(StreamTaskActionExecutor.java:50)
	at org.apache.flink.streaming.runtime.tasks.mailbox.Mail.run(Mail.java:90)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMail(MailboxProcessor.java:398)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMailsWhenDefaultActionUnavailable(MailboxProcessor.java:367)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMail(MailboxProcessor.java:352)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:229)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:839)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:788)
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:952)
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:931)
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:745)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:562)
	at java.base/java.lang.Thread.run(Thread.java:829)
WARN  - ConsumerConfig             - The configuration 'client.id.prefix' was supplied but isn't a known config.
WARN  - ConsumerConfig             - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290630630
WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.consumer:type=app-info,id=flink-0
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:816)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:666)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:647)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:627)
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.<init>(KafkaPartitionSplitReader.java:88)
	at org.apache.flink.connector.kafka.source.KafkaSource.lambda$createReader$1(KafkaSource.java:160)
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager.createSplitFetcher(SplitFetcherManager.java:196)
	at org.apache.flink.connector.base.source.reader.fetcher.SingleThreadFetcherManager.addSplits(SingleThreadFetcherManager.java:107)
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.addSplits(SourceReaderBase.java:242)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleAddSplitsEvent(SourceOperator.java:584)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleOperatorEvent(SourceOperator.java:561)
	at org.apache.flink.streaming.runtime.tasks.OperatorEventDispatcherImpl.dispatchEventToHandlers(OperatorEventDispatcherImpl.java:72)
	at org.apache.flink.streaming.runtime.tasks.RegularOperatorChain.dispatchOperatorEvent(RegularOperatorChain.java:80)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$dispatchOperatorEvent$20(StreamTask.java:1473)
	at org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$1.runThrowing(StreamTaskActionExecutor.java:50)
	at org.apache.flink.streaming.runtime.tasks.mailbox.Mail.run(Mail.java:90)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMail(MailboxProcessor.java:398)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMailsWhenDefaultActionUnavailable(MailboxProcessor.java:367)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMail(MailboxProcessor.java:352)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:229)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:839)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:788)
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:952)
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:931)
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:745)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:562)
	at java.base/java.lang.Thread.run(Thread.java:829)
INFO  - SplitFetcher               - Starting split fetcher 0
INFO  - ExecutionGraph             - Join[45] -> Calc[46] -> ConstraintEnforcer[47] (1/1) (a5db4d5da596a9c0b858e30fe60e5a2e_6d4fd8dcc30b46c08121fc16d7e07e79_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - mbeddedRocksDBStateBackend - Obtained shared RocksDB cache of size 6710886 bytes
INFO  - mbeddedRocksDBStateBackend - Obtained shared RocksDB cache of size 6710886 bytes
INFO  - KafkaConsumer              - [Consumer clientId=flink-0, groupId=flink] Subscribed to partition(s): openmrs.openmrs.care_setting-0
WARN  - ConsumerConfig             - The configuration 'client.id.prefix' was supplied but isn't a known config.
WARN  - ConsumerConfig             - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290630635
WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.consumer:type=app-info,id=flink-0
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:816)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:666)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:647)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:627)
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.<init>(KafkaPartitionSplitReader.java:88)
	at org.apache.flink.connector.kafka.source.KafkaSource.lambda$createReader$1(KafkaSource.java:160)
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager.createSplitFetcher(SplitFetcherManager.java:196)
	at org.apache.flink.connector.base.source.reader.fetcher.SingleThreadFetcherManager.addSplits(SingleThreadFetcherManager.java:107)
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.addSplits(SourceReaderBase.java:242)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleAddSplitsEvent(SourceOperator.java:584)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleOperatorEvent(SourceOperator.java:561)
	at org.apache.flink.streaming.runtime.tasks.OperatorEventDispatcherImpl.dispatchEventToHandlers(OperatorEventDispatcherImpl.java:72)
	at org.apache.flink.streaming.runtime.tasks.RegularOperatorChain.dispatchOperatorEvent(RegularOperatorChain.java:80)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$dispatchOperatorEvent$20(StreamTask.java:1473)
	at org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$1.runThrowing(StreamTaskActionExecutor.java:50)
	at org.apache.flink.streaming.runtime.tasks.mailbox.Mail.run(Mail.java:90)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMail(MailboxProcessor.java:398)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMailsWhenDefaultActionUnavailable(MailboxProcessor.java:367)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMail(MailboxProcessor.java:352)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:229)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:839)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:788)
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:952)
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:931)
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:745)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:562)
	at java.base/java.lang.Thread.run(Thread.java:829)
INFO  - mbeddedRocksDBStateBackend - Getting shared memory for RocksDB: shareScope=SLOT, managed=false
INFO  - mbeddedRocksDBStateBackend - Obtained shared RocksDB cache of size 6710886 bytes
INFO  - ConsumerConfig             - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = flink-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Seeking to EARLIEST offset of partition openmrs.openmrs.care_setting-0
INFO  - SplitFetcher               - Starting split fetcher 0
INFO  - SplitFetcher               - Starting split fetcher 0
INFO  - SplitFetcher               - Starting split fetcher 0
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Resetting the last seen epoch of partition openmrs.openmrs.care_setting-0 to 0 since the associated topicId changed from null to KGTlvq8QSWmKgRD8eWVapQ
WARN  - ConsumerConfig             - The configuration 'client.id.prefix' was supplied but isn't a known config.
WARN  - ConsumerConfig             - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
INFO  - KafkaConsumer              - [Consumer clientId=flink-0, groupId=flink] Subscribed to partition(s): openmrs.openmrs.encounter_type-0
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - KafkaConsumer              - [Consumer clientId=flink-0, groupId=flink] Subscribed to partition(s): openmrs.openmrs.order_type-0
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290630642
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Cluster ID: 5Yr1SIgYQz-b-dgRabWx4g
INFO  - KafkaConsumer              - [Consumer clientId=flink-0, groupId=flink] Subscribed to partition(s): openmrs.openmrs.orders-0
INFO  - DBKeyedStateBackendBuilder - Finished building RocksDB keyed state-backend at /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_1d1394375e4908f94ef8c8210cd9a417_op_StreamingJoinOperator_55d7dd5010de5a0cb7f3223050a51b73__1_1__uuid_363f05b0-51d6-4cfa-989d-e540a324e94b.
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Seeking to EARLIEST offset of partition openmrs.openmrs.encounter_type-0
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Seeking to EARLIEST offset of partition openmrs.openmrs.order_type-0
INFO  - Task                       - SinkMaterializer[47] -> Sink: orders[47] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_4595a980807a13db332f9917535d0424_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Seeking to EARLIEST offset of partition openmrs.openmrs.orders-0
WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.consumer:type=app-info,id=flink-0
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:816)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:666)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:647)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:627)
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.<init>(KafkaPartitionSplitReader.java:88)
	at org.apache.flink.connector.kafka.source.KafkaSource.lambda$createReader$1(KafkaSource.java:160)
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager.createSplitFetcher(SplitFetcherManager.java:196)
	at org.apache.flink.connector.base.source.reader.fetcher.SingleThreadFetcherManager.addSplits(SingleThreadFetcherManager.java:107)
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.addSplits(SourceReaderBase.java:242)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleAddSplitsEvent(SourceOperator.java:584)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleOperatorEvent(SourceOperator.java:561)
	at org.apache.flink.streaming.runtime.tasks.OperatorEventDispatcherImpl.dispatchEventToHandlers(OperatorEventDispatcherImpl.java:72)
	at org.apache.flink.streaming.runtime.tasks.RegularOperatorChain.dispatchOperatorEvent(RegularOperatorChain.java:80)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$dispatchOperatorEvent$20(StreamTask.java:1473)
	at org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$1.runThrowing(StreamTaskActionExecutor.java:50)
	at org.apache.flink.streaming.runtime.tasks.mailbox.Mail.run(Mail.java:90)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMail(MailboxProcessor.java:398)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMailsWhenDefaultActionUnavailable(MailboxProcessor.java:367)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMail(MailboxProcessor.java:352)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:229)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:839)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:788)
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:952)
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:931)
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:745)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:562)
	at java.base/java.lang.Thread.run(Thread.java:829)
INFO  - DBKeyedStateBackendBuilder - Finished building RocksDB keyed state-backend at /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_1d1394375e4908f94ef8c8210cd9a417_op_StreamingJoinOperator_ab06fe1c886f2b2a7030a8ed4a30b46a__1_1__uuid_701dc00f-3081-4196-8205-fd8593d3b816.
INFO  - ExecutionGraph             - SinkMaterializer[47] -> Sink: orders[47] (1/1) (a5db4d5da596a9c0b858e30fe60e5a2e_4595a980807a13db332f9917535d0424_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - DBKeyedStateBackendBuilder - Finished building RocksDB keyed state-backend at /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_1d1394375e4908f94ef8c8210cd9a417_op_StreamingJoinOperator_2e54324c2d6d30259944e7ab21f8249d__1_1__uuid_6c423438-a367-4e56-be2e-b9174b3d9678.
INFO  - SplitFetcher               - Starting split fetcher 0
INFO  - KafkaConsumer              - [Consumer clientId=flink-0, groupId=flink] Subscribed to partition(s): openmrs.openmrs.encounter-0
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Seeking to EARLIEST offset of partition openmrs.openmrs.encounter-0
WARN  - RocksDBOperationUtils      - RocksDBStateBackend performance will be poor because of the current Flink memory configuration! RocksDB will flush memtable constantly, causing high IO and CPU. Typically the easiest fix is to increase task manager managed memory size. If running locally, see the parameter taskmanager.memory.managed.size. Details: arenaBlockSize 8388608 > mutableLimit 1957341 (writeBufferSize = 67108864, arenaBlockSizeConfigured = 0, defaultArenaBlockSize = 8388608, writeBufferManagerCapacity = 2236962)
WARN  - RocksDBOperationUtils      - RocksDBStateBackend performance will be poor because of the current Flink memory configuration! RocksDB will flush memtable constantly, causing high IO and CPU. Typically the easiest fix is to increase task manager managed memory size. If running locally, see the parameter taskmanager.memory.managed.size. Details: arenaBlockSize 8388608 > mutableLimit 1957341 (writeBufferSize = 67108864, arenaBlockSizeConfigured = 0, defaultArenaBlockSize = 8388608, writeBufferManagerCapacity = 2236962)
INFO  - mbeddedRocksDBStateBackend - Getting shared memory for RocksDB: shareScope=SLOT, managed=false
INFO  - mbeddedRocksDBStateBackend - Obtained shared RocksDB cache of size 6710886 bytes
WARN  - RocksDBOperationUtils      - RocksDBStateBackend performance will be poor because of the current Flink memory configuration! RocksDB will flush memtable constantly, causing high IO and CPU. Typically the easiest fix is to increase task manager managed memory size. If running locally, see the parameter taskmanager.memory.managed.size. Details: arenaBlockSize 8388608 > mutableLimit 1957341 (writeBufferSize = 67108864, arenaBlockSizeConfigured = 0, defaultArenaBlockSize = 8388608, writeBufferManagerCapacity = 2236962)
WARN  - RocksDBOperationUtils      - RocksDBStateBackend performance will be poor because of the current Flink memory configuration! RocksDB will flush memtable constantly, causing high IO and CPU. Typically the easiest fix is to increase task manager managed memory size. If running locally, see the parameter taskmanager.memory.managed.size. Details: arenaBlockSize 8388608 > mutableLimit 1957341 (writeBufferSize = 67108864, arenaBlockSizeConfigured = 0, defaultArenaBlockSize = 8388608, writeBufferManagerCapacity = 2236962)
WARN  - RocksDBOperationUtils      - RocksDBStateBackend performance will be poor because of the current Flink memory configuration! RocksDB will flush memtable constantly, causing high IO and CPU. Typically the easiest fix is to increase task manager managed memory size. If running locally, see the parameter taskmanager.memory.managed.size. Details: arenaBlockSize 8388608 > mutableLimit 1957341 (writeBufferSize = 67108864, arenaBlockSizeConfigured = 0, defaultArenaBlockSize = 8388608, writeBufferManagerCapacity = 2236962)
WARN  - RocksDBOperationUtils      - RocksDBStateBackend performance will be poor because of the current Flink memory configuration! RocksDB will flush memtable constantly, causing high IO and CPU. Typically the easiest fix is to increase task manager managed memory size. If running locally, see the parameter taskmanager.memory.managed.size. Details: arenaBlockSize 8388608 > mutableLimit 1957341 (writeBufferSize = 67108864, arenaBlockSizeConfigured = 0, defaultArenaBlockSize = 8388608, writeBufferManagerCapacity = 2236962)
INFO  - DBKeyedStateBackendBuilder - Finished building RocksDB keyed state-backend at /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_1d1394375e4908f94ef8c8210cd9a417_op_StreamingJoinOperator_6d4fd8dcc30b46c08121fc16d7e07e79__1_1__uuid_3c7e9d33-ea34-457e-ad27-d0aed0f12ed7.
INFO  - Task                       - Join[39] -> Calc[40] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_ab06fe1c886f2b2a7030a8ed4a30b46a_0_0) switched from INITIALIZING to RUNNING.
INFO  - Task                       - Join[27] -> Calc[28] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_55d7dd5010de5a0cb7f3223050a51b73_0_0) switched from INITIALIZING to RUNNING.
INFO  - Task                       - Join[33] -> Calc[34] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_2e54324c2d6d30259944e7ab21f8249d_0_0) switched from INITIALIZING to RUNNING.
INFO  - ExecutionGraph             - Join[39] -> Calc[40] (1/1) (a5db4d5da596a9c0b858e30fe60e5a2e_ab06fe1c886f2b2a7030a8ed4a30b46a_0_0) switched from INITIALIZING to RUNNING.
INFO  - ExecutionGraph             - Join[27] -> Calc[28] (1/1) (a5db4d5da596a9c0b858e30fe60e5a2e_55d7dd5010de5a0cb7f3223050a51b73_0_0) switched from INITIALIZING to RUNNING.
INFO  - ExecutionGraph             - Join[33] -> Calc[34] (1/1) (a5db4d5da596a9c0b858e30fe60e5a2e_2e54324c2d6d30259944e7ab21f8249d_0_0) switched from INITIALIZING to RUNNING.
WARN  - RocksDBOperationUtils      - RocksDBStateBackend performance will be poor because of the current Flink memory configuration! RocksDB will flush memtable constantly, causing high IO and CPU. Typically the easiest fix is to increase task manager managed memory size. If running locally, see the parameter taskmanager.memory.managed.size. Details: arenaBlockSize 8388608 > mutableLimit 1957341 (writeBufferSize = 67108864, arenaBlockSizeConfigured = 0, defaultArenaBlockSize = 8388608, writeBufferManagerCapacity = 2236962)
WARN  - RocksDBOperationUtils      - RocksDBStateBackend performance will be poor because of the current Flink memory configuration! RocksDB will flush memtable constantly, causing high IO and CPU. Typically the easiest fix is to increase task manager managed memory size. If running locally, see the parameter taskmanager.memory.managed.size. Details: arenaBlockSize 8388608 > mutableLimit 1957341 (writeBufferSize = 67108864, arenaBlockSizeConfigured = 0, defaultArenaBlockSize = 8388608, writeBufferManagerCapacity = 2236962)
INFO  - Task                       - Join[45] -> Calc[46] -> ConstraintEnforcer[47] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_6d4fd8dcc30b46c08121fc16d7e07e79_0_0) switched from INITIALIZING to RUNNING.
INFO  - ExecutionGraph             - Join[45] -> Calc[46] -> ConstraintEnforcer[47] (1/1) (a5db4d5da596a9c0b858e30fe60e5a2e_6d4fd8dcc30b46c08121fc16d7e07e79_0_0) switched from INITIALIZING to RUNNING.
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Resetting the last seen epoch of partition openmrs.openmrs.orders-0 to 0 since the associated topicId changed from null to WIAis2x0RmuI-ENNFifZBg
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Cluster ID: 5Yr1SIgYQz-b-dgRabWx4g
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Resetting the last seen epoch of partition openmrs.openmrs.encounter-0 to 0 since the associated topicId changed from null to zWxOkhYORpiMkF36dZ8hdw
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Resetting the last seen epoch of partition openmrs.openmrs.order_type-0 to 0 since the associated topicId changed from null to KZ154hF9T8WKDtYWohjkxQ
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Cluster ID: 5Yr1SIgYQz-b-dgRabWx4g
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Cluster ID: 5Yr1SIgYQz-b-dgRabWx4g
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Resetting the last seen epoch of partition openmrs.openmrs.encounter_type-0 to 0 since the associated topicId changed from null to 3O3oUm5rRvqkLZ4RLoiCYA
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Cluster ID: 5Yr1SIgYQz-b-dgRabWx4g
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Resetting offset for partition openmrs.openmrs.care_setting-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:29092 (id: 1 rack: null)], epoch=0}}.
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Resetting offset for partition openmrs.openmrs.encounter-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:29092 (id: 1 rack: null)], epoch=0}}.
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Resetting offset for partition openmrs.openmrs.orders-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:29092 (id: 1 rack: null)], epoch=0}}.
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Resetting offset for partition openmrs.openmrs.encounter_type-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:29092 (id: 1 rack: null)], epoch=0}}.
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Resetting offset for partition openmrs.openmrs.order_type-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:29092 (id: 1 rack: null)], epoch=0}}.
INFO  - mbeddedRocksDBStateBackend - Getting shared memory for RocksDB: shareScope=SLOT, managed=false
INFO  - mbeddedRocksDBStateBackend - Obtained shared RocksDB cache of size 6710886 bytes
INFO  - DBKeyedStateBackendBuilder - Finished building RocksDB keyed state-backend at /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_1d1394375e4908f94ef8c8210cd9a417_op_SinkUpsertMaterializer_4595a980807a13db332f9917535d0424__1_1__uuid_82150774-3961-4072-97a7-e1857004c6b4.
WARN  - RocksDBOperationUtils      - RocksDBStateBackend performance will be poor because of the current Flink memory configuration! RocksDB will flush memtable constantly, causing high IO and CPU. Typically the easiest fix is to increase task manager managed memory size. If running locally, see the parameter taskmanager.memory.managed.size. Details: arenaBlockSize 8388608 > mutableLimit 1957341 (writeBufferSize = 67108864, arenaBlockSizeConfigured = 0, defaultArenaBlockSize = 8388608, writeBufferManagerCapacity = 2236962)
INFO  - Task                       - SinkMaterializer[47] -> Sink: orders[47] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_4595a980807a13db332f9917535d0424_0_0) switched from INITIALIZING to RUNNING.
INFO  - ExecutionGraph             - SinkMaterializer[47] -> Sink: orders[47] (1/1) (a5db4d5da596a9c0b858e30fe60e5a2e_4595a980807a13db332f9917535d0424_0_0) switched from INITIALIZING to RUNNING.
INFO  - ZooKeeper                  - Session: 0x10009b90d4f0002 closed
INFO  - ClientCnxn                 - EventThread shut down for session: 0x10009b90d4f0002
WARN  - Configuration              - Config uses deprecated configuration key 'high-availability' instead of proper key 'high-availability.type'
INFO  - ZooKeeperUtils             - Enforcing default ACL for ZK connections
INFO  - ZooKeeperUtils             - Using '/flink/default' as Zookeeper namespace.
INFO  - CuratorFrameworkImpl       - Starting
INFO  - ZooKeeper                  - Initiating client connection, connectString=localhost:2181 sessionTimeout=60000 watcher=org.apache.flink.shaded.curator5.org.apache.curator.ConnectionState@6871ca0d
INFO  - ClientCnxnSocket           - jute.maxbuffer value is 1048575 Bytes
INFO  - ClientCnxn                 - zookeeper.request.timeout value is 0. feature enabled=false
INFO  - ClientCnxn                 - Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181.
INFO  - ClientCnxn                 - SASL config status: Will not attempt to authenticate using SASL (unknown error)
INFO  - CuratorFrameworkImpl       - Default schema
INFO  - aultLeaderRetrievalService - Starting DefaultLeaderRetrievalService with ZookeeperLeaderRetrievalDriver{connectionInformationPath='/leader/rest_server/connection_info'}.
INFO  - ClientCnxn                 - Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:52238, server: localhost/0:0:0:0:0:0:0:1:2181
INFO  - ClientCnxn                 - Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, session id = 0x10009b90d4f0003, negotiated timeout = 40000
INFO  - ConnectionStateManager     - State change: CONNECTED
INFO  - EnsembleTracker            - New config event received: {}
INFO  - EnsembleTracker            - New config event received: {}
INFO  - RestClusterClient          - Submitting job 'insert-into_analytics.analytics.concepts' (9deef106e67c2b1f77d94f2e02251d44).
INFO  - StandaloneDispatcher       - Received JobGraph submission 'insert-into_analytics.analytics.concepts' (9deef106e67c2b1f77d94f2e02251d44).
INFO  - StandaloneDispatcher       - Submitting job 'insert-into_analytics.analytics.concepts' (9deef106e67c2b1f77d94f2e02251d44).
INFO  - DefaultJobGraphStore       - Added JobGraph(jobId: 9deef106e67c2b1f77d94f2e02251d44) to ZooKeeperStateHandleStore{namespace='flink/default/jobgraphs'}.
INFO  - faultLeaderElectionService - Starting DefaultLeaderElectionService with org.apache.flink.runtime.leaderelection.MultipleComponentLeaderElectionDriverAdapter@53da95a4.
INFO  - terServiceLeadershipRunner - JobMasterServiceLeadershipRunner for job 9deef106e67c2b1f77d94f2e02251d44 was granted leadership with leader id 3a82a6ce-fb62-4610-b46c-7fb86bd673d4. Creating new JobMasterServiceProcess.
INFO  - AkkaRpcService             - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/rpc/jobmanager_5 .
INFO  - JobMaster                  - Initializing job 'insert-into_analytics.analytics.concepts' (9deef106e67c2b1f77d94f2e02251d44).
INFO  - RestClusterClient          - Successfully submitted job 'insert-into_analytics.analytics.concepts' (9deef106e67c2b1f77d94f2e02251d44) to 'http://localhost:8081'.
INFO  - JobMaster                  - Using restart back off time strategy ExponentialDelayRestartBackoffTimeStrategy(initialBackoffMS=1000, maxBackoffMS=300000, backoffMultiplier=2.0, resetBackoffThresholdMS=3600000, jitterFactor=0.1, currentBackoffMS=1000, lastFailureTimestamp=0) for insert-into_analytics.analytics.concepts (9deef106e67c2b1f77d94f2e02251d44).
INFO  - pletedCheckpointStoreUtils - Recovering checkpoints from ZooKeeperStateHandleStore{namespace='flink/default/jobs/9deef106e67c2b1f77d94f2e02251d44/checkpoints'}.
INFO  - pletedCheckpointStoreUtils - Found 0 checkpoints in ZooKeeperStateHandleStore{namespace='flink/default/jobs/9deef106e67c2b1f77d94f2e02251d44/checkpoints'}.
INFO  - pletedCheckpointStoreUtils - Trying to fetch 0 checkpoints from storage.
INFO  - ZooKeeperUtils             - Initialized DefaultCompletedCheckpointStore in 'ZooKeeperStateHandleStore{namespace='flink/default/jobs/9deef106e67c2b1f77d94f2e02251d44/checkpoints'}' with /checkpoints.
INFO  - ExecutionGraph             - Created execution graph 80aa942084eddc41f7baf859b5ecb269 for job 9deef106e67c2b1f77d94f2e02251d44.
INFO  - JobMaster                  - Running initialization on master for job insert-into_analytics.analytics.concepts (9deef106e67c2b1f77d94f2e02251d44).
INFO  - JobMaster                  - Successfully ran initialization on master in 0 ms.
INFO  - DefaultExecutionTopology   - Built 1 new pipelined regions in 0 ms, total 1 pipelined regions currently.
INFO  - JobMaster                  - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - JobMaster                  - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - JobMaster                  - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - CheckpointCoordinator      - No checkpoint found during restore.
INFO  - JobMaster                  - Using failover strategy org.apache.flink.runtime.executiongraph.failover.flip1.RestartPipelinedRegionFailoverStrategy@555cf60e for insert-into_analytics.analytics.concepts (9deef106e67c2b1f77d94f2e02251d44).
INFO  - aultLeaderRetrievalService - Starting DefaultLeaderRetrievalService with ZookeeperLeaderRetrievalDriver{connectionInformationPath='/resource_manager/connection_info'}.
INFO  - JobMaster                  - Starting execution of job 'insert-into_analytics.analytics.concepts' (9deef106e67c2b1f77d94f2e02251d44) under job master id b46c7fb86bd673d43a82a6cefb624610.
INFO  - SourceCoordinator          - Starting split enumerator for source Source: concept[48].
INFO  - SourceCoordinator          - Starting split enumerator for source Source: concept_reference_source[63].
INFO  - AdminClientConfig          - AdminClientConfig values: 
	bootstrap.servers = [localhost:29092]
	client.dns.lookup = use_all_dns_ips
	client.id = flink-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

INFO  - SourceCoordinator          - Starting split enumerator for source Source: concept_name[69].
INFO  - AdminClientConfig          - AdminClientConfig values: 
	bootstrap.servers = [localhost:29092]
	client.dns.lookup = use_all_dns_ips
	client.id = flink-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

INFO  - SourceCoordinator          - Starting split enumerator for source Source: concept_reference_map[51].
INFO  - SourceCoordinator          - Starting split enumerator for source Source: concept_reference_term[57].
INFO  - AdminClientConfig          - AdminClientConfig values: 
	bootstrap.servers = [localhost:29092]
	client.dns.lookup = use_all_dns_ips
	client.id = flink-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

INFO  - AdminClientConfig          - AdminClientConfig values: 
	bootstrap.servers = [localhost:29092]
	client.dns.lookup = use_all_dns_ips
	client.id = flink-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

INFO  - AdminClientConfig          - AdminClientConfig values: 
	bootstrap.servers = [localhost:29092]
	client.dns.lookup = use_all_dns_ips
	client.id = flink-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

INFO  - JobMaster                  - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
INFO  - ExecutionGraph             - Job insert-into_analytics.analytics.concepts (9deef106e67c2b1f77d94f2e02251d44) switched from state CREATED to RUNNING.
INFO  - ExecutionGraph             - Source: concept[48] -> Calc[49] (1/1) (80aa942084eddc41f7baf859b5ecb269_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to SCHEDULED.
INFO  - ExecutionGraph             - Source: concept_reference_map[51] -> Calc[52] (1/1) (80aa942084eddc41f7baf859b5ecb269_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) switched from CREATED to SCHEDULED.
INFO  - ExecutionGraph             - Source: concept_reference_term[57] -> Calc[58] (1/1) (80aa942084eddc41f7baf859b5ecb269_2963852293169ba90d9d1e7d6308db5c_0_0) switched from CREATED to SCHEDULED.
INFO  - ExecutionGraph             - Source: concept_reference_source[63] -> Calc[64] (1/1) (80aa942084eddc41f7baf859b5ecb269_1171dea6747ab509fdaefbe74f7195af_0_0) switched from CREATED to SCHEDULED.
INFO  - ExecutionGraph             - Source: concept_name[69] -> Calc[70] (1/1) (80aa942084eddc41f7baf859b5ecb269_2fa5fc7df17f61cb0e1946288970d799_0_0) switched from CREATED to SCHEDULED.
INFO  - ExecutionGraph             - Join[54] -> Calc[55] (1/1) (80aa942084eddc41f7baf859b5ecb269_55d7dd5010de5a0cb7f3223050a51b73_0_0) switched from CREATED to SCHEDULED.
WARN  - AdminClientConfig          - The configuration 'key.deserializer' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'value.deserializer' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'enable.auto.commit' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'client.id.prefix' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'group.id' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'auto.offset.reset' was supplied but isn't a known config.
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290631116
INFO  - ExecutionGraph             - Join[60] -> Calc[61] (1/1) (80aa942084eddc41f7baf859b5ecb269_2e54324c2d6d30259944e7ab21f8249d_0_0) switched from CREATED to SCHEDULED.
WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.admin.client:type=app-info,id=flink-enumerator-admin-client
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.admin.KafkaAdminClient.<init>(KafkaAdminClient.java:597)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:539)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:478)
	at org.apache.kafka.clients.admin.Admin.create(Admin.java:133)
	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getKafkaAdminClient(KafkaSourceEnumerator.java:410)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.start(KafkaSourceEnumerator.java:151)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$start$1(SourceCoordinator.java:234)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$runInEventLoop$10(SourceCoordinator.java:458)
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
INFO  - ExecutionGraph             - Join[66] -> Calc[67] (1/1) (80aa942084eddc41f7baf859b5ecb269_ab06fe1c886f2b2a7030a8ed4a30b46a_0_0) switched from CREATED to SCHEDULED.
INFO  - KafkaSourceEnumerator      - Starting the KafkaSourceEnumerator for consumer group flink without periodic partition discovery.
INFO  - ExecutionGraph             - Join[72] -> Calc[73] -> ConstraintEnforcer[74] (1/1) (80aa942084eddc41f7baf859b5ecb269_6d4fd8dcc30b46c08121fc16d7e07e79_0_0) switched from CREATED to SCHEDULED.
INFO  - ExecutionGraph             - SinkMaterializer[74] -> Sink: concepts[74] (1/1) (80aa942084eddc41f7baf859b5ecb269_4595a980807a13db332f9917535d0424_0_0) switched from CREATED to SCHEDULED.
INFO  - JobMaster                  - Connecting to ResourceManager akka://flink/user/rpc/resourcemanager_1(b46c7fb86bd673d43a82a6cefb624610)
INFO  - JobMaster                  - Resolved ResourceManager address, beginning registration
WARN  - AdminClientConfig          - The configuration 'key.deserializer' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'value.deserializer' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'enable.auto.commit' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'client.id.prefix' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'group.id' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'auto.offset.reset' was supplied but isn't a known config.
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290631119
WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.admin.client:type=app-info,id=flink-enumerator-admin-client
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.admin.KafkaAdminClient.<init>(KafkaAdminClient.java:597)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:539)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:478)
	at org.apache.kafka.clients.admin.Admin.create(Admin.java:133)
	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getKafkaAdminClient(KafkaSourceEnumerator.java:410)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.start(KafkaSourceEnumerator.java:151)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$start$1(SourceCoordinator.java:234)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$runInEventLoop$10(SourceCoordinator.java:458)
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
INFO  - aultLeaderRetrievalService - Starting DefaultLeaderRetrievalService with ZookeeperLeaderRetrievalDriver{connectionInformationPath='/9deef106e67c2b1f77d94f2e02251d44/connection_info'}.
INFO  - StandaloneResourceManager  - Registering job manager b46c7fb86bd673d43a82a6cefb624610@akka://flink/user/rpc/jobmanager_5 for job 9deef106e67c2b1f77d94f2e02251d44.
WARN  - AdminClientConfig          - The configuration 'key.deserializer' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'value.deserializer' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'enable.auto.commit' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'client.id.prefix' was supplied but isn't a known config.
INFO  - KafkaSourceEnumerator      - Starting the KafkaSourceEnumerator for consumer group flink without periodic partition discovery.
WARN  - AdminClientConfig          - The configuration 'group.id' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'auto.offset.reset' was supplied but isn't a known config.
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290631120
WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.admin.client:type=app-info,id=flink-enumerator-admin-client
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.admin.KafkaAdminClient.<init>(KafkaAdminClient.java:597)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:539)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:478)
	at org.apache.kafka.clients.admin.Admin.create(Admin.java:133)
	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getKafkaAdminClient(KafkaSourceEnumerator.java:410)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.start(KafkaSourceEnumerator.java:151)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$start$1(SourceCoordinator.java:234)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$runInEventLoop$10(SourceCoordinator.java:458)
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
WARN  - AdminClientConfig          - The configuration 'key.deserializer' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'value.deserializer' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'enable.auto.commit' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'client.id.prefix' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'group.id' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'auto.offset.reset' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'key.deserializer' was supplied but isn't a known config.
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290631121
INFO  - KafkaSourceEnumerator      - Starting the KafkaSourceEnumerator for consumer group flink without periodic partition discovery.
WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.admin.client:type=app-info,id=flink-enumerator-admin-client
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.admin.KafkaAdminClient.<init>(KafkaAdminClient.java:597)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:539)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:478)
	at org.apache.kafka.clients.admin.Admin.create(Admin.java:133)
	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getKafkaAdminClient(KafkaSourceEnumerator.java:410)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.start(KafkaSourceEnumerator.java:151)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$start$1(SourceCoordinator.java:234)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$runInEventLoop$10(SourceCoordinator.java:458)
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
WARN  - AdminClientConfig          - The configuration 'value.deserializer' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'enable.auto.commit' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'client.id.prefix' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'group.id' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'auto.offset.reset' was supplied but isn't a known config.
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290631123
WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.admin.client:type=app-info,id=flink-enumerator-admin-client
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.admin.KafkaAdminClient.<init>(KafkaAdminClient.java:597)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:539)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:478)
	at org.apache.kafka.clients.admin.Admin.create(Admin.java:133)
	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getKafkaAdminClient(KafkaSourceEnumerator.java:410)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.start(KafkaSourceEnumerator.java:151)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$start$1(SourceCoordinator.java:234)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$runInEventLoop$10(SourceCoordinator.java:458)
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
INFO  - KafkaSourceEnumerator      - Starting the KafkaSourceEnumerator for consumer group flink without periodic partition discovery.
INFO  - KafkaSourceEnumerator      - Starting the KafkaSourceEnumerator for consumer group flink without periodic partition discovery.
INFO  - KafkaSourceEnumerator      - Discovered new partitions: [openmrs.openmrs.concept-0]
INFO  - KafkaSourceEnumerator      - Discovered new partitions: [openmrs.openmrs.concept_name-0]
INFO  - KafkaSourceEnumerator      - Discovered new partitions: [openmrs.openmrs.concept_reference_map-0]
INFO  - KafkaSourceEnumerator      - Discovered new partitions: [openmrs.openmrs.concept_reference_term-0]
INFO  - KafkaSourceEnumerator      - Discovered new partitions: [openmrs.openmrs.concept_reference_source-0]
INFO  - StandaloneResourceManager  - Registered job manager b46c7fb86bd673d43a82a6cefb624610@akka://flink/user/rpc/jobmanager_5 for job 9deef106e67c2b1f77d94f2e02251d44.
INFO  - JobMaster                  - JobManager successfully registered at ResourceManager, leader id: b46c7fb86bd673d43a82a6cefb624610.
INFO  - DeclarativeSlotManager     - Received resource requirements from job 9deef106e67c2b1f77d94f2e02251d44: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
INFO  - aultLeaderRetrievalService - Stopping DefaultLeaderRetrievalService.
INFO  - eeperLeaderRetrievalDriver - Closing ZookeeperLeaderRetrievalDriver{connectionInformationPath='/leader/rest_server/connection_info'}.
INFO  - CuratorFrameworkImpl       - backgroundOperationsLoop exiting
INFO  - TaskExecutor               - Receive slot request 3a4745ee6ec4f2015cfc2866daa83bc7 for job 9deef106e67c2b1f77d94f2e02251d44 from resource manager with leader id b46c7fb86bd673d43a82a6cefb624610.
INFO  - TaskExecutor               - Allocated slot for 3a4745ee6ec4f2015cfc2866daa83bc7.
INFO  - DefaultJobLeaderService    - Add job 9deef106e67c2b1f77d94f2e02251d44 for job leader monitoring.
INFO  - aultLeaderRetrievalService - Starting DefaultLeaderRetrievalService with ZookeeperLeaderRetrievalDriver{connectionInformationPath='/9deef106e67c2b1f77d94f2e02251d44/connection_info'}.
INFO  - DefaultJobLeaderService    - Try to register at job manager akka://flink/user/rpc/jobmanager_5 with leader id 3a82a6ce-fb62-4610-b46c-7fb86bd673d4.
INFO  - DefaultJobLeaderService    - Resolved JobManager address, beginning registration
INFO  - DefaultJobLeaderService    - Successful registration at job manager akka://flink/user/rpc/jobmanager_5 for job 9deef106e67c2b1f77d94f2e02251d44.
INFO  - TaskExecutor               - Establish JobManager connection for job 9deef106e67c2b1f77d94f2e02251d44.
INFO  - TaskExecutor               - Offer reserved slots to the leader of job 9deef106e67c2b1f77d94f2e02251d44.
INFO  - ExecutionGraph             - Source: concept[48] -> Calc[49] (1/1) (80aa942084eddc41f7baf859b5ecb269_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - ExecutionGraph             - Deploying Source: concept[48] -> Calc[49] (1/1) (attempt #0) with attempt id 80aa942084eddc41f7baf859b5ecb269_cbc357ccb763df2852fee8c4fc7d55f2_0_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id 3a4745ee6ec4f2015cfc2866daa83bc7
INFO  - ExecutionGraph             - Source: concept_reference_map[51] -> Calc[52] (1/1) (80aa942084eddc41f7baf859b5ecb269_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - ExecutionGraph             - Deploying Source: concept_reference_map[51] -> Calc[52] (1/1) (attempt #0) with attempt id 80aa942084eddc41f7baf859b5ecb269_6cdc5bb954874d922eaee11a8e7b5dd5_0_0 and vertex id 6cdc5bb954874d922eaee11a8e7b5dd5_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id 3a4745ee6ec4f2015cfc2866daa83bc7
INFO  - ExecutionGraph             - Source: concept_reference_term[57] -> Calc[58] (1/1) (80aa942084eddc41f7baf859b5ecb269_2963852293169ba90d9d1e7d6308db5c_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - TaskSlotTableImpl          - Activate slot 3a4745ee6ec4f2015cfc2866daa83bc7.
INFO  - ExecutionGraph             - Deploying Source: concept_reference_term[57] -> Calc[58] (1/1) (attempt #0) with attempt id 80aa942084eddc41f7baf859b5ecb269_2963852293169ba90d9d1e7d6308db5c_0_0 and vertex id 2963852293169ba90d9d1e7d6308db5c_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id 3a4745ee6ec4f2015cfc2866daa83bc7
INFO  - ExecutionGraph             - Source: concept_reference_source[63] -> Calc[64] (1/1) (80aa942084eddc41f7baf859b5ecb269_1171dea6747ab509fdaefbe74f7195af_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - ExecutionGraph             - Deploying Source: concept_reference_source[63] -> Calc[64] (1/1) (attempt #0) with attempt id 80aa942084eddc41f7baf859b5ecb269_1171dea6747ab509fdaefbe74f7195af_0_0 and vertex id 1171dea6747ab509fdaefbe74f7195af_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id 3a4745ee6ec4f2015cfc2866daa83bc7
INFO  - ExecutionGraph             - Source: concept_name[69] -> Calc[70] (1/1) (80aa942084eddc41f7baf859b5ecb269_2fa5fc7df17f61cb0e1946288970d799_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - ExecutionGraph             - Deploying Source: concept_name[69] -> Calc[70] (1/1) (attempt #0) with attempt id 80aa942084eddc41f7baf859b5ecb269_2fa5fc7df17f61cb0e1946288970d799_0_0 and vertex id 2fa5fc7df17f61cb0e1946288970d799_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id 3a4745ee6ec4f2015cfc2866daa83bc7
INFO  - ExecutionGraph             - Join[54] -> Calc[55] (1/1) (80aa942084eddc41f7baf859b5ecb269_55d7dd5010de5a0cb7f3223050a51b73_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - ExecutionGraph             - Deploying Join[54] -> Calc[55] (1/1) (attempt #0) with attempt id 80aa942084eddc41f7baf859b5ecb269_55d7dd5010de5a0cb7f3223050a51b73_0_0 and vertex id 55d7dd5010de5a0cb7f3223050a51b73_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id 3a4745ee6ec4f2015cfc2866daa83bc7
INFO  - tateChangelogStorageLoader - Creating a changelog storage with name 'memory'.
INFO  - tateExecutorFactoryManager - Creating the channel state executor factory for job id 9deef106e67c2b1f77d94f2e02251d44
INFO  - TaskExecutor               - Received task Source: concept[48] -> Calc[49] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_cbc357ccb763df2852fee8c4fc7d55f2_0_0), deploy into slot with allocation id 3a4745ee6ec4f2015cfc2866daa83bc7.
INFO  - Task                       - Source: concept[48] -> Calc[49] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to DEPLOYING.
INFO  - Task                       - Loading JAR files for task Source: concept[48] -> Calc[49] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_cbc357ccb763df2852fee8c4fc7d55f2_0_0) [DEPLOYING].
INFO  - ExecutionGraph             - Join[60] -> Calc[61] (1/1) (80aa942084eddc41f7baf859b5ecb269_2e54324c2d6d30259944e7ab21f8249d_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - ExecutionGraph             - Deploying Join[60] -> Calc[61] (1/1) (attempt #0) with attempt id 80aa942084eddc41f7baf859b5ecb269_2e54324c2d6d30259944e7ab21f8249d_0_0 and vertex id 2e54324c2d6d30259944e7ab21f8249d_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id 3a4745ee6ec4f2015cfc2866daa83bc7
INFO  - TaskSlotTableImpl          - Activate slot 3a4745ee6ec4f2015cfc2866daa83bc7.
INFO  - ExecutionGraph             - Join[66] -> Calc[67] (1/1) (80aa942084eddc41f7baf859b5ecb269_ab06fe1c886f2b2a7030a8ed4a30b46a_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - ExecutionGraph             - Deploying Join[66] -> Calc[67] (1/1) (attempt #0) with attempt id 80aa942084eddc41f7baf859b5ecb269_ab06fe1c886f2b2a7030a8ed4a30b46a_0_0 and vertex id ab06fe1c886f2b2a7030a8ed4a30b46a_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id 3a4745ee6ec4f2015cfc2866daa83bc7
INFO  - TaskExecutor               - Received task Source: concept_reference_map[51] -> Calc[52] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_6cdc5bb954874d922eaee11a8e7b5dd5_0_0), deploy into slot with allocation id 3a4745ee6ec4f2015cfc2866daa83bc7.
INFO  - ExecutionGraph             - Join[72] -> Calc[73] -> ConstraintEnforcer[74] (1/1) (80aa942084eddc41f7baf859b5ecb269_6d4fd8dcc30b46c08121fc16d7e07e79_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - ExecutionGraph             - Deploying Join[72] -> Calc[73] -> ConstraintEnforcer[74] (1/1) (attempt #0) with attempt id 80aa942084eddc41f7baf859b5ecb269_6d4fd8dcc30b46c08121fc16d7e07e79_0_0 and vertex id 6d4fd8dcc30b46c08121fc16d7e07e79_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id 3a4745ee6ec4f2015cfc2866daa83bc7
INFO  - ExecutionGraph             - SinkMaterializer[74] -> Sink: concepts[74] (1/1) (80aa942084eddc41f7baf859b5ecb269_4595a980807a13db332f9917535d0424_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - ExecutionGraph             - Deploying SinkMaterializer[74] -> Sink: concepts[74] (1/1) (attempt #0) with attempt id 80aa942084eddc41f7baf859b5ecb269_4595a980807a13db332f9917535d0424_0_0 and vertex id 4595a980807a13db332f9917535d0424_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id 3a4745ee6ec4f2015cfc2866daa83bc7
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - Task                       - Source: concept_reference_map[51] -> Calc[52] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) switched from CREATED to DEPLOYING.
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - Task                       - Loading JAR files for task Source: concept_reference_map[51] -> Calc[52] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) [DEPLOYING].
INFO  - TaskSlotTableImpl          - Activate slot 3a4745ee6ec4f2015cfc2866daa83bc7.
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - TaskExecutor               - Received task Source: concept_reference_term[57] -> Calc[58] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_2963852293169ba90d9d1e7d6308db5c_0_0), deploy into slot with allocation id 3a4745ee6ec4f2015cfc2866daa83bc7.
INFO  - Task                       - Source: concept[48] -> Calc[49] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - TaskSlotTableImpl          - Activate slot 3a4745ee6ec4f2015cfc2866daa83bc7.
INFO  - Task                       - Source: concept_reference_term[57] -> Calc[58] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_2963852293169ba90d9d1e7d6308db5c_0_0) switched from CREATED to DEPLOYING.
INFO  - Task                       - Loading JAR files for task Source: concept_reference_term[57] -> Calc[58] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_2963852293169ba90d9d1e7d6308db5c_0_0) [DEPLOYING].
INFO  - ExecutionGraph             - Source: concept[48] -> Calc[49] (1/1) (80aa942084eddc41f7baf859b5ecb269_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - TaskExecutor               - Received task Source: concept_name[69] -> Calc[70] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_2fa5fc7df17f61cb0e1946288970d799_0_0), deploy into slot with allocation id 3a4745ee6ec4f2015cfc2866daa83bc7.
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - Task                       - Source: concept_name[69] -> Calc[70] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_2fa5fc7df17f61cb0e1946288970d799_0_0) switched from CREATED to DEPLOYING.
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - TaskSlotTableImpl          - Activate slot 3a4745ee6ec4f2015cfc2866daa83bc7.
INFO  - Task                       - Loading JAR files for task Source: concept_name[69] -> Calc[70] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_2fa5fc7df17f61cb0e1946288970d799_0_0) [DEPLOYING].
INFO  - Task                       - Source: concept_reference_map[51] -> Calc[52] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - TaskExecutor               - Received task Source: concept_reference_source[63] -> Calc[64] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_1171dea6747ab509fdaefbe74f7195af_0_0), deploy into slot with allocation id 3a4745ee6ec4f2015cfc2866daa83bc7.
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - Task                       - Source: concept_reference_term[57] -> Calc[58] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_2963852293169ba90d9d1e7d6308db5c_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - ExecutionGraph             - Source: concept_reference_map[51] -> Calc[52] (1/1) (80aa942084eddc41f7baf859b5ecb269_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - ExecutionGraph             - Source: concept_reference_term[57] -> Calc[58] (1/1) (80aa942084eddc41f7baf859b5ecb269_2963852293169ba90d9d1e7d6308db5c_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - TaskSlotTableImpl          - Activate slot 3a4745ee6ec4f2015cfc2866daa83bc7.
INFO  - Task                       - Source: concept_reference_source[63] -> Calc[64] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_1171dea6747ab509fdaefbe74f7195af_0_0) switched from CREATED to DEPLOYING.
INFO  - Task                       - Loading JAR files for task Source: concept_reference_source[63] -> Calc[64] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_1171dea6747ab509fdaefbe74f7195af_0_0) [DEPLOYING].
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - Task                       - Source: concept_name[69] -> Calc[70] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_2fa5fc7df17f61cb0e1946288970d799_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - ExecutionGraph             - Source: concept_name[69] -> Calc[70] (1/1) (80aa942084eddc41f7baf859b5ecb269_2fa5fc7df17f61cb0e1946288970d799_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - Task                       - Source: concept_reference_source[63] -> Calc[64] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_1171dea6747ab509fdaefbe74f7195af_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - ExecutionGraph             - Source: concept_reference_source[63] -> Calc[64] (1/1) (80aa942084eddc41f7baf859b5ecb269_1171dea6747ab509fdaefbe74f7195af_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - TaskExecutor               - Received task Join[54] -> Calc[55] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_55d7dd5010de5a0cb7f3223050a51b73_0_0), deploy into slot with allocation id 3a4745ee6ec4f2015cfc2866daa83bc7.
INFO  - TaskSlotTableImpl          - Activate slot 3a4745ee6ec4f2015cfc2866daa83bc7.
INFO  - Task                       - Join[54] -> Calc[55] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_55d7dd5010de5a0cb7f3223050a51b73_0_0) switched from CREATED to DEPLOYING.
INFO  - Task                       - Loading JAR files for task Join[54] -> Calc[55] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_55d7dd5010de5a0cb7f3223050a51b73_0_0) [DEPLOYING].
INFO  - TaskExecutor               - Received task Join[60] -> Calc[61] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_2e54324c2d6d30259944e7ab21f8249d_0_0), deploy into slot with allocation id 3a4745ee6ec4f2015cfc2866daa83bc7.
INFO  - Task                       - Join[60] -> Calc[61] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_2e54324c2d6d30259944e7ab21f8249d_0_0) switched from CREATED to DEPLOYING.
INFO  - Task                       - Loading JAR files for task Join[60] -> Calc[61] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_2e54324c2d6d30259944e7ab21f8249d_0_0) [DEPLOYING].
INFO  - TaskSlotTableImpl          - Activate slot 3a4745ee6ec4f2015cfc2866daa83bc7.
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - Task                       - Join[54] -> Calc[55] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_55d7dd5010de5a0cb7f3223050a51b73_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - ExecutionGraph             - Join[54] -> Calc[55] (1/1) (80aa942084eddc41f7baf859b5ecb269_55d7dd5010de5a0cb7f3223050a51b73_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - Task                       - Join[60] -> Calc[61] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_2e54324c2d6d30259944e7ab21f8249d_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - TaskExecutor               - Received task Join[66] -> Calc[67] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_ab06fe1c886f2b2a7030a8ed4a30b46a_0_0), deploy into slot with allocation id 3a4745ee6ec4f2015cfc2866daa83bc7.
INFO  - TaskSlotTableImpl          - Activate slot 3a4745ee6ec4f2015cfc2866daa83bc7.
INFO  - ExecutionGraph             - Join[60] -> Calc[61] (1/1) (80aa942084eddc41f7baf859b5ecb269_2e54324c2d6d30259944e7ab21f8249d_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - Task                       - Join[66] -> Calc[67] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_ab06fe1c886f2b2a7030a8ed4a30b46a_0_0) switched from CREATED to DEPLOYING.
INFO  - Task                       - Loading JAR files for task Join[66] -> Calc[67] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_ab06fe1c886f2b2a7030a8ed4a30b46a_0_0) [DEPLOYING].
INFO  - TaskExecutor               - Received task Join[72] -> Calc[73] -> ConstraintEnforcer[74] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_6d4fd8dcc30b46c08121fc16d7e07e79_0_0), deploy into slot with allocation id 3a4745ee6ec4f2015cfc2866daa83bc7.
INFO  - Task                       - Join[72] -> Calc[73] -> ConstraintEnforcer[74] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_6d4fd8dcc30b46c08121fc16d7e07e79_0_0) switched from CREATED to DEPLOYING.
INFO  - Task                       - Loading JAR files for task Join[72] -> Calc[73] -> ConstraintEnforcer[74] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_6d4fd8dcc30b46c08121fc16d7e07e79_0_0) [DEPLOYING].
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - TaskSlotTableImpl          - Activate slot 3a4745ee6ec4f2015cfc2866daa83bc7.
INFO  - TaskSlotTableImpl          - Activate slot 3a4745ee6ec4f2015cfc2866daa83bc7.
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - Task                       - Join[72] -> Calc[73] -> ConstraintEnforcer[74] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_6d4fd8dcc30b46c08121fc16d7e07e79_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - Task                       - Join[66] -> Calc[67] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_ab06fe1c886f2b2a7030a8ed4a30b46a_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - ExecutionGraph             - Join[66] -> Calc[67] (1/1) (80aa942084eddc41f7baf859b5ecb269_ab06fe1c886f2b2a7030a8ed4a30b46a_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - ExecutionGraph             - Join[72] -> Calc[73] -> ConstraintEnforcer[74] (1/1) (80aa942084eddc41f7baf859b5ecb269_6d4fd8dcc30b46c08121fc16d7e07e79_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - SourceCoordinator          - Source Source: concept_reference_map[51] registering reader for parallel task 0 (#0) @ 
INFO  - KafkaSourceEnumerator      - Assigning splits to readers {0=[[Partition: openmrs.openmrs.concept_reference_map-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}
INFO  - TaskExecutor               - Received task SinkMaterializer[74] -> Sink: concepts[74] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_4595a980807a13db332f9917535d0424_0_0), deploy into slot with allocation id 3a4745ee6ec4f2015cfc2866daa83bc7.
INFO  - SourceCoordinator          - Source Source: concept_name[69] registering reader for parallel task 0 (#0) @ 
INFO  - KafkaSourceEnumerator      - Assigning splits to readers {0=[[Partition: openmrs.openmrs.concept_name-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}
INFO  - Task                       - Source: concept_reference_map[51] -> Calc[52] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) switched from INITIALIZING to RUNNING.
INFO  - SourceCoordinator          - Source Source: concept_reference_source[63] registering reader for parallel task 0 (#0) @ 
INFO  - KafkaSourceEnumerator      - Assigning splits to readers {0=[[Partition: openmrs.openmrs.concept_reference_source-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}
INFO  - ExecutionGraph             - Source: concept_reference_map[51] -> Calc[52] (1/1) (80aa942084eddc41f7baf859b5ecb269_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) switched from INITIALIZING to RUNNING.
INFO  - SourceCoordinator          - Source Source: concept_reference_term[57] registering reader for parallel task 0 (#0) @ 
INFO  - KafkaSourceEnumerator      - Assigning splits to readers {0=[[Partition: openmrs.openmrs.concept_reference_term-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}
INFO  - Task                       - Source: concept_reference_term[57] -> Calc[58] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_2963852293169ba90d9d1e7d6308db5c_0_0) switched from INITIALIZING to RUNNING.
INFO  - ExecutionGraph             - Source: concept_reference_term[57] -> Calc[58] (1/1) (80aa942084eddc41f7baf859b5ecb269_2963852293169ba90d9d1e7d6308db5c_0_0) switched from INITIALIZING to RUNNING.
INFO  - SourceCoordinator          - Source Source: concept[48] registering reader for parallel task 0 (#0) @ 
INFO  - mbeddedRocksDBStateBackend - Getting shared memory for RocksDB: shareScope=SLOT, managed=false
INFO  - KafkaSourceEnumerator      - Assigning splits to readers {0=[[Partition: openmrs.openmrs.concept-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}
INFO  - mbeddedRocksDBStateBackend - Obtained shared RocksDB cache of size 6710886 bytes
INFO  - Task                       - Source: concept_reference_source[63] -> Calc[64] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_1171dea6747ab509fdaefbe74f7195af_0_0) switched from INITIALIZING to RUNNING.
INFO  - ExecutionGraph             - Source: concept_reference_source[63] -> Calc[64] (1/1) (80aa942084eddc41f7baf859b5ecb269_1171dea6747ab509fdaefbe74f7195af_0_0) switched from INITIALIZING to RUNNING.
INFO  - Task                       - Source: concept_name[69] -> Calc[70] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_2fa5fc7df17f61cb0e1946288970d799_0_0) switched from INITIALIZING to RUNNING.
INFO  - ExecutionGraph             - Source: concept_name[69] -> Calc[70] (1/1) (80aa942084eddc41f7baf859b5ecb269_2fa5fc7df17f61cb0e1946288970d799_0_0) switched from INITIALIZING to RUNNING.
INFO  - Task                       - SinkMaterializer[74] -> Sink: concepts[74] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_4595a980807a13db332f9917535d0424_0_0) switched from CREATED to DEPLOYING.
INFO  - Task                       - Loading JAR files for task SinkMaterializer[74] -> Sink: concepts[74] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_4595a980807a13db332f9917535d0424_0_0) [DEPLOYING].
INFO  - mbeddedRocksDBStateBackend - Getting shared memory for RocksDB: shareScope=SLOT, managed=false
INFO  - mbeddedRocksDBStateBackend - Obtained shared RocksDB cache of size 6710886 bytes
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - SourceReaderBase           - Adding split(s) to reader: [[Partition: openmrs.openmrs.concept_reference_map-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - SourceReaderBase           - Adding split(s) to reader: [[Partition: openmrs.openmrs.concept_name-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]
INFO  - ConsumerConfig             - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = flink-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

INFO  - Task                       - SinkMaterializer[74] -> Sink: concepts[74] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_4595a980807a13db332f9917535d0424_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - SourceReaderBase           - Adding split(s) to reader: [[Partition: openmrs.openmrs.concept_reference_term-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]
INFO  - ConsumerConfig             - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = flink-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

INFO  - ExecutionGraph             - SinkMaterializer[74] -> Sink: concepts[74] (1/1) (80aa942084eddc41f7baf859b5ecb269_4595a980807a13db332f9917535d0424_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - ConsumerConfig             - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = flink-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

INFO  - SourceReaderBase           - Adding split(s) to reader: [[Partition: openmrs.openmrs.concept_reference_source-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]
INFO  - ConsumerConfig             - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = flink-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

WARN  - ConsumerConfig             - The configuration 'client.id.prefix' was supplied but isn't a known config.
WARN  - ConsumerConfig             - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290631236
WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.consumer:type=app-info,id=flink-0
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:816)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:666)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:647)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:627)
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.<init>(KafkaPartitionSplitReader.java:88)
	at org.apache.flink.connector.kafka.source.KafkaSource.lambda$createReader$1(KafkaSource.java:160)
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager.createSplitFetcher(SplitFetcherManager.java:196)
	at org.apache.flink.connector.base.source.reader.fetcher.SingleThreadFetcherManager.addSplits(SingleThreadFetcherManager.java:107)
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.addSplits(SourceReaderBase.java:242)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleAddSplitsEvent(SourceOperator.java:584)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleOperatorEvent(SourceOperator.java:561)
	at org.apache.flink.streaming.runtime.tasks.OperatorEventDispatcherImpl.dispatchEventToHandlers(OperatorEventDispatcherImpl.java:72)
	at org.apache.flink.streaming.runtime.tasks.RegularOperatorChain.dispatchOperatorEvent(RegularOperatorChain.java:80)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$dispatchOperatorEvent$20(StreamTask.java:1473)
	at org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$1.runThrowing(StreamTaskActionExecutor.java:50)
	at org.apache.flink.streaming.runtime.tasks.mailbox.Mail.run(Mail.java:90)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMail(MailboxProcessor.java:398)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMailsWhenDefaultActionUnavailable(MailboxProcessor.java:367)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMail(MailboxProcessor.java:352)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:229)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:839)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:788)
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:952)
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:931)
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:745)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:562)
	at java.base/java.lang.Thread.run(Thread.java:829)
INFO  - DBKeyedStateBackendBuilder - Finished building RocksDB keyed state-backend at /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_9deef106e67c2b1f77d94f2e02251d44_op_StreamingJoinOperator_55d7dd5010de5a0cb7f3223050a51b73__1_1__uuid_0a0c929e-3274-4bf4-9e84-2dd433c44390.
WARN  - ConsumerConfig             - The configuration 'client.id.prefix' was supplied but isn't a known config.
WARN  - ConsumerConfig             - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290631237
WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.consumer:type=app-info,id=flink-0
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:816)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:666)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:647)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:627)
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.<init>(KafkaPartitionSplitReader.java:88)
	at org.apache.flink.connector.kafka.source.KafkaSource.lambda$createReader$1(KafkaSource.java:160)
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager.createSplitFetcher(SplitFetcherManager.java:196)
	at org.apache.flink.connector.base.source.reader.fetcher.SingleThreadFetcherManager.addSplits(SingleThreadFetcherManager.java:107)
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.addSplits(SourceReaderBase.java:242)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleAddSplitsEvent(SourceOperator.java:584)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleOperatorEvent(SourceOperator.java:561)
	at org.apache.flink.streaming.runtime.tasks.OperatorEventDispatcherImpl.dispatchEventToHandlers(OperatorEventDispatcherImpl.java:72)
	at org.apache.flink.streaming.runtime.tasks.RegularOperatorChain.dispatchOperatorEvent(RegularOperatorChain.java:80)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$dispatchOperatorEvent$20(StreamTask.java:1473)
	at org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$1.runThrowing(StreamTaskActionExecutor.java:50)
	at org.apache.flink.streaming.runtime.tasks.mailbox.Mail.run(Mail.java:90)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMail(MailboxProcessor.java:398)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMailsWhenDefaultActionUnavailable(MailboxProcessor.java:367)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMail(MailboxProcessor.java:352)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:229)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:839)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:788)
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:952)
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:931)
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:745)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:562)
	at java.base/java.lang.Thread.run(Thread.java:829)
INFO  - DBKeyedStateBackendBuilder - Finished building RocksDB keyed state-backend at /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_9deef106e67c2b1f77d94f2e02251d44_op_StreamingJoinOperator_2e54324c2d6d30259944e7ab21f8249d__1_1__uuid_c2b36257-c314-4fa2-bda0-79bf040f0528.
INFO  - SplitFetcher               - Starting split fetcher 0
WARN  - RocksDBOperationUtils      - RocksDBStateBackend performance will be poor because of the current Flink memory configuration! RocksDB will flush memtable constantly, causing high IO and CPU. Typically the easiest fix is to increase task manager managed memory size. If running locally, see the parameter taskmanager.memory.managed.size. Details: arenaBlockSize 8388608 > mutableLimit 1957341 (writeBufferSize = 67108864, arenaBlockSizeConfigured = 0, defaultArenaBlockSize = 8388608, writeBufferManagerCapacity = 2236962)
INFO  - mbeddedRocksDBStateBackend - Getting shared memory for RocksDB: shareScope=SLOT, managed=false
INFO  - mbeddedRocksDBStateBackend - Obtained shared RocksDB cache of size 6710886 bytes
WARN  - RocksDBOperationUtils      - RocksDBStateBackend performance will be poor because of the current Flink memory configuration! RocksDB will flush memtable constantly, causing high IO and CPU. Typically the easiest fix is to increase task manager managed memory size. If running locally, see the parameter taskmanager.memory.managed.size. Details: arenaBlockSize 8388608 > mutableLimit 1957341 (writeBufferSize = 67108864, arenaBlockSizeConfigured = 0, defaultArenaBlockSize = 8388608, writeBufferManagerCapacity = 2236962)
WARN  - ConsumerConfig             - The configuration 'client.id.prefix' was supplied but isn't a known config.
WARN  - ConsumerConfig             - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290631239
WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.consumer:type=app-info,id=flink-0
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:816)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:666)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:647)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:627)
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.<init>(KafkaPartitionSplitReader.java:88)
	at org.apache.flink.connector.kafka.source.KafkaSource.lambda$createReader$1(KafkaSource.java:160)
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager.createSplitFetcher(SplitFetcherManager.java:196)
	at org.apache.flink.connector.base.source.reader.fetcher.SingleThreadFetcherManager.addSplits(SingleThreadFetcherManager.java:107)
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.addSplits(SourceReaderBase.java:242)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleAddSplitsEvent(SourceOperator.java:584)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleOperatorEvent(SourceOperator.java:561)
	at org.apache.flink.streaming.runtime.tasks.OperatorEventDispatcherImpl.dispatchEventToHandlers(OperatorEventDispatcherImpl.java:72)
	at org.apache.flink.streaming.runtime.tasks.RegularOperatorChain.dispatchOperatorEvent(RegularOperatorChain.java:80)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$dispatchOperatorEvent$20(StreamTask.java:1473)
	at org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$1.runThrowing(StreamTaskActionExecutor.java:50)
	at org.apache.flink.streaming.runtime.tasks.mailbox.Mail.run(Mail.java:90)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMail(MailboxProcessor.java:398)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMailsWhenDefaultActionUnavailable(MailboxProcessor.java:367)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMail(MailboxProcessor.java:352)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:229)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:839)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:788)
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:952)
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:931)
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:745)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:562)
	at java.base/java.lang.Thread.run(Thread.java:829)
INFO  - Task                       - Source: concept[48] -> Calc[49] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
INFO  - mbeddedRocksDBStateBackend - Getting shared memory for RocksDB: shareScope=SLOT, managed=false
INFO  - mbeddedRocksDBStateBackend - Obtained shared RocksDB cache of size 6710886 bytes
INFO  - SourceReaderBase           - Adding split(s) to reader: [[Partition: openmrs.openmrs.concept-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]
INFO  - ExecutionGraph             - Source: concept[48] -> Calc[49] (1/1) (80aa942084eddc41f7baf859b5ecb269_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
INFO  - SplitFetcher               - Starting split fetcher 0
WARN  - ConsumerConfig             - The configuration 'client.id.prefix' was supplied but isn't a known config.
WARN  - ConsumerConfig             - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290631240
WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.consumer:type=app-info,id=flink-0
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:816)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:666)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:647)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:627)
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.<init>(KafkaPartitionSplitReader.java:88)
	at org.apache.flink.connector.kafka.source.KafkaSource.lambda$createReader$1(KafkaSource.java:160)
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager.createSplitFetcher(SplitFetcherManager.java:196)
	at org.apache.flink.connector.base.source.reader.fetcher.SingleThreadFetcherManager.addSplits(SingleThreadFetcherManager.java:107)
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.addSplits(SourceReaderBase.java:242)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleAddSplitsEvent(SourceOperator.java:584)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleOperatorEvent(SourceOperator.java:561)
	at org.apache.flink.streaming.runtime.tasks.OperatorEventDispatcherImpl.dispatchEventToHandlers(OperatorEventDispatcherImpl.java:72)
	at org.apache.flink.streaming.runtime.tasks.RegularOperatorChain.dispatchOperatorEvent(RegularOperatorChain.java:80)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$dispatchOperatorEvent$20(StreamTask.java:1473)
	at org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$1.runThrowing(StreamTaskActionExecutor.java:50)
	at org.apache.flink.streaming.runtime.tasks.mailbox.Mail.run(Mail.java:90)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMail(MailboxProcessor.java:398)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMailsWhenDefaultActionUnavailable(MailboxProcessor.java:367)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMail(MailboxProcessor.java:352)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:229)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:839)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:788)
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:952)
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:931)
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:745)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:562)
	at java.base/java.lang.Thread.run(Thread.java:829)
INFO  - ConsumerConfig             - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = flink-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

WARN  - RocksDBOperationUtils      - RocksDBStateBackend performance will be poor because of the current Flink memory configuration! RocksDB will flush memtable constantly, causing high IO and CPU. Typically the easiest fix is to increase task manager managed memory size. If running locally, see the parameter taskmanager.memory.managed.size. Details: arenaBlockSize 8388608 > mutableLimit 1957341 (writeBufferSize = 67108864, arenaBlockSizeConfigured = 0, defaultArenaBlockSize = 8388608, writeBufferManagerCapacity = 2236962)
WARN  - RocksDBOperationUtils      - RocksDBStateBackend performance will be poor because of the current Flink memory configuration! RocksDB will flush memtable constantly, causing high IO and CPU. Typically the easiest fix is to increase task manager managed memory size. If running locally, see the parameter taskmanager.memory.managed.size. Details: arenaBlockSize 8388608 > mutableLimit 1957341 (writeBufferSize = 67108864, arenaBlockSizeConfigured = 0, defaultArenaBlockSize = 8388608, writeBufferManagerCapacity = 2236962)
INFO  - SplitFetcher               - Starting split fetcher 0
WARN  - ConsumerConfig             - The configuration 'client.id.prefix' was supplied but isn't a known config.
WARN  - ConsumerConfig             - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290631242
WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.consumer:type=app-info,id=flink-0
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:816)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:666)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:647)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:627)
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.<init>(KafkaPartitionSplitReader.java:88)
	at org.apache.flink.connector.kafka.source.KafkaSource.lambda$createReader$1(KafkaSource.java:160)
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager.createSplitFetcher(SplitFetcherManager.java:196)
	at org.apache.flink.connector.base.source.reader.fetcher.SingleThreadFetcherManager.addSplits(SingleThreadFetcherManager.java:107)
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.addSplits(SourceReaderBase.java:242)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleAddSplitsEvent(SourceOperator.java:584)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleOperatorEvent(SourceOperator.java:561)
	at org.apache.flink.streaming.runtime.tasks.OperatorEventDispatcherImpl.dispatchEventToHandlers(OperatorEventDispatcherImpl.java:72)
	at org.apache.flink.streaming.runtime.tasks.RegularOperatorChain.dispatchOperatorEvent(RegularOperatorChain.java:80)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$dispatchOperatorEvent$20(StreamTask.java:1473)
	at org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$1.runThrowing(StreamTaskActionExecutor.java:50)
	at org.apache.flink.streaming.runtime.tasks.mailbox.Mail.run(Mail.java:90)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMail(MailboxProcessor.java:398)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMailsNonBlocking(MailboxProcessor.java:383)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMail(MailboxProcessor.java:345)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:229)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:839)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:788)
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:952)
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:931)
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:745)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:562)
	at java.base/java.lang.Thread.run(Thread.java:829)
INFO  - SplitFetcher               - Starting split fetcher 0
INFO  - DBKeyedStateBackendBuilder - Finished building RocksDB keyed state-backend at /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_9deef106e67c2b1f77d94f2e02251d44_op_StreamingJoinOperator_ab06fe1c886f2b2a7030a8ed4a30b46a__1_1__uuid_5bd3fab9-09c1-4b85-b0ab-a24d8d861204.
INFO  - SplitFetcher               - Starting split fetcher 0
INFO  - ZooKeeper                  - Session: 0x10009b90d4f0003 closed
INFO  - ClientCnxn                 - EventThread shut down for session: 0x10009b90d4f0003
INFO  - KafkaConsumer              - [Consumer clientId=flink-0, groupId=flink] Subscribed to partition(s): openmrs.openmrs.concept_reference_source-0
INFO  - KafkaConsumer              - [Consumer clientId=flink-0, groupId=flink] Subscribed to partition(s): openmrs.openmrs.concept_reference_map-0
INFO  - KafkaConsumer              - [Consumer clientId=flink-0, groupId=flink] Subscribed to partition(s): openmrs.openmrs.concept_reference_term-0
INFO  - DBKeyedStateBackendBuilder - Finished building RocksDB keyed state-backend at /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_9deef106e67c2b1f77d94f2e02251d44_op_StreamingJoinOperator_6d4fd8dcc30b46c08121fc16d7e07e79__1_1__uuid_e8bcb993-885c-451e-9c59-2fc082124329.
INFO  - KafkaConsumer              - [Consumer clientId=flink-0, groupId=flink] Subscribed to partition(s): openmrs.openmrs.concept_name-0
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Seeking to EARLIEST offset of partition openmrs.openmrs.concept_reference_source-0
INFO  - KafkaConsumer              - [Consumer clientId=flink-0, groupId=flink] Subscribed to partition(s): openmrs.openmrs.concept-0
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Seeking to EARLIEST offset of partition openmrs.openmrs.concept_reference_term-0
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Seeking to EARLIEST offset of partition openmrs.openmrs.concept_name-0
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Seeking to EARLIEST offset of partition openmrs.openmrs.concept_reference_map-0
WARN  - RocksDBOperationUtils      - RocksDBStateBackend performance will be poor because of the current Flink memory configuration! RocksDB will flush memtable constantly, causing high IO and CPU. Typically the easiest fix is to increase task manager managed memory size. If running locally, see the parameter taskmanager.memory.managed.size. Details: arenaBlockSize 8388608 > mutableLimit 1957341 (writeBufferSize = 67108864, arenaBlockSizeConfigured = 0, defaultArenaBlockSize = 8388608, writeBufferManagerCapacity = 2236962)
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Seeking to EARLIEST offset of partition openmrs.openmrs.concept-0
WARN  - RocksDBOperationUtils      - RocksDBStateBackend performance will be poor because of the current Flink memory configuration! RocksDB will flush memtable constantly, causing high IO and CPU. Typically the easiest fix is to increase task manager managed memory size. If running locally, see the parameter taskmanager.memory.managed.size. Details: arenaBlockSize 8388608 > mutableLimit 1957341 (writeBufferSize = 67108864, arenaBlockSizeConfigured = 0, defaultArenaBlockSize = 8388608, writeBufferManagerCapacity = 2236962)
INFO  - Task                       - Join[60] -> Calc[61] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_2e54324c2d6d30259944e7ab21f8249d_0_0) switched from INITIALIZING to RUNNING.
INFO  - ExecutionGraph             - Join[60] -> Calc[61] (1/1) (80aa942084eddc41f7baf859b5ecb269_2e54324c2d6d30259944e7ab21f8249d_0_0) switched from INITIALIZING to RUNNING.
WARN  - RocksDBOperationUtils      - RocksDBStateBackend performance will be poor because of the current Flink memory configuration! RocksDB will flush memtable constantly, causing high IO and CPU. Typically the easiest fix is to increase task manager managed memory size. If running locally, see the parameter taskmanager.memory.managed.size. Details: arenaBlockSize 8388608 > mutableLimit 1957341 (writeBufferSize = 67108864, arenaBlockSizeConfigured = 0, defaultArenaBlockSize = 8388608, writeBufferManagerCapacity = 2236962)
WARN  - RocksDBOperationUtils      - RocksDBStateBackend performance will be poor because of the current Flink memory configuration! RocksDB will flush memtable constantly, causing high IO and CPU. Typically the easiest fix is to increase task manager managed memory size. If running locally, see the parameter taskmanager.memory.managed.size. Details: arenaBlockSize 8388608 > mutableLimit 1957341 (writeBufferSize = 67108864, arenaBlockSizeConfigured = 0, defaultArenaBlockSize = 8388608, writeBufferManagerCapacity = 2236962)
INFO  - Task                       - Join[54] -> Calc[55] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_55d7dd5010de5a0cb7f3223050a51b73_0_0) switched from INITIALIZING to RUNNING.
INFO  - ExecutionGraph             - Join[54] -> Calc[55] (1/1) (80aa942084eddc41f7baf859b5ecb269_55d7dd5010de5a0cb7f3223050a51b73_0_0) switched from INITIALIZING to RUNNING.
INFO  - Task                       - Join[72] -> Calc[73] -> ConstraintEnforcer[74] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_6d4fd8dcc30b46c08121fc16d7e07e79_0_0) switched from INITIALIZING to RUNNING.
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Resetting the last seen epoch of partition openmrs.openmrs.concept_reference_source-0 to 0 since the associated topicId changed from null to Bk3mblErR16tHJfziMo-Bg
INFO  - ExecutionGraph             - Join[72] -> Calc[73] -> ConstraintEnforcer[74] (1/1) (80aa942084eddc41f7baf859b5ecb269_6d4fd8dcc30b46c08121fc16d7e07e79_0_0) switched from INITIALIZING to RUNNING.
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Cluster ID: 5Yr1SIgYQz-b-dgRabWx4g
INFO  - Task                       - Join[66] -> Calc[67] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_ab06fe1c886f2b2a7030a8ed4a30b46a_0_0) switched from INITIALIZING to RUNNING.
INFO  - ExecutionGraph             - Join[66] -> Calc[67] (1/1) (80aa942084eddc41f7baf859b5ecb269_ab06fe1c886f2b2a7030a8ed4a30b46a_0_0) switched from INITIALIZING to RUNNING.
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Resetting the last seen epoch of partition openmrs.openmrs.concept-0 to 0 since the associated topicId changed from null to 2eysKeABSC22oZW4SWrq7g
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Cluster ID: 5Yr1SIgYQz-b-dgRabWx4g
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Resetting the last seen epoch of partition openmrs.openmrs.concept_reference_map-0 to 0 since the associated topicId changed from null to LF-xdKN6QGaH7r6AwgrUSg
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Cluster ID: 5Yr1SIgYQz-b-dgRabWx4g
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Resetting the last seen epoch of partition openmrs.openmrs.concept_name-0 to 0 since the associated topicId changed from null to 6V3PMGEHRjG76RMD32edGQ
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Cluster ID: 5Yr1SIgYQz-b-dgRabWx4g
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Resetting offset for partition openmrs.openmrs.concept_reference_source-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:29092 (id: 1 rack: null)], epoch=0}}.
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Resetting the last seen epoch of partition openmrs.openmrs.concept_reference_term-0 to 0 since the associated topicId changed from null to lm-lVMeuSTGt8Xx54iz8VQ
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Cluster ID: 5Yr1SIgYQz-b-dgRabWx4g
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Resetting offset for partition openmrs.openmrs.concept-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:29092 (id: 1 rack: null)], epoch=0}}.
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Resetting offset for partition openmrs.openmrs.concept_reference_map-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:29092 (id: 1 rack: null)], epoch=0}}.
INFO  - mbeddedRocksDBStateBackend - Getting shared memory for RocksDB: shareScope=SLOT, managed=false
INFO  - mbeddedRocksDBStateBackend - Obtained shared RocksDB cache of size 6710886 bytes
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Resetting offset for partition openmrs.openmrs.concept_name-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:29092 (id: 1 rack: null)], epoch=0}}.
INFO  - DBKeyedStateBackendBuilder - Finished building RocksDB keyed state-backend at /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_9deef106e67c2b1f77d94f2e02251d44_op_SinkUpsertMaterializer_4595a980807a13db332f9917535d0424__1_1__uuid_80814085-681b-47ed-972d-ffc8ce8cd50f.
WARN  - RocksDBOperationUtils      - RocksDBStateBackend performance will be poor because of the current Flink memory configuration! RocksDB will flush memtable constantly, causing high IO and CPU. Typically the easiest fix is to increase task manager managed memory size. If running locally, see the parameter taskmanager.memory.managed.size. Details: arenaBlockSize 8388608 > mutableLimit 1957341 (writeBufferSize = 67108864, arenaBlockSizeConfigured = 0, defaultArenaBlockSize = 8388608, writeBufferManagerCapacity = 2236962)
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Resetting offset for partition openmrs.openmrs.concept_reference_term-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:29092 (id: 1 rack: null)], epoch=0}}.
INFO  - Task                       - SinkMaterializer[74] -> Sink: concepts[74] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_4595a980807a13db332f9917535d0424_0_0) switched from INITIALIZING to RUNNING.
INFO  - ExecutionGraph             - SinkMaterializer[74] -> Sink: concepts[74] (1/1) (80aa942084eddc41f7baf859b5ecb269_4595a980807a13db332f9917535d0424_0_0) switched from INITIALIZING to RUNNING.
WARN  - Configuration              - Config uses deprecated configuration key 'high-availability' instead of proper key 'high-availability.type'
INFO  - ZooKeeperUtils             - Enforcing default ACL for ZK connections
INFO  - ZooKeeperUtils             - Using '/flink/default' as Zookeeper namespace.
INFO  - CuratorFrameworkImpl       - Starting
INFO  - ZooKeeper                  - Initiating client connection, connectString=localhost:2181 sessionTimeout=60000 watcher=org.apache.flink.shaded.curator5.org.apache.curator.ConnectionState@49002cba
INFO  - ClientCnxnSocket           - jute.maxbuffer value is 1048575 Bytes
INFO  - ClientCnxn                 - zookeeper.request.timeout value is 0. feature enabled=false
INFO  - CuratorFrameworkImpl       - Default schema
INFO  - aultLeaderRetrievalService - Starting DefaultLeaderRetrievalService with ZookeeperLeaderRetrievalDriver{connectionInformationPath='/leader/rest_server/connection_info'}.
INFO  - ClientCnxn                 - Opening socket connection to server localhost/127.0.0.1:2181.
INFO  - ClientCnxn                 - SASL config status: Will not attempt to authenticate using SASL (unknown error)
INFO  - ClientCnxn                 - Socket connection established, initiating session, client: /127.0.0.1:52267, server: localhost/127.0.0.1:2181
INFO  - RestClusterClient          - Submitting job 'insert-into_analytics.analytics.patients' (3450ce4e11df2cb7a382b3520dc37240).
INFO  - ClientCnxn                 - Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x10009b90d4f0004, negotiated timeout = 40000
INFO  - ConnectionStateManager     - State change: CONNECTED
INFO  - EnsembleTracker            - New config event received: {}
INFO  - EnsembleTracker            - New config event received: {}
INFO  - StandaloneDispatcher       - Received JobGraph submission 'insert-into_analytics.analytics.patients' (3450ce4e11df2cb7a382b3520dc37240).
INFO  - StandaloneDispatcher       - Submitting job 'insert-into_analytics.analytics.patients' (3450ce4e11df2cb7a382b3520dc37240).
INFO  - DefaultJobGraphStore       - Added JobGraph(jobId: 3450ce4e11df2cb7a382b3520dc37240) to ZooKeeperStateHandleStore{namespace='flink/default/jobgraphs'}.
INFO  - faultLeaderElectionService - Starting DefaultLeaderElectionService with org.apache.flink.runtime.leaderelection.MultipleComponentLeaderElectionDriverAdapter@4e9569fc.
INFO  - terServiceLeadershipRunner - JobMasterServiceLeadershipRunner for job 3450ce4e11df2cb7a382b3520dc37240 was granted leadership with leader id 3a82a6ce-fb62-4610-b46c-7fb86bd673d4. Creating new JobMasterServiceProcess.
INFO  - AkkaRpcService             - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/rpc/jobmanager_6 .
INFO  - JobMaster                  - Initializing job 'insert-into_analytics.analytics.patients' (3450ce4e11df2cb7a382b3520dc37240).
INFO  - RestClusterClient          - Successfully submitted job 'insert-into_analytics.analytics.patients' (3450ce4e11df2cb7a382b3520dc37240) to 'http://localhost:8081'.
INFO  - JobMaster                  - Using restart back off time strategy ExponentialDelayRestartBackoffTimeStrategy(initialBackoffMS=1000, maxBackoffMS=300000, backoffMultiplier=2.0, resetBackoffThresholdMS=3600000, jitterFactor=0.1, currentBackoffMS=1000, lastFailureTimestamp=0) for insert-into_analytics.analytics.patients (3450ce4e11df2cb7a382b3520dc37240).
INFO  - pletedCheckpointStoreUtils - Recovering checkpoints from ZooKeeperStateHandleStore{namespace='flink/default/jobs/3450ce4e11df2cb7a382b3520dc37240/checkpoints'}.
INFO  - pletedCheckpointStoreUtils - Found 0 checkpoints in ZooKeeperStateHandleStore{namespace='flink/default/jobs/3450ce4e11df2cb7a382b3520dc37240/checkpoints'}.
INFO  - pletedCheckpointStoreUtils - Trying to fetch 0 checkpoints from storage.
INFO  - ZooKeeperUtils             - Initialized DefaultCompletedCheckpointStore in 'ZooKeeperStateHandleStore{namespace='flink/default/jobs/3450ce4e11df2cb7a382b3520dc37240/checkpoints'}' with /checkpoints.
INFO  - ExecutionGraph             - Created execution graph 588c992944dd31552e175761339ab856 for job 3450ce4e11df2cb7a382b3520dc37240.
INFO  - JobMaster                  - Running initialization on master for job insert-into_analytics.analytics.patients (3450ce4e11df2cb7a382b3520dc37240).
INFO  - JobMaster                  - Successfully ran initialization on master in 0 ms.
INFO  - DefaultExecutionTopology   - Built 1 new pipelined regions in 0 ms, total 1 pipelined regions currently.
INFO  - JobMaster                  - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - JobMaster                  - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - JobMaster                  - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - CheckpointCoordinator      - No checkpoint found during restore.
INFO  - JobMaster                  - Using failover strategy org.apache.flink.runtime.executiongraph.failover.flip1.RestartPipelinedRegionFailoverStrategy@77835586 for insert-into_analytics.analytics.patients (3450ce4e11df2cb7a382b3520dc37240).
INFO  - aultLeaderRetrievalService - Starting DefaultLeaderRetrievalService with ZookeeperLeaderRetrievalDriver{connectionInformationPath='/resource_manager/connection_info'}.
INFO  - JobMaster                  - Starting execution of job 'insert-into_analytics.analytics.patients' (3450ce4e11df2cb7a382b3520dc37240) under job master id b46c7fb86bd673d43a82a6cefb624610.
INFO  - SourceCoordinator          - Starting split enumerator for source Source: patient[75].
INFO  - SourceCoordinator          - Starting split enumerator for source Source: person_address[89].
INFO  - AdminClientConfig          - AdminClientConfig values: 
	bootstrap.servers = [localhost:29092]
	client.dns.lookup = use_all_dns_ips
	client.id = flink-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

WARN  - AdminClientConfig          - The configuration 'key.deserializer' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'value.deserializer' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'enable.auto.commit' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'client.id.prefix' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'group.id' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'auto.offset.reset' was supplied but isn't a known config.
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290631778
WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.admin.client:type=app-info,id=flink-enumerator-admin-client
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.admin.KafkaAdminClient.<init>(KafkaAdminClient.java:597)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:539)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:478)
	at org.apache.kafka.clients.admin.Admin.create(Admin.java:133)
	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getKafkaAdminClient(KafkaSourceEnumerator.java:410)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.start(KafkaSourceEnumerator.java:151)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$start$1(SourceCoordinator.java:234)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$runInEventLoop$10(SourceCoordinator.java:458)
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
INFO  - KafkaSourceEnumerator      - Starting the KafkaSourceEnumerator for consumer group flink without periodic partition discovery.
INFO  - AdminClientConfig          - AdminClientConfig values: 
	bootstrap.servers = [localhost:29092]
	client.dns.lookup = use_all_dns_ips
	client.id = flink-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

WARN  - AdminClientConfig          - The configuration 'key.deserializer' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'value.deserializer' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'enable.auto.commit' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'client.id.prefix' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'group.id' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'auto.offset.reset' was supplied but isn't a known config.
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290631780
WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.admin.client:type=app-info,id=flink-enumerator-admin-client
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.admin.KafkaAdminClient.<init>(KafkaAdminClient.java:597)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:539)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:478)
	at org.apache.kafka.clients.admin.Admin.create(Admin.java:133)
	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getKafkaAdminClient(KafkaSourceEnumerator.java:410)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.start(KafkaSourceEnumerator.java:151)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$start$1(SourceCoordinator.java:234)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$runInEventLoop$10(SourceCoordinator.java:458)
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
INFO  - KafkaSourceEnumerator      - Starting the KafkaSourceEnumerator for consumer group flink without periodic partition discovery.
INFO  - SourceCoordinator          - Starting split enumerator for source Source: patient_identifier[95].
INFO  - AdminClientConfig          - AdminClientConfig values: 
	bootstrap.servers = [localhost:29092]
	client.dns.lookup = use_all_dns_ips
	client.id = flink-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

INFO  - SourceCoordinator          - Starting split enumerator for source Source: person[78].
WARN  - AdminClientConfig          - The configuration 'key.deserializer' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'value.deserializer' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'enable.auto.commit' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'client.id.prefix' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'group.id' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'auto.offset.reset' was supplied but isn't a known config.
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290631783
WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.admin.client:type=app-info,id=flink-enumerator-admin-client
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.admin.KafkaAdminClient.<init>(KafkaAdminClient.java:597)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:539)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:478)
	at org.apache.kafka.clients.admin.Admin.create(Admin.java:133)
	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getKafkaAdminClient(KafkaSourceEnumerator.java:410)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.start(KafkaSourceEnumerator.java:151)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$start$1(SourceCoordinator.java:234)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$runInEventLoop$10(SourceCoordinator.java:458)
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
INFO  - AdminClientConfig          - AdminClientConfig values: 
	bootstrap.servers = [localhost:29092]
	client.dns.lookup = use_all_dns_ips
	client.id = flink-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

INFO  - KafkaSourceEnumerator      - Starting the KafkaSourceEnumerator for consumer group flink without periodic partition discovery.
WARN  - AdminClientConfig          - The configuration 'key.deserializer' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'value.deserializer' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'enable.auto.commit' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'client.id.prefix' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'group.id' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'auto.offset.reset' was supplied but isn't a known config.
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290631785
WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.admin.client:type=app-info,id=flink-enumerator-admin-client
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.admin.KafkaAdminClient.<init>(KafkaAdminClient.java:597)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:539)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:478)
	at org.apache.kafka.clients.admin.Admin.create(Admin.java:133)
	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getKafkaAdminClient(KafkaSourceEnumerator.java:410)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.start(KafkaSourceEnumerator.java:151)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$start$1(SourceCoordinator.java:234)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$runInEventLoop$10(SourceCoordinator.java:458)
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
INFO  - SourceCoordinator          - Starting split enumerator for source Source: person_name[83].
INFO  - KafkaSourceEnumerator      - Starting the KafkaSourceEnumerator for consumer group flink without periodic partition discovery.
INFO  - JobMaster                  - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
INFO  - ExecutionGraph             - Job insert-into_analytics.analytics.patients (3450ce4e11df2cb7a382b3520dc37240) switched from state CREATED to RUNNING.
INFO  - AdminClientConfig          - AdminClientConfig values: 
	bootstrap.servers = [localhost:29092]
	client.dns.lookup = use_all_dns_ips
	client.id = flink-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

WARN  - AdminClientConfig          - The configuration 'key.deserializer' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'value.deserializer' was supplied but isn't a known config.
INFO  - ExecutionGraph             - Source: patient[75] -> Calc[76] (1/1) (588c992944dd31552e175761339ab856_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to SCHEDULED.
WARN  - AdminClientConfig          - The configuration 'enable.auto.commit' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'client.id.prefix' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'group.id' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'auto.offset.reset' was supplied but isn't a known config.
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290631786
WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.admin.client:type=app-info,id=flink-enumerator-admin-client
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.admin.KafkaAdminClient.<init>(KafkaAdminClient.java:597)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:539)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:478)
	at org.apache.kafka.clients.admin.Admin.create(Admin.java:133)
	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getKafkaAdminClient(KafkaSourceEnumerator.java:410)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.start(KafkaSourceEnumerator.java:151)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$start$1(SourceCoordinator.java:234)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$runInEventLoop$10(SourceCoordinator.java:458)
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
INFO  - ExecutionGraph             - Source: person[78] -> Calc[79] (1/1) (588c992944dd31552e175761339ab856_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) switched from CREATED to SCHEDULED.
INFO  - ExecutionGraph             - Source: person_name[83] -> Calc[84] (1/1) (588c992944dd31552e175761339ab856_2963852293169ba90d9d1e7d6308db5c_0_0) switched from CREATED to SCHEDULED.
INFO  - ExecutionGraph             - Source: person_address[89] -> Calc[90] (1/1) (588c992944dd31552e175761339ab856_1171dea6747ab509fdaefbe74f7195af_0_0) switched from CREATED to SCHEDULED.
INFO  - KafkaSourceEnumerator      - Starting the KafkaSourceEnumerator for consumer group flink without periodic partition discovery.
INFO  - ExecutionGraph             - Source: patient_identifier[95] -> Calc[96] (1/1) (588c992944dd31552e175761339ab856_2fa5fc7df17f61cb0e1946288970d799_0_0) switched from CREATED to SCHEDULED.
INFO  - ExecutionGraph             - Join[81] (1/1) (588c992944dd31552e175761339ab856_e6807280e63afa30c980423999b48cc6_0_0) switched from CREATED to SCHEDULED.
INFO  - ExecutionGraph             - Join[86] -> Calc[87] (1/1) (588c992944dd31552e175761339ab856_eb7d99873eea63dacba8fd9c596677e3_0_0) switched from CREATED to SCHEDULED.
INFO  - ExecutionGraph             - Join[92] -> Calc[93] (1/1) (588c992944dd31552e175761339ab856_fa7571c07da635c59ba82f92b55840d8_0_0) switched from CREATED to SCHEDULED.
INFO  - ExecutionGraph             - Join[98] -> Calc[99] -> ConstraintEnforcer[100] (1/1) (588c992944dd31552e175761339ab856_c6adced987710239013e40eb9ab41362_0_0) switched from CREATED to SCHEDULED.
INFO  - ExecutionGraph             - SinkMaterializer[100] -> Sink: patients[100] (1/1) (588c992944dd31552e175761339ab856_4969848647857cea5647cb2eb2d99d6b_0_0) switched from CREATED to SCHEDULED.
INFO  - JobMaster                  - Connecting to ResourceManager akka://flink/user/rpc/resourcemanager_1(b46c7fb86bd673d43a82a6cefb624610)
INFO  - JobMaster                  - Resolved ResourceManager address, beginning registration
INFO  - aultLeaderRetrievalService - Starting DefaultLeaderRetrievalService with ZookeeperLeaderRetrievalDriver{connectionInformationPath='/3450ce4e11df2cb7a382b3520dc37240/connection_info'}.
INFO  - StandaloneResourceManager  - Registering job manager b46c7fb86bd673d43a82a6cefb624610@akka://flink/user/rpc/jobmanager_6 for job 3450ce4e11df2cb7a382b3520dc37240.
INFO  - KafkaSourceEnumerator      - Discovered new partitions: [openmrs.openmrs.patient-0]
INFO  - KafkaSourceEnumerator      - Discovered new partitions: [openmrs.openmrs.person_name-0]
INFO  - KafkaSourceEnumerator      - Discovered new partitions: [openmrs.openmrs.person_address-0]
INFO  - KafkaSourceEnumerator      - Discovered new partitions: [openmrs.openmrs.patient_identifier-0]
INFO  - KafkaSourceEnumerator      - Discovered new partitions: [openmrs.openmrs.person-0]
INFO  - StandaloneResourceManager  - Registered job manager b46c7fb86bd673d43a82a6cefb624610@akka://flink/user/rpc/jobmanager_6 for job 3450ce4e11df2cb7a382b3520dc37240.
INFO  - JobMaster                  - JobManager successfully registered at ResourceManager, leader id: b46c7fb86bd673d43a82a6cefb624610.
INFO  - DeclarativeSlotManager     - Received resource requirements from job 3450ce4e11df2cb7a382b3520dc37240: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
INFO  - aultLeaderRetrievalService - Stopping DefaultLeaderRetrievalService.
INFO  - eeperLeaderRetrievalDriver - Closing ZookeeperLeaderRetrievalDriver{connectionInformationPath='/leader/rest_server/connection_info'}.
INFO  - CuratorFrameworkImpl       - backgroundOperationsLoop exiting
INFO  - TaskExecutor               - Receive slot request bb0d34cb23436eb0f022e71ecc902bf6 for job 3450ce4e11df2cb7a382b3520dc37240 from resource manager with leader id b46c7fb86bd673d43a82a6cefb624610.
INFO  - TaskExecutor               - Allocated slot for bb0d34cb23436eb0f022e71ecc902bf6.
INFO  - DefaultJobLeaderService    - Add job 3450ce4e11df2cb7a382b3520dc37240 for job leader monitoring.
INFO  - aultLeaderRetrievalService - Starting DefaultLeaderRetrievalService with ZookeeperLeaderRetrievalDriver{connectionInformationPath='/3450ce4e11df2cb7a382b3520dc37240/connection_info'}.
INFO  - DefaultJobLeaderService    - Try to register at job manager akka://flink/user/rpc/jobmanager_6 with leader id 3a82a6ce-fb62-4610-b46c-7fb86bd673d4.
INFO  - DefaultJobLeaderService    - Resolved JobManager address, beginning registration
INFO  - DefaultJobLeaderService    - Successful registration at job manager akka://flink/user/rpc/jobmanager_6 for job 3450ce4e11df2cb7a382b3520dc37240.
INFO  - TaskExecutor               - Establish JobManager connection for job 3450ce4e11df2cb7a382b3520dc37240.
INFO  - TaskExecutor               - Offer reserved slots to the leader of job 3450ce4e11df2cb7a382b3520dc37240.
INFO  - ExecutionGraph             - Source: patient[75] -> Calc[76] (1/1) (588c992944dd31552e175761339ab856_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - ExecutionGraph             - Deploying Source: patient[75] -> Calc[76] (1/1) (attempt #0) with attempt id 588c992944dd31552e175761339ab856_cbc357ccb763df2852fee8c4fc7d55f2_0_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id bb0d34cb23436eb0f022e71ecc902bf6
INFO  - ExecutionGraph             - Source: person[78] -> Calc[79] (1/1) (588c992944dd31552e175761339ab856_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - ExecutionGraph             - Deploying Source: person[78] -> Calc[79] (1/1) (attempt #0) with attempt id 588c992944dd31552e175761339ab856_6cdc5bb954874d922eaee11a8e7b5dd5_0_0 and vertex id 6cdc5bb954874d922eaee11a8e7b5dd5_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id bb0d34cb23436eb0f022e71ecc902bf6
INFO  - ExecutionGraph             - Source: person_name[83] -> Calc[84] (1/1) (588c992944dd31552e175761339ab856_2963852293169ba90d9d1e7d6308db5c_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - ExecutionGraph             - Deploying Source: person_name[83] -> Calc[84] (1/1) (attempt #0) with attempt id 588c992944dd31552e175761339ab856_2963852293169ba90d9d1e7d6308db5c_0_0 and vertex id 2963852293169ba90d9d1e7d6308db5c_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id bb0d34cb23436eb0f022e71ecc902bf6
INFO  - ExecutionGraph             - Source: person_address[89] -> Calc[90] (1/1) (588c992944dd31552e175761339ab856_1171dea6747ab509fdaefbe74f7195af_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - ExecutionGraph             - Deploying Source: person_address[89] -> Calc[90] (1/1) (attempt #0) with attempt id 588c992944dd31552e175761339ab856_1171dea6747ab509fdaefbe74f7195af_0_0 and vertex id 1171dea6747ab509fdaefbe74f7195af_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id bb0d34cb23436eb0f022e71ecc902bf6
INFO  - ExecutionGraph             - Source: patient_identifier[95] -> Calc[96] (1/1) (588c992944dd31552e175761339ab856_2fa5fc7df17f61cb0e1946288970d799_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - ExecutionGraph             - Deploying Source: patient_identifier[95] -> Calc[96] (1/1) (attempt #0) with attempt id 588c992944dd31552e175761339ab856_2fa5fc7df17f61cb0e1946288970d799_0_0 and vertex id 2fa5fc7df17f61cb0e1946288970d799_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id bb0d34cb23436eb0f022e71ecc902bf6
INFO  - ExecutionGraph             - Join[81] (1/1) (588c992944dd31552e175761339ab856_e6807280e63afa30c980423999b48cc6_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - ExecutionGraph             - Deploying Join[81] (1/1) (attempt #0) with attempt id 588c992944dd31552e175761339ab856_e6807280e63afa30c980423999b48cc6_0_0 and vertex id e6807280e63afa30c980423999b48cc6_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id bb0d34cb23436eb0f022e71ecc902bf6
INFO  - ExecutionGraph             - Join[86] -> Calc[87] (1/1) (588c992944dd31552e175761339ab856_eb7d99873eea63dacba8fd9c596677e3_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - ExecutionGraph             - Deploying Join[86] -> Calc[87] (1/1) (attempt #0) with attempt id 588c992944dd31552e175761339ab856_eb7d99873eea63dacba8fd9c596677e3_0_0 and vertex id eb7d99873eea63dacba8fd9c596677e3_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id bb0d34cb23436eb0f022e71ecc902bf6
INFO  - ExecutionGraph             - Join[92] -> Calc[93] (1/1) (588c992944dd31552e175761339ab856_fa7571c07da635c59ba82f92b55840d8_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - ExecutionGraph             - Deploying Join[92] -> Calc[93] (1/1) (attempt #0) with attempt id 588c992944dd31552e175761339ab856_fa7571c07da635c59ba82f92b55840d8_0_0 and vertex id fa7571c07da635c59ba82f92b55840d8_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id bb0d34cb23436eb0f022e71ecc902bf6
INFO  - ExecutionGraph             - Join[98] -> Calc[99] -> ConstraintEnforcer[100] (1/1) (588c992944dd31552e175761339ab856_c6adced987710239013e40eb9ab41362_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - ExecutionGraph             - Deploying Join[98] -> Calc[99] -> ConstraintEnforcer[100] (1/1) (attempt #0) with attempt id 588c992944dd31552e175761339ab856_c6adced987710239013e40eb9ab41362_0_0 and vertex id c6adced987710239013e40eb9ab41362_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id bb0d34cb23436eb0f022e71ecc902bf6
INFO  - TaskSlotTableImpl          - Activate slot bb0d34cb23436eb0f022e71ecc902bf6.
INFO  - tateChangelogStorageLoader - Creating a changelog storage with name 'memory'.
INFO  - tateExecutorFactoryManager - Creating the channel state executor factory for job id 3450ce4e11df2cb7a382b3520dc37240
INFO  - TaskExecutor               - Received task Source: patient[75] -> Calc[76] (1/1)#0 (588c992944dd31552e175761339ab856_cbc357ccb763df2852fee8c4fc7d55f2_0_0), deploy into slot with allocation id bb0d34cb23436eb0f022e71ecc902bf6.
INFO  - ExecutionGraph             - SinkMaterializer[100] -> Sink: patients[100] (1/1) (588c992944dd31552e175761339ab856_4969848647857cea5647cb2eb2d99d6b_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - ExecutionGraph             - Deploying SinkMaterializer[100] -> Sink: patients[100] (1/1) (attempt #0) with attempt id 588c992944dd31552e175761339ab856_4969848647857cea5647cb2eb2d99d6b_0_0 and vertex id 4969848647857cea5647cb2eb2d99d6b_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id bb0d34cb23436eb0f022e71ecc902bf6
INFO  - TaskSlotTableImpl          - Activate slot bb0d34cb23436eb0f022e71ecc902bf6.
INFO  - TaskExecutor               - Received task Source: person[78] -> Calc[79] (1/1)#0 (588c992944dd31552e175761339ab856_6cdc5bb954874d922eaee11a8e7b5dd5_0_0), deploy into slot with allocation id bb0d34cb23436eb0f022e71ecc902bf6.
INFO  - Task                       - Source: patient[75] -> Calc[76] (1/1)#0 (588c992944dd31552e175761339ab856_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to DEPLOYING.
INFO  - Task                       - Loading JAR files for task Source: patient[75] -> Calc[76] (1/1)#0 (588c992944dd31552e175761339ab856_cbc357ccb763df2852fee8c4fc7d55f2_0_0) [DEPLOYING].
INFO  - TaskSlotTableImpl          - Activate slot bb0d34cb23436eb0f022e71ecc902bf6.
INFO  - TaskExecutor               - Received task Source: person_name[83] -> Calc[84] (1/1)#0 (588c992944dd31552e175761339ab856_2963852293169ba90d9d1e7d6308db5c_0_0), deploy into slot with allocation id bb0d34cb23436eb0f022e71ecc902bf6.
INFO  - Task                       - Source: person[78] -> Calc[79] (1/1)#0 (588c992944dd31552e175761339ab856_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) switched from CREATED to DEPLOYING.
INFO  - Task                       - Loading JAR files for task Source: person[78] -> Calc[79] (1/1)#0 (588c992944dd31552e175761339ab856_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) [DEPLOYING].
INFO  - ZooKeeper                  - Session: 0x10009b90d4f0004 closed
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - ClientCnxn                 - EventThread shut down for session: 0x10009b90d4f0004
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - TaskSlotTableImpl          - Activate slot bb0d34cb23436eb0f022e71ecc902bf6.
INFO  - Task                       - Source: patient[75] -> Calc[76] (1/1)#0 (588c992944dd31552e175761339ab856_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - Task                       - Source: person[78] -> Calc[79] (1/1)#0 (588c992944dd31552e175761339ab856_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - ExecutionGraph             - Source: patient[75] -> Calc[76] (1/1) (588c992944dd31552e175761339ab856_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - ExecutionGraph             - Source: person[78] -> Calc[79] (1/1) (588c992944dd31552e175761339ab856_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - TaskExecutor               - Received task Source: person_address[89] -> Calc[90] (1/1)#0 (588c992944dd31552e175761339ab856_1171dea6747ab509fdaefbe74f7195af_0_0), deploy into slot with allocation id bb0d34cb23436eb0f022e71ecc902bf6.
INFO  - TaskSlotTableImpl          - Activate slot bb0d34cb23436eb0f022e71ecc902bf6.
INFO  - Task                       - Source: person_address[89] -> Calc[90] (1/1)#0 (588c992944dd31552e175761339ab856_1171dea6747ab509fdaefbe74f7195af_0_0) switched from CREATED to DEPLOYING.
INFO  - Task                       - Loading JAR files for task Source: person_address[89] -> Calc[90] (1/1)#0 (588c992944dd31552e175761339ab856_1171dea6747ab509fdaefbe74f7195af_0_0) [DEPLOYING].
INFO  - TaskExecutor               - Received task Source: patient_identifier[95] -> Calc[96] (1/1)#0 (588c992944dd31552e175761339ab856_2fa5fc7df17f61cb0e1946288970d799_0_0), deploy into slot with allocation id bb0d34cb23436eb0f022e71ecc902bf6.
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - Task                       - Source: person_address[89] -> Calc[90] (1/1)#0 (588c992944dd31552e175761339ab856_1171dea6747ab509fdaefbe74f7195af_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - ExecutionGraph             - Source: person_address[89] -> Calc[90] (1/1) (588c992944dd31552e175761339ab856_1171dea6747ab509fdaefbe74f7195af_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - Task                       - Source: person_name[83] -> Calc[84] (1/1)#0 (588c992944dd31552e175761339ab856_2963852293169ba90d9d1e7d6308db5c_0_0) switched from CREATED to DEPLOYING.
INFO  - Task                       - Loading JAR files for task Source: person_name[83] -> Calc[84] (1/1)#0 (588c992944dd31552e175761339ab856_2963852293169ba90d9d1e7d6308db5c_0_0) [DEPLOYING].
INFO  - TaskSlotTableImpl          - Activate slot bb0d34cb23436eb0f022e71ecc902bf6.
INFO  - Task                       - Source: patient_identifier[95] -> Calc[96] (1/1)#0 (588c992944dd31552e175761339ab856_2fa5fc7df17f61cb0e1946288970d799_0_0) switched from CREATED to DEPLOYING.
INFO  - Task                       - Loading JAR files for task Source: patient_identifier[95] -> Calc[96] (1/1)#0 (588c992944dd31552e175761339ab856_2fa5fc7df17f61cb0e1946288970d799_0_0) [DEPLOYING].
INFO  - TaskExecutor               - Received task Join[81] (1/1)#0 (588c992944dd31552e175761339ab856_e6807280e63afa30c980423999b48cc6_0_0), deploy into slot with allocation id bb0d34cb23436eb0f022e71ecc902bf6.
INFO  - TaskSlotTableImpl          - Activate slot bb0d34cb23436eb0f022e71ecc902bf6.
INFO  - TaskExecutor               - Received task Join[86] -> Calc[87] (1/1)#0 (588c992944dd31552e175761339ab856_eb7d99873eea63dacba8fd9c596677e3_0_0), deploy into slot with allocation id bb0d34cb23436eb0f022e71ecc902bf6.
INFO  - Task                       - Join[81] (1/1)#0 (588c992944dd31552e175761339ab856_e6807280e63afa30c980423999b48cc6_0_0) switched from CREATED to DEPLOYING.
INFO  - Task                       - Loading JAR files for task Join[81] (1/1)#0 (588c992944dd31552e175761339ab856_e6807280e63afa30c980423999b48cc6_0_0) [DEPLOYING].
INFO  - TaskSlotTableImpl          - Activate slot bb0d34cb23436eb0f022e71ecc902bf6.
INFO  - Task                       - Join[86] -> Calc[87] (1/1)#0 (588c992944dd31552e175761339ab856_eb7d99873eea63dacba8fd9c596677e3_0_0) switched from CREATED to DEPLOYING.
INFO  - Task                       - Loading JAR files for task Join[86] -> Calc[87] (1/1)#0 (588c992944dd31552e175761339ab856_eb7d99873eea63dacba8fd9c596677e3_0_0) [DEPLOYING].
INFO  - TaskExecutor               - Received task Join[92] -> Calc[93] (1/1)#0 (588c992944dd31552e175761339ab856_fa7571c07da635c59ba82f92b55840d8_0_0), deploy into slot with allocation id bb0d34cb23436eb0f022e71ecc902bf6.
INFO  - TaskSlotTableImpl          - Activate slot bb0d34cb23436eb0f022e71ecc902bf6.
INFO  - TaskExecutor               - Received task Join[98] -> Calc[99] -> ConstraintEnforcer[100] (1/1)#0 (588c992944dd31552e175761339ab856_c6adced987710239013e40eb9ab41362_0_0), deploy into slot with allocation id bb0d34cb23436eb0f022e71ecc902bf6.
INFO  - Task                       - Join[92] -> Calc[93] (1/1)#0 (588c992944dd31552e175761339ab856_fa7571c07da635c59ba82f92b55840d8_0_0) switched from CREATED to DEPLOYING.
INFO  - Task                       - Loading JAR files for task Join[92] -> Calc[93] (1/1)#0 (588c992944dd31552e175761339ab856_fa7571c07da635c59ba82f92b55840d8_0_0) [DEPLOYING].
INFO  - Task                       - Join[98] -> Calc[99] -> ConstraintEnforcer[100] (1/1)#0 (588c992944dd31552e175761339ab856_c6adced987710239013e40eb9ab41362_0_0) switched from CREATED to DEPLOYING.
INFO  - Task                       - Loading JAR files for task Join[98] -> Calc[99] -> ConstraintEnforcer[100] (1/1)#0 (588c992944dd31552e175761339ab856_c6adced987710239013e40eb9ab41362_0_0) [DEPLOYING].
INFO  - TaskSlotTableImpl          - Activate slot bb0d34cb23436eb0f022e71ecc902bf6.
INFO  - TaskSlotTableImpl          - Activate slot bb0d34cb23436eb0f022e71ecc902bf6.
INFO  - TaskExecutor               - Received task SinkMaterializer[100] -> Sink: patients[100] (1/1)#0 (588c992944dd31552e175761339ab856_4969848647857cea5647cb2eb2d99d6b_0_0), deploy into slot with allocation id bb0d34cb23436eb0f022e71ecc902bf6.
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - Task                       - Source: person_name[83] -> Calc[84] (1/1)#0 (588c992944dd31552e175761339ab856_2963852293169ba90d9d1e7d6308db5c_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - ExecutionGraph             - Source: person_name[83] -> Calc[84] (1/1) (588c992944dd31552e175761339ab856_2963852293169ba90d9d1e7d6308db5c_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - Task                       - Join[86] -> Calc[87] (1/1)#0 (588c992944dd31552e175761339ab856_eb7d99873eea63dacba8fd9c596677e3_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - ExecutionGraph             - Join[86] -> Calc[87] (1/1) (588c992944dd31552e175761339ab856_eb7d99873eea63dacba8fd9c596677e3_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - Task                       - Source: patient_identifier[95] -> Calc[96] (1/1)#0 (588c992944dd31552e175761339ab856_2fa5fc7df17f61cb0e1946288970d799_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - ExecutionGraph             - Source: patient_identifier[95] -> Calc[96] (1/1) (588c992944dd31552e175761339ab856_2fa5fc7df17f61cb0e1946288970d799_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - SourceCoordinator          - Source Source: person_address[89] registering reader for parallel task 0 (#0) @ 
INFO  - KafkaSourceEnumerator      - Assigning splits to readers {0=[[Partition: openmrs.openmrs.person_address-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}
INFO  - Task                       - Source: person_name[83] -> Calc[84] (1/1)#0 (588c992944dd31552e175761339ab856_2963852293169ba90d9d1e7d6308db5c_0_0) switched from INITIALIZING to RUNNING.
INFO  - Task                       - Source: person[78] -> Calc[79] (1/1)#0 (588c992944dd31552e175761339ab856_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) switched from INITIALIZING to RUNNING.
INFO  - ExecutionGraph             - Source: person_name[83] -> Calc[84] (1/1) (588c992944dd31552e175761339ab856_2963852293169ba90d9d1e7d6308db5c_0_0) switched from INITIALIZING to RUNNING.
INFO  - ExecutionGraph             - Source: person[78] -> Calc[79] (1/1) (588c992944dd31552e175761339ab856_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) switched from INITIALIZING to RUNNING.
INFO  - Task                       - SinkMaterializer[100] -> Sink: patients[100] (1/1)#0 (588c992944dd31552e175761339ab856_4969848647857cea5647cb2eb2d99d6b_0_0) switched from CREATED to DEPLOYING.
INFO  - Task                       - Loading JAR files for task SinkMaterializer[100] -> Sink: patients[100] (1/1)#0 (588c992944dd31552e175761339ab856_4969848647857cea5647cb2eb2d99d6b_0_0) [DEPLOYING].
INFO  - SourceCoordinator          - Source Source: patient_identifier[95] registering reader for parallel task 0 (#0) @ 
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - SourceCoordinator          - Source Source: patient[75] registering reader for parallel task 0 (#0) @ 
INFO  - SourceCoordinator          - Source Source: person[78] registering reader for parallel task 0 (#0) @ 
INFO  - mbeddedRocksDBStateBackend - Getting shared memory for RocksDB: shareScope=SLOT, managed=false
INFO  - KafkaSourceEnumerator      - Assigning splits to readers {0=[[Partition: openmrs.openmrs.person-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}
INFO  - Task                       - Source: person_address[89] -> Calc[90] (1/1)#0 (588c992944dd31552e175761339ab856_1171dea6747ab509fdaefbe74f7195af_0_0) switched from INITIALIZING to RUNNING.
INFO  - mbeddedRocksDBStateBackend - Obtained shared RocksDB cache of size 6710886 bytes
INFO  - SourceCoordinator          - Source Source: person_name[83] registering reader for parallel task 0 (#0) @ 
INFO  - KafkaSourceEnumerator      - Assigning splits to readers {0=[[Partition: openmrs.openmrs.person_name-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}
INFO  - SourceReaderBase           - Adding split(s) to reader: [[Partition: openmrs.openmrs.person_address-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - Task                       - Join[98] -> Calc[99] -> ConstraintEnforcer[100] (1/1)#0 (588c992944dd31552e175761339ab856_c6adced987710239013e40eb9ab41362_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - KafkaSourceEnumerator      - Assigning splits to readers {0=[[Partition: openmrs.openmrs.patient-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - KafkaSourceEnumerator      - Assigning splits to readers {0=[[Partition: openmrs.openmrs.patient_identifier-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - Task                       - Source: patient_identifier[95] -> Calc[96] (1/1)#0 (588c992944dd31552e175761339ab856_2fa5fc7df17f61cb0e1946288970d799_0_0) switched from INITIALIZING to RUNNING.
INFO  - Task                       - Source: patient[75] -> Calc[76] (1/1)#0 (588c992944dd31552e175761339ab856_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
INFO  - Task                       - Join[81] (1/1)#0 (588c992944dd31552e175761339ab856_e6807280e63afa30c980423999b48cc6_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - SourceReaderBase           - Adding split(s) to reader: [[Partition: openmrs.openmrs.person-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]
INFO  - Task                       - Join[92] -> Calc[93] (1/1)#0 (588c992944dd31552e175761339ab856_fa7571c07da635c59ba82f92b55840d8_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - Task                       - SinkMaterializer[100] -> Sink: patients[100] (1/1)#0 (588c992944dd31552e175761339ab856_4969848647857cea5647cb2eb2d99d6b_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - ConsumerConfig             - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = flink-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

INFO  - ConsumerConfig             - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = flink-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

INFO  - ExecutionGraph             - Source: person_address[89] -> Calc[90] (1/1) (588c992944dd31552e175761339ab856_1171dea6747ab509fdaefbe74f7195af_0_0) switched from INITIALIZING to RUNNING.
INFO  - ExecutionGraph             - Join[98] -> Calc[99] -> ConstraintEnforcer[100] (1/1) (588c992944dd31552e175761339ab856_c6adced987710239013e40eb9ab41362_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - SourceReaderBase           - Adding split(s) to reader: [[Partition: openmrs.openmrs.person_name-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]
INFO  - mbeddedRocksDBStateBackend - Getting shared memory for RocksDB: shareScope=SLOT, managed=false
INFO  - ConsumerConfig             - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = flink-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

INFO  - mbeddedRocksDBStateBackend - Obtained shared RocksDB cache of size 6710886 bytes
WARN  - ConsumerConfig             - The configuration 'client.id.prefix' was supplied but isn't a known config.
WARN  - ConsumerConfig             - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290632071
WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.consumer:type=app-info,id=flink-0
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:816)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:666)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:647)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:627)
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.<init>(KafkaPartitionSplitReader.java:88)
	at org.apache.flink.connector.kafka.source.KafkaSource.lambda$createReader$1(KafkaSource.java:160)
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager.createSplitFetcher(SplitFetcherManager.java:196)
	at org.apache.flink.connector.base.source.reader.fetcher.SingleThreadFetcherManager.addSplits(SingleThreadFetcherManager.java:107)
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.addSplits(SourceReaderBase.java:242)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleAddSplitsEvent(SourceOperator.java:584)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleOperatorEvent(SourceOperator.java:561)
	at org.apache.flink.streaming.runtime.tasks.OperatorEventDispatcherImpl.dispatchEventToHandlers(OperatorEventDispatcherImpl.java:72)
	at org.apache.flink.streaming.runtime.tasks.RegularOperatorChain.dispatchOperatorEvent(RegularOperatorChain.java:80)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$dispatchOperatorEvent$20(StreamTask.java:1473)
	at org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$1.runThrowing(StreamTaskActionExecutor.java:50)
	at org.apache.flink.streaming.runtime.tasks.mailbox.Mail.run(Mail.java:90)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMail(MailboxProcessor.java:398)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMailsWhenDefaultActionUnavailable(MailboxProcessor.java:367)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMail(MailboxProcessor.java:352)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:229)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:839)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:788)
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:952)
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:931)
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:745)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:562)
	at java.base/java.lang.Thread.run(Thread.java:829)
WARN  - ConsumerConfig             - The configuration 'client.id.prefix' was supplied but isn't a known config.
WARN  - ConsumerConfig             - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290632072
WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.consumer:type=app-info,id=flink-0
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:816)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:666)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:647)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:627)
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.<init>(KafkaPartitionSplitReader.java:88)
	at org.apache.flink.connector.kafka.source.KafkaSource.lambda$createReader$1(KafkaSource.java:160)
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager.createSplitFetcher(SplitFetcherManager.java:196)
	at org.apache.flink.connector.base.source.reader.fetcher.SingleThreadFetcherManager.addSplits(SingleThreadFetcherManager.java:107)
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.addSplits(SourceReaderBase.java:242)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleAddSplitsEvent(SourceOperator.java:584)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleOperatorEvent(SourceOperator.java:561)
	at org.apache.flink.streaming.runtime.tasks.OperatorEventDispatcherImpl.dispatchEventToHandlers(OperatorEventDispatcherImpl.java:72)
	at org.apache.flink.streaming.runtime.tasks.RegularOperatorChain.dispatchOperatorEvent(RegularOperatorChain.java:80)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$dispatchOperatorEvent$20(StreamTask.java:1473)
	at org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$1.runThrowing(StreamTaskActionExecutor.java:50)
	at org.apache.flink.streaming.runtime.tasks.mailbox.Mail.run(Mail.java:90)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMail(MailboxProcessor.java:398)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMailsWhenDefaultActionUnavailable(MailboxProcessor.java:367)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMail(MailboxProcessor.java:352)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:229)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:839)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:788)
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:952)
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:931)
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:745)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:562)
	at java.base/java.lang.Thread.run(Thread.java:829)
INFO  - SplitFetcher               - Starting split fetcher 0
WARN  - ConsumerConfig             - The configuration 'client.id.prefix' was supplied but isn't a known config.
INFO  - ExecutionGraph             - Source: patient[75] -> Calc[76] (1/1) (588c992944dd31552e175761339ab856_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
INFO  - SourceReaderBase           - Adding split(s) to reader: [[Partition: openmrs.openmrs.patient-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]
INFO  - SourceReaderBase           - Adding split(s) to reader: [[Partition: openmrs.openmrs.patient_identifier-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]
INFO  - ExecutionGraph             - Join[81] (1/1) (588c992944dd31552e175761339ab856_e6807280e63afa30c980423999b48cc6_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - DBKeyedStateBackendBuilder - Finished building RocksDB keyed state-backend at /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_3450ce4e11df2cb7a382b3520dc37240_op_StreamingJoinOperator_eb7d99873eea63dacba8fd9c596677e3__1_1__uuid_a29cd578-e03c-42f3-b4ad-9e2c379595fd.
WARN  - ConsumerConfig             - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290632078
INFO  - ExecutionGraph             - Source: patient_identifier[95] -> Calc[96] (1/1) (588c992944dd31552e175761339ab856_2fa5fc7df17f61cb0e1946288970d799_0_0) switched from INITIALIZING to RUNNING.
WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.consumer:type=app-info,id=flink-0
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:816)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:666)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:647)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:627)
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.<init>(KafkaPartitionSplitReader.java:88)
	at org.apache.flink.connector.kafka.source.KafkaSource.lambda$createReader$1(KafkaSource.java:160)
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager.createSplitFetcher(SplitFetcherManager.java:196)
	at org.apache.flink.connector.base.source.reader.fetcher.SingleThreadFetcherManager.addSplits(SingleThreadFetcherManager.java:107)
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.addSplits(SourceReaderBase.java:242)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleAddSplitsEvent(SourceOperator.java:584)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleOperatorEvent(SourceOperator.java:561)
	at org.apache.flink.streaming.runtime.tasks.OperatorEventDispatcherImpl.dispatchEventToHandlers(OperatorEventDispatcherImpl.java:72)
	at org.apache.flink.streaming.runtime.tasks.RegularOperatorChain.dispatchOperatorEvent(RegularOperatorChain.java:80)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$dispatchOperatorEvent$20(StreamTask.java:1473)
	at org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$1.runThrowing(StreamTaskActionExecutor.java:50)
	at org.apache.flink.streaming.runtime.tasks.mailbox.Mail.run(Mail.java:90)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMail(MailboxProcessor.java:398)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMailsNonBlocking(MailboxProcessor.java:383)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMail(MailboxProcessor.java:345)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:229)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:839)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:788)
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:952)
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:931)
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:745)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:562)
	at java.base/java.lang.Thread.run(Thread.java:829)
INFO  - ConsumerConfig             - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = flink-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

INFO  - mbeddedRocksDBStateBackend - Getting shared memory for RocksDB: shareScope=SLOT, managed=false
INFO  - mbeddedRocksDBStateBackend - Obtained shared RocksDB cache of size 6710886 bytes
INFO  - SplitFetcher               - Starting split fetcher 0
INFO  - KafkaConsumer              - [Consumer clientId=flink-0, groupId=flink] Subscribed to partition(s): openmrs.openmrs.person_name-0
INFO  - mbeddedRocksDBStateBackend - Getting shared memory for RocksDB: shareScope=SLOT, managed=false
INFO  - mbeddedRocksDBStateBackend - Obtained shared RocksDB cache of size 6710886 bytes
WARN  - RocksDBOperationUtils      - RocksDBStateBackend performance will be poor because of the current Flink memory configuration! RocksDB will flush memtable constantly, causing high IO and CPU. Typically the easiest fix is to increase task manager managed memory size. If running locally, see the parameter taskmanager.memory.managed.size. Details: arenaBlockSize 8388608 > mutableLimit 1957341 (writeBufferSize = 67108864, arenaBlockSizeConfigured = 0, defaultArenaBlockSize = 8388608, writeBufferManagerCapacity = 2236962)
WARN  - ConsumerConfig             - The configuration 'client.id.prefix' was supplied but isn't a known config.
WARN  - ConsumerConfig             - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
INFO  - SplitFetcher               - Starting split fetcher 0
INFO  - ExecutionGraph             - Join[92] -> Calc[93] (1/1) (588c992944dd31552e175761339ab856_fa7571c07da635c59ba82f92b55840d8_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - ConsumerConfig             - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = flink-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

INFO  - ExecutionGraph             - SinkMaterializer[100] -> Sink: patients[100] (1/1) (588c992944dd31552e175761339ab856_4969848647857cea5647cb2eb2d99d6b_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - KafkaConsumer              - [Consumer clientId=flink-0, groupId=flink] Subscribed to partition(s): openmrs.openmrs.person_address-0
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290632084
WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.consumer:type=app-info,id=flink-0
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:816)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:666)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:647)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:627)
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.<init>(KafkaPartitionSplitReader.java:88)
	at org.apache.flink.connector.kafka.source.KafkaSource.lambda$createReader$1(KafkaSource.java:160)
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager.createSplitFetcher(SplitFetcherManager.java:196)
	at org.apache.flink.connector.base.source.reader.fetcher.SingleThreadFetcherManager.addSplits(SingleThreadFetcherManager.java:107)
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.addSplits(SourceReaderBase.java:242)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleAddSplitsEvent(SourceOperator.java:584)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleOperatorEvent(SourceOperator.java:561)
	at org.apache.flink.streaming.runtime.tasks.OperatorEventDispatcherImpl.dispatchEventToHandlers(OperatorEventDispatcherImpl.java:72)
	at org.apache.flink.streaming.runtime.tasks.RegularOperatorChain.dispatchOperatorEvent(RegularOperatorChain.java:80)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$dispatchOperatorEvent$20(StreamTask.java:1473)
	at org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$1.runThrowing(StreamTaskActionExecutor.java:50)
	at org.apache.flink.streaming.runtime.tasks.mailbox.Mail.run(Mail.java:90)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMail(MailboxProcessor.java:398)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMailsWhenDefaultActionUnavailable(MailboxProcessor.java:367)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMail(MailboxProcessor.java:352)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:229)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:839)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:788)
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:952)
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:931)
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:745)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:562)
	at java.base/java.lang.Thread.run(Thread.java:829)
INFO  - mbeddedRocksDBStateBackend - Getting shared memory for RocksDB: shareScope=SLOT, managed=false
INFO  - mbeddedRocksDBStateBackend - Obtained shared RocksDB cache of size 6710886 bytes
WARN  - RocksDBOperationUtils      - RocksDBStateBackend performance will be poor because of the current Flink memory configuration! RocksDB will flush memtable constantly, causing high IO and CPU. Typically the easiest fix is to increase task manager managed memory size. If running locally, see the parameter taskmanager.memory.managed.size. Details: arenaBlockSize 8388608 > mutableLimit 1957341 (writeBufferSize = 67108864, arenaBlockSizeConfigured = 0, defaultArenaBlockSize = 8388608, writeBufferManagerCapacity = 2236962)
INFO  - DBKeyedStateBackendBuilder - Finished building RocksDB keyed state-backend at /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_3450ce4e11df2cb7a382b3520dc37240_op_StreamingJoinOperator_e6807280e63afa30c980423999b48cc6__1_1__uuid_ac3d83a8-2b9c-4f39-9696-bc0d78b435bf.
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Seeking to EARLIEST offset of partition openmrs.openmrs.person_name-0
INFO  - KafkaConsumer              - [Consumer clientId=flink-0, groupId=flink] Subscribed to partition(s): openmrs.openmrs.person-0
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Resetting the last seen epoch of partition openmrs.openmrs.person_name-0 to 0 since the associated topicId changed from null to zSinlMUVRWqRRXXA_9djag
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Cluster ID: 5Yr1SIgYQz-b-dgRabWx4g
WARN  - RocksDBOperationUtils      - RocksDBStateBackend performance will be poor because of the current Flink memory configuration! RocksDB will flush memtable constantly, causing high IO and CPU. Typically the easiest fix is to increase task manager managed memory size. If running locally, see the parameter taskmanager.memory.managed.size. Details: arenaBlockSize 8388608 > mutableLimit 1957341 (writeBufferSize = 67108864, arenaBlockSizeConfigured = 0, defaultArenaBlockSize = 8388608, writeBufferManagerCapacity = 2236962)
INFO  - SplitFetcher               - Starting split fetcher 0
WARN  - ConsumerConfig             - The configuration 'client.id.prefix' was supplied but isn't a known config.
WARN  - ConsumerConfig             - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Seeking to EARLIEST offset of partition openmrs.openmrs.person_address-0
INFO  - DBKeyedStateBackendBuilder - Finished building RocksDB keyed state-backend at /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_3450ce4e11df2cb7a382b3520dc37240_op_StreamingJoinOperator_fa7571c07da635c59ba82f92b55840d8__1_1__uuid_05066527-5cf8-494c-bafc-822db9006a2d.
INFO  - KafkaConsumer              - [Consumer clientId=flink-0, groupId=flink] Subscribed to partition(s): openmrs.openmrs.patient_identifier-0
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290632092
WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.consumer:type=app-info,id=flink-0
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:816)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:666)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:647)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:627)
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.<init>(KafkaPartitionSplitReader.java:88)
	at org.apache.flink.connector.kafka.source.KafkaSource.lambda$createReader$1(KafkaSource.java:160)
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager.createSplitFetcher(SplitFetcherManager.java:196)
	at org.apache.flink.connector.base.source.reader.fetcher.SingleThreadFetcherManager.addSplits(SingleThreadFetcherManager.java:107)
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.addSplits(SourceReaderBase.java:242)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleAddSplitsEvent(SourceOperator.java:584)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleOperatorEvent(SourceOperator.java:561)
	at org.apache.flink.streaming.runtime.tasks.OperatorEventDispatcherImpl.dispatchEventToHandlers(OperatorEventDispatcherImpl.java:72)
	at org.apache.flink.streaming.runtime.tasks.RegularOperatorChain.dispatchOperatorEvent(RegularOperatorChain.java:80)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$dispatchOperatorEvent$20(StreamTask.java:1473)
	at org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$1.runThrowing(StreamTaskActionExecutor.java:50)
	at org.apache.flink.streaming.runtime.tasks.mailbox.Mail.run(Mail.java:90)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMail(MailboxProcessor.java:398)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMailsWhenDefaultActionUnavailable(MailboxProcessor.java:367)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMail(MailboxProcessor.java:352)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:229)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:839)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:788)
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:952)
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:931)
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:745)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:562)
	at java.base/java.lang.Thread.run(Thread.java:829)
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Seeking to EARLIEST offset of partition openmrs.openmrs.person-0
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Resetting the last seen epoch of partition openmrs.openmrs.person_address-0 to 0 since the associated topicId changed from null to E6TnCqmUQQy7aj2YfzxgfQ
WARN  - RocksDBOperationUtils      - RocksDBStateBackend performance will be poor because of the current Flink memory configuration! RocksDB will flush memtable constantly, causing high IO and CPU. Typically the easiest fix is to increase task manager managed memory size. If running locally, see the parameter taskmanager.memory.managed.size. Details: arenaBlockSize 8388608 > mutableLimit 1957341 (writeBufferSize = 67108864, arenaBlockSizeConfigured = 0, defaultArenaBlockSize = 8388608, writeBufferManagerCapacity = 2236962)
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Cluster ID: 5Yr1SIgYQz-b-dgRabWx4g
INFO  - SplitFetcher               - Starting split fetcher 0
INFO  - Task                       - Join[86] -> Calc[87] (1/1)#0 (588c992944dd31552e175761339ab856_eb7d99873eea63dacba8fd9c596677e3_0_0) switched from INITIALIZING to RUNNING.
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Resetting offset for partition openmrs.openmrs.person_name-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:29092 (id: 1 rack: null)], epoch=0}}.
WARN  - RocksDBOperationUtils      - RocksDBStateBackend performance will be poor because of the current Flink memory configuration! RocksDB will flush memtable constantly, causing high IO and CPU. Typically the easiest fix is to increase task manager managed memory size. If running locally, see the parameter taskmanager.memory.managed.size. Details: arenaBlockSize 8388608 > mutableLimit 1957341 (writeBufferSize = 67108864, arenaBlockSizeConfigured = 0, defaultArenaBlockSize = 8388608, writeBufferManagerCapacity = 2236962)
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Seeking to EARLIEST offset of partition openmrs.openmrs.patient_identifier-0
INFO  - KafkaConsumer              - [Consumer clientId=flink-0, groupId=flink] Subscribed to partition(s): openmrs.openmrs.patient-0
INFO  - ExecutionGraph             - Join[86] -> Calc[87] (1/1) (588c992944dd31552e175761339ab856_eb7d99873eea63dacba8fd9c596677e3_0_0) switched from INITIALIZING to RUNNING.
WARN  - RocksDBOperationUtils      - RocksDBStateBackend performance will be poor because of the current Flink memory configuration! RocksDB will flush memtable constantly, causing high IO and CPU. Typically the easiest fix is to increase task manager managed memory size. If running locally, see the parameter taskmanager.memory.managed.size. Details: arenaBlockSize 8388608 > mutableLimit 1957341 (writeBufferSize = 67108864, arenaBlockSizeConfigured = 0, defaultArenaBlockSize = 8388608, writeBufferManagerCapacity = 2236962)
INFO  - DBKeyedStateBackendBuilder - Finished building RocksDB keyed state-backend at /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_3450ce4e11df2cb7a382b3520dc37240_op_StreamingJoinOperator_c6adced987710239013e40eb9ab41362__1_1__uuid_47fbfd74-6bb2-4080-881b-2f892599cabc.
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Resetting offset for partition openmrs.openmrs.person_address-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:29092 (id: 1 rack: null)], epoch=0}}.
INFO  - Task                       - Join[92] -> Calc[93] (1/1)#0 (588c992944dd31552e175761339ab856_fa7571c07da635c59ba82f92b55840d8_0_0) switched from INITIALIZING to RUNNING.
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Resetting the last seen epoch of partition openmrs.openmrs.person-0 to 0 since the associated topicId changed from null to mtn9qgqVSxmjr7K25Brqdg
INFO  - ExecutionGraph             - Join[92] -> Calc[93] (1/1) (588c992944dd31552e175761339ab856_fa7571c07da635c59ba82f92b55840d8_0_0) switched from INITIALIZING to RUNNING.
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Cluster ID: 5Yr1SIgYQz-b-dgRabWx4g
INFO  - DBKeyedStateBackendBuilder - Finished building RocksDB keyed state-backend at /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_3450ce4e11df2cb7a382b3520dc37240_op_SinkUpsertMaterializer_4969848647857cea5647cb2eb2d99d6b__1_1__uuid_ee0391e6-5d5b-454e-b383-582e12feea44.
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Seeking to EARLIEST offset of partition openmrs.openmrs.patient-0
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Resetting the last seen epoch of partition openmrs.openmrs.patient_identifier-0 to 0 since the associated topicId changed from null to MezQvDn_S6OYKBgWZg2VvQ
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Cluster ID: 5Yr1SIgYQz-b-dgRabWx4g
WARN  - RocksDBOperationUtils      - RocksDBStateBackend performance will be poor because of the current Flink memory configuration! RocksDB will flush memtable constantly, causing high IO and CPU. Typically the easiest fix is to increase task manager managed memory size. If running locally, see the parameter taskmanager.memory.managed.size. Details: arenaBlockSize 8388608 > mutableLimit 1957341 (writeBufferSize = 67108864, arenaBlockSizeConfigured = 0, defaultArenaBlockSize = 8388608, writeBufferManagerCapacity = 2236962)
WARN  - Configuration              - Config uses deprecated configuration key 'high-availability' instead of proper key 'high-availability.type'
INFO  - ZooKeeperUtils             - Enforcing default ACL for ZK connections
INFO  - ZooKeeperUtils             - Using '/flink/default' as Zookeeper namespace.
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Resetting offset for partition openmrs.openmrs.person-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:29092 (id: 1 rack: null)], epoch=0}}.
INFO  - CuratorFrameworkImpl       - Starting
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Resetting the last seen epoch of partition openmrs.openmrs.patient-0 to 0 since the associated topicId changed from null to Q8xcR2BjS7ipdu-5SeNN4w
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Cluster ID: 5Yr1SIgYQz-b-dgRabWx4g
WARN  - RocksDBOperationUtils      - RocksDBStateBackend performance will be poor because of the current Flink memory configuration! RocksDB will flush memtable constantly, causing high IO and CPU. Typically the easiest fix is to increase task manager managed memory size. If running locally, see the parameter taskmanager.memory.managed.size. Details: arenaBlockSize 8388608 > mutableLimit 1957341 (writeBufferSize = 67108864, arenaBlockSizeConfigured = 0, defaultArenaBlockSize = 8388608, writeBufferManagerCapacity = 2236962)
INFO  - Task                       - Join[81] (1/1)#0 (588c992944dd31552e175761339ab856_e6807280e63afa30c980423999b48cc6_0_0) switched from INITIALIZING to RUNNING.
INFO  - ZooKeeper                  - Initiating client connection, connectString=localhost:2181 sessionTimeout=60000 watcher=org.apache.flink.shaded.curator5.org.apache.curator.ConnectionState@8b41f7e
INFO  - ClientCnxnSocket           - jute.maxbuffer value is 1048575 Bytes
INFO  - ClientCnxn                 - zookeeper.request.timeout value is 0. feature enabled=false
WARN  - RocksDBOperationUtils      - RocksDBStateBackend performance will be poor because of the current Flink memory configuration! RocksDB will flush memtable constantly, causing high IO and CPU. Typically the easiest fix is to increase task manager managed memory size. If running locally, see the parameter taskmanager.memory.managed.size. Details: arenaBlockSize 8388608 > mutableLimit 1957341 (writeBufferSize = 67108864, arenaBlockSizeConfigured = 0, defaultArenaBlockSize = 8388608, writeBufferManagerCapacity = 2236962)
INFO  - ExecutionGraph             - Join[81] (1/1) (588c992944dd31552e175761339ab856_e6807280e63afa30c980423999b48cc6_0_0) switched from INITIALIZING to RUNNING.
INFO  - CuratorFrameworkImpl       - Default schema
INFO  - aultLeaderRetrievalService - Starting DefaultLeaderRetrievalService with ZookeeperLeaderRetrievalDriver{connectionInformationPath='/leader/rest_server/connection_info'}.
INFO  - ClientCnxn                 - Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181.
INFO  - ClientCnxn                 - SASL config status: Will not attempt to authenticate using SASL (unknown error)
INFO  - ClientCnxn                 - Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:52297, server: localhost/0:0:0:0:0:0:0:1:2181
INFO  - Task                       - SinkMaterializer[100] -> Sink: patients[100] (1/1)#0 (588c992944dd31552e175761339ab856_4969848647857cea5647cb2eb2d99d6b_0_0) switched from INITIALIZING to RUNNING.
INFO  - RestClusterClient          - Submitting job 'insert-into_analytics.analytics.encounter_diagnoses' (3b099420ea7206c78ac6154209036e81).
INFO  - ExecutionGraph             - SinkMaterializer[100] -> Sink: patients[100] (1/1) (588c992944dd31552e175761339ab856_4969848647857cea5647cb2eb2d99d6b_0_0) switched from INITIALIZING to RUNNING.
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Resetting offset for partition openmrs.openmrs.patient_identifier-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:29092 (id: 1 rack: null)], epoch=0}}.
INFO  - Task                       - Join[98] -> Calc[99] -> ConstraintEnforcer[100] (1/1)#0 (588c992944dd31552e175761339ab856_c6adced987710239013e40eb9ab41362_0_0) switched from INITIALIZING to RUNNING.
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Resetting offset for partition openmrs.openmrs.patient-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:29092 (id: 1 rack: null)], epoch=0}}.
INFO  - ExecutionGraph             - Join[98] -> Calc[99] -> ConstraintEnforcer[100] (1/1) (588c992944dd31552e175761339ab856_c6adced987710239013e40eb9ab41362_0_0) switched from INITIALIZING to RUNNING.
INFO  - ClientCnxn                 - Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, session id = 0x10009b90d4f0005, negotiated timeout = 40000
INFO  - ConnectionStateManager     - State change: CONNECTED
INFO  - EnsembleTracker            - New config event received: {}
INFO  - EnsembleTracker            - New config event received: {}
INFO  - StandaloneDispatcher       - Received JobGraph submission 'insert-into_analytics.analytics.encounter_diagnoses' (3b099420ea7206c78ac6154209036e81).
INFO  - StandaloneDispatcher       - Submitting job 'insert-into_analytics.analytics.encounter_diagnoses' (3b099420ea7206c78ac6154209036e81).
INFO  - DefaultJobGraphStore       - Added JobGraph(jobId: 3b099420ea7206c78ac6154209036e81) to ZooKeeperStateHandleStore{namespace='flink/default/jobgraphs'}.
INFO  - faultLeaderElectionService - Starting DefaultLeaderElectionService with org.apache.flink.runtime.leaderelection.MultipleComponentLeaderElectionDriverAdapter@3fb45faa.
INFO  - terServiceLeadershipRunner - JobMasterServiceLeadershipRunner for job 3b099420ea7206c78ac6154209036e81 was granted leadership with leader id 3a82a6ce-fb62-4610-b46c-7fb86bd673d4. Creating new JobMasterServiceProcess.
INFO  - AkkaRpcService             - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/rpc/jobmanager_7 .
INFO  - RestClusterClient          - Successfully submitted job 'insert-into_analytics.analytics.encounter_diagnoses' (3b099420ea7206c78ac6154209036e81) to 'http://localhost:8081'.
INFO  - JobMaster                  - Initializing job 'insert-into_analytics.analytics.encounter_diagnoses' (3b099420ea7206c78ac6154209036e81).
INFO  - JobMaster                  - Using restart back off time strategy ExponentialDelayRestartBackoffTimeStrategy(initialBackoffMS=1000, maxBackoffMS=300000, backoffMultiplier=2.0, resetBackoffThresholdMS=3600000, jitterFactor=0.1, currentBackoffMS=1000, lastFailureTimestamp=0) for insert-into_analytics.analytics.encounter_diagnoses (3b099420ea7206c78ac6154209036e81).
INFO  - pletedCheckpointStoreUtils - Recovering checkpoints from ZooKeeperStateHandleStore{namespace='flink/default/jobs/3b099420ea7206c78ac6154209036e81/checkpoints'}.
INFO  - pletedCheckpointStoreUtils - Found 0 checkpoints in ZooKeeperStateHandleStore{namespace='flink/default/jobs/3b099420ea7206c78ac6154209036e81/checkpoints'}.
INFO  - pletedCheckpointStoreUtils - Trying to fetch 0 checkpoints from storage.
INFO  - ZooKeeperUtils             - Initialized DefaultCompletedCheckpointStore in 'ZooKeeperStateHandleStore{namespace='flink/default/jobs/3b099420ea7206c78ac6154209036e81/checkpoints'}' with /checkpoints.
INFO  - ExecutionGraph             - Created execution graph 6d9d8d9b1d918481a134ea752ea88d14 for job 3b099420ea7206c78ac6154209036e81.
INFO  - JobMaster                  - Running initialization on master for job insert-into_analytics.analytics.encounter_diagnoses (3b099420ea7206c78ac6154209036e81).
INFO  - JobMaster                  - Successfully ran initialization on master in 0 ms.
INFO  - DefaultExecutionTopology   - Built 1 new pipelined regions in 1 ms, total 1 pipelined regions currently.
INFO  - JobMaster                  - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - JobMaster                  - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - JobMaster                  - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - CheckpointCoordinator      - No checkpoint found during restore.
INFO  - JobMaster                  - Using failover strategy org.apache.flink.runtime.executiongraph.failover.flip1.RestartPipelinedRegionFailoverStrategy@7ca4b32e for insert-into_analytics.analytics.encounter_diagnoses (3b099420ea7206c78ac6154209036e81).
INFO  - aultLeaderRetrievalService - Starting DefaultLeaderRetrievalService with ZookeeperLeaderRetrievalDriver{connectionInformationPath='/resource_manager/connection_info'}.
INFO  - JobMaster                  - Starting execution of job 'insert-into_analytics.analytics.encounter_diagnoses' (3b099420ea7206c78ac6154209036e81) under job master id b46c7fb86bd673d43a82a6cefb624610.
INFO  - SourceCoordinator          - Starting split enumerator for source Source: encounter_diagnosis[101].
INFO  - JobMaster                  - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
INFO  - ExecutionGraph             - Job insert-into_analytics.analytics.encounter_diagnoses (3b099420ea7206c78ac6154209036e81) switched from state CREATED to RUNNING.
INFO  - AdminClientConfig          - AdminClientConfig values: 
	bootstrap.servers = [localhost:29092]
	client.dns.lookup = use_all_dns_ips
	client.id = flink-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

INFO  - ExecutionGraph             - Source: encounter_diagnosis[101] -> DropUpdateBefore[102] -> Calc[103] -> ConstraintEnforcer[104] -> Sink: encounter_diagnoses[104] (1/1) (6d9d8d9b1d918481a134ea752ea88d14_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to SCHEDULED.
INFO  - JobMaster                  - Connecting to ResourceManager akka://flink/user/rpc/resourcemanager_1(b46c7fb86bd673d43a82a6cefb624610)
WARN  - AdminClientConfig          - The configuration 'key.deserializer' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'value.deserializer' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'enable.auto.commit' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'client.id.prefix' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'group.id' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'auto.offset.reset' was supplied but isn't a known config.
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290632319
WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.admin.client:type=app-info,id=flink-enumerator-admin-client
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.admin.KafkaAdminClient.<init>(KafkaAdminClient.java:597)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:539)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:478)
	at org.apache.kafka.clients.admin.Admin.create(Admin.java:133)
	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getKafkaAdminClient(KafkaSourceEnumerator.java:410)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.start(KafkaSourceEnumerator.java:151)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$start$1(SourceCoordinator.java:234)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$runInEventLoop$10(SourceCoordinator.java:458)
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
INFO  - KafkaSourceEnumerator      - Starting the KafkaSourceEnumerator for consumer group flink without periodic partition discovery.
INFO  - JobMaster                  - Resolved ResourceManager address, beginning registration
INFO  - aultLeaderRetrievalService - Starting DefaultLeaderRetrievalService with ZookeeperLeaderRetrievalDriver{connectionInformationPath='/3b099420ea7206c78ac6154209036e81/connection_info'}.
INFO  - StandaloneResourceManager  - Registering job manager b46c7fb86bd673d43a82a6cefb624610@akka://flink/user/rpc/jobmanager_7 for job 3b099420ea7206c78ac6154209036e81.
INFO  - KafkaSourceEnumerator      - Discovered new partitions: [openmrs.openmrs.encounter_diagnosis-0]
INFO  - StandaloneResourceManager  - Registered job manager b46c7fb86bd673d43a82a6cefb624610@akka://flink/user/rpc/jobmanager_7 for job 3b099420ea7206c78ac6154209036e81.
INFO  - JobMaster                  - JobManager successfully registered at ResourceManager, leader id: b46c7fb86bd673d43a82a6cefb624610.
INFO  - DeclarativeSlotManager     - Received resource requirements from job 3b099420ea7206c78ac6154209036e81: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
INFO  - aultLeaderRetrievalService - Stopping DefaultLeaderRetrievalService.
INFO  - eeperLeaderRetrievalDriver - Closing ZookeeperLeaderRetrievalDriver{connectionInformationPath='/leader/rest_server/connection_info'}.
INFO  - CuratorFrameworkImpl       - backgroundOperationsLoop exiting
INFO  - TaskExecutor               - Receive slot request 6a991bc2fc24dceefcd9d8c546a1cb0a for job 3b099420ea7206c78ac6154209036e81 from resource manager with leader id b46c7fb86bd673d43a82a6cefb624610.
INFO  - TaskExecutor               - Allocated slot for 6a991bc2fc24dceefcd9d8c546a1cb0a.
INFO  - DefaultJobLeaderService    - Add job 3b099420ea7206c78ac6154209036e81 for job leader monitoring.
INFO  - aultLeaderRetrievalService - Starting DefaultLeaderRetrievalService with ZookeeperLeaderRetrievalDriver{connectionInformationPath='/3b099420ea7206c78ac6154209036e81/connection_info'}.
INFO  - DefaultJobLeaderService    - Try to register at job manager akka://flink/user/rpc/jobmanager_7 with leader id 3a82a6ce-fb62-4610-b46c-7fb86bd673d4.
INFO  - DefaultJobLeaderService    - Resolved JobManager address, beginning registration
INFO  - DefaultJobLeaderService    - Successful registration at job manager akka://flink/user/rpc/jobmanager_7 for job 3b099420ea7206c78ac6154209036e81.
INFO  - TaskExecutor               - Establish JobManager connection for job 3b099420ea7206c78ac6154209036e81.
INFO  - TaskExecutor               - Offer reserved slots to the leader of job 3b099420ea7206c78ac6154209036e81.
INFO  - ExecutionGraph             - Source: encounter_diagnosis[101] -> DropUpdateBefore[102] -> Calc[103] -> ConstraintEnforcer[104] -> Sink: encounter_diagnoses[104] (1/1) (6d9d8d9b1d918481a134ea752ea88d14_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - ExecutionGraph             - Deploying Source: encounter_diagnosis[101] -> DropUpdateBefore[102] -> Calc[103] -> ConstraintEnforcer[104] -> Sink: encounter_diagnoses[104] (1/1) (attempt #0) with attempt id 6d9d8d9b1d918481a134ea752ea88d14_cbc357ccb763df2852fee8c4fc7d55f2_0_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id 6a991bc2fc24dceefcd9d8c546a1cb0a
INFO  - TaskSlotTableImpl          - Activate slot 6a991bc2fc24dceefcd9d8c546a1cb0a.
INFO  - TaskSlotTableImpl          - Activate slot 6a991bc2fc24dceefcd9d8c546a1cb0a.
INFO  - tateChangelogStorageLoader - Creating a changelog storage with name 'memory'.
INFO  - tateExecutorFactoryManager - Creating the channel state executor factory for job id 3b099420ea7206c78ac6154209036e81
INFO  - TaskExecutor               - Received task Source: encounter_diagnosis[101] -> DropUpdateBefore[102] -> Calc[103] -> ConstraintEnforcer[104] -> Sink: encounter_diagnoses[104] (1/1)#0 (6d9d8d9b1d918481a134ea752ea88d14_cbc357ccb763df2852fee8c4fc7d55f2_0_0), deploy into slot with allocation id 6a991bc2fc24dceefcd9d8c546a1cb0a.
INFO  - Task                       - Source: encounter_diagnosis[101] -> DropUpdateBefore[102] -> Calc[103] -> ConstraintEnforcer[104] -> Sink: encounter_diagnoses[104] (1/1)#0 (6d9d8d9b1d918481a134ea752ea88d14_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to DEPLOYING.
INFO  - Task                       - Loading JAR files for task Source: encounter_diagnosis[101] -> DropUpdateBefore[102] -> Calc[103] -> ConstraintEnforcer[104] -> Sink: encounter_diagnoses[104] (1/1)#0 (6d9d8d9b1d918481a134ea752ea88d14_cbc357ccb763df2852fee8c4fc7d55f2_0_0) [DEPLOYING].
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - Task                       - Source: encounter_diagnosis[101] -> DropUpdateBefore[102] -> Calc[103] -> ConstraintEnforcer[104] -> Sink: encounter_diagnoses[104] (1/1)#0 (6d9d8d9b1d918481a134ea752ea88d14_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - ExecutionGraph             - Source: encounter_diagnosis[101] -> DropUpdateBefore[102] -> Calc[103] -> ConstraintEnforcer[104] -> Sink: encounter_diagnoses[104] (1/1) (6d9d8d9b1d918481a134ea752ea88d14_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - SourceCoordinator          - Source Source: encounter_diagnosis[101] registering reader for parallel task 0 (#0) @ 
INFO  - Task                       - Source: encounter_diagnosis[101] -> DropUpdateBefore[102] -> Calc[103] -> ConstraintEnforcer[104] -> Sink: encounter_diagnoses[104] (1/1)#0 (6d9d8d9b1d918481a134ea752ea88d14_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
INFO  - KafkaSourceEnumerator      - Assigning splits to readers {0=[[Partition: openmrs.openmrs.encounter_diagnosis-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}
INFO  - ExecutionGraph             - Source: encounter_diagnosis[101] -> DropUpdateBefore[102] -> Calc[103] -> ConstraintEnforcer[104] -> Sink: encounter_diagnoses[104] (1/1) (6d9d8d9b1d918481a134ea752ea88d14_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
INFO  - SourceReaderBase           - Adding split(s) to reader: [[Partition: openmrs.openmrs.encounter_diagnosis-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]
INFO  - ConsumerConfig             - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = flink-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

WARN  - ConsumerConfig             - The configuration 'client.id.prefix' was supplied but isn't a known config.
WARN  - ConsumerConfig             - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290632431
WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.consumer:type=app-info,id=flink-0
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:816)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:666)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:647)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:627)
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.<init>(KafkaPartitionSplitReader.java:88)
	at org.apache.flink.connector.kafka.source.KafkaSource.lambda$createReader$1(KafkaSource.java:160)
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager.createSplitFetcher(SplitFetcherManager.java:196)
	at org.apache.flink.connector.base.source.reader.fetcher.SingleThreadFetcherManager.addSplits(SingleThreadFetcherManager.java:107)
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.addSplits(SourceReaderBase.java:242)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleAddSplitsEvent(SourceOperator.java:584)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleOperatorEvent(SourceOperator.java:561)
	at org.apache.flink.streaming.runtime.tasks.OperatorEventDispatcherImpl.dispatchEventToHandlers(OperatorEventDispatcherImpl.java:72)
	at org.apache.flink.streaming.runtime.tasks.RegularOperatorChain.dispatchOperatorEvent(RegularOperatorChain.java:80)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$dispatchOperatorEvent$20(StreamTask.java:1473)
	at org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$1.runThrowing(StreamTaskActionExecutor.java:50)
	at org.apache.flink.streaming.runtime.tasks.mailbox.Mail.run(Mail.java:90)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMail(MailboxProcessor.java:398)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMailsWhenDefaultActionUnavailable(MailboxProcessor.java:367)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMail(MailboxProcessor.java:352)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:229)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:839)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:788)
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:952)
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:931)
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:745)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:562)
	at java.base/java.lang.Thread.run(Thread.java:829)
INFO  - SplitFetcher               - Starting split fetcher 0
INFO  - KafkaConsumer              - [Consumer clientId=flink-0, groupId=flink] Subscribed to partition(s): openmrs.openmrs.encounter_diagnosis-0
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Seeking to EARLIEST offset of partition openmrs.openmrs.encounter_diagnosis-0
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Resetting the last seen epoch of partition openmrs.openmrs.encounter_diagnosis-0 to 0 since the associated topicId changed from null to lMov0O3MR_CSAWuw4BBjKQ
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Cluster ID: 5Yr1SIgYQz-b-dgRabWx4g
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Resetting offset for partition openmrs.openmrs.encounter_diagnosis-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:29092 (id: 1 rack: null)], epoch=0}}.
INFO  - ZooKeeper                  - Session: 0x10009b90d4f0005 closed
INFO  - ClientCnxn                 - EventThread shut down for session: 0x10009b90d4f0005
WARN  - Configuration              - Config uses deprecated configuration key 'high-availability' instead of proper key 'high-availability.type'
INFO  - ZooKeeperUtils             - Enforcing default ACL for ZK connections
INFO  - ZooKeeperUtils             - Using '/flink/default' as Zookeeper namespace.
INFO  - CuratorFrameworkImpl       - Starting
INFO  - ZooKeeper                  - Initiating client connection, connectString=localhost:2181 sessionTimeout=60000 watcher=org.apache.flink.shaded.curator5.org.apache.curator.ConnectionState@5677c91c
INFO  - ClientCnxnSocket           - jute.maxbuffer value is 1048575 Bytes
INFO  - ClientCnxn                 - zookeeper.request.timeout value is 0. feature enabled=false
INFO  - ClientCnxn                 - Opening socket connection to server localhost/127.0.0.1:2181.
INFO  - ClientCnxn                 - SASL config status: Will not attempt to authenticate using SASL (unknown error)
INFO  - CuratorFrameworkImpl       - Default schema
INFO  - aultLeaderRetrievalService - Starting DefaultLeaderRetrievalService with ZookeeperLeaderRetrievalDriver{connectionInformationPath='/leader/rest_server/connection_info'}.
INFO  - ClientCnxn                 - Socket connection established, initiating session, client: /127.0.0.1:52310, server: localhost/127.0.0.1:2181
INFO  - ClientCnxn                 - Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x10009b90d4f0006, negotiated timeout = 40000
INFO  - ConnectionStateManager     - State change: CONNECTED
INFO  - EnsembleTracker            - New config event received: {}
INFO  - RestClusterClient          - Submitting job 'insert-into_analytics.analytics.visits' (e08bfbac0c29fa3541fbb236ff4c9568).
INFO  - EnsembleTracker            - New config event received: {}
INFO  - StandaloneDispatcher       - Received JobGraph submission 'insert-into_analytics.analytics.visits' (e08bfbac0c29fa3541fbb236ff4c9568).
INFO  - StandaloneDispatcher       - Submitting job 'insert-into_analytics.analytics.visits' (e08bfbac0c29fa3541fbb236ff4c9568).
INFO  - DefaultJobGraphStore       - Added JobGraph(jobId: e08bfbac0c29fa3541fbb236ff4c9568) to ZooKeeperStateHandleStore{namespace='flink/default/jobgraphs'}.
INFO  - faultLeaderElectionService - Starting DefaultLeaderElectionService with org.apache.flink.runtime.leaderelection.MultipleComponentLeaderElectionDriverAdapter@582af47e.
INFO  - terServiceLeadershipRunner - JobMasterServiceLeadershipRunner for job e08bfbac0c29fa3541fbb236ff4c9568 was granted leadership with leader id 3a82a6ce-fb62-4610-b46c-7fb86bd673d4. Creating new JobMasterServiceProcess.
INFO  - AkkaRpcService             - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/rpc/jobmanager_8 .
INFO  - JobMaster                  - Initializing job 'insert-into_analytics.analytics.visits' (e08bfbac0c29fa3541fbb236ff4c9568).
INFO  - RestClusterClient          - Successfully submitted job 'insert-into_analytics.analytics.visits' (e08bfbac0c29fa3541fbb236ff4c9568) to 'http://localhost:8081'.
INFO  - JobMaster                  - Using restart back off time strategy ExponentialDelayRestartBackoffTimeStrategy(initialBackoffMS=1000, maxBackoffMS=300000, backoffMultiplier=2.0, resetBackoffThresholdMS=3600000, jitterFactor=0.1, currentBackoffMS=1000, lastFailureTimestamp=0) for insert-into_analytics.analytics.visits (e08bfbac0c29fa3541fbb236ff4c9568).
INFO  - pletedCheckpointStoreUtils - Recovering checkpoints from ZooKeeperStateHandleStore{namespace='flink/default/jobs/e08bfbac0c29fa3541fbb236ff4c9568/checkpoints'}.
INFO  - pletedCheckpointStoreUtils - Found 0 checkpoints in ZooKeeperStateHandleStore{namespace='flink/default/jobs/e08bfbac0c29fa3541fbb236ff4c9568/checkpoints'}.
INFO  - pletedCheckpointStoreUtils - Trying to fetch 0 checkpoints from storage.
INFO  - ZooKeeperUtils             - Initialized DefaultCompletedCheckpointStore in 'ZooKeeperStateHandleStore{namespace='flink/default/jobs/e08bfbac0c29fa3541fbb236ff4c9568/checkpoints'}' with /checkpoints.
INFO  - ExecutionGraph             - Created execution graph 42d00b36fc131a16543be5485c916ea3 for job e08bfbac0c29fa3541fbb236ff4c9568.
INFO  - JobMaster                  - Running initialization on master for job insert-into_analytics.analytics.visits (e08bfbac0c29fa3541fbb236ff4c9568).
INFO  - JobMaster                  - Successfully ran initialization on master in 0 ms.
INFO  - DefaultExecutionTopology   - Built 1 new pipelined regions in 0 ms, total 1 pipelined regions currently.
INFO  - JobMaster                  - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - JobMaster                  - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - JobMaster                  - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - CheckpointCoordinator      - No checkpoint found during restore.
INFO  - JobMaster                  - Using failover strategy org.apache.flink.runtime.executiongraph.failover.flip1.RestartPipelinedRegionFailoverStrategy@7d478005 for insert-into_analytics.analytics.visits (e08bfbac0c29fa3541fbb236ff4c9568).
INFO  - aultLeaderRetrievalService - Starting DefaultLeaderRetrievalService with ZookeeperLeaderRetrievalDriver{connectionInformationPath='/resource_manager/connection_info'}.
INFO  - JobMaster                  - Starting execution of job 'insert-into_analytics.analytics.visits' (e08bfbac0c29fa3541fbb236ff4c9568) under job master id b46c7fb86bd673d43a82a6cefb624610.
INFO  - SourceCoordinator          - Starting split enumerator for source Source: visit[105].
INFO  - SourceCoordinator          - Starting split enumerator for source Source: visit_type[108].
INFO  - SourceCoordinator          - Starting split enumerator for source Source: person[114].
INFO  - JobMaster                  - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
INFO  - ExecutionGraph             - Job insert-into_analytics.analytics.visits (e08bfbac0c29fa3541fbb236ff4c9568) switched from state CREATED to RUNNING.
INFO  - AdminClientConfig          - AdminClientConfig values: 
	bootstrap.servers = [localhost:29092]
	client.dns.lookup = use_all_dns_ips
	client.id = flink-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

INFO  - AdminClientConfig          - AdminClientConfig values: 
	bootstrap.servers = [localhost:29092]
	client.dns.lookup = use_all_dns_ips
	client.id = flink-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

INFO  - AdminClientConfig          - AdminClientConfig values: 
	bootstrap.servers = [localhost:29092]
	client.dns.lookup = use_all_dns_ips
	client.id = flink-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

INFO  - ExecutionGraph             - Source: visit[105] -> Calc[106] (1/1) (42d00b36fc131a16543be5485c916ea3_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to SCHEDULED.
INFO  - ExecutionGraph             - Source: visit_type[108] -> Calc[109] (1/1) (42d00b36fc131a16543be5485c916ea3_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) switched from CREATED to SCHEDULED.
INFO  - ExecutionGraph             - Source: person[114] -> Calc[115] (1/1) (42d00b36fc131a16543be5485c916ea3_2963852293169ba90d9d1e7d6308db5c_0_0) switched from CREATED to SCHEDULED.
INFO  - ExecutionGraph             - Join[111] -> Calc[112] (1/1) (42d00b36fc131a16543be5485c916ea3_bd51d758b4efb5e2f06d8b93962c12d2_0_0) switched from CREATED to SCHEDULED.
INFO  - ExecutionGraph             - Join[117] -> Calc[118] -> ConstraintEnforcer[119] (1/1) (42d00b36fc131a16543be5485c916ea3_2e97d77449c913cf0f6bfb4cb4497fa8_0_0) switched from CREATED to SCHEDULED.
INFO  - ExecutionGraph             - SinkMaterializer[119] -> Sink: visits[119] (1/1) (42d00b36fc131a16543be5485c916ea3_b6b54abcd38d0cf242f4ba4c18cb7ed5_0_0) switched from CREATED to SCHEDULED.
INFO  - JobMaster                  - Connecting to ResourceManager akka://flink/user/rpc/resourcemanager_1(b46c7fb86bd673d43a82a6cefb624610)
INFO  - JobMaster                  - Resolved ResourceManager address, beginning registration
INFO  - aultLeaderRetrievalService - Starting DefaultLeaderRetrievalService with ZookeeperLeaderRetrievalDriver{connectionInformationPath='/e08bfbac0c29fa3541fbb236ff4c9568/connection_info'}.
INFO  - StandaloneResourceManager  - Registering job manager b46c7fb86bd673d43a82a6cefb624610@akka://flink/user/rpc/jobmanager_8 for job e08bfbac0c29fa3541fbb236ff4c9568.
WARN  - AdminClientConfig          - The configuration 'key.deserializer' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'value.deserializer' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'enable.auto.commit' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'client.id.prefix' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'group.id' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'auto.offset.reset' was supplied but isn't a known config.
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290632883
WARN  - AdminClientConfig          - The configuration 'key.deserializer' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'value.deserializer' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'enable.auto.commit' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'client.id.prefix' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'group.id' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'auto.offset.reset' was supplied but isn't a known config.
WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.admin.client:type=app-info,id=flink-enumerator-admin-client
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.admin.KafkaAdminClient.<init>(KafkaAdminClient.java:597)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:539)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:478)
	at org.apache.kafka.clients.admin.Admin.create(Admin.java:133)
	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getKafkaAdminClient(KafkaSourceEnumerator.java:410)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.start(KafkaSourceEnumerator.java:151)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$start$1(SourceCoordinator.java:234)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$runInEventLoop$10(SourceCoordinator.java:458)
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290632883
WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.admin.client:type=app-info,id=flink-enumerator-admin-client
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.admin.KafkaAdminClient.<init>(KafkaAdminClient.java:597)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:539)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:478)
	at org.apache.kafka.clients.admin.Admin.create(Admin.java:133)
	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getKafkaAdminClient(KafkaSourceEnumerator.java:410)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.start(KafkaSourceEnumerator.java:151)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$start$1(SourceCoordinator.java:234)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$runInEventLoop$10(SourceCoordinator.java:458)
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
INFO  - KafkaSourceEnumerator      - Starting the KafkaSourceEnumerator for consumer group flink without periodic partition discovery.
INFO  - KafkaSourceEnumerator      - Starting the KafkaSourceEnumerator for consumer group flink without periodic partition discovery.
WARN  - AdminClientConfig          - The configuration 'key.deserializer' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'value.deserializer' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'enable.auto.commit' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'client.id.prefix' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'group.id' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'auto.offset.reset' was supplied but isn't a known config.
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290632885
WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.admin.client:type=app-info,id=flink-enumerator-admin-client
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.admin.KafkaAdminClient.<init>(KafkaAdminClient.java:597)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:539)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:478)
	at org.apache.kafka.clients.admin.Admin.create(Admin.java:133)
	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getKafkaAdminClient(KafkaSourceEnumerator.java:410)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.start(KafkaSourceEnumerator.java:151)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$start$1(SourceCoordinator.java:234)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$runInEventLoop$10(SourceCoordinator.java:458)
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
INFO  - KafkaSourceEnumerator      - Starting the KafkaSourceEnumerator for consumer group flink without periodic partition discovery.
INFO  - KafkaSourceEnumerator      - Discovered new partitions: [openmrs.openmrs.visit_type-0]
INFO  - KafkaSourceEnumerator      - Discovered new partitions: [openmrs.openmrs.visit-0]
INFO  - KafkaSourceEnumerator      - Discovered new partitions: [openmrs.openmrs.person-0]
INFO  - StandaloneResourceManager  - Registered job manager b46c7fb86bd673d43a82a6cefb624610@akka://flink/user/rpc/jobmanager_8 for job e08bfbac0c29fa3541fbb236ff4c9568.
INFO  - JobMaster                  - JobManager successfully registered at ResourceManager, leader id: b46c7fb86bd673d43a82a6cefb624610.
INFO  - DeclarativeSlotManager     - Received resource requirements from job e08bfbac0c29fa3541fbb236ff4c9568: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
INFO  - aultLeaderRetrievalService - Stopping DefaultLeaderRetrievalService.
INFO  - eeperLeaderRetrievalDriver - Closing ZookeeperLeaderRetrievalDriver{connectionInformationPath='/leader/rest_server/connection_info'}.
INFO  - CuratorFrameworkImpl       - backgroundOperationsLoop exiting
INFO  - TaskExecutor               - Receive slot request b94ebd3252ffb87b668723573ce4520e for job e08bfbac0c29fa3541fbb236ff4c9568 from resource manager with leader id b46c7fb86bd673d43a82a6cefb624610.
INFO  - TaskExecutor               - Allocated slot for b94ebd3252ffb87b668723573ce4520e.
INFO  - DefaultJobLeaderService    - Add job e08bfbac0c29fa3541fbb236ff4c9568 for job leader monitoring.
INFO  - aultLeaderRetrievalService - Starting DefaultLeaderRetrievalService with ZookeeperLeaderRetrievalDriver{connectionInformationPath='/e08bfbac0c29fa3541fbb236ff4c9568/connection_info'}.
INFO  - DefaultJobLeaderService    - Try to register at job manager akka://flink/user/rpc/jobmanager_8 with leader id 3a82a6ce-fb62-4610-b46c-7fb86bd673d4.
INFO  - DefaultJobLeaderService    - Resolved JobManager address, beginning registration
INFO  - DefaultJobLeaderService    - Successful registration at job manager akka://flink/user/rpc/jobmanager_8 for job e08bfbac0c29fa3541fbb236ff4c9568.
INFO  - TaskExecutor               - Establish JobManager connection for job e08bfbac0c29fa3541fbb236ff4c9568.
INFO  - TaskExecutor               - Offer reserved slots to the leader of job e08bfbac0c29fa3541fbb236ff4c9568.
INFO  - ExecutionGraph             - Source: visit[105] -> Calc[106] (1/1) (42d00b36fc131a16543be5485c916ea3_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - ExecutionGraph             - Deploying Source: visit[105] -> Calc[106] (1/1) (attempt #0) with attempt id 42d00b36fc131a16543be5485c916ea3_cbc357ccb763df2852fee8c4fc7d55f2_0_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id b94ebd3252ffb87b668723573ce4520e
INFO  - ExecutionGraph             - Source: visit_type[108] -> Calc[109] (1/1) (42d00b36fc131a16543be5485c916ea3_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - ExecutionGraph             - Deploying Source: visit_type[108] -> Calc[109] (1/1) (attempt #0) with attempt id 42d00b36fc131a16543be5485c916ea3_6cdc5bb954874d922eaee11a8e7b5dd5_0_0 and vertex id 6cdc5bb954874d922eaee11a8e7b5dd5_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id b94ebd3252ffb87b668723573ce4520e
INFO  - TaskSlotTableImpl          - Activate slot b94ebd3252ffb87b668723573ce4520e.
INFO  - ExecutionGraph             - Source: person[114] -> Calc[115] (1/1) (42d00b36fc131a16543be5485c916ea3_2963852293169ba90d9d1e7d6308db5c_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - ExecutionGraph             - Deploying Source: person[114] -> Calc[115] (1/1) (attempt #0) with attempt id 42d00b36fc131a16543be5485c916ea3_2963852293169ba90d9d1e7d6308db5c_0_0 and vertex id 2963852293169ba90d9d1e7d6308db5c_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id b94ebd3252ffb87b668723573ce4520e
INFO  - ExecutionGraph             - Join[111] -> Calc[112] (1/1) (42d00b36fc131a16543be5485c916ea3_bd51d758b4efb5e2f06d8b93962c12d2_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - ExecutionGraph             - Deploying Join[111] -> Calc[112] (1/1) (attempt #0) with attempt id 42d00b36fc131a16543be5485c916ea3_bd51d758b4efb5e2f06d8b93962c12d2_0_0 and vertex id bd51d758b4efb5e2f06d8b93962c12d2_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id b94ebd3252ffb87b668723573ce4520e
INFO  - tateChangelogStorageLoader - Creating a changelog storage with name 'memory'.
INFO  - tateExecutorFactoryManager - Creating the channel state executor factory for job id e08bfbac0c29fa3541fbb236ff4c9568
INFO  - TaskExecutor               - Received task Source: visit[105] -> Calc[106] (1/1)#0 (42d00b36fc131a16543be5485c916ea3_cbc357ccb763df2852fee8c4fc7d55f2_0_0), deploy into slot with allocation id b94ebd3252ffb87b668723573ce4520e.
INFO  - Task                       - Source: visit[105] -> Calc[106] (1/1)#0 (42d00b36fc131a16543be5485c916ea3_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to DEPLOYING.
INFO  - ExecutionGraph             - Join[117] -> Calc[118] -> ConstraintEnforcer[119] (1/1) (42d00b36fc131a16543be5485c916ea3_2e97d77449c913cf0f6bfb4cb4497fa8_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - TaskSlotTableImpl          - Activate slot b94ebd3252ffb87b668723573ce4520e.
INFO  - Task                       - Loading JAR files for task Source: visit[105] -> Calc[106] (1/1)#0 (42d00b36fc131a16543be5485c916ea3_cbc357ccb763df2852fee8c4fc7d55f2_0_0) [DEPLOYING].
INFO  - ExecutionGraph             - Deploying Join[117] -> Calc[118] -> ConstraintEnforcer[119] (1/1) (attempt #0) with attempt id 42d00b36fc131a16543be5485c916ea3_2e97d77449c913cf0f6bfb4cb4497fa8_0_0 and vertex id 2e97d77449c913cf0f6bfb4cb4497fa8_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id b94ebd3252ffb87b668723573ce4520e
INFO  - TaskExecutor               - Received task Source: visit_type[108] -> Calc[109] (1/1)#0 (42d00b36fc131a16543be5485c916ea3_6cdc5bb954874d922eaee11a8e7b5dd5_0_0), deploy into slot with allocation id b94ebd3252ffb87b668723573ce4520e.
INFO  - ExecutionGraph             - SinkMaterializer[119] -> Sink: visits[119] (1/1) (42d00b36fc131a16543be5485c916ea3_b6b54abcd38d0cf242f4ba4c18cb7ed5_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - Task                       - Source: visit_type[108] -> Calc[109] (1/1)#0 (42d00b36fc131a16543be5485c916ea3_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) switched from CREATED to DEPLOYING.
INFO  - TaskSlotTableImpl          - Activate slot b94ebd3252ffb87b668723573ce4520e.
INFO  - Task                       - Loading JAR files for task Source: visit_type[108] -> Calc[109] (1/1)#0 (42d00b36fc131a16543be5485c916ea3_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) [DEPLOYING].
INFO  - ExecutionGraph             - Deploying SinkMaterializer[119] -> Sink: visits[119] (1/1) (attempt #0) with attempt id 42d00b36fc131a16543be5485c916ea3_b6b54abcd38d0cf242f4ba4c18cb7ed5_0_0 and vertex id b6b54abcd38d0cf242f4ba4c18cb7ed5_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id b94ebd3252ffb87b668723573ce4520e
INFO  - TaskExecutor               - Received task Source: person[114] -> Calc[115] (1/1)#0 (42d00b36fc131a16543be5485c916ea3_2963852293169ba90d9d1e7d6308db5c_0_0), deploy into slot with allocation id b94ebd3252ffb87b668723573ce4520e.
INFO  - TaskSlotTableImpl          - Activate slot b94ebd3252ffb87b668723573ce4520e.
INFO  - Task                       - Source: person[114] -> Calc[115] (1/1)#0 (42d00b36fc131a16543be5485c916ea3_2963852293169ba90d9d1e7d6308db5c_0_0) switched from CREATED to DEPLOYING.
INFO  - Task                       - Loading JAR files for task Source: person[114] -> Calc[115] (1/1)#0 (42d00b36fc131a16543be5485c916ea3_2963852293169ba90d9d1e7d6308db5c_0_0) [DEPLOYING].
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - TaskExecutor               - Received task Join[111] -> Calc[112] (1/1)#0 (42d00b36fc131a16543be5485c916ea3_bd51d758b4efb5e2f06d8b93962c12d2_0_0), deploy into slot with allocation id b94ebd3252ffb87b668723573ce4520e.
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - Task                       - Join[111] -> Calc[112] (1/1)#0 (42d00b36fc131a16543be5485c916ea3_bd51d758b4efb5e2f06d8b93962c12d2_0_0) switched from CREATED to DEPLOYING.
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - TaskSlotTableImpl          - Activate slot b94ebd3252ffb87b668723573ce4520e.
INFO  - Task                       - Source: visit[105] -> Calc[106] (1/1)#0 (42d00b36fc131a16543be5485c916ea3_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - Task                       - Loading JAR files for task Join[111] -> Calc[112] (1/1)#0 (42d00b36fc131a16543be5485c916ea3_bd51d758b4efb5e2f06d8b93962c12d2_0_0) [DEPLOYING].
INFO  - Task                       - Source: visit_type[108] -> Calc[109] (1/1)#0 (42d00b36fc131a16543be5485c916ea3_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - Task                       - Source: person[114] -> Calc[115] (1/1)#0 (42d00b36fc131a16543be5485c916ea3_2963852293169ba90d9d1e7d6308db5c_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - TaskExecutor               - Received task Join[117] -> Calc[118] -> ConstraintEnforcer[119] (1/1)#0 (42d00b36fc131a16543be5485c916ea3_2e97d77449c913cf0f6bfb4cb4497fa8_0_0), deploy into slot with allocation id b94ebd3252ffb87b668723573ce4520e.
INFO  - ExecutionGraph             - Source: visit[105] -> Calc[106] (1/1) (42d00b36fc131a16543be5485c916ea3_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - ExecutionGraph             - Source: visit_type[108] -> Calc[109] (1/1) (42d00b36fc131a16543be5485c916ea3_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - ExecutionGraph             - Source: person[114] -> Calc[115] (1/1) (42d00b36fc131a16543be5485c916ea3_2963852293169ba90d9d1e7d6308db5c_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - TaskSlotTableImpl          - Activate slot b94ebd3252ffb87b668723573ce4520e.
INFO  - Task                       - Join[117] -> Calc[118] -> ConstraintEnforcer[119] (1/1)#0 (42d00b36fc131a16543be5485c916ea3_2e97d77449c913cf0f6bfb4cb4497fa8_0_0) switched from CREATED to DEPLOYING.
INFO  - Task                       - Loading JAR files for task Join[117] -> Calc[118] -> ConstraintEnforcer[119] (1/1)#0 (42d00b36fc131a16543be5485c916ea3_2e97d77449c913cf0f6bfb4cb4497fa8_0_0) [DEPLOYING].
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - Task                       - Join[111] -> Calc[112] (1/1)#0 (42d00b36fc131a16543be5485c916ea3_bd51d758b4efb5e2f06d8b93962c12d2_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - ExecutionGraph             - Join[111] -> Calc[112] (1/1) (42d00b36fc131a16543be5485c916ea3_bd51d758b4efb5e2f06d8b93962c12d2_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - TaskExecutor               - Received task SinkMaterializer[119] -> Sink: visits[119] (1/1)#0 (42d00b36fc131a16543be5485c916ea3_b6b54abcd38d0cf242f4ba4c18cb7ed5_0_0), deploy into slot with allocation id b94ebd3252ffb87b668723573ce4520e.
INFO  - TaskSlotTableImpl          - Activate slot b94ebd3252ffb87b668723573ce4520e.
INFO  - Task                       - SinkMaterializer[119] -> Sink: visits[119] (1/1)#0 (42d00b36fc131a16543be5485c916ea3_b6b54abcd38d0cf242f4ba4c18cb7ed5_0_0) switched from CREATED to DEPLOYING.
INFO  - Task                       - Loading JAR files for task SinkMaterializer[119] -> Sink: visits[119] (1/1)#0 (42d00b36fc131a16543be5485c916ea3_b6b54abcd38d0cf242f4ba4c18cb7ed5_0_0) [DEPLOYING].
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - Task                       - Join[117] -> Calc[118] -> ConstraintEnforcer[119] (1/1)#0 (42d00b36fc131a16543be5485c916ea3_2e97d77449c913cf0f6bfb4cb4497fa8_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - ExecutionGraph             - Join[117] -> Calc[118] -> ConstraintEnforcer[119] (1/1) (42d00b36fc131a16543be5485c916ea3_2e97d77449c913cf0f6bfb4cb4497fa8_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - Task                       - SinkMaterializer[119] -> Sink: visits[119] (1/1)#0 (42d00b36fc131a16543be5485c916ea3_b6b54abcd38d0cf242f4ba4c18cb7ed5_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - ExecutionGraph             - SinkMaterializer[119] -> Sink: visits[119] (1/1) (42d00b36fc131a16543be5485c916ea3_b6b54abcd38d0cf242f4ba4c18cb7ed5_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - mbeddedRocksDBStateBackend - Getting shared memory for RocksDB: shareScope=SLOT, managed=false
INFO  - mbeddedRocksDBStateBackend - Obtained shared RocksDB cache of size 6710886 bytes
INFO  - Task                       - Source: visit[105] -> Calc[106] (1/1)#0 (42d00b36fc131a16543be5485c916ea3_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
INFO  - Task                       - Source: visit_type[108] -> Calc[109] (1/1)#0 (42d00b36fc131a16543be5485c916ea3_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) switched from INITIALIZING to RUNNING.
INFO  - DBKeyedStateBackendBuilder - Finished building RocksDB keyed state-backend at /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_e08bfbac0c29fa3541fbb236ff4c9568_op_StreamingJoinOperator_bd51d758b4efb5e2f06d8b93962c12d2__1_1__uuid_1249d7f7-f4e9-4e45-ad3e-db5266c4ea1f.
INFO  - SourceCoordinator          - Source Source: person[114] registering reader for parallel task 0 (#0) @ 
INFO  - KafkaSourceEnumerator      - Assigning splits to readers {0=[[Partition: openmrs.openmrs.person-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}
INFO  - SourceCoordinator          - Source Source: visit[105] registering reader for parallel task 0 (#0) @ 
INFO  - SourceCoordinator          - Source Source: visit_type[108] registering reader for parallel task 0 (#0) @ 
INFO  - KafkaSourceEnumerator      - Assigning splits to readers {0=[[Partition: openmrs.openmrs.visit_type-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}
INFO  - Task                       - Source: person[114] -> Calc[115] (1/1)#0 (42d00b36fc131a16543be5485c916ea3_2963852293169ba90d9d1e7d6308db5c_0_0) switched from INITIALIZING to RUNNING.
INFO  - KafkaSourceEnumerator      - Assigning splits to readers {0=[[Partition: openmrs.openmrs.visit-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}
INFO  - ExecutionGraph             - Source: visit[105] -> Calc[106] (1/1) (42d00b36fc131a16543be5485c916ea3_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
INFO  - ExecutionGraph             - Source: visit_type[108] -> Calc[109] (1/1) (42d00b36fc131a16543be5485c916ea3_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) switched from INITIALIZING to RUNNING.
INFO  - ExecutionGraph             - Source: person[114] -> Calc[115] (1/1) (42d00b36fc131a16543be5485c916ea3_2963852293169ba90d9d1e7d6308db5c_0_0) switched from INITIALIZING to RUNNING.
INFO  - SourceReaderBase           - Adding split(s) to reader: [[Partition: openmrs.openmrs.person-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]
INFO  - SourceReaderBase           - Adding split(s) to reader: [[Partition: openmrs.openmrs.visit_type-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]
INFO  - SourceReaderBase           - Adding split(s) to reader: [[Partition: openmrs.openmrs.visit-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]
INFO  - ConsumerConfig             - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = flink-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

INFO  - ConsumerConfig             - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = flink-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

WARN  - RocksDBOperationUtils      - RocksDBStateBackend performance will be poor because of the current Flink memory configuration! RocksDB will flush memtable constantly, causing high IO and CPU. Typically the easiest fix is to increase task manager managed memory size. If running locally, see the parameter taskmanager.memory.managed.size. Details: arenaBlockSize 8388608 > mutableLimit 1957341 (writeBufferSize = 67108864, arenaBlockSizeConfigured = 0, defaultArenaBlockSize = 8388608, writeBufferManagerCapacity = 2236962)
INFO  - ConsumerConfig             - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = flink-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

WARN  - ConsumerConfig             - The configuration 'client.id.prefix' was supplied but isn't a known config.
WARN  - ConsumerConfig             - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
WARN  - RocksDBOperationUtils      - RocksDBStateBackend performance will be poor because of the current Flink memory configuration! RocksDB will flush memtable constantly, causing high IO and CPU. Typically the easiest fix is to increase task manager managed memory size. If running locally, see the parameter taskmanager.memory.managed.size. Details: arenaBlockSize 8388608 > mutableLimit 1957341 (writeBufferSize = 67108864, arenaBlockSizeConfigured = 0, defaultArenaBlockSize = 8388608, writeBufferManagerCapacity = 2236962)
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290632990
WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.consumer:type=app-info,id=flink-0
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:816)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:666)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:647)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:627)
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.<init>(KafkaPartitionSplitReader.java:88)
	at org.apache.flink.connector.kafka.source.KafkaSource.lambda$createReader$1(KafkaSource.java:160)
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager.createSplitFetcher(SplitFetcherManager.java:196)
	at org.apache.flink.connector.base.source.reader.fetcher.SingleThreadFetcherManager.addSplits(SingleThreadFetcherManager.java:107)
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.addSplits(SourceReaderBase.java:242)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleAddSplitsEvent(SourceOperator.java:584)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleOperatorEvent(SourceOperator.java:561)
	at org.apache.flink.streaming.runtime.tasks.OperatorEventDispatcherImpl.dispatchEventToHandlers(OperatorEventDispatcherImpl.java:72)
	at org.apache.flink.streaming.runtime.tasks.RegularOperatorChain.dispatchOperatorEvent(RegularOperatorChain.java:80)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$dispatchOperatorEvent$20(StreamTask.java:1473)
	at org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$1.runThrowing(StreamTaskActionExecutor.java:50)
	at org.apache.flink.streaming.runtime.tasks.mailbox.Mail.run(Mail.java:90)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMail(MailboxProcessor.java:398)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMailsWhenDefaultActionUnavailable(MailboxProcessor.java:367)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMail(MailboxProcessor.java:352)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:229)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:839)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:788)
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:952)
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:931)
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:745)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:562)
	at java.base/java.lang.Thread.run(Thread.java:829)
INFO  - SplitFetcher               - Starting split fetcher 0
INFO  - KafkaConsumer              - [Consumer clientId=flink-0, groupId=flink] Subscribed to partition(s): openmrs.openmrs.visit_type-0
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Seeking to EARLIEST offset of partition openmrs.openmrs.visit_type-0
INFO  - Task                       - Join[111] -> Calc[112] (1/1)#0 (42d00b36fc131a16543be5485c916ea3_bd51d758b4efb5e2f06d8b93962c12d2_0_0) switched from INITIALIZING to RUNNING.
INFO  - mbeddedRocksDBStateBackend - Getting shared memory for RocksDB: shareScope=SLOT, managed=false
INFO  - mbeddedRocksDBStateBackend - Obtained shared RocksDB cache of size 6710886 bytes
INFO  - ExecutionGraph             - Join[111] -> Calc[112] (1/1) (42d00b36fc131a16543be5485c916ea3_bd51d758b4efb5e2f06d8b93962c12d2_0_0) switched from INITIALIZING to RUNNING.
WARN  - ConsumerConfig             - The configuration 'client.id.prefix' was supplied but isn't a known config.
WARN  - ConsumerConfig             - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290632995
WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.consumer:type=app-info,id=flink-0
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:816)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:666)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:647)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:627)
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.<init>(KafkaPartitionSplitReader.java:88)
	at org.apache.flink.connector.kafka.source.KafkaSource.lambda$createReader$1(KafkaSource.java:160)
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager.createSplitFetcher(SplitFetcherManager.java:196)
	at org.apache.flink.connector.base.source.reader.fetcher.SingleThreadFetcherManager.addSplits(SingleThreadFetcherManager.java:107)
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.addSplits(SourceReaderBase.java:242)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleAddSplitsEvent(SourceOperator.java:584)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleOperatorEvent(SourceOperator.java:561)
	at org.apache.flink.streaming.runtime.tasks.OperatorEventDispatcherImpl.dispatchEventToHandlers(OperatorEventDispatcherImpl.java:72)
	at org.apache.flink.streaming.runtime.tasks.RegularOperatorChain.dispatchOperatorEvent(RegularOperatorChain.java:80)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$dispatchOperatorEvent$20(StreamTask.java:1473)
	at org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$1.runThrowing(StreamTaskActionExecutor.java:50)
	at org.apache.flink.streaming.runtime.tasks.mailbox.Mail.run(Mail.java:90)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMail(MailboxProcessor.java:398)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMailsWhenDefaultActionUnavailable(MailboxProcessor.java:367)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMail(MailboxProcessor.java:352)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:229)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:839)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:788)
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:952)
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:931)
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:745)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:562)
	at java.base/java.lang.Thread.run(Thread.java:829)
WARN  - ConsumerConfig             - The configuration 'client.id.prefix' was supplied but isn't a known config.
WARN  - ConsumerConfig             - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - SplitFetcher               - Starting split fetcher 0
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290632995
WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.consumer:type=app-info,id=flink-0
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:816)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:666)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:647)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:627)
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.<init>(KafkaPartitionSplitReader.java:88)
	at org.apache.flink.connector.kafka.source.KafkaSource.lambda$createReader$1(KafkaSource.java:160)
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager.createSplitFetcher(SplitFetcherManager.java:196)
	at org.apache.flink.connector.base.source.reader.fetcher.SingleThreadFetcherManager.addSplits(SingleThreadFetcherManager.java:107)
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.addSplits(SourceReaderBase.java:242)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleAddSplitsEvent(SourceOperator.java:584)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleOperatorEvent(SourceOperator.java:561)
	at org.apache.flink.streaming.runtime.tasks.OperatorEventDispatcherImpl.dispatchEventToHandlers(OperatorEventDispatcherImpl.java:72)
	at org.apache.flink.streaming.runtime.tasks.RegularOperatorChain.dispatchOperatorEvent(RegularOperatorChain.java:80)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$dispatchOperatorEvent$20(StreamTask.java:1473)
	at org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$1.runThrowing(StreamTaskActionExecutor.java:50)
	at org.apache.flink.streaming.runtime.tasks.mailbox.Mail.run(Mail.java:90)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMail(MailboxProcessor.java:398)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMailsWhenDefaultActionUnavailable(MailboxProcessor.java:367)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMail(MailboxProcessor.java:352)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:229)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:839)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:788)
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:952)
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:931)
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:745)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:562)
	at java.base/java.lang.Thread.run(Thread.java:829)
INFO  - KafkaConsumer              - [Consumer clientId=flink-0, groupId=flink] Subscribed to partition(s): openmrs.openmrs.person-0
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Seeking to EARLIEST offset of partition openmrs.openmrs.person-0
INFO  - SplitFetcher               - Starting split fetcher 0
INFO  - KafkaConsumer              - [Consumer clientId=flink-0, groupId=flink] Subscribed to partition(s): openmrs.openmrs.visit-0
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Seeking to EARLIEST offset of partition openmrs.openmrs.visit-0
INFO  - DBKeyedStateBackendBuilder - Finished building RocksDB keyed state-backend at /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_e08bfbac0c29fa3541fbb236ff4c9568_op_SinkUpsertMaterializer_b6b54abcd38d0cf242f4ba4c18cb7ed5__1_1__uuid_a32c743c-1674-4ab4-9885-0793ca97bc88.
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Resetting the last seen epoch of partition openmrs.openmrs.visit_type-0 to 0 since the associated topicId changed from null to 1AXMBPpnTz65Spybw8yL5Q
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Cluster ID: 5Yr1SIgYQz-b-dgRabWx4g
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Resetting the last seen epoch of partition openmrs.openmrs.person-0 to 0 since the associated topicId changed from null to mtn9qgqVSxmjr7K25Brqdg
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Cluster ID: 5Yr1SIgYQz-b-dgRabWx4g
INFO  - ZooKeeper                  - Session: 0x10009b90d4f0006 closed
INFO  - ClientCnxn                 - EventThread shut down for session: 0x10009b90d4f0006
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Resetting offset for partition openmrs.openmrs.visit_type-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:29092 (id: 1 rack: null)], epoch=0}}.
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Resetting the last seen epoch of partition openmrs.openmrs.visit-0 to 0 since the associated topicId changed from null to u28pspNHRmO5MJKK1_LAXw
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Cluster ID: 5Yr1SIgYQz-b-dgRabWx4g
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Resetting offset for partition openmrs.openmrs.person-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:29092 (id: 1 rack: null)], epoch=0}}.
WARN  - RocksDBOperationUtils      - RocksDBStateBackend performance will be poor because of the current Flink memory configuration! RocksDB will flush memtable constantly, causing high IO and CPU. Typically the easiest fix is to increase task manager managed memory size. If running locally, see the parameter taskmanager.memory.managed.size. Details: arenaBlockSize 8388608 > mutableLimit 1957341 (writeBufferSize = 67108864, arenaBlockSizeConfigured = 0, defaultArenaBlockSize = 8388608, writeBufferManagerCapacity = 2236962)
INFO  - mbeddedRocksDBStateBackend - Getting shared memory for RocksDB: shareScope=SLOT, managed=false
INFO  - mbeddedRocksDBStateBackend - Obtained shared RocksDB cache of size 6710886 bytes
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Resetting offset for partition openmrs.openmrs.visit-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:29092 (id: 1 rack: null)], epoch=0}}.
INFO  - Task                       - SinkMaterializer[119] -> Sink: visits[119] (1/1)#0 (42d00b36fc131a16543be5485c916ea3_b6b54abcd38d0cf242f4ba4c18cb7ed5_0_0) switched from INITIALIZING to RUNNING.
INFO  - ExecutionGraph             - SinkMaterializer[119] -> Sink: visits[119] (1/1) (42d00b36fc131a16543be5485c916ea3_b6b54abcd38d0cf242f4ba4c18cb7ed5_0_0) switched from INITIALIZING to RUNNING.
INFO  - DBKeyedStateBackendBuilder - Finished building RocksDB keyed state-backend at /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_e08bfbac0c29fa3541fbb236ff4c9568_op_StreamingJoinOperator_2e97d77449c913cf0f6bfb4cb4497fa8__1_1__uuid_3233301e-d8f8-441d-a92c-70366ed50a90.
WARN  - RocksDBOperationUtils      - RocksDBStateBackend performance will be poor because of the current Flink memory configuration! RocksDB will flush memtable constantly, causing high IO and CPU. Typically the easiest fix is to increase task manager managed memory size. If running locally, see the parameter taskmanager.memory.managed.size. Details: arenaBlockSize 8388608 > mutableLimit 1957341 (writeBufferSize = 67108864, arenaBlockSizeConfigured = 0, defaultArenaBlockSize = 8388608, writeBufferManagerCapacity = 2236962)
WARN  - RocksDBOperationUtils      - RocksDBStateBackend performance will be poor because of the current Flink memory configuration! RocksDB will flush memtable constantly, causing high IO and CPU. Typically the easiest fix is to increase task manager managed memory size. If running locally, see the parameter taskmanager.memory.managed.size. Details: arenaBlockSize 8388608 > mutableLimit 1957341 (writeBufferSize = 67108864, arenaBlockSizeConfigured = 0, defaultArenaBlockSize = 8388608, writeBufferManagerCapacity = 2236962)
INFO  - Task                       - Join[117] -> Calc[118] -> ConstraintEnforcer[119] (1/1)#0 (42d00b36fc131a16543be5485c916ea3_2e97d77449c913cf0f6bfb4cb4497fa8_0_0) switched from INITIALIZING to RUNNING.
INFO  - ExecutionGraph             - Join[117] -> Calc[118] -> ConstraintEnforcer[119] (1/1) (42d00b36fc131a16543be5485c916ea3_2e97d77449c913cf0f6bfb4cb4497fa8_0_0) switched from INITIALIZING to RUNNING.
WARN  - Configuration              - Config uses deprecated configuration key 'high-availability' instead of proper key 'high-availability.type'
INFO  - ZooKeeperUtils             - Enforcing default ACL for ZK connections
INFO  - ZooKeeperUtils             - Using '/flink/default' as Zookeeper namespace.
INFO  - CuratorFrameworkImpl       - Starting
INFO  - ZooKeeper                  - Initiating client connection, connectString=localhost:2181 sessionTimeout=60000 watcher=org.apache.flink.shaded.curator5.org.apache.curator.ConnectionState@2000fa3d
INFO  - ClientCnxnSocket           - jute.maxbuffer value is 1048575 Bytes
INFO  - ClientCnxn                 - zookeeper.request.timeout value is 0. feature enabled=false
INFO  - ClientCnxn                 - Opening socket connection to server localhost/127.0.0.1:2181.
INFO  - ClientCnxn                 - SASL config status: Will not attempt to authenticate using SASL (unknown error)
INFO  - CuratorFrameworkImpl       - Default schema
INFO  - aultLeaderRetrievalService - Starting DefaultLeaderRetrievalService with ZookeeperLeaderRetrievalDriver{connectionInformationPath='/leader/rest_server/connection_info'}.
INFO  - ClientCnxn                 - Socket connection established, initiating session, client: /127.0.0.1:52332, server: localhost/127.0.0.1:2181
INFO  - ClientCnxn                 - Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x10009b90d4f0007, negotiated timeout = 40000
INFO  - ConnectionStateManager     - State change: CONNECTED
INFO  - EnsembleTracker            - New config event received: {}
INFO  - EnsembleTracker            - New config event received: {}
INFO  - RestClusterClient          - Submitting job 'insert-into_analytics.analytics.observations' (ee8b603bf5edab3af85b6467db69921f).
INFO  - StandaloneDispatcher       - Received JobGraph submission 'insert-into_analytics.analytics.observations' (ee8b603bf5edab3af85b6467db69921f).
INFO  - StandaloneDispatcher       - Submitting job 'insert-into_analytics.analytics.observations' (ee8b603bf5edab3af85b6467db69921f).
INFO  - DefaultJobGraphStore       - Added JobGraph(jobId: ee8b603bf5edab3af85b6467db69921f) to ZooKeeperStateHandleStore{namespace='flink/default/jobgraphs'}.
INFO  - faultLeaderElectionService - Starting DefaultLeaderElectionService with org.apache.flink.runtime.leaderelection.MultipleComponentLeaderElectionDriverAdapter@544d7b67.
INFO  - terServiceLeadershipRunner - JobMasterServiceLeadershipRunner for job ee8b603bf5edab3af85b6467db69921f was granted leadership with leader id 3a82a6ce-fb62-4610-b46c-7fb86bd673d4. Creating new JobMasterServiceProcess.
INFO  - AkkaRpcService             - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/rpc/jobmanager_9 .
INFO  - JobMaster                  - Initializing job 'insert-into_analytics.analytics.observations' (ee8b603bf5edab3af85b6467db69921f).
INFO  - RestClusterClient          - Successfully submitted job 'insert-into_analytics.analytics.observations' (ee8b603bf5edab3af85b6467db69921f) to 'http://localhost:8081'.
INFO  - JobMaster                  - Using restart back off time strategy ExponentialDelayRestartBackoffTimeStrategy(initialBackoffMS=1000, maxBackoffMS=300000, backoffMultiplier=2.0, resetBackoffThresholdMS=3600000, jitterFactor=0.1, currentBackoffMS=1000, lastFailureTimestamp=0) for insert-into_analytics.analytics.observations (ee8b603bf5edab3af85b6467db69921f).
INFO  - pletedCheckpointStoreUtils - Recovering checkpoints from ZooKeeperStateHandleStore{namespace='flink/default/jobs/ee8b603bf5edab3af85b6467db69921f/checkpoints'}.
INFO  - pletedCheckpointStoreUtils - Found 0 checkpoints in ZooKeeperStateHandleStore{namespace='flink/default/jobs/ee8b603bf5edab3af85b6467db69921f/checkpoints'}.
INFO  - pletedCheckpointStoreUtils - Trying to fetch 0 checkpoints from storage.
INFO  - ZooKeeperUtils             - Initialized DefaultCompletedCheckpointStore in 'ZooKeeperStateHandleStore{namespace='flink/default/jobs/ee8b603bf5edab3af85b6467db69921f/checkpoints'}' with /checkpoints.
INFO  - ExecutionGraph             - Created execution graph 580277ceefe8efaa1a64deb029a01c5c for job ee8b603bf5edab3af85b6467db69921f.
INFO  - JobMaster                  - Running initialization on master for job insert-into_analytics.analytics.observations (ee8b603bf5edab3af85b6467db69921f).
INFO  - JobMaster                  - Successfully ran initialization on master in 0 ms.
INFO  - DefaultExecutionTopology   - Built 1 new pipelined regions in 0 ms, total 1 pipelined regions currently.
INFO  - JobMaster                  - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - JobMaster                  - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - JobMaster                  - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - CheckpointCoordinator      - No checkpoint found during restore.
INFO  - JobMaster                  - Using failover strategy org.apache.flink.runtime.executiongraph.failover.flip1.RestartPipelinedRegionFailoverStrategy@212a9bb3 for insert-into_analytics.analytics.observations (ee8b603bf5edab3af85b6467db69921f).
INFO  - aultLeaderRetrievalService - Starting DefaultLeaderRetrievalService with ZookeeperLeaderRetrievalDriver{connectionInformationPath='/resource_manager/connection_info'}.
INFO  - JobMaster                  - Starting execution of job 'insert-into_analytics.analytics.observations' (ee8b603bf5edab3af85b6467db69921f) under job master id b46c7fb86bd673d43a82a6cefb624610.
INFO  - SourceCoordinator          - Starting split enumerator for source Source: obs[120].
INFO  - SourceCoordinator          - Starting split enumerator for source Source: location[153].
INFO  - SourceCoordinator          - Starting split enumerator for source Source: visit[135].
INFO  - AdminClientConfig          - AdminClientConfig values: 
	bootstrap.servers = [localhost:29092]
	client.dns.lookup = use_all_dns_ips
	client.id = flink-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

INFO  - SourceCoordinator          - Starting split enumerator for source Source: visit_type[147].
INFO  - SourceCoordinator          - Starting split enumerator for source Source: encounter_type[141].
INFO  - AdminClientConfig          - AdminClientConfig values: 
	bootstrap.servers = [localhost:29092]
	client.dns.lookup = use_all_dns_ips
	client.id = flink-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

INFO  - AdminClientConfig          - AdminClientConfig values: 
	bootstrap.servers = [localhost:29092]
	client.dns.lookup = use_all_dns_ips
	client.id = flink-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

INFO  - AdminClientConfig          - AdminClientConfig values: 
	bootstrap.servers = [localhost:29092]
	client.dns.lookup = use_all_dns_ips
	client.id = flink-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

INFO  - AdminClientConfig          - AdminClientConfig values: 
	bootstrap.servers = [localhost:29092]
	client.dns.lookup = use_all_dns_ips
	client.id = flink-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

INFO  - SourceCoordinator          - Starting split enumerator for source Source: concept_name[123].
INFO  - SourceCoordinator          - Starting split enumerator for source Source: encounter[129].
INFO  - JobMaster                  - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
INFO  - ExecutionGraph             - Job insert-into_analytics.analytics.observations (ee8b603bf5edab3af85b6467db69921f) switched from state CREATED to RUNNING.
INFO  - AdminClientConfig          - AdminClientConfig values: 
	bootstrap.servers = [localhost:29092]
	client.dns.lookup = use_all_dns_ips
	client.id = flink-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

INFO  - AdminClientConfig          - AdminClientConfig values: 
	bootstrap.servers = [localhost:29092]
	client.dns.lookup = use_all_dns_ips
	client.id = flink-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

INFO  - ExecutionGraph             - Source: obs[120] -> Calc[121] (1/1) (580277ceefe8efaa1a64deb029a01c5c_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to SCHEDULED.
INFO  - ExecutionGraph             - Source: concept_name[123] -> Calc[124] (1/1) (580277ceefe8efaa1a64deb029a01c5c_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) switched from CREATED to SCHEDULED.
INFO  - ExecutionGraph             - Source: encounter[129] -> Calc[130] (1/1) (580277ceefe8efaa1a64deb029a01c5c_2963852293169ba90d9d1e7d6308db5c_0_0) switched from CREATED to SCHEDULED.
INFO  - ExecutionGraph             - Source: visit[135] -> Calc[136] (1/1) (580277ceefe8efaa1a64deb029a01c5c_1171dea6747ab509fdaefbe74f7195af_0_0) switched from CREATED to SCHEDULED.
INFO  - ExecutionGraph             - Source: encounter_type[141] -> Calc[142] (1/1) (580277ceefe8efaa1a64deb029a01c5c_2fa5fc7df17f61cb0e1946288970d799_0_0) switched from CREATED to SCHEDULED.
INFO  - ExecutionGraph             - Source: visit_type[147] -> Calc[148] (1/1) (580277ceefe8efaa1a64deb029a01c5c_5c4ca2fea30dcf09bf3ee40c495fe808_0_0) switched from CREATED to SCHEDULED.
INFO  - ExecutionGraph             - Source: location[153] -> Calc[154] (1/1) (580277ceefe8efaa1a64deb029a01c5c_6dc0226b15c44c9c2e1f9ea1a65fd400_0_0) switched from CREATED to SCHEDULED.
INFO  - ExecutionGraph             - Join[126] -> Calc[127] (1/1) (580277ceefe8efaa1a64deb029a01c5c_3619c62de06dab71ff39a3a74a9f2151_0_0) switched from CREATED to SCHEDULED.
INFO  - ExecutionGraph             - Join[132] -> Calc[133] (1/1) (580277ceefe8efaa1a64deb029a01c5c_e2fa199699a83ccdc9109b613d7b5bcb_0_0) switched from CREATED to SCHEDULED.
INFO  - ExecutionGraph             - Join[138] -> Calc[139] (1/1) (580277ceefe8efaa1a64deb029a01c5c_a180dc35eba3df5d9593070701e62815_0_0) switched from CREATED to SCHEDULED.
INFO  - ExecutionGraph             - Join[144] -> Calc[145] (1/1) (580277ceefe8efaa1a64deb029a01c5c_5a4f0cabf832f59a1be42827a99c3e0b_0_0) switched from CREATED to SCHEDULED.
INFO  - ExecutionGraph             - Join[150] -> Calc[151] (1/1) (580277ceefe8efaa1a64deb029a01c5c_962215956b0b799dc86f9b7cf721b29f_0_0) switched from CREATED to SCHEDULED.
INFO  - ExecutionGraph             - Join[156] -> Calc[157] (1/1) (580277ceefe8efaa1a64deb029a01c5c_922a00317cf5b7bf8065287dc182322e_0_0) switched from CREATED to SCHEDULED.
INFO  - ExecutionGraph             - Join[159] -> Calc[160] -> ConstraintEnforcer[161] (1/1) (580277ceefe8efaa1a64deb029a01c5c_a9f432d42f94da06ca5ecfb8d49d422a_0_0) switched from CREATED to SCHEDULED.
INFO  - ExecutionGraph             - SinkMaterializer[161] -> Sink: observations[161] (1/1) (580277ceefe8efaa1a64deb029a01c5c_f4513f6c8f56192fb7e41d1eacfc44d9_0_0) switched from CREATED to SCHEDULED.
INFO  - JobMaster                  - Connecting to ResourceManager akka://flink/user/rpc/resourcemanager_1(b46c7fb86bd673d43a82a6cefb624610)
INFO  - JobMaster                  - Resolved ResourceManager address, beginning registration
INFO  - aultLeaderRetrievalService - Starting DefaultLeaderRetrievalService with ZookeeperLeaderRetrievalDriver{connectionInformationPath='/ee8b603bf5edab3af85b6467db69921f/connection_info'}.
INFO  - StandaloneResourceManager  - Registering job manager b46c7fb86bd673d43a82a6cefb624610@akka://flink/user/rpc/jobmanager_9 for job ee8b603bf5edab3af85b6467db69921f.
WARN  - AdminClientConfig          - The configuration 'key.deserializer' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'value.deserializer' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'enable.auto.commit' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'client.id.prefix' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'group.id' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'auto.offset.reset' was supplied but isn't a known config.
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290633611
WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.admin.client:type=app-info,id=flink-enumerator-admin-client
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.admin.KafkaAdminClient.<init>(KafkaAdminClient.java:597)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:539)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:478)
	at org.apache.kafka.clients.admin.Admin.create(Admin.java:133)
	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getKafkaAdminClient(KafkaSourceEnumerator.java:410)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.start(KafkaSourceEnumerator.java:151)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$start$1(SourceCoordinator.java:234)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$runInEventLoop$10(SourceCoordinator.java:458)
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
INFO  - KafkaSourceEnumerator      - Starting the KafkaSourceEnumerator for consumer group flink without periodic partition discovery.
WARN  - AdminClientConfig          - The configuration 'key.deserializer' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'value.deserializer' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'enable.auto.commit' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'client.id.prefix' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'group.id' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'auto.offset.reset' was supplied but isn't a known config.
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290633613
WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.admin.client:type=app-info,id=flink-enumerator-admin-client
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.admin.KafkaAdminClient.<init>(KafkaAdminClient.java:597)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:539)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:478)
	at org.apache.kafka.clients.admin.Admin.create(Admin.java:133)
	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getKafkaAdminClient(KafkaSourceEnumerator.java:410)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.start(KafkaSourceEnumerator.java:151)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$start$1(SourceCoordinator.java:234)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$runInEventLoop$10(SourceCoordinator.java:458)
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
INFO  - KafkaSourceEnumerator      - Starting the KafkaSourceEnumerator for consumer group flink without periodic partition discovery.
WARN  - AdminClientConfig          - The configuration 'key.deserializer' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'value.deserializer' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'enable.auto.commit' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'client.id.prefix' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'group.id' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'auto.offset.reset' was supplied but isn't a known config.
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290633613
WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.admin.client:type=app-info,id=flink-enumerator-admin-client
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.admin.KafkaAdminClient.<init>(KafkaAdminClient.java:597)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:539)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:478)
	at org.apache.kafka.clients.admin.Admin.create(Admin.java:133)
	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getKafkaAdminClient(KafkaSourceEnumerator.java:410)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.start(KafkaSourceEnumerator.java:151)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$start$1(SourceCoordinator.java:234)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$runInEventLoop$10(SourceCoordinator.java:458)
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
INFO  - KafkaSourceEnumerator      - Starting the KafkaSourceEnumerator for consumer group flink without periodic partition discovery.
WARN  - AdminClientConfig          - The configuration 'key.deserializer' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'value.deserializer' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'enable.auto.commit' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'client.id.prefix' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'group.id' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'auto.offset.reset' was supplied but isn't a known config.
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290633615
WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.admin.client:type=app-info,id=flink-enumerator-admin-client
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.admin.KafkaAdminClient.<init>(KafkaAdminClient.java:597)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:539)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:478)
	at org.apache.kafka.clients.admin.Admin.create(Admin.java:133)
	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getKafkaAdminClient(KafkaSourceEnumerator.java:410)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.start(KafkaSourceEnumerator.java:151)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$start$1(SourceCoordinator.java:234)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$runInEventLoop$10(SourceCoordinator.java:458)
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
WARN  - AdminClientConfig          - The configuration 'key.deserializer' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'value.deserializer' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'enable.auto.commit' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'client.id.prefix' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'group.id' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'auto.offset.reset' was supplied but isn't a known config.
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290633615
WARN  - AdminClientConfig          - The configuration 'key.deserializer' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'value.deserializer' was supplied but isn't a known config.
WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.admin.client:type=app-info,id=flink-enumerator-admin-client
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.admin.KafkaAdminClient.<init>(KafkaAdminClient.java:597)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:539)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:478)
	at org.apache.kafka.clients.admin.Admin.create(Admin.java:133)
	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getKafkaAdminClient(KafkaSourceEnumerator.java:410)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.start(KafkaSourceEnumerator.java:151)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$start$1(SourceCoordinator.java:234)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$runInEventLoop$10(SourceCoordinator.java:458)
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
WARN  - AdminClientConfig          - The configuration 'enable.auto.commit' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'client.id.prefix' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'group.id' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'auto.offset.reset' was supplied but isn't a known config.
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290633615
WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.admin.client:type=app-info,id=flink-enumerator-admin-client
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.admin.KafkaAdminClient.<init>(KafkaAdminClient.java:597)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:539)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:478)
	at org.apache.kafka.clients.admin.Admin.create(Admin.java:133)
	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getKafkaAdminClient(KafkaSourceEnumerator.java:410)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.start(KafkaSourceEnumerator.java:151)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$start$1(SourceCoordinator.java:234)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$runInEventLoop$10(SourceCoordinator.java:458)
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
INFO  - KafkaSourceEnumerator      - Starting the KafkaSourceEnumerator for consumer group flink without periodic partition discovery.
WARN  - AdminClientConfig          - The configuration 'key.deserializer' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'value.deserializer' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'enable.auto.commit' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'client.id.prefix' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'group.id' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'auto.offset.reset' was supplied but isn't a known config.
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290633616
WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.admin.client:type=app-info,id=flink-enumerator-admin-client
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.admin.KafkaAdminClient.<init>(KafkaAdminClient.java:597)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:539)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:478)
	at org.apache.kafka.clients.admin.Admin.create(Admin.java:133)
	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getKafkaAdminClient(KafkaSourceEnumerator.java:410)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.start(KafkaSourceEnumerator.java:151)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$start$1(SourceCoordinator.java:234)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$runInEventLoop$10(SourceCoordinator.java:458)
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
INFO  - KafkaSourceEnumerator      - Starting the KafkaSourceEnumerator for consumer group flink without periodic partition discovery.
INFO  - KafkaSourceEnumerator      - Starting the KafkaSourceEnumerator for consumer group flink without periodic partition discovery.
INFO  - KafkaSourceEnumerator      - Starting the KafkaSourceEnumerator for consumer group flink without periodic partition discovery.
INFO  - KafkaSourceEnumerator      - Discovered new partitions: [openmrs.openmrs.encounter_type-0]
INFO  - KafkaSourceEnumerator      - Discovered new partitions: [openmrs.openmrs.obs-0]
INFO  - KafkaSourceEnumerator      - Discovered new partitions: [openmrs.openmrs.location-0]
INFO  - KafkaSourceEnumerator      - Discovered new partitions: [openmrs.openmrs.visit-0]
INFO  - KafkaSourceEnumerator      - Discovered new partitions: [openmrs.openmrs.visit_type-0]
INFO  - KafkaSourceEnumerator      - Discovered new partitions: [openmrs.openmrs.concept_name-0]
INFO  - KafkaSourceEnumerator      - Discovered new partitions: [openmrs.openmrs.encounter-0]
INFO  - StandaloneResourceManager  - Registered job manager b46c7fb86bd673d43a82a6cefb624610@akka://flink/user/rpc/jobmanager_9 for job ee8b603bf5edab3af85b6467db69921f.
INFO  - JobMaster                  - JobManager successfully registered at ResourceManager, leader id: b46c7fb86bd673d43a82a6cefb624610.
INFO  - aultLeaderRetrievalService - Stopping DefaultLeaderRetrievalService.
INFO  - eeperLeaderRetrievalDriver - Closing ZookeeperLeaderRetrievalDriver{connectionInformationPath='/leader/rest_server/connection_info'}.
INFO  - DeclarativeSlotManager     - Received resource requirements from job ee8b603bf5edab3af85b6467db69921f: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
INFO  - CuratorFrameworkImpl       - backgroundOperationsLoop exiting
INFO  - TaskExecutor               - Receive slot request 5c199daed31ff568700a3dd6ab9ac282 for job ee8b603bf5edab3af85b6467db69921f from resource manager with leader id b46c7fb86bd673d43a82a6cefb624610.
INFO  - TaskExecutor               - Allocated slot for 5c199daed31ff568700a3dd6ab9ac282.
INFO  - DefaultJobLeaderService    - Add job ee8b603bf5edab3af85b6467db69921f for job leader monitoring.
INFO  - aultLeaderRetrievalService - Starting DefaultLeaderRetrievalService with ZookeeperLeaderRetrievalDriver{connectionInformationPath='/ee8b603bf5edab3af85b6467db69921f/connection_info'}.
INFO  - DefaultJobLeaderService    - Try to register at job manager akka://flink/user/rpc/jobmanager_9 with leader id 3a82a6ce-fb62-4610-b46c-7fb86bd673d4.
INFO  - DefaultJobLeaderService    - Resolved JobManager address, beginning registration
INFO  - DefaultJobLeaderService    - Successful registration at job manager akka://flink/user/rpc/jobmanager_9 for job ee8b603bf5edab3af85b6467db69921f.
INFO  - TaskExecutor               - Establish JobManager connection for job ee8b603bf5edab3af85b6467db69921f.
INFO  - TaskExecutor               - Offer reserved slots to the leader of job ee8b603bf5edab3af85b6467db69921f.
INFO  - ExecutionGraph             - Source: obs[120] -> Calc[121] (1/1) (580277ceefe8efaa1a64deb029a01c5c_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - ExecutionGraph             - Deploying Source: obs[120] -> Calc[121] (1/1) (attempt #0) with attempt id 580277ceefe8efaa1a64deb029a01c5c_cbc357ccb763df2852fee8c4fc7d55f2_0_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id 5c199daed31ff568700a3dd6ab9ac282
INFO  - ExecutionGraph             - Source: concept_name[123] -> Calc[124] (1/1) (580277ceefe8efaa1a64deb029a01c5c_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - ExecutionGraph             - Deploying Source: concept_name[123] -> Calc[124] (1/1) (attempt #0) with attempt id 580277ceefe8efaa1a64deb029a01c5c_6cdc5bb954874d922eaee11a8e7b5dd5_0_0 and vertex id 6cdc5bb954874d922eaee11a8e7b5dd5_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id 5c199daed31ff568700a3dd6ab9ac282
INFO  - ExecutionGraph             - Source: encounter[129] -> Calc[130] (1/1) (580277ceefe8efaa1a64deb029a01c5c_2963852293169ba90d9d1e7d6308db5c_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - ExecutionGraph             - Deploying Source: encounter[129] -> Calc[130] (1/1) (attempt #0) with attempt id 580277ceefe8efaa1a64deb029a01c5c_2963852293169ba90d9d1e7d6308db5c_0_0 and vertex id 2963852293169ba90d9d1e7d6308db5c_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id 5c199daed31ff568700a3dd6ab9ac282
INFO  - TaskSlotTableImpl          - Activate slot 5c199daed31ff568700a3dd6ab9ac282.
INFO  - ExecutionGraph             - Source: visit[135] -> Calc[136] (1/1) (580277ceefe8efaa1a64deb029a01c5c_1171dea6747ab509fdaefbe74f7195af_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - ExecutionGraph             - Deploying Source: visit[135] -> Calc[136] (1/1) (attempt #0) with attempt id 580277ceefe8efaa1a64deb029a01c5c_1171dea6747ab509fdaefbe74f7195af_0_0 and vertex id 1171dea6747ab509fdaefbe74f7195af_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id 5c199daed31ff568700a3dd6ab9ac282
INFO  - ExecutionGraph             - Source: encounter_type[141] -> Calc[142] (1/1) (580277ceefe8efaa1a64deb029a01c5c_2fa5fc7df17f61cb0e1946288970d799_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - ExecutionGraph             - Deploying Source: encounter_type[141] -> Calc[142] (1/1) (attempt #0) with attempt id 580277ceefe8efaa1a64deb029a01c5c_2fa5fc7df17f61cb0e1946288970d799_0_0 and vertex id 2fa5fc7df17f61cb0e1946288970d799_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id 5c199daed31ff568700a3dd6ab9ac282
INFO  - ExecutionGraph             - Source: visit_type[147] -> Calc[148] (1/1) (580277ceefe8efaa1a64deb029a01c5c_5c4ca2fea30dcf09bf3ee40c495fe808_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - ExecutionGraph             - Deploying Source: visit_type[147] -> Calc[148] (1/1) (attempt #0) with attempt id 580277ceefe8efaa1a64deb029a01c5c_5c4ca2fea30dcf09bf3ee40c495fe808_0_0 and vertex id 5c4ca2fea30dcf09bf3ee40c495fe808_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id 5c199daed31ff568700a3dd6ab9ac282
INFO  - tateChangelogStorageLoader - Creating a changelog storage with name 'memory'.
INFO  - ExecutionGraph             - Source: location[153] -> Calc[154] (1/1) (580277ceefe8efaa1a64deb029a01c5c_6dc0226b15c44c9c2e1f9ea1a65fd400_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - tateExecutorFactoryManager - Creating the channel state executor factory for job id ee8b603bf5edab3af85b6467db69921f
INFO  - ExecutionGraph             - Deploying Source: location[153] -> Calc[154] (1/1) (attempt #0) with attempt id 580277ceefe8efaa1a64deb029a01c5c_6dc0226b15c44c9c2e1f9ea1a65fd400_0_0 and vertex id 6dc0226b15c44c9c2e1f9ea1a65fd400_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id 5c199daed31ff568700a3dd6ab9ac282
INFO  - ExecutionGraph             - Join[126] -> Calc[127] (1/1) (580277ceefe8efaa1a64deb029a01c5c_3619c62de06dab71ff39a3a74a9f2151_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - ExecutionGraph             - Deploying Join[126] -> Calc[127] (1/1) (attempt #0) with attempt id 580277ceefe8efaa1a64deb029a01c5c_3619c62de06dab71ff39a3a74a9f2151_0_0 and vertex id 3619c62de06dab71ff39a3a74a9f2151_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id 5c199daed31ff568700a3dd6ab9ac282
INFO  - TaskExecutor               - Received task Source: obs[120] -> Calc[121] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_cbc357ccb763df2852fee8c4fc7d55f2_0_0), deploy into slot with allocation id 5c199daed31ff568700a3dd6ab9ac282.
INFO  - Task                       - Source: obs[120] -> Calc[121] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to DEPLOYING.
INFO  - Task                       - Loading JAR files for task Source: obs[120] -> Calc[121] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_cbc357ccb763df2852fee8c4fc7d55f2_0_0) [DEPLOYING].
INFO  - TaskSlotTableImpl          - Activate slot 5c199daed31ff568700a3dd6ab9ac282.
INFO  - ExecutionGraph             - Join[132] -> Calc[133] (1/1) (580277ceefe8efaa1a64deb029a01c5c_e2fa199699a83ccdc9109b613d7b5bcb_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - ExecutionGraph             - Deploying Join[132] -> Calc[133] (1/1) (attempt #0) with attempt id 580277ceefe8efaa1a64deb029a01c5c_e2fa199699a83ccdc9109b613d7b5bcb_0_0 and vertex id e2fa199699a83ccdc9109b613d7b5bcb_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id 5c199daed31ff568700a3dd6ab9ac282
INFO  - TaskExecutor               - Received task Source: concept_name[123] -> Calc[124] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_6cdc5bb954874d922eaee11a8e7b5dd5_0_0), deploy into slot with allocation id 5c199daed31ff568700a3dd6ab9ac282.
INFO  - ExecutionGraph             - Join[138] -> Calc[139] (1/1) (580277ceefe8efaa1a64deb029a01c5c_a180dc35eba3df5d9593070701e62815_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - ExecutionGraph             - Deploying Join[138] -> Calc[139] (1/1) (attempt #0) with attempt id 580277ceefe8efaa1a64deb029a01c5c_a180dc35eba3df5d9593070701e62815_0_0 and vertex id a180dc35eba3df5d9593070701e62815_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id 5c199daed31ff568700a3dd6ab9ac282
INFO  - Task                       - Source: concept_name[123] -> Calc[124] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) switched from CREATED to DEPLOYING.
INFO  - TaskSlotTableImpl          - Activate slot 5c199daed31ff568700a3dd6ab9ac282.
INFO  - Task                       - Loading JAR files for task Source: concept_name[123] -> Calc[124] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) [DEPLOYING].
INFO  - ExecutionGraph             - Join[144] -> Calc[145] (1/1) (580277ceefe8efaa1a64deb029a01c5c_5a4f0cabf832f59a1be42827a99c3e0b_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - ExecutionGraph             - Deploying Join[144] -> Calc[145] (1/1) (attempt #0) with attempt id 580277ceefe8efaa1a64deb029a01c5c_5a4f0cabf832f59a1be42827a99c3e0b_0_0 and vertex id 5a4f0cabf832f59a1be42827a99c3e0b_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id 5c199daed31ff568700a3dd6ab9ac282
INFO  - TaskExecutor               - Received task Source: encounter[129] -> Calc[130] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_2963852293169ba90d9d1e7d6308db5c_0_0), deploy into slot with allocation id 5c199daed31ff568700a3dd6ab9ac282.
INFO  - TaskSlotTableImpl          - Activate slot 5c199daed31ff568700a3dd6ab9ac282.
INFO  - ExecutionGraph             - Join[150] -> Calc[151] (1/1) (580277ceefe8efaa1a64deb029a01c5c_962215956b0b799dc86f9b7cf721b29f_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - ExecutionGraph             - Deploying Join[150] -> Calc[151] (1/1) (attempt #0) with attempt id 580277ceefe8efaa1a64deb029a01c5c_962215956b0b799dc86f9b7cf721b29f_0_0 and vertex id 962215956b0b799dc86f9b7cf721b29f_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id 5c199daed31ff568700a3dd6ab9ac282
INFO  - Task                       - Source: encounter[129] -> Calc[130] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_2963852293169ba90d9d1e7d6308db5c_0_0) switched from CREATED to DEPLOYING.
INFO  - Task                       - Loading JAR files for task Source: encounter[129] -> Calc[130] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_2963852293169ba90d9d1e7d6308db5c_0_0) [DEPLOYING].
INFO  - TaskExecutor               - Received task Source: visit[135] -> Calc[136] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_1171dea6747ab509fdaefbe74f7195af_0_0), deploy into slot with allocation id 5c199daed31ff568700a3dd6ab9ac282.
INFO  - ExecutionGraph             - Join[156] -> Calc[157] (1/1) (580277ceefe8efaa1a64deb029a01c5c_922a00317cf5b7bf8065287dc182322e_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - ExecutionGraph             - Deploying Join[156] -> Calc[157] (1/1) (attempt #0) with attempt id 580277ceefe8efaa1a64deb029a01c5c_922a00317cf5b7bf8065287dc182322e_0_0 and vertex id 922a00317cf5b7bf8065287dc182322e_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id 5c199daed31ff568700a3dd6ab9ac282
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - TaskSlotTableImpl          - Activate slot 5c199daed31ff568700a3dd6ab9ac282.
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - Task                       - Source: visit[135] -> Calc[136] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_1171dea6747ab509fdaefbe74f7195af_0_0) switched from CREATED to DEPLOYING.
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - Task                       - Loading JAR files for task Source: visit[135] -> Calc[136] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_1171dea6747ab509fdaefbe74f7195af_0_0) [DEPLOYING].
INFO  - ExecutionGraph             - Join[159] -> Calc[160] -> ConstraintEnforcer[161] (1/1) (580277ceefe8efaa1a64deb029a01c5c_a9f432d42f94da06ca5ecfb8d49d422a_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - TaskExecutor               - Received task Source: encounter_type[141] -> Calc[142] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_2fa5fc7df17f61cb0e1946288970d799_0_0), deploy into slot with allocation id 5c199daed31ff568700a3dd6ab9ac282.
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - ExecutionGraph             - Deploying Join[159] -> Calc[160] -> ConstraintEnforcer[161] (1/1) (attempt #0) with attempt id 580277ceefe8efaa1a64deb029a01c5c_a9f432d42f94da06ca5ecfb8d49d422a_0_0 and vertex id a9f432d42f94da06ca5ecfb8d49d422a_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id 5c199daed31ff568700a3dd6ab9ac282
INFO  - Task                       - Source: encounter_type[141] -> Calc[142] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_2fa5fc7df17f61cb0e1946288970d799_0_0) switched from CREATED to DEPLOYING.
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - Task                       - Loading JAR files for task Source: encounter_type[141] -> Calc[142] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_2fa5fc7df17f61cb0e1946288970d799_0_0) [DEPLOYING].
INFO  - TaskSlotTableImpl          - Activate slot 5c199daed31ff568700a3dd6ab9ac282.
INFO  - ExecutionGraph             - SinkMaterializer[161] -> Sink: observations[161] (1/1) (580277ceefe8efaa1a64deb029a01c5c_f4513f6c8f56192fb7e41d1eacfc44d9_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - ExecutionGraph             - Deploying SinkMaterializer[161] -> Sink: observations[161] (1/1) (attempt #0) with attempt id 580277ceefe8efaa1a64deb029a01c5c_f4513f6c8f56192fb7e41d1eacfc44d9_0_0 and vertex id f4513f6c8f56192fb7e41d1eacfc44d9_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id 5c199daed31ff568700a3dd6ab9ac282
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - Task                       - Source: obs[120] -> Calc[121] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - Task                       - Source: concept_name[123] -> Calc[124] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - ExecutionGraph             - Source: obs[120] -> Calc[121] (1/1) (580277ceefe8efaa1a64deb029a01c5c_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - ExecutionGraph             - Source: concept_name[123] -> Calc[124] (1/1) (580277ceefe8efaa1a64deb029a01c5c_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - Task                       - Source: encounter_type[141] -> Calc[142] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_2fa5fc7df17f61cb0e1946288970d799_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - Task                       - Source: encounter[129] -> Calc[130] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_2963852293169ba90d9d1e7d6308db5c_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - TaskExecutor               - Received task Source: visit_type[147] -> Calc[148] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_5c4ca2fea30dcf09bf3ee40c495fe808_0_0), deploy into slot with allocation id 5c199daed31ff568700a3dd6ab9ac282.
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - ExecutionGraph             - Source: encounter_type[141] -> Calc[142] (1/1) (580277ceefe8efaa1a64deb029a01c5c_2fa5fc7df17f61cb0e1946288970d799_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - ExecutionGraph             - Source: encounter[129] -> Calc[130] (1/1) (580277ceefe8efaa1a64deb029a01c5c_2963852293169ba90d9d1e7d6308db5c_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - TaskSlotTableImpl          - Activate slot 5c199daed31ff568700a3dd6ab9ac282.
INFO  - Task                       - Source: visit_type[147] -> Calc[148] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_5c4ca2fea30dcf09bf3ee40c495fe808_0_0) switched from CREATED to DEPLOYING.
INFO  - Task                       - Loading JAR files for task Source: visit_type[147] -> Calc[148] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_5c4ca2fea30dcf09bf3ee40c495fe808_0_0) [DEPLOYING].
INFO  - Task                       - Source: visit[135] -> Calc[136] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_1171dea6747ab509fdaefbe74f7195af_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - TaskExecutor               - Received task Source: location[153] -> Calc[154] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_6dc0226b15c44c9c2e1f9ea1a65fd400_0_0), deploy into slot with allocation id 5c199daed31ff568700a3dd6ab9ac282.
INFO  - ExecutionGraph             - Source: visit[135] -> Calc[136] (1/1) (580277ceefe8efaa1a64deb029a01c5c_1171dea6747ab509fdaefbe74f7195af_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - Task                       - Source: location[153] -> Calc[154] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_6dc0226b15c44c9c2e1f9ea1a65fd400_0_0) switched from CREATED to DEPLOYING.
INFO  - Task                       - Loading JAR files for task Source: location[153] -> Calc[154] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_6dc0226b15c44c9c2e1f9ea1a65fd400_0_0) [DEPLOYING].
INFO  - TaskSlotTableImpl          - Activate slot 5c199daed31ff568700a3dd6ab9ac282.
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - Task                       - Source: visit_type[147] -> Calc[148] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_5c4ca2fea30dcf09bf3ee40c495fe808_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - TaskExecutor               - Received task Join[126] -> Calc[127] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_3619c62de06dab71ff39a3a74a9f2151_0_0), deploy into slot with allocation id 5c199daed31ff568700a3dd6ab9ac282.
INFO  - ExecutionGraph             - Source: visit_type[147] -> Calc[148] (1/1) (580277ceefe8efaa1a64deb029a01c5c_5c4ca2fea30dcf09bf3ee40c495fe808_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - TaskSlotTableImpl          - Activate slot 5c199daed31ff568700a3dd6ab9ac282.
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - Task                       - Join[126] -> Calc[127] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_3619c62de06dab71ff39a3a74a9f2151_0_0) switched from CREATED to DEPLOYING.
INFO  - Task                       - Loading JAR files for task Join[126] -> Calc[127] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_3619c62de06dab71ff39a3a74a9f2151_0_0) [DEPLOYING].
INFO  - Task                       - Source: location[153] -> Calc[154] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_6dc0226b15c44c9c2e1f9ea1a65fd400_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - ExecutionGraph             - Source: location[153] -> Calc[154] (1/1) (580277ceefe8efaa1a64deb029a01c5c_6dc0226b15c44c9c2e1f9ea1a65fd400_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - TaskExecutor               - Received task Join[132] -> Calc[133] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_e2fa199699a83ccdc9109b613d7b5bcb_0_0), deploy into slot with allocation id 5c199daed31ff568700a3dd6ab9ac282.
INFO  - Task                       - Join[126] -> Calc[127] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_3619c62de06dab71ff39a3a74a9f2151_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - TaskSlotTableImpl          - Activate slot 5c199daed31ff568700a3dd6ab9ac282.
INFO  - ExecutionGraph             - Join[126] -> Calc[127] (1/1) (580277ceefe8efaa1a64deb029a01c5c_3619c62de06dab71ff39a3a74a9f2151_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - Task                       - Join[132] -> Calc[133] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_e2fa199699a83ccdc9109b613d7b5bcb_0_0) switched from CREATED to DEPLOYING.
INFO  - Task                       - Loading JAR files for task Join[132] -> Calc[133] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_e2fa199699a83ccdc9109b613d7b5bcb_0_0) [DEPLOYING].
INFO  - TaskExecutor               - Received task Join[138] -> Calc[139] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_a180dc35eba3df5d9593070701e62815_0_0), deploy into slot with allocation id 5c199daed31ff568700a3dd6ab9ac282.
INFO  - Task                       - Join[138] -> Calc[139] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_a180dc35eba3df5d9593070701e62815_0_0) switched from CREATED to DEPLOYING.
INFO  - Task                       - Loading JAR files for task Join[138] -> Calc[139] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_a180dc35eba3df5d9593070701e62815_0_0) [DEPLOYING].
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - Task                       - Join[132] -> Calc[133] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_e2fa199699a83ccdc9109b613d7b5bcb_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - TaskSlotTableImpl          - Activate slot 5c199daed31ff568700a3dd6ab9ac282.
INFO  - ExecutionGraph             - Join[132] -> Calc[133] (1/1) (580277ceefe8efaa1a64deb029a01c5c_e2fa199699a83ccdc9109b613d7b5bcb_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - Task                       - Join[138] -> Calc[139] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_a180dc35eba3df5d9593070701e62815_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - ExecutionGraph             - Join[138] -> Calc[139] (1/1) (580277ceefe8efaa1a64deb029a01c5c_a180dc35eba3df5d9593070701e62815_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - TaskExecutor               - Received task Join[144] -> Calc[145] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_5a4f0cabf832f59a1be42827a99c3e0b_0_0), deploy into slot with allocation id 5c199daed31ff568700a3dd6ab9ac282.
INFO  - TaskSlotTableImpl          - Activate slot 5c199daed31ff568700a3dd6ab9ac282.
INFO  - Task                       - Join[144] -> Calc[145] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_5a4f0cabf832f59a1be42827a99c3e0b_0_0) switched from CREATED to DEPLOYING.
INFO  - Task                       - Loading JAR files for task Join[144] -> Calc[145] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_5a4f0cabf832f59a1be42827a99c3e0b_0_0) [DEPLOYING].
INFO  - TaskExecutor               - Received task Join[150] -> Calc[151] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_962215956b0b799dc86f9b7cf721b29f_0_0), deploy into slot with allocation id 5c199daed31ff568700a3dd6ab9ac282.
INFO  - TaskSlotTableImpl          - Activate slot 5c199daed31ff568700a3dd6ab9ac282.
INFO  - SourceCoordinator          - Source Source: encounter_type[141] registering reader for parallel task 0 (#0) @ 
INFO  - KafkaSourceEnumerator      - Assigning splits to readers {0=[[Partition: openmrs.openmrs.encounter_type-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}
INFO  - Task                       - Join[150] -> Calc[151] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_962215956b0b799dc86f9b7cf721b29f_0_0) switched from CREATED to DEPLOYING.
INFO  - Task                       - Loading JAR files for task Join[150] -> Calc[151] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_962215956b0b799dc86f9b7cf721b29f_0_0) [DEPLOYING].
INFO  - SourceCoordinator          - Source Source: visit_type[147] registering reader for parallel task 0 (#0) @ 
INFO  - SourceCoordinator          - Source Source: encounter[129] registering reader for parallel task 0 (#0) @ 
INFO  - KafkaSourceEnumerator      - Assigning splits to readers {0=[[Partition: openmrs.openmrs.encounter-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}
INFO  - KafkaSourceEnumerator      - Assigning splits to readers {0=[[Partition: openmrs.openmrs.visit_type-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}
INFO  - TaskExecutor               - Received task Join[156] -> Calc[157] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_922a00317cf5b7bf8065287dc182322e_0_0), deploy into slot with allocation id 5c199daed31ff568700a3dd6ab9ac282.
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - SourceCoordinator          - Source Source: concept_name[123] registering reader for parallel task 0 (#0) @ 
INFO  - KafkaSourceEnumerator      - Assigning splits to readers {0=[[Partition: openmrs.openmrs.concept_name-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}
INFO  - SourceCoordinator          - Source Source: visit[135] registering reader for parallel task 0 (#0) @ 
INFO  - KafkaSourceEnumerator      - Assigning splits to readers {0=[[Partition: openmrs.openmrs.visit-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}
INFO  - Task                       - Join[144] -> Calc[145] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_5a4f0cabf832f59a1be42827a99c3e0b_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - ExecutionGraph             - Join[144] -> Calc[145] (1/1) (580277ceefe8efaa1a64deb029a01c5c_5a4f0cabf832f59a1be42827a99c3e0b_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - Task                       - Source: concept_name[123] -> Calc[124] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) switched from INITIALIZING to RUNNING.
INFO  - ExecutionGraph             - Source: concept_name[123] -> Calc[124] (1/1) (580277ceefe8efaa1a64deb029a01c5c_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) switched from INITIALIZING to RUNNING.
INFO  - SourceCoordinator          - Source Source: obs[120] registering reader for parallel task 0 (#0) @ 
INFO  - KafkaSourceEnumerator      - Assigning splits to readers {0=[[Partition: openmrs.openmrs.obs-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}
INFO  - SourceCoordinator          - Source Source: location[153] registering reader for parallel task 0 (#0) @ 
INFO  - KafkaSourceEnumerator      - Assigning splits to readers {0=[[Partition: openmrs.openmrs.location-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}
INFO  - Task                       - Source: location[153] -> Calc[154] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_6dc0226b15c44c9c2e1f9ea1a65fd400_0_0) switched from INITIALIZING to RUNNING.
INFO  - TaskSlotTableImpl          - Activate slot 5c199daed31ff568700a3dd6ab9ac282.
INFO  - Task                       - Join[156] -> Calc[157] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_922a00317cf5b7bf8065287dc182322e_0_0) switched from CREATED to DEPLOYING.
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - mbeddedRocksDBStateBackend - Getting shared memory for RocksDB: shareScope=SLOT, managed=false
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - mbeddedRocksDBStateBackend - Obtained shared RocksDB cache of size 6710886 bytes
INFO  - ExecutionGraph             - Source: location[153] -> Calc[154] (1/1) (580277ceefe8efaa1a64deb029a01c5c_6dc0226b15c44c9c2e1f9ea1a65fd400_0_0) switched from INITIALIZING to RUNNING.
INFO  - Task                       - Loading JAR files for task Join[156] -> Calc[157] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_922a00317cf5b7bf8065287dc182322e_0_0) [DEPLOYING].
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - Task                       - Source: visit_type[147] -> Calc[148] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_5c4ca2fea30dcf09bf3ee40c495fe808_0_0) switched from INITIALIZING to RUNNING.
INFO  - Task                       - Join[150] -> Calc[151] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_962215956b0b799dc86f9b7cf721b29f_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - Task                       - Source: obs[120] -> Calc[121] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
INFO  - Task                       - Source: visit[135] -> Calc[136] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_1171dea6747ab509fdaefbe74f7195af_0_0) switched from INITIALIZING to RUNNING.
INFO  - Task                       - Source: encounter_type[141] -> Calc[142] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_2fa5fc7df17f61cb0e1946288970d799_0_0) switched from INITIALIZING to RUNNING.
INFO  - ExecutionGraph             - Source: visit_type[147] -> Calc[148] (1/1) (580277ceefe8efaa1a64deb029a01c5c_5c4ca2fea30dcf09bf3ee40c495fe808_0_0) switched from INITIALIZING to RUNNING.
INFO  - Task                       - Source: encounter[129] -> Calc[130] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_2963852293169ba90d9d1e7d6308db5c_0_0) switched from INITIALIZING to RUNNING.
INFO  - ExecutionGraph             - Join[150] -> Calc[151] (1/1) (580277ceefe8efaa1a64deb029a01c5c_962215956b0b799dc86f9b7cf721b29f_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - ExecutionGraph             - Source: obs[120] -> Calc[121] (1/1) (580277ceefe8efaa1a64deb029a01c5c_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
INFO  - DBKeyedStateBackendBuilder - Finished building RocksDB keyed state-backend at /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_ee8b603bf5edab3af85b6467db69921f_op_StreamingJoinOperator_3619c62de06dab71ff39a3a74a9f2151__1_1__uuid_fddeb50c-52ce-4530-b407-2bcaae53fdb9.
INFO  - ExecutionGraph             - Source: visit[135] -> Calc[136] (1/1) (580277ceefe8efaa1a64deb029a01c5c_1171dea6747ab509fdaefbe74f7195af_0_0) switched from INITIALIZING to RUNNING.
INFO  - ExecutionGraph             - Source: encounter_type[141] -> Calc[142] (1/1) (580277ceefe8efaa1a64deb029a01c5c_2fa5fc7df17f61cb0e1946288970d799_0_0) switched from INITIALIZING to RUNNING.
INFO  - ExecutionGraph             - Source: encounter[129] -> Calc[130] (1/1) (580277ceefe8efaa1a64deb029a01c5c_2963852293169ba90d9d1e7d6308db5c_0_0) switched from INITIALIZING to RUNNING.
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - TaskExecutor               - Received task Join[159] -> Calc[160] -> ConstraintEnforcer[161] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_a9f432d42f94da06ca5ecfb8d49d422a_0_0), deploy into slot with allocation id 5c199daed31ff568700a3dd6ab9ac282.
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - Task                       - Join[159] -> Calc[160] -> ConstraintEnforcer[161] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_a9f432d42f94da06ca5ecfb8d49d422a_0_0) switched from CREATED to DEPLOYING.
INFO  - Task                       - Join[156] -> Calc[157] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_922a00317cf5b7bf8065287dc182322e_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - Task                       - Loading JAR files for task Join[159] -> Calc[160] -> ConstraintEnforcer[161] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_a9f432d42f94da06ca5ecfb8d49d422a_0_0) [DEPLOYING].
INFO  - TaskSlotTableImpl          - Activate slot 5c199daed31ff568700a3dd6ab9ac282.
INFO  - TaskSlotTableImpl          - Activate slot 5c199daed31ff568700a3dd6ab9ac282.
INFO  - ExecutionGraph             - Join[156] -> Calc[157] (1/1) (580277ceefe8efaa1a64deb029a01c5c_922a00317cf5b7bf8065287dc182322e_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - TaskExecutor               - Received task SinkMaterializer[161] -> Sink: observations[161] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_f4513f6c8f56192fb7e41d1eacfc44d9_0_0), deploy into slot with allocation id 5c199daed31ff568700a3dd6ab9ac282.
INFO  - mbeddedRocksDBStateBackend - Getting shared memory for RocksDB: shareScope=SLOT, managed=false
INFO  - mbeddedRocksDBStateBackend - Obtained shared RocksDB cache of size 6710886 bytes
WARN  - RocksDBOperationUtils      - RocksDBStateBackend performance will be poor because of the current Flink memory configuration! RocksDB will flush memtable constantly, causing high IO and CPU. Typically the easiest fix is to increase task manager managed memory size. If running locally, see the parameter taskmanager.memory.managed.size. Details: arenaBlockSize 8388608 > mutableLimit 1957341 (writeBufferSize = 67108864, arenaBlockSizeConfigured = 0, defaultArenaBlockSize = 8388608, writeBufferManagerCapacity = 2236962)
INFO  - Task                       - SinkMaterializer[161] -> Sink: observations[161] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_f4513f6c8f56192fb7e41d1eacfc44d9_0_0) switched from CREATED to DEPLOYING.
INFO  - Task                       - Loading JAR files for task SinkMaterializer[161] -> Sink: observations[161] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_f4513f6c8f56192fb7e41d1eacfc44d9_0_0) [DEPLOYING].
INFO  - SourceReaderBase           - Adding split(s) to reader: [[Partition: openmrs.openmrs.encounter_type-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]
INFO  - SourceReaderBase           - Adding split(s) to reader: [[Partition: openmrs.openmrs.encounter-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]
INFO  - mbeddedRocksDBStateBackend - Getting shared memory for RocksDB: shareScope=SLOT, managed=false
INFO  - mbeddedRocksDBStateBackend - Obtained shared RocksDB cache of size 6710886 bytes
INFO  - ConsumerConfig             - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = flink-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

INFO  - SourceReaderBase           - Adding split(s) to reader: [[Partition: openmrs.openmrs.visit_type-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - Task                       - SinkMaterializer[161] -> Sink: observations[161] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_f4513f6c8f56192fb7e41d1eacfc44d9_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
WARN  - ConsumerConfig             - The configuration 'client.id.prefix' was supplied but isn't a known config.
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - ConsumerConfig             - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = flink-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

WARN  - ConsumerConfig             - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290633728
INFO  - SourceReaderBase           - Adding split(s) to reader: [[Partition: openmrs.openmrs.visit-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]
INFO  - ConsumerConfig             - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = flink-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

INFO  - SourceReaderBase           - Adding split(s) to reader: [[Partition: openmrs.openmrs.obs-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]
INFO  - SourceReaderBase           - Adding split(s) to reader: [[Partition: openmrs.openmrs.location-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]
INFO  - ConsumerConfig             - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = flink-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

INFO  - Task                       - Join[159] -> Calc[160] -> ConstraintEnforcer[161] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_a9f432d42f94da06ca5ecfb8d49d422a_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - ConsumerConfig             - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = flink-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

INFO  - ExecutionGraph             - Join[159] -> Calc[160] -> ConstraintEnforcer[161] (1/1) (580277ceefe8efaa1a64deb029a01c5c_a9f432d42f94da06ca5ecfb8d49d422a_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - SourceReaderBase           - Adding split(s) to reader: [[Partition: openmrs.openmrs.concept_name-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]
WARN  - ConsumerConfig             - The configuration 'client.id.prefix' was supplied but isn't a known config.
WARN  - ConsumerConfig             - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
INFO  - ConsumerConfig             - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = flink-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.consumer:type=app-info,id=flink-0
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:816)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:666)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:647)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:627)
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.<init>(KafkaPartitionSplitReader.java:88)
	at org.apache.flink.connector.kafka.source.KafkaSource.lambda$createReader$1(KafkaSource.java:160)
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager.createSplitFetcher(SplitFetcherManager.java:196)
	at org.apache.flink.connector.base.source.reader.fetcher.SingleThreadFetcherManager.addSplits(SingleThreadFetcherManager.java:107)
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.addSplits(SourceReaderBase.java:242)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleAddSplitsEvent(SourceOperator.java:584)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleOperatorEvent(SourceOperator.java:561)
	at org.apache.flink.streaming.runtime.tasks.OperatorEventDispatcherImpl.dispatchEventToHandlers(OperatorEventDispatcherImpl.java:72)
	at org.apache.flink.streaming.runtime.tasks.RegularOperatorChain.dispatchOperatorEvent(RegularOperatorChain.java:80)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$dispatchOperatorEvent$20(StreamTask.java:1473)
	at org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$1.runThrowing(StreamTaskActionExecutor.java:50)
	at org.apache.flink.streaming.runtime.tasks.mailbox.Mail.run(Mail.java:90)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMail(MailboxProcessor.java:398)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMailsWhenDefaultActionUnavailable(MailboxProcessor.java:367)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMail(MailboxProcessor.java:352)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:229)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:839)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:788)
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:952)
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:931)
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:745)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:562)
	at java.base/java.lang.Thread.run(Thread.java:829)
INFO  - DBKeyedStateBackendBuilder - Finished building RocksDB keyed state-backend at /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_ee8b603bf5edab3af85b6467db69921f_op_StreamingJoinOperator_a180dc35eba3df5d9593070701e62815__1_1__uuid_c79cb389-d3b6-40c3-8b29-2785dcccd66f.
WARN  - RocksDBOperationUtils      - RocksDBStateBackend performance will be poor because of the current Flink memory configuration! RocksDB will flush memtable constantly, causing high IO and CPU. Typically the easiest fix is to increase task manager managed memory size. If running locally, see the parameter taskmanager.memory.managed.size. Details: arenaBlockSize 8388608 > mutableLimit 1957341 (writeBufferSize = 67108864, arenaBlockSizeConfigured = 0, defaultArenaBlockSize = 8388608, writeBufferManagerCapacity = 2236962)
INFO  - ExecutionGraph             - SinkMaterializer[161] -> Sink: observations[161] (1/1) (580277ceefe8efaa1a64deb029a01c5c_f4513f6c8f56192fb7e41d1eacfc44d9_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290633729
WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.consumer:type=app-info,id=flink-0
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:816)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:666)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:647)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:627)
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.<init>(KafkaPartitionSplitReader.java:88)
	at org.apache.flink.connector.kafka.source.KafkaSource.lambda$createReader$1(KafkaSource.java:160)
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager.createSplitFetcher(SplitFetcherManager.java:196)
	at org.apache.flink.connector.base.source.reader.fetcher.SingleThreadFetcherManager.addSplits(SingleThreadFetcherManager.java:107)
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.addSplits(SourceReaderBase.java:242)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleAddSplitsEvent(SourceOperator.java:584)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleOperatorEvent(SourceOperator.java:561)
	at org.apache.flink.streaming.runtime.tasks.OperatorEventDispatcherImpl.dispatchEventToHandlers(OperatorEventDispatcherImpl.java:72)
	at org.apache.flink.streaming.runtime.tasks.RegularOperatorChain.dispatchOperatorEvent(RegularOperatorChain.java:80)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$dispatchOperatorEvent$20(StreamTask.java:1473)
	at org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$1.runThrowing(StreamTaskActionExecutor.java:50)
	at org.apache.flink.streaming.runtime.tasks.mailbox.Mail.run(Mail.java:90)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMail(MailboxProcessor.java:398)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMailsWhenDefaultActionUnavailable(MailboxProcessor.java:367)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMail(MailboxProcessor.java:352)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:229)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:839)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:788)
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:952)
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:931)
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:745)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:562)
	at java.base/java.lang.Thread.run(Thread.java:829)
INFO  - DBKeyedStateBackendBuilder - Finished building RocksDB keyed state-backend at /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_ee8b603bf5edab3af85b6467db69921f_op_StreamingJoinOperator_e2fa199699a83ccdc9109b613d7b5bcb__1_1__uuid_cc7fc9b4-a652-467c-93a6-09b5569a6d7b.
INFO  - ConsumerConfig             - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = flink-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

WARN  - RocksDBOperationUtils      - RocksDBStateBackend performance will be poor because of the current Flink memory configuration! RocksDB will flush memtable constantly, causing high IO and CPU. Typically the easiest fix is to increase task manager managed memory size. If running locally, see the parameter taskmanager.memory.managed.size. Details: arenaBlockSize 8388608 > mutableLimit 1957341 (writeBufferSize = 67108864, arenaBlockSizeConfigured = 0, defaultArenaBlockSize = 8388608, writeBufferManagerCapacity = 2236962)
WARN  - RocksDBOperationUtils      - RocksDBStateBackend performance will be poor because of the current Flink memory configuration! RocksDB will flush memtable constantly, causing high IO and CPU. Typically the easiest fix is to increase task manager managed memory size. If running locally, see the parameter taskmanager.memory.managed.size. Details: arenaBlockSize 8388608 > mutableLimit 1957341 (writeBufferSize = 67108864, arenaBlockSizeConfigured = 0, defaultArenaBlockSize = 8388608, writeBufferManagerCapacity = 2236962)
WARN  - ConsumerConfig             - The configuration 'client.id.prefix' was supplied but isn't a known config.
WARN  - ConsumerConfig             - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
INFO  - SplitFetcher               - Starting split fetcher 0
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290633732
WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.consumer:type=app-info,id=flink-0
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:816)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:666)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:647)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:627)
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.<init>(KafkaPartitionSplitReader.java:88)
	at org.apache.flink.connector.kafka.source.KafkaSource.lambda$createReader$1(KafkaSource.java:160)
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager.createSplitFetcher(SplitFetcherManager.java:196)
	at org.apache.flink.connector.base.source.reader.fetcher.SingleThreadFetcherManager.addSplits(SingleThreadFetcherManager.java:107)
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.addSplits(SourceReaderBase.java:242)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleAddSplitsEvent(SourceOperator.java:584)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleOperatorEvent(SourceOperator.java:561)
	at org.apache.flink.streaming.runtime.tasks.OperatorEventDispatcherImpl.dispatchEventToHandlers(OperatorEventDispatcherImpl.java:72)
	at org.apache.flink.streaming.runtime.tasks.RegularOperatorChain.dispatchOperatorEvent(RegularOperatorChain.java:80)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$dispatchOperatorEvent$20(StreamTask.java:1473)
	at org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$1.runThrowing(StreamTaskActionExecutor.java:50)
	at org.apache.flink.streaming.runtime.tasks.mailbox.Mail.run(Mail.java:90)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMail(MailboxProcessor.java:398)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMailsWhenDefaultActionUnavailable(MailboxProcessor.java:367)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMail(MailboxProcessor.java:352)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:229)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:839)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:788)
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:952)
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:931)
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:745)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:562)
	at java.base/java.lang.Thread.run(Thread.java:829)
WARN  - RocksDBOperationUtils      - RocksDBStateBackend performance will be poor because of the current Flink memory configuration! RocksDB will flush memtable constantly, causing high IO and CPU. Typically the easiest fix is to increase task manager managed memory size. If running locally, see the parameter taskmanager.memory.managed.size. Details: arenaBlockSize 8388608 > mutableLimit 1957341 (writeBufferSize = 67108864, arenaBlockSizeConfigured = 0, defaultArenaBlockSize = 8388608, writeBufferManagerCapacity = 2236962)
WARN  - RocksDBOperationUtils      - RocksDBStateBackend performance will be poor because of the current Flink memory configuration! RocksDB will flush memtable constantly, causing high IO and CPU. Typically the easiest fix is to increase task manager managed memory size. If running locally, see the parameter taskmanager.memory.managed.size. Details: arenaBlockSize 8388608 > mutableLimit 1957341 (writeBufferSize = 67108864, arenaBlockSizeConfigured = 0, defaultArenaBlockSize = 8388608, writeBufferManagerCapacity = 2236962)
INFO  - mbeddedRocksDBStateBackend - Getting shared memory for RocksDB: shareScope=SLOT, managed=false
INFO  - mbeddedRocksDBStateBackend - Obtained shared RocksDB cache of size 6710886 bytes
INFO  - SplitFetcher               - Starting split fetcher 0
WARN  - ConsumerConfig             - The configuration 'client.id.prefix' was supplied but isn't a known config.
WARN  - ConsumerConfig             - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290633735
WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.consumer:type=app-info,id=flink-0
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:816)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:666)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:647)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:627)
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.<init>(KafkaPartitionSplitReader.java:88)
	at org.apache.flink.connector.kafka.source.KafkaSource.lambda$createReader$1(KafkaSource.java:160)
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager.createSplitFetcher(SplitFetcherManager.java:196)
	at org.apache.flink.connector.base.source.reader.fetcher.SingleThreadFetcherManager.addSplits(SingleThreadFetcherManager.java:107)
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.addSplits(SourceReaderBase.java:242)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleAddSplitsEvent(SourceOperator.java:584)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleOperatorEvent(SourceOperator.java:561)
	at org.apache.flink.streaming.runtime.tasks.OperatorEventDispatcherImpl.dispatchEventToHandlers(OperatorEventDispatcherImpl.java:72)
	at org.apache.flink.streaming.runtime.tasks.RegularOperatorChain.dispatchOperatorEvent(RegularOperatorChain.java:80)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$dispatchOperatorEvent$20(StreamTask.java:1473)
	at org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$1.runThrowing(StreamTaskActionExecutor.java:50)
	at org.apache.flink.streaming.runtime.tasks.mailbox.Mail.run(Mail.java:90)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMail(MailboxProcessor.java:398)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMailsWhenDefaultActionUnavailable(MailboxProcessor.java:367)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMail(MailboxProcessor.java:352)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:229)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:839)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:788)
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:952)
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:931)
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:745)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:562)
	at java.base/java.lang.Thread.run(Thread.java:829)
WARN  - ConsumerConfig             - The configuration 'client.id.prefix' was supplied but isn't a known config.
WARN  - ConsumerConfig             - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290633735
WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.consumer:type=app-info,id=flink-0
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:816)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:666)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:647)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:627)
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.<init>(KafkaPartitionSplitReader.java:88)
	at org.apache.flink.connector.kafka.source.KafkaSource.lambda$createReader$1(KafkaSource.java:160)
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager.createSplitFetcher(SplitFetcherManager.java:196)
	at org.apache.flink.connector.base.source.reader.fetcher.SingleThreadFetcherManager.addSplits(SingleThreadFetcherManager.java:107)
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.addSplits(SourceReaderBase.java:242)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleAddSplitsEvent(SourceOperator.java:584)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleOperatorEvent(SourceOperator.java:561)
	at org.apache.flink.streaming.runtime.tasks.OperatorEventDispatcherImpl.dispatchEventToHandlers(OperatorEventDispatcherImpl.java:72)
	at org.apache.flink.streaming.runtime.tasks.RegularOperatorChain.dispatchOperatorEvent(RegularOperatorChain.java:80)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$dispatchOperatorEvent$20(StreamTask.java:1473)
	at org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$1.runThrowing(StreamTaskActionExecutor.java:50)
	at org.apache.flink.streaming.runtime.tasks.mailbox.Mail.run(Mail.java:90)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMail(MailboxProcessor.java:398)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMailsWhenDefaultActionUnavailable(MailboxProcessor.java:367)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMail(MailboxProcessor.java:352)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:229)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:839)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:788)
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:952)
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:931)
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:745)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:562)
	at java.base/java.lang.Thread.run(Thread.java:829)
WARN  - ConsumerConfig             - The configuration 'client.id.prefix' was supplied but isn't a known config.
WARN  - ConsumerConfig             - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290633736
WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.consumer:type=app-info,id=flink-0
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:816)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:666)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:647)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:627)
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.<init>(KafkaPartitionSplitReader.java:88)
	at org.apache.flink.connector.kafka.source.KafkaSource.lambda$createReader$1(KafkaSource.java:160)
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager.createSplitFetcher(SplitFetcherManager.java:196)
	at org.apache.flink.connector.base.source.reader.fetcher.SingleThreadFetcherManager.addSplits(SingleThreadFetcherManager.java:107)
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.addSplits(SourceReaderBase.java:242)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleAddSplitsEvent(SourceOperator.java:584)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleOperatorEvent(SourceOperator.java:561)
	at org.apache.flink.streaming.runtime.tasks.OperatorEventDispatcherImpl.dispatchEventToHandlers(OperatorEventDispatcherImpl.java:72)
	at org.apache.flink.streaming.runtime.tasks.RegularOperatorChain.dispatchOperatorEvent(RegularOperatorChain.java:80)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$dispatchOperatorEvent$20(StreamTask.java:1473)
	at org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$1.runThrowing(StreamTaskActionExecutor.java:50)
	at org.apache.flink.streaming.runtime.tasks.mailbox.Mail.run(Mail.java:90)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMail(MailboxProcessor.java:398)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMailsWhenDefaultActionUnavailable(MailboxProcessor.java:367)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMail(MailboxProcessor.java:352)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:229)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:839)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:788)
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:952)
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:931)
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:745)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:562)
	at java.base/java.lang.Thread.run(Thread.java:829)
INFO  - ZooKeeper                  - Session: 0x10009b90d4f0007 closed
WARN  - ConsumerConfig             - The configuration 'client.id.prefix' was supplied but isn't a known config.
WARN  - ConsumerConfig             - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290633736
WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.consumer:type=app-info,id=flink-0
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:816)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:666)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:647)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:627)
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.<init>(KafkaPartitionSplitReader.java:88)
	at org.apache.flink.connector.kafka.source.KafkaSource.lambda$createReader$1(KafkaSource.java:160)
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager.createSplitFetcher(SplitFetcherManager.java:196)
	at org.apache.flink.connector.base.source.reader.fetcher.SingleThreadFetcherManager.addSplits(SingleThreadFetcherManager.java:107)
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.addSplits(SourceReaderBase.java:242)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleAddSplitsEvent(SourceOperator.java:584)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleOperatorEvent(SourceOperator.java:561)
	at org.apache.flink.streaming.runtime.tasks.OperatorEventDispatcherImpl.dispatchEventToHandlers(OperatorEventDispatcherImpl.java:72)
	at org.apache.flink.streaming.runtime.tasks.RegularOperatorChain.dispatchOperatorEvent(RegularOperatorChain.java:80)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$dispatchOperatorEvent$20(StreamTask.java:1473)
	at org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$1.runThrowing(StreamTaskActionExecutor.java:50)
	at org.apache.flink.streaming.runtime.tasks.mailbox.Mail.run(Mail.java:90)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMail(MailboxProcessor.java:398)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMailsWhenDefaultActionUnavailable(MailboxProcessor.java:367)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMail(MailboxProcessor.java:352)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:229)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:839)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:788)
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:952)
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:931)
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:745)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:562)
	at java.base/java.lang.Thread.run(Thread.java:829)
INFO  - SplitFetcher               - Starting split fetcher 0
INFO  - ClientCnxn                 - EventThread shut down for session: 0x10009b90d4f0007
INFO  - mbeddedRocksDBStateBackend - Getting shared memory for RocksDB: shareScope=SLOT, managed=false
INFO  - mbeddedRocksDBStateBackend - Obtained shared RocksDB cache of size 6710886 bytes
INFO  - SplitFetcher               - Starting split fetcher 0
INFO  - SplitFetcher               - Starting split fetcher 0
INFO  - mbeddedRocksDBStateBackend - Getting shared memory for RocksDB: shareScope=SLOT, managed=false
INFO  - mbeddedRocksDBStateBackend - Obtained shared RocksDB cache of size 6710886 bytes
INFO  - Task                       - Join[126] -> Calc[127] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_3619c62de06dab71ff39a3a74a9f2151_0_0) switched from INITIALIZING to RUNNING.
INFO  - SplitFetcher               - Starting split fetcher 0
INFO  - ExecutionGraph             - Join[126] -> Calc[127] (1/1) (580277ceefe8efaa1a64deb029a01c5c_3619c62de06dab71ff39a3a74a9f2151_0_0) switched from INITIALIZING to RUNNING.
INFO  - SplitFetcher               - Starting split fetcher 0
INFO  - DBKeyedStateBackendBuilder - Finished building RocksDB keyed state-backend at /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_ee8b603bf5edab3af85b6467db69921f_op_StreamingJoinOperator_5a4f0cabf832f59a1be42827a99c3e0b__1_1__uuid_5b562fbb-dc2c-466d-81c7-9784f62345d3.
INFO  - Task                       - Join[132] -> Calc[133] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_e2fa199699a83ccdc9109b613d7b5bcb_0_0) switched from INITIALIZING to RUNNING.
INFO  - ExecutionGraph             - Join[132] -> Calc[133] (1/1) (580277ceefe8efaa1a64deb029a01c5c_e2fa199699a83ccdc9109b613d7b5bcb_0_0) switched from INITIALIZING to RUNNING.
INFO  - DBKeyedStateBackendBuilder - Finished building RocksDB keyed state-backend at /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_ee8b603bf5edab3af85b6467db69921f_op_StreamingJoinOperator_962215956b0b799dc86f9b7cf721b29f__1_1__uuid_9d390c89-33af-4e7d-b703-2006f0c070b3.
INFO  - DBKeyedStateBackendBuilder - Finished building RocksDB keyed state-backend at /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_ee8b603bf5edab3af85b6467db69921f_op_StreamingJoinOperator_922a00317cf5b7bf8065287dc182322e__1_1__uuid_810b464f-f49d-4d22-bd0d-602b08dc4284.
INFO  - Task                       - Join[138] -> Calc[139] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_a180dc35eba3df5d9593070701e62815_0_0) switched from INITIALIZING to RUNNING.
WARN  - RocksDBOperationUtils      - RocksDBStateBackend performance will be poor because of the current Flink memory configuration! RocksDB will flush memtable constantly, causing high IO and CPU. Typically the easiest fix is to increase task manager managed memory size. If running locally, see the parameter taskmanager.memory.managed.size. Details: arenaBlockSize 8388608 > mutableLimit 1957341 (writeBufferSize = 67108864, arenaBlockSizeConfigured = 0, defaultArenaBlockSize = 8388608, writeBufferManagerCapacity = 2236962)
INFO  - ExecutionGraph             - Join[138] -> Calc[139] (1/1) (580277ceefe8efaa1a64deb029a01c5c_a180dc35eba3df5d9593070701e62815_0_0) switched from INITIALIZING to RUNNING.
WARN  - RocksDBOperationUtils      - RocksDBStateBackend performance will be poor because of the current Flink memory configuration! RocksDB will flush memtable constantly, causing high IO and CPU. Typically the easiest fix is to increase task manager managed memory size. If running locally, see the parameter taskmanager.memory.managed.size. Details: arenaBlockSize 8388608 > mutableLimit 1957341 (writeBufferSize = 67108864, arenaBlockSizeConfigured = 0, defaultArenaBlockSize = 8388608, writeBufferManagerCapacity = 2236962)
WARN  - RocksDBOperationUtils      - RocksDBStateBackend performance will be poor because of the current Flink memory configuration! RocksDB will flush memtable constantly, causing high IO and CPU. Typically the easiest fix is to increase task manager managed memory size. If running locally, see the parameter taskmanager.memory.managed.size. Details: arenaBlockSize 8388608 > mutableLimit 1957341 (writeBufferSize = 67108864, arenaBlockSizeConfigured = 0, defaultArenaBlockSize = 8388608, writeBufferManagerCapacity = 2236962)
INFO  - KafkaConsumer              - [Consumer clientId=flink-0, groupId=flink] Subscribed to partition(s): openmrs.openmrs.encounter_type-0
INFO  - KafkaConsumer              - [Consumer clientId=flink-0, groupId=flink] Subscribed to partition(s): openmrs.openmrs.visit_type-0
WARN  - RocksDBOperationUtils      - RocksDBStateBackend performance will be poor because of the current Flink memory configuration! RocksDB will flush memtable constantly, causing high IO and CPU. Typically the easiest fix is to increase task manager managed memory size. If running locally, see the parameter taskmanager.memory.managed.size. Details: arenaBlockSize 8388608 > mutableLimit 1957341 (writeBufferSize = 67108864, arenaBlockSizeConfigured = 0, defaultArenaBlockSize = 8388608, writeBufferManagerCapacity = 2236962)
INFO  - KafkaConsumer              - [Consumer clientId=flink-0, groupId=flink] Subscribed to partition(s): openmrs.openmrs.obs-0
INFO  - KafkaConsumer              - [Consumer clientId=flink-0, groupId=flink] Subscribed to partition(s): openmrs.openmrs.concept_name-0
INFO  - KafkaConsumer              - [Consumer clientId=flink-0, groupId=flink] Subscribed to partition(s): openmrs.openmrs.location-0
WARN  - RocksDBOperationUtils      - RocksDBStateBackend performance will be poor because of the current Flink memory configuration! RocksDB will flush memtable constantly, causing high IO and CPU. Typically the easiest fix is to increase task manager managed memory size. If running locally, see the parameter taskmanager.memory.managed.size. Details: arenaBlockSize 8388608 > mutableLimit 1957341 (writeBufferSize = 67108864, arenaBlockSizeConfigured = 0, defaultArenaBlockSize = 8388608, writeBufferManagerCapacity = 2236962)
INFO  - KafkaConsumer              - [Consumer clientId=flink-0, groupId=flink] Subscribed to partition(s): openmrs.openmrs.encounter-0
INFO  - KafkaConsumer              - [Consumer clientId=flink-0, groupId=flink] Subscribed to partition(s): openmrs.openmrs.visit-0
WARN  - RocksDBOperationUtils      - RocksDBStateBackend performance will be poor because of the current Flink memory configuration! RocksDB will flush memtable constantly, causing high IO and CPU. Typically the easiest fix is to increase task manager managed memory size. If running locally, see the parameter taskmanager.memory.managed.size. Details: arenaBlockSize 8388608 > mutableLimit 1957341 (writeBufferSize = 67108864, arenaBlockSizeConfigured = 0, defaultArenaBlockSize = 8388608, writeBufferManagerCapacity = 2236962)
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Seeking to EARLIEST offset of partition openmrs.openmrs.encounter_type-0
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Seeking to EARLIEST offset of partition openmrs.openmrs.visit_type-0
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Seeking to EARLIEST offset of partition openmrs.openmrs.obs-0
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Seeking to EARLIEST offset of partition openmrs.openmrs.concept_name-0
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Seeking to EARLIEST offset of partition openmrs.openmrs.location-0
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Seeking to EARLIEST offset of partition openmrs.openmrs.encounter-0
INFO  - mbeddedRocksDBStateBackend - Getting shared memory for RocksDB: shareScope=SLOT, managed=false
INFO  - mbeddedRocksDBStateBackend - Obtained shared RocksDB cache of size 6710886 bytes
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Seeking to EARLIEST offset of partition openmrs.openmrs.visit-0
INFO  - Task                       - Join[144] -> Calc[145] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_5a4f0cabf832f59a1be42827a99c3e0b_0_0) switched from INITIALIZING to RUNNING.
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Resetting the last seen epoch of partition openmrs.openmrs.encounter_type-0 to 0 since the associated topicId changed from null to 3O3oUm5rRvqkLZ4RLoiCYA
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Cluster ID: 5Yr1SIgYQz-b-dgRabWx4g
INFO  - ExecutionGraph             - Join[144] -> Calc[145] (1/1) (580277ceefe8efaa1a64deb029a01c5c_5a4f0cabf832f59a1be42827a99c3e0b_0_0) switched from INITIALIZING to RUNNING.
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Resetting the last seen epoch of partition openmrs.openmrs.visit_type-0 to 0 since the associated topicId changed from null to 1AXMBPpnTz65Spybw8yL5Q
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Cluster ID: 5Yr1SIgYQz-b-dgRabWx4g
INFO  - Task                       - Join[156] -> Calc[157] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_922a00317cf5b7bf8065287dc182322e_0_0) switched from INITIALIZING to RUNNING.
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Resetting the last seen epoch of partition openmrs.openmrs.concept_name-0 to 0 since the associated topicId changed from null to 6V3PMGEHRjG76RMD32edGQ
INFO  - DBKeyedStateBackendBuilder - Finished building RocksDB keyed state-backend at /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_ee8b603bf5edab3af85b6467db69921f_op_StreamingJoinOperator_a9f432d42f94da06ca5ecfb8d49d422a__1_1__uuid_b9d4c66e-6cb3-44ff-877f-761e385740fc.
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Cluster ID: 5Yr1SIgYQz-b-dgRabWx4g
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Resetting the last seen epoch of partition openmrs.openmrs.obs-0 to 0 since the associated topicId changed from null to yGJbvGTnQGepDFc_izYPog
INFO  - ExecutionGraph             - Join[156] -> Calc[157] (1/1) (580277ceefe8efaa1a64deb029a01c5c_922a00317cf5b7bf8065287dc182322e_0_0) switched from INITIALIZING to RUNNING.
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Cluster ID: 5Yr1SIgYQz-b-dgRabWx4g
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Resetting the last seen epoch of partition openmrs.openmrs.encounter-0 to 0 since the associated topicId changed from null to zWxOkhYORpiMkF36dZ8hdw
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Cluster ID: 5Yr1SIgYQz-b-dgRabWx4g
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Resetting the last seen epoch of partition openmrs.openmrs.location-0 to 0 since the associated topicId changed from null to SyQP9S-7S5OkuBrIseTAPw
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Cluster ID: 5Yr1SIgYQz-b-dgRabWx4g
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Resetting the last seen epoch of partition openmrs.openmrs.visit-0 to 0 since the associated topicId changed from null to u28pspNHRmO5MJKK1_LAXw
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Cluster ID: 5Yr1SIgYQz-b-dgRabWx4g
WARN  - RocksDBOperationUtils      - RocksDBStateBackend performance will be poor because of the current Flink memory configuration! RocksDB will flush memtable constantly, causing high IO and CPU. Typically the easiest fix is to increase task manager managed memory size. If running locally, see the parameter taskmanager.memory.managed.size. Details: arenaBlockSize 8388608 > mutableLimit 1957341 (writeBufferSize = 67108864, arenaBlockSizeConfigured = 0, defaultArenaBlockSize = 8388608, writeBufferManagerCapacity = 2236962)
INFO  - mbeddedRocksDBStateBackend - Getting shared memory for RocksDB: shareScope=SLOT, managed=false
INFO  - mbeddedRocksDBStateBackend - Obtained shared RocksDB cache of size 6710886 bytes
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Resetting offset for partition openmrs.openmrs.visit_type-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:29092 (id: 1 rack: null)], epoch=0}}.
INFO  - Task                       - Join[150] -> Calc[151] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_962215956b0b799dc86f9b7cf721b29f_0_0) switched from INITIALIZING to RUNNING.
WARN  - RocksDBOperationUtils      - RocksDBStateBackend performance will be poor because of the current Flink memory configuration! RocksDB will flush memtable constantly, causing high IO and CPU. Typically the easiest fix is to increase task manager managed memory size. If running locally, see the parameter taskmanager.memory.managed.size. Details: arenaBlockSize 8388608 > mutableLimit 1957341 (writeBufferSize = 67108864, arenaBlockSizeConfigured = 0, defaultArenaBlockSize = 8388608, writeBufferManagerCapacity = 2236962)
INFO  - ExecutionGraph             - Join[150] -> Calc[151] (1/1) (580277ceefe8efaa1a64deb029a01c5c_962215956b0b799dc86f9b7cf721b29f_0_0) switched from INITIALIZING to RUNNING.
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Resetting offset for partition openmrs.openmrs.concept_name-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:29092 (id: 1 rack: null)], epoch=0}}.
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Resetting offset for partition openmrs.openmrs.encounter_type-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:29092 (id: 1 rack: null)], epoch=0}}.
INFO  - DBKeyedStateBackendBuilder - Finished building RocksDB keyed state-backend at /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_ee8b603bf5edab3af85b6467db69921f_op_SinkUpsertMaterializer_f4513f6c8f56192fb7e41d1eacfc44d9__1_1__uuid_972fc070-ae5d-464f-9ef7-51d6d6dd18c5.
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Resetting offset for partition openmrs.openmrs.obs-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:29092 (id: 1 rack: null)], epoch=0}}.
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Resetting offset for partition openmrs.openmrs.visit-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:29092 (id: 1 rack: null)], epoch=0}}.
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Resetting offset for partition openmrs.openmrs.encounter-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:29092 (id: 1 rack: null)], epoch=0}}.
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Resetting offset for partition openmrs.openmrs.location-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:29092 (id: 1 rack: null)], epoch=0}}.
INFO  - Task                       - Join[159] -> Calc[160] -> ConstraintEnforcer[161] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_a9f432d42f94da06ca5ecfb8d49d422a_0_0) switched from INITIALIZING to RUNNING.
INFO  - ExecutionGraph             - Join[159] -> Calc[160] -> ConstraintEnforcer[161] (1/1) (580277ceefe8efaa1a64deb029a01c5c_a9f432d42f94da06ca5ecfb8d49d422a_0_0) switched from INITIALIZING to RUNNING.
WARN  - RocksDBOperationUtils      - RocksDBStateBackend performance will be poor because of the current Flink memory configuration! RocksDB will flush memtable constantly, causing high IO and CPU. Typically the easiest fix is to increase task manager managed memory size. If running locally, see the parameter taskmanager.memory.managed.size. Details: arenaBlockSize 8388608 > mutableLimit 1957341 (writeBufferSize = 67108864, arenaBlockSizeConfigured = 0, defaultArenaBlockSize = 8388608, writeBufferManagerCapacity = 2236962)
INFO  - Task                       - SinkMaterializer[161] -> Sink: observations[161] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_f4513f6c8f56192fb7e41d1eacfc44d9_0_0) switched from INITIALIZING to RUNNING.
INFO  - ExecutionGraph             - SinkMaterializer[161] -> Sink: observations[161] (1/1) (580277ceefe8efaa1a64deb029a01c5c_f4513f6c8f56192fb7e41d1eacfc44d9_0_0) switched from INITIALIZING to RUNNING.
WARN  - Configuration              - Config uses deprecated configuration key 'high-availability' instead of proper key 'high-availability.type'
INFO  - ZooKeeperUtils             - Enforcing default ACL for ZK connections
INFO  - ZooKeeperUtils             - Using '/flink/default' as Zookeeper namespace.
INFO  - CuratorFrameworkImpl       - Starting
INFO  - ZooKeeper                  - Initiating client connection, connectString=localhost:2181 sessionTimeout=60000 watcher=org.apache.flink.shaded.curator5.org.apache.curator.ConnectionState@36fa39e4
INFO  - ClientCnxnSocket           - jute.maxbuffer value is 1048575 Bytes
INFO  - ClientCnxn                 - zookeeper.request.timeout value is 0. feature enabled=false
INFO  - ClientCnxn                 - Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181.
INFO  - ClientCnxn                 - SASL config status: Will not attempt to authenticate using SASL (unknown error)
INFO  - CuratorFrameworkImpl       - Default schema
INFO  - aultLeaderRetrievalService - Starting DefaultLeaderRetrievalService with ZookeeperLeaderRetrievalDriver{connectionInformationPath='/leader/rest_server/connection_info'}.
INFO  - ClientCnxn                 - Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:52369, server: localhost/0:0:0:0:0:0:0:1:2181
INFO  - RestClusterClient          - Submitting job 'insert-into_analytics.analytics.sale_order' (6cadd3411b812f5aeb1f461ff6051653).
INFO  - ClientCnxn                 - Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, session id = 0x10009b90d4f0008, negotiated timeout = 40000
INFO  - ConnectionStateManager     - State change: CONNECTED
INFO  - EnsembleTracker            - New config event received: {}
INFO  - EnsembleTracker            - New config event received: {}
INFO  - StandaloneDispatcher       - Received JobGraph submission 'insert-into_analytics.analytics.sale_order' (6cadd3411b812f5aeb1f461ff6051653).
INFO  - StandaloneDispatcher       - Submitting job 'insert-into_analytics.analytics.sale_order' (6cadd3411b812f5aeb1f461ff6051653).
INFO  - DefaultJobGraphStore       - Added JobGraph(jobId: 6cadd3411b812f5aeb1f461ff6051653) to ZooKeeperStateHandleStore{namespace='flink/default/jobgraphs'}.
INFO  - faultLeaderElectionService - Starting DefaultLeaderElectionService with org.apache.flink.runtime.leaderelection.MultipleComponentLeaderElectionDriverAdapter@7970f0ae.
INFO  - terServiceLeadershipRunner - JobMasterServiceLeadershipRunner for job 6cadd3411b812f5aeb1f461ff6051653 was granted leadership with leader id 3a82a6ce-fb62-4610-b46c-7fb86bd673d4. Creating new JobMasterServiceProcess.
INFO  - AkkaRpcService             - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/rpc/jobmanager_10 .
INFO  - RestClusterClient          - Successfully submitted job 'insert-into_analytics.analytics.sale_order' (6cadd3411b812f5aeb1f461ff6051653) to 'http://localhost:8081'.
INFO  - JobMaster                  - Initializing job 'insert-into_analytics.analytics.sale_order' (6cadd3411b812f5aeb1f461ff6051653).
INFO  - JobMaster                  - Using restart back off time strategy ExponentialDelayRestartBackoffTimeStrategy(initialBackoffMS=1000, maxBackoffMS=300000, backoffMultiplier=2.0, resetBackoffThresholdMS=3600000, jitterFactor=0.1, currentBackoffMS=1000, lastFailureTimestamp=0) for insert-into_analytics.analytics.sale_order (6cadd3411b812f5aeb1f461ff6051653).
INFO  - pletedCheckpointStoreUtils - Recovering checkpoints from ZooKeeperStateHandleStore{namespace='flink/default/jobs/6cadd3411b812f5aeb1f461ff6051653/checkpoints'}.
INFO  - pletedCheckpointStoreUtils - Found 0 checkpoints in ZooKeeperStateHandleStore{namespace='flink/default/jobs/6cadd3411b812f5aeb1f461ff6051653/checkpoints'}.
INFO  - pletedCheckpointStoreUtils - Trying to fetch 0 checkpoints from storage.
INFO  - ZooKeeperUtils             - Initialized DefaultCompletedCheckpointStore in 'ZooKeeperStateHandleStore{namespace='flink/default/jobs/6cadd3411b812f5aeb1f461ff6051653/checkpoints'}' with /checkpoints.
INFO  - ExecutionGraph             - Created execution graph a1c2895d942138a93658723314479d9c for job 6cadd3411b812f5aeb1f461ff6051653.
INFO  - JobMaster                  - Running initialization on master for job insert-into_analytics.analytics.sale_order (6cadd3411b812f5aeb1f461ff6051653).
INFO  - JobMaster                  - Successfully ran initialization on master in 0 ms.
INFO  - DefaultExecutionTopology   - Built 1 new pipelined regions in 0 ms, total 1 pipelined regions currently.
INFO  - JobMaster                  - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - JobMaster                  - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - JobMaster                  - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - CheckpointCoordinator      - No checkpoint found during restore.
INFO  - JobMaster                  - Using failover strategy org.apache.flink.runtime.executiongraph.failover.flip1.RestartPipelinedRegionFailoverStrategy@6d66dbbc for insert-into_analytics.analytics.sale_order (6cadd3411b812f5aeb1f461ff6051653).
INFO  - aultLeaderRetrievalService - Starting DefaultLeaderRetrievalService with ZookeeperLeaderRetrievalDriver{connectionInformationPath='/resource_manager/connection_info'}.
INFO  - JobMaster                  - Starting execution of job 'insert-into_analytics.analytics.sale_order' (6cadd3411b812f5aeb1f461ff6051653) under job master id b46c7fb86bd673d43a82a6cefb624610.
INFO  - SourceCoordinator          - Starting split enumerator for source Source: sale_order[162].
INFO  - JobMaster                  - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
INFO  - ExecutionGraph             - Job insert-into_analytics.analytics.sale_order (6cadd3411b812f5aeb1f461ff6051653) switched from state CREATED to RUNNING.
INFO  - AdminClientConfig          - AdminClientConfig values: 
	bootstrap.servers = [localhost:29092]
	client.dns.lookup = use_all_dns_ips
	client.id = flink-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

INFO  - ExecutionGraph             - Source: sale_order[162] -> Calc[163] -> ConstraintEnforcer[164] (1/1) (a1c2895d942138a93658723314479d9c_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to SCHEDULED.
INFO  - ExecutionGraph             - SinkMaterializer[164] -> Sink: sale_order[164] (1/1) (a1c2895d942138a93658723314479d9c_c27dcf7b54ef6bfd6cff02ca8870b681_0_0) switched from CREATED to SCHEDULED.
INFO  - JobMaster                  - Connecting to ResourceManager akka://flink/user/rpc/resourcemanager_1(b46c7fb86bd673d43a82a6cefb624610)
WARN  - AdminClientConfig          - The configuration 'key.deserializer' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'value.deserializer' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'enable.auto.commit' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'client.id.prefix' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'group.id' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'auto.offset.reset' was supplied but isn't a known config.
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290634035
WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.admin.client:type=app-info,id=flink-enumerator-admin-client
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.admin.KafkaAdminClient.<init>(KafkaAdminClient.java:597)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:539)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:478)
	at org.apache.kafka.clients.admin.Admin.create(Admin.java:133)
	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getKafkaAdminClient(KafkaSourceEnumerator.java:410)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.start(KafkaSourceEnumerator.java:151)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$start$1(SourceCoordinator.java:234)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$runInEventLoop$10(SourceCoordinator.java:458)
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
INFO  - JobMaster                  - Resolved ResourceManager address, beginning registration
INFO  - KafkaSourceEnumerator      - Starting the KafkaSourceEnumerator for consumer group flink without periodic partition discovery.
INFO  - aultLeaderRetrievalService - Starting DefaultLeaderRetrievalService with ZookeeperLeaderRetrievalDriver{connectionInformationPath='/6cadd3411b812f5aeb1f461ff6051653/connection_info'}.
INFO  - StandaloneResourceManager  - Registering job manager b46c7fb86bd673d43a82a6cefb624610@akka://flink/user/rpc/jobmanager_10 for job 6cadd3411b812f5aeb1f461ff6051653.
INFO  - KafkaSourceEnumerator      - Discovered new partitions: [odoo.public.sale_order-0]
INFO  - aultLeaderRetrievalService - Stopping DefaultLeaderRetrievalService.
INFO  - eeperLeaderRetrievalDriver - Closing ZookeeperLeaderRetrievalDriver{connectionInformationPath='/leader/rest_server/connection_info'}.
INFO  - StandaloneResourceManager  - Registered job manager b46c7fb86bd673d43a82a6cefb624610@akka://flink/user/rpc/jobmanager_10 for job 6cadd3411b812f5aeb1f461ff6051653.
INFO  - CuratorFrameworkImpl       - backgroundOperationsLoop exiting
INFO  - JobMaster                  - JobManager successfully registered at ResourceManager, leader id: b46c7fb86bd673d43a82a6cefb624610.
INFO  - DeclarativeSlotManager     - Received resource requirements from job 6cadd3411b812f5aeb1f461ff6051653: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
INFO  - TaskExecutor               - Receive slot request a5e3467386b53061bfc7af5aea8a7faa for job 6cadd3411b812f5aeb1f461ff6051653 from resource manager with leader id b46c7fb86bd673d43a82a6cefb624610.
INFO  - TaskExecutor               - Allocated slot for a5e3467386b53061bfc7af5aea8a7faa.
INFO  - DefaultJobLeaderService    - Add job 6cadd3411b812f5aeb1f461ff6051653 for job leader monitoring.
INFO  - aultLeaderRetrievalService - Starting DefaultLeaderRetrievalService with ZookeeperLeaderRetrievalDriver{connectionInformationPath='/6cadd3411b812f5aeb1f461ff6051653/connection_info'}.
INFO  - DefaultJobLeaderService    - Try to register at job manager akka://flink/user/rpc/jobmanager_10 with leader id 3a82a6ce-fb62-4610-b46c-7fb86bd673d4.
INFO  - DefaultJobLeaderService    - Resolved JobManager address, beginning registration
INFO  - DefaultJobLeaderService    - Successful registration at job manager akka://flink/user/rpc/jobmanager_10 for job 6cadd3411b812f5aeb1f461ff6051653.
INFO  - TaskExecutor               - Establish JobManager connection for job 6cadd3411b812f5aeb1f461ff6051653.
INFO  - TaskExecutor               - Offer reserved slots to the leader of job 6cadd3411b812f5aeb1f461ff6051653.
INFO  - ExecutionGraph             - Source: sale_order[162] -> Calc[163] -> ConstraintEnforcer[164] (1/1) (a1c2895d942138a93658723314479d9c_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - ExecutionGraph             - Deploying Source: sale_order[162] -> Calc[163] -> ConstraintEnforcer[164] (1/1) (attempt #0) with attempt id a1c2895d942138a93658723314479d9c_cbc357ccb763df2852fee8c4fc7d55f2_0_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id a5e3467386b53061bfc7af5aea8a7faa
INFO  - ExecutionGraph             - SinkMaterializer[164] -> Sink: sale_order[164] (1/1) (a1c2895d942138a93658723314479d9c_c27dcf7b54ef6bfd6cff02ca8870b681_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - ExecutionGraph             - Deploying SinkMaterializer[164] -> Sink: sale_order[164] (1/1) (attempt #0) with attempt id a1c2895d942138a93658723314479d9c_c27dcf7b54ef6bfd6cff02ca8870b681_0_0 and vertex id c27dcf7b54ef6bfd6cff02ca8870b681_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id a5e3467386b53061bfc7af5aea8a7faa
INFO  - TaskSlotTableImpl          - Activate slot a5e3467386b53061bfc7af5aea8a7faa.
INFO  - tateChangelogStorageLoader - Creating a changelog storage with name 'memory'.
INFO  - tateExecutorFactoryManager - Creating the channel state executor factory for job id 6cadd3411b812f5aeb1f461ff6051653
INFO  - TaskExecutor               - Received task Source: sale_order[162] -> Calc[163] -> ConstraintEnforcer[164] (1/1)#0 (a1c2895d942138a93658723314479d9c_cbc357ccb763df2852fee8c4fc7d55f2_0_0), deploy into slot with allocation id a5e3467386b53061bfc7af5aea8a7faa.
INFO  - Task                       - Source: sale_order[162] -> Calc[163] -> ConstraintEnforcer[164] (1/1)#0 (a1c2895d942138a93658723314479d9c_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to DEPLOYING.
INFO  - Task                       - Loading JAR files for task Source: sale_order[162] -> Calc[163] -> ConstraintEnforcer[164] (1/1)#0 (a1c2895d942138a93658723314479d9c_cbc357ccb763df2852fee8c4fc7d55f2_0_0) [DEPLOYING].
INFO  - TaskSlotTableImpl          - Activate slot a5e3467386b53061bfc7af5aea8a7faa.
INFO  - TaskExecutor               - Received task SinkMaterializer[164] -> Sink: sale_order[164] (1/1)#0 (a1c2895d942138a93658723314479d9c_c27dcf7b54ef6bfd6cff02ca8870b681_0_0), deploy into slot with allocation id a5e3467386b53061bfc7af5aea8a7faa.
INFO  - Task                       - SinkMaterializer[164] -> Sink: sale_order[164] (1/1)#0 (a1c2895d942138a93658723314479d9c_c27dcf7b54ef6bfd6cff02ca8870b681_0_0) switched from CREATED to DEPLOYING.
INFO  - TaskSlotTableImpl          - Activate slot a5e3467386b53061bfc7af5aea8a7faa.
INFO  - Task                       - Loading JAR files for task SinkMaterializer[164] -> Sink: sale_order[164] (1/1)#0 (a1c2895d942138a93658723314479d9c_c27dcf7b54ef6bfd6cff02ca8870b681_0_0) [DEPLOYING].
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - Task                       - SinkMaterializer[164] -> Sink: sale_order[164] (1/1)#0 (a1c2895d942138a93658723314479d9c_c27dcf7b54ef6bfd6cff02ca8870b681_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - Task                       - Source: sale_order[162] -> Calc[163] -> ConstraintEnforcer[164] (1/1)#0 (a1c2895d942138a93658723314479d9c_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - ExecutionGraph             - SinkMaterializer[164] -> Sink: sale_order[164] (1/1) (a1c2895d942138a93658723314479d9c_c27dcf7b54ef6bfd6cff02ca8870b681_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - ExecutionGraph             - Source: sale_order[162] -> Calc[163] -> ConstraintEnforcer[164] (1/1) (a1c2895d942138a93658723314479d9c_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - SourceCoordinator          - Source Source: sale_order[162] registering reader for parallel task 0 (#0) @ 
INFO  - KafkaSourceEnumerator      - Assigning splits to readers {0=[[Partition: odoo.public.sale_order-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}
INFO  - Task                       - Source: sale_order[162] -> Calc[163] -> ConstraintEnforcer[164] (1/1)#0 (a1c2895d942138a93658723314479d9c_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
INFO  - ExecutionGraph             - Source: sale_order[162] -> Calc[163] -> ConstraintEnforcer[164] (1/1) (a1c2895d942138a93658723314479d9c_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
INFO  - SourceReaderBase           - Adding split(s) to reader: [[Partition: odoo.public.sale_order-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]
INFO  - ConsumerConfig             - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = flink-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

WARN  - ConsumerConfig             - The configuration 'client.id.prefix' was supplied but isn't a known config.
WARN  - ConsumerConfig             - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290634140
WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.consumer:type=app-info,id=flink-0
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:816)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:666)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:647)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:627)
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.<init>(KafkaPartitionSplitReader.java:88)
	at org.apache.flink.connector.kafka.source.KafkaSource.lambda$createReader$1(KafkaSource.java:160)
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager.createSplitFetcher(SplitFetcherManager.java:196)
	at org.apache.flink.connector.base.source.reader.fetcher.SingleThreadFetcherManager.addSplits(SingleThreadFetcherManager.java:107)
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.addSplits(SourceReaderBase.java:242)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleAddSplitsEvent(SourceOperator.java:584)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleOperatorEvent(SourceOperator.java:561)
	at org.apache.flink.streaming.runtime.tasks.OperatorEventDispatcherImpl.dispatchEventToHandlers(OperatorEventDispatcherImpl.java:72)
	at org.apache.flink.streaming.runtime.tasks.RegularOperatorChain.dispatchOperatorEvent(RegularOperatorChain.java:80)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$dispatchOperatorEvent$20(StreamTask.java:1473)
	at org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$1.runThrowing(StreamTaskActionExecutor.java:50)
	at org.apache.flink.streaming.runtime.tasks.mailbox.Mail.run(Mail.java:90)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMail(MailboxProcessor.java:398)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMailsWhenDefaultActionUnavailable(MailboxProcessor.java:367)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMail(MailboxProcessor.java:352)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:229)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:839)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:788)
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:952)
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:931)
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:745)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:562)
	at java.base/java.lang.Thread.run(Thread.java:829)
INFO  - SplitFetcher               - Starting split fetcher 0
INFO  - KafkaConsumer              - [Consumer clientId=flink-0, groupId=flink] Subscribed to partition(s): odoo.public.sale_order-0
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Seeking to EARLIEST offset of partition odoo.public.sale_order-0
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Resetting the last seen epoch of partition odoo.public.sale_order-0 to 0 since the associated topicId changed from null to w4sMkilAQJmiEdcMtNIhnQ
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Cluster ID: 5Yr1SIgYQz-b-dgRabWx4g
INFO  - mbeddedRocksDBStateBackend - Getting shared memory for RocksDB: shareScope=SLOT, managed=false
INFO  - mbeddedRocksDBStateBackend - Obtained shared RocksDB cache of size 6710886 bytes
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Resetting offset for partition odoo.public.sale_order-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:29092 (id: 1 rack: null)], epoch=0}}.
INFO  - DBKeyedStateBackendBuilder - Finished building RocksDB keyed state-backend at /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_6cadd3411b812f5aeb1f461ff6051653_op_SinkUpsertMaterializer_c27dcf7b54ef6bfd6cff02ca8870b681__1_1__uuid_bd9c7b06-ec9e-4d19-aa5a-7ce30a053ac6.
WARN  - RocksDBOperationUtils      - RocksDBStateBackend performance will be poor because of the current Flink memory configuration! RocksDB will flush memtable constantly, causing high IO and CPU. Typically the easiest fix is to increase task manager managed memory size. If running locally, see the parameter taskmanager.memory.managed.size. Details: arenaBlockSize 8388608 > mutableLimit 1957341 (writeBufferSize = 67108864, arenaBlockSizeConfigured = 0, defaultArenaBlockSize = 8388608, writeBufferManagerCapacity = 2236962)
INFO  - Task                       - SinkMaterializer[164] -> Sink: sale_order[164] (1/1)#0 (a1c2895d942138a93658723314479d9c_c27dcf7b54ef6bfd6cff02ca8870b681_0_0) switched from INITIALIZING to RUNNING.
INFO  - ExecutionGraph             - SinkMaterializer[164] -> Sink: sale_order[164] (1/1) (a1c2895d942138a93658723314479d9c_c27dcf7b54ef6bfd6cff02ca8870b681_0_0) switched from INITIALIZING to RUNNING.
INFO  - ZooKeeper                  - Session: 0x10009b90d4f0008 closed
INFO  - ClientCnxn                 - EventThread shut down for session: 0x10009b90d4f0008
WARN  - Configuration              - Config uses deprecated configuration key 'high-availability' instead of proper key 'high-availability.type'
INFO  - ZooKeeperUtils             - Enforcing default ACL for ZK connections
INFO  - ZooKeeperUtils             - Using '/flink/default' as Zookeeper namespace.
INFO  - CuratorFrameworkImpl       - Starting
INFO  - ZooKeeper                  - Initiating client connection, connectString=localhost:2181 sessionTimeout=60000 watcher=org.apache.flink.shaded.curator5.org.apache.curator.ConnectionState@7b92113c
INFO  - ClientCnxnSocket           - jute.maxbuffer value is 1048575 Bytes
INFO  - ClientCnxn                 - zookeeper.request.timeout value is 0. feature enabled=false
INFO  - ClientCnxn                 - Opening socket connection to server localhost/127.0.0.1:2181.
INFO  - ClientCnxn                 - SASL config status: Will not attempt to authenticate using SASL (unknown error)
INFO  - CuratorFrameworkImpl       - Default schema
INFO  - aultLeaderRetrievalService - Starting DefaultLeaderRetrievalService with ZookeeperLeaderRetrievalDriver{connectionInformationPath='/leader/rest_server/connection_info'}.
INFO  - ClientCnxn                 - Socket connection established, initiating session, client: /127.0.0.1:52382, server: localhost/127.0.0.1:2181
INFO  - ClientCnxn                 - Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x10009b90d4f0009, negotiated timeout = 40000
INFO  - ConnectionStateManager     - State change: CONNECTED
INFO  - EnsembleTracker            - New config event received: {}
INFO  - EnsembleTracker            - New config event received: {}
INFO  - RestClusterClient          - Submitting job 'insert-into_analytics.analytics.encounters' (c3c54da01848bf81457a865e46b38d18).
INFO  - StandaloneDispatcher       - Received JobGraph submission 'insert-into_analytics.analytics.encounters' (c3c54da01848bf81457a865e46b38d18).
INFO  - StandaloneDispatcher       - Submitting job 'insert-into_analytics.analytics.encounters' (c3c54da01848bf81457a865e46b38d18).
INFO  - DefaultJobGraphStore       - Added JobGraph(jobId: c3c54da01848bf81457a865e46b38d18) to ZooKeeperStateHandleStore{namespace='flink/default/jobgraphs'}.
INFO  - faultLeaderElectionService - Starting DefaultLeaderElectionService with org.apache.flink.runtime.leaderelection.MultipleComponentLeaderElectionDriverAdapter@4cd371e7.
INFO  - terServiceLeadershipRunner - JobMasterServiceLeadershipRunner for job c3c54da01848bf81457a865e46b38d18 was granted leadership with leader id 3a82a6ce-fb62-4610-b46c-7fb86bd673d4. Creating new JobMasterServiceProcess.
INFO  - AkkaRpcService             - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/rpc/jobmanager_11 .
INFO  - JobMaster                  - Initializing job 'insert-into_analytics.analytics.encounters' (c3c54da01848bf81457a865e46b38d18).
INFO  - RestClusterClient          - Successfully submitted job 'insert-into_analytics.analytics.encounters' (c3c54da01848bf81457a865e46b38d18) to 'http://localhost:8081'.
INFO  - JobMaster                  - Using restart back off time strategy ExponentialDelayRestartBackoffTimeStrategy(initialBackoffMS=1000, maxBackoffMS=300000, backoffMultiplier=2.0, resetBackoffThresholdMS=3600000, jitterFactor=0.1, currentBackoffMS=1000, lastFailureTimestamp=0) for insert-into_analytics.analytics.encounters (c3c54da01848bf81457a865e46b38d18).
INFO  - pletedCheckpointStoreUtils - Recovering checkpoints from ZooKeeperStateHandleStore{namespace='flink/default/jobs/c3c54da01848bf81457a865e46b38d18/checkpoints'}.
INFO  - pletedCheckpointStoreUtils - Found 0 checkpoints in ZooKeeperStateHandleStore{namespace='flink/default/jobs/c3c54da01848bf81457a865e46b38d18/checkpoints'}.
INFO  - pletedCheckpointStoreUtils - Trying to fetch 0 checkpoints from storage.
INFO  - ZooKeeperUtils             - Initialized DefaultCompletedCheckpointStore in 'ZooKeeperStateHandleStore{namespace='flink/default/jobs/c3c54da01848bf81457a865e46b38d18/checkpoints'}' with /checkpoints.
INFO  - ExecutionGraph             - Created execution graph 08238906b158b0367ef377eedf0e5e8e for job c3c54da01848bf81457a865e46b38d18.
INFO  - JobMaster                  - Running initialization on master for job insert-into_analytics.analytics.encounters (c3c54da01848bf81457a865e46b38d18).
INFO  - JobMaster                  - Successfully ran initialization on master in 0 ms.
INFO  - DefaultExecutionTopology   - Built 1 new pipelined regions in 0 ms, total 1 pipelined regions currently.
INFO  - JobMaster                  - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - JobMaster                  - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - JobMaster                  - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - CheckpointCoordinator      - No checkpoint found during restore.
INFO  - JobMaster                  - Using failover strategy org.apache.flink.runtime.executiongraph.failover.flip1.RestartPipelinedRegionFailoverStrategy@31e24e81 for insert-into_analytics.analytics.encounters (c3c54da01848bf81457a865e46b38d18).
INFO  - aultLeaderRetrievalService - Starting DefaultLeaderRetrievalService with ZookeeperLeaderRetrievalDriver{connectionInformationPath='/resource_manager/connection_info'}.
INFO  - JobMaster                  - Starting execution of job 'insert-into_analytics.analytics.encounters' (c3c54da01848bf81457a865e46b38d18) under job master id b46c7fb86bd673d43a82a6cefb624610.
INFO  - SourceCoordinator          - Starting split enumerator for source Source: form[179].
INFO  - SourceCoordinator          - Starting split enumerator for source Source: visit_type[191].
INFO  - SourceCoordinator          - Starting split enumerator for source Source: visit[185].
INFO  - AdminClientConfig          - AdminClientConfig values: 
	bootstrap.servers = [localhost:29092]
	client.dns.lookup = use_all_dns_ips
	client.id = flink-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

INFO  - SourceCoordinator          - Starting split enumerator for source Source: encounter[165].
INFO  - AdminClientConfig          - AdminClientConfig values: 
	bootstrap.servers = [localhost:29092]
	client.dns.lookup = use_all_dns_ips
	client.id = flink-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

INFO  - SourceCoordinator          - Starting split enumerator for source Source: encounter_type[167].
INFO  - SourceCoordinator          - Starting split enumerator for source Source: location[173].
INFO  - JobMaster                  - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
INFO  - AdminClientConfig          - AdminClientConfig values: 
	bootstrap.servers = [localhost:29092]
	client.dns.lookup = use_all_dns_ips
	client.id = flink-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

INFO  - AdminClientConfig          - AdminClientConfig values: 
	bootstrap.servers = [localhost:29092]
	client.dns.lookup = use_all_dns_ips
	client.id = flink-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

INFO  - AdminClientConfig          - AdminClientConfig values: 
	bootstrap.servers = [localhost:29092]
	client.dns.lookup = use_all_dns_ips
	client.id = flink-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

INFO  - ExecutionGraph             - Job insert-into_analytics.analytics.encounters (c3c54da01848bf81457a865e46b38d18) switched from state CREATED to RUNNING.
INFO  - ExecutionGraph             - Source: encounter[165] (1/1) (08238906b158b0367ef377eedf0e5e8e_bc764cd8ddf7a0cff126f51c16239658_0_0) switched from CREATED to SCHEDULED.
WARN  - AdminClientConfig          - The configuration 'key.deserializer' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'value.deserializer' was supplied but isn't a known config.
INFO  - ExecutionGraph             - Source: encounter_type[167] -> Calc[168] (1/1) (08238906b158b0367ef377eedf0e5e8e_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) switched from CREATED to SCHEDULED.
INFO  - ExecutionGraph             - Source: location[173] -> Calc[174] (1/1) (08238906b158b0367ef377eedf0e5e8e_2963852293169ba90d9d1e7d6308db5c_0_0) switched from CREATED to SCHEDULED.
INFO  - ExecutionGraph             - Source: form[179] -> Calc[180] (1/1) (08238906b158b0367ef377eedf0e5e8e_1171dea6747ab509fdaefbe74f7195af_0_0) switched from CREATED to SCHEDULED.
INFO  - ExecutionGraph             - Source: visit[185] -> Calc[186] (1/1) (08238906b158b0367ef377eedf0e5e8e_2fa5fc7df17f61cb0e1946288970d799_0_0) switched from CREATED to SCHEDULED.
INFO  - ExecutionGraph             - Source: visit_type[191] -> Calc[192] (1/1) (08238906b158b0367ef377eedf0e5e8e_5c4ca2fea30dcf09bf3ee40c495fe808_0_0) switched from CREATED to SCHEDULED.
INFO  - ExecutionGraph             - Join[170] -> Calc[171] (1/1) (08238906b158b0367ef377eedf0e5e8e_13ff54467ae8d49b7c9f1ac12fb64224_0_0) switched from CREATED to SCHEDULED.
INFO  - ExecutionGraph             - Join[176] -> Calc[177] (1/1) (08238906b158b0367ef377eedf0e5e8e_f9afc738306b4169a24150490d8848b9_0_0) switched from CREATED to SCHEDULED.
INFO  - ExecutionGraph             - Join[182] -> Calc[183] (1/1) (08238906b158b0367ef377eedf0e5e8e_94f730e433abfd15ea618c51df02d4b0_0_0) switched from CREATED to SCHEDULED.
INFO  - ExecutionGraph             - Join[188] -> Calc[189] (1/1) (08238906b158b0367ef377eedf0e5e8e_01389bc9e2643187cd29ee681db6e960_0_0) switched from CREATED to SCHEDULED.
INFO  - ExecutionGraph             - Join[194] -> Calc[195] -> ConstraintEnforcer[196] (1/1) (08238906b158b0367ef377eedf0e5e8e_1eb956e4b1189e52250876d9eaefba9a_0_0) switched from CREATED to SCHEDULED.
INFO  - ExecutionGraph             - SinkMaterializer[196] -> Sink: encounters[196] (1/1) (08238906b158b0367ef377eedf0e5e8e_24dade4534f1f5ef5856c625ffee2704_0_0) switched from CREATED to SCHEDULED.
INFO  - AdminClientConfig          - AdminClientConfig values: 
	bootstrap.servers = [localhost:29092]
	client.dns.lookup = use_all_dns_ips
	client.id = flink-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

WARN  - AdminClientConfig          - The configuration 'enable.auto.commit' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'client.id.prefix' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'group.id' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'auto.offset.reset' was supplied but isn't a known config.
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290634667
WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.admin.client:type=app-info,id=flink-enumerator-admin-client
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.admin.KafkaAdminClient.<init>(KafkaAdminClient.java:597)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:539)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:478)
	at org.apache.kafka.clients.admin.Admin.create(Admin.java:133)
	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getKafkaAdminClient(KafkaSourceEnumerator.java:410)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.start(KafkaSourceEnumerator.java:151)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$start$1(SourceCoordinator.java:234)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$runInEventLoop$10(SourceCoordinator.java:458)
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
INFO  - JobMaster                  - Connecting to ResourceManager akka://flink/user/rpc/resourcemanager_1(b46c7fb86bd673d43a82a6cefb624610)
WARN  - AdminClientConfig          - The configuration 'key.deserializer' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'value.deserializer' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'enable.auto.commit' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'client.id.prefix' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'group.id' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'auto.offset.reset' was supplied but isn't a known config.
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290634667
WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.admin.client:type=app-info,id=flink-enumerator-admin-client
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.admin.KafkaAdminClient.<init>(KafkaAdminClient.java:597)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:539)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:478)
	at org.apache.kafka.clients.admin.Admin.create(Admin.java:133)
	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getKafkaAdminClient(KafkaSourceEnumerator.java:410)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.start(KafkaSourceEnumerator.java:151)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$start$1(SourceCoordinator.java:234)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$runInEventLoop$10(SourceCoordinator.java:458)
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
INFO  - KafkaSourceEnumerator      - Starting the KafkaSourceEnumerator for consumer group flink without periodic partition discovery.
INFO  - JobMaster                  - Resolved ResourceManager address, beginning registration
WARN  - AdminClientConfig          - The configuration 'key.deserializer' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'value.deserializer' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'enable.auto.commit' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'client.id.prefix' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'group.id' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'key.deserializer' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'value.deserializer' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'enable.auto.commit' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'client.id.prefix' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'group.id' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'auto.offset.reset' was supplied but isn't a known config.
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290634668
WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.admin.client:type=app-info,id=flink-enumerator-admin-client
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.admin.KafkaAdminClient.<init>(KafkaAdminClient.java:597)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:539)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:478)
	at org.apache.kafka.clients.admin.Admin.create(Admin.java:133)
	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getKafkaAdminClient(KafkaSourceEnumerator.java:410)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.start(KafkaSourceEnumerator.java:151)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$start$1(SourceCoordinator.java:234)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$runInEventLoop$10(SourceCoordinator.java:458)
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
INFO  - KafkaSourceEnumerator      - Starting the KafkaSourceEnumerator for consumer group flink without periodic partition discovery.
INFO  - aultLeaderRetrievalService - Starting DefaultLeaderRetrievalService with ZookeeperLeaderRetrievalDriver{connectionInformationPath='/c3c54da01848bf81457a865e46b38d18/connection_info'}.
INFO  - StandaloneResourceManager  - Registering job manager b46c7fb86bd673d43a82a6cefb624610@akka://flink/user/rpc/jobmanager_11 for job c3c54da01848bf81457a865e46b38d18.
WARN  - AdminClientConfig          - The configuration 'key.deserializer' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'value.deserializer' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'enable.auto.commit' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'client.id.prefix' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'group.id' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'auto.offset.reset' was supplied but isn't a known config.
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290634669
WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.admin.client:type=app-info,id=flink-enumerator-admin-client
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.admin.KafkaAdminClient.<init>(KafkaAdminClient.java:597)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:539)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:478)
	at org.apache.kafka.clients.admin.Admin.create(Admin.java:133)
	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getKafkaAdminClient(KafkaSourceEnumerator.java:410)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.start(KafkaSourceEnumerator.java:151)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$start$1(SourceCoordinator.java:234)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$runInEventLoop$10(SourceCoordinator.java:458)
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
WARN  - AdminClientConfig          - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'auto.offset.reset' was supplied but isn't a known config.
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290634669
WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.admin.client:type=app-info,id=flink-enumerator-admin-client
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.admin.KafkaAdminClient.<init>(KafkaAdminClient.java:597)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:539)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:478)
	at org.apache.kafka.clients.admin.Admin.create(Admin.java:133)
	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getKafkaAdminClient(KafkaSourceEnumerator.java:410)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.start(KafkaSourceEnumerator.java:151)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$start$1(SourceCoordinator.java:234)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$runInEventLoop$10(SourceCoordinator.java:458)
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
WARN  - AdminClientConfig          - The configuration 'key.deserializer' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'value.deserializer' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'enable.auto.commit' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'client.id.prefix' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'group.id' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'auto.offset.reset' was supplied but isn't a known config.
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290634670
WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.admin.client:type=app-info,id=flink-enumerator-admin-client
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.admin.KafkaAdminClient.<init>(KafkaAdminClient.java:597)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:539)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:478)
	at org.apache.kafka.clients.admin.Admin.create(Admin.java:133)
	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getKafkaAdminClient(KafkaSourceEnumerator.java:410)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.start(KafkaSourceEnumerator.java:151)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$start$1(SourceCoordinator.java:234)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$runInEventLoop$10(SourceCoordinator.java:458)
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
INFO  - KafkaSourceEnumerator      - Starting the KafkaSourceEnumerator for consumer group flink without periodic partition discovery.
INFO  - KafkaSourceEnumerator      - Starting the KafkaSourceEnumerator for consumer group flink without periodic partition discovery.
INFO  - KafkaSourceEnumerator      - Starting the KafkaSourceEnumerator for consumer group flink without periodic partition discovery.
INFO  - KafkaSourceEnumerator      - Starting the KafkaSourceEnumerator for consumer group flink without periodic partition discovery.
INFO  - KafkaSourceEnumerator      - Discovered new partitions: [openmrs.openmrs.encounter_type-0]
INFO  - KafkaSourceEnumerator      - Discovered new partitions: [openmrs.openmrs.encounter-0]
INFO  - KafkaSourceEnumerator      - Discovered new partitions: [openmrs.openmrs.form-0]
INFO  - KafkaSourceEnumerator      - Discovered new partitions: [openmrs.openmrs.visit-0]
INFO  - KafkaSourceEnumerator      - Discovered new partitions: [openmrs.openmrs.visit_type-0]
INFO  - KafkaSourceEnumerator      - Discovered new partitions: [openmrs.openmrs.location-0]
INFO  - StandaloneResourceManager  - Registered job manager b46c7fb86bd673d43a82a6cefb624610@akka://flink/user/rpc/jobmanager_11 for job c3c54da01848bf81457a865e46b38d18.
INFO  - JobMaster                  - JobManager successfully registered at ResourceManager, leader id: b46c7fb86bd673d43a82a6cefb624610.
INFO  - DeclarativeSlotManager     - Received resource requirements from job c3c54da01848bf81457a865e46b38d18: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
INFO  - aultLeaderRetrievalService - Stopping DefaultLeaderRetrievalService.
INFO  - eeperLeaderRetrievalDriver - Closing ZookeeperLeaderRetrievalDriver{connectionInformationPath='/leader/rest_server/connection_info'}.
INFO  - CuratorFrameworkImpl       - backgroundOperationsLoop exiting
INFO  - TaskExecutor               - Receive slot request 0e9d00d8da42dc96c4f8c4a1e15d40ca for job c3c54da01848bf81457a865e46b38d18 from resource manager with leader id b46c7fb86bd673d43a82a6cefb624610.
INFO  - TaskExecutor               - Allocated slot for 0e9d00d8da42dc96c4f8c4a1e15d40ca.
INFO  - DefaultJobLeaderService    - Add job c3c54da01848bf81457a865e46b38d18 for job leader monitoring.
INFO  - aultLeaderRetrievalService - Starting DefaultLeaderRetrievalService with ZookeeperLeaderRetrievalDriver{connectionInformationPath='/c3c54da01848bf81457a865e46b38d18/connection_info'}.
INFO  - DefaultJobLeaderService    - Try to register at job manager akka://flink/user/rpc/jobmanager_11 with leader id 3a82a6ce-fb62-4610-b46c-7fb86bd673d4.
INFO  - DefaultJobLeaderService    - Resolved JobManager address, beginning registration
INFO  - DefaultJobLeaderService    - Successful registration at job manager akka://flink/user/rpc/jobmanager_11 for job c3c54da01848bf81457a865e46b38d18.
INFO  - TaskExecutor               - Establish JobManager connection for job c3c54da01848bf81457a865e46b38d18.
INFO  - TaskExecutor               - Offer reserved slots to the leader of job c3c54da01848bf81457a865e46b38d18.
INFO  - ExecutionGraph             - Source: encounter[165] (1/1) (08238906b158b0367ef377eedf0e5e8e_bc764cd8ddf7a0cff126f51c16239658_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - ExecutionGraph             - Deploying Source: encounter[165] (1/1) (attempt #0) with attempt id 08238906b158b0367ef377eedf0e5e8e_bc764cd8ddf7a0cff126f51c16239658_0_0 and vertex id bc764cd8ddf7a0cff126f51c16239658_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id 0e9d00d8da42dc96c4f8c4a1e15d40ca
INFO  - ExecutionGraph             - Source: encounter_type[167] -> Calc[168] (1/1) (08238906b158b0367ef377eedf0e5e8e_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - ExecutionGraph             - Deploying Source: encounter_type[167] -> Calc[168] (1/1) (attempt #0) with attempt id 08238906b158b0367ef377eedf0e5e8e_6cdc5bb954874d922eaee11a8e7b5dd5_0_0 and vertex id 6cdc5bb954874d922eaee11a8e7b5dd5_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id 0e9d00d8da42dc96c4f8c4a1e15d40ca
INFO  - TaskSlotTableImpl          - Activate slot 0e9d00d8da42dc96c4f8c4a1e15d40ca.
INFO  - ExecutionGraph             - Source: location[173] -> Calc[174] (1/1) (08238906b158b0367ef377eedf0e5e8e_2963852293169ba90d9d1e7d6308db5c_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - ExecutionGraph             - Deploying Source: location[173] -> Calc[174] (1/1) (attempt #0) with attempt id 08238906b158b0367ef377eedf0e5e8e_2963852293169ba90d9d1e7d6308db5c_0_0 and vertex id 2963852293169ba90d9d1e7d6308db5c_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id 0e9d00d8da42dc96c4f8c4a1e15d40ca
INFO  - ExecutionGraph             - Source: form[179] -> Calc[180] (1/1) (08238906b158b0367ef377eedf0e5e8e_1171dea6747ab509fdaefbe74f7195af_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - ExecutionGraph             - Deploying Source: form[179] -> Calc[180] (1/1) (attempt #0) with attempt id 08238906b158b0367ef377eedf0e5e8e_1171dea6747ab509fdaefbe74f7195af_0_0 and vertex id 1171dea6747ab509fdaefbe74f7195af_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id 0e9d00d8da42dc96c4f8c4a1e15d40ca
INFO  - tateChangelogStorageLoader - Creating a changelog storage with name 'memory'.
INFO  - ExecutionGraph             - Source: visit[185] -> Calc[186] (1/1) (08238906b158b0367ef377eedf0e5e8e_2fa5fc7df17f61cb0e1946288970d799_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - tateExecutorFactoryManager - Creating the channel state executor factory for job id c3c54da01848bf81457a865e46b38d18
INFO  - ExecutionGraph             - Deploying Source: visit[185] -> Calc[186] (1/1) (attempt #0) with attempt id 08238906b158b0367ef377eedf0e5e8e_2fa5fc7df17f61cb0e1946288970d799_0_0 and vertex id 2fa5fc7df17f61cb0e1946288970d799_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id 0e9d00d8da42dc96c4f8c4a1e15d40ca
INFO  - ExecutionGraph             - Source: visit_type[191] -> Calc[192] (1/1) (08238906b158b0367ef377eedf0e5e8e_5c4ca2fea30dcf09bf3ee40c495fe808_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - TaskExecutor               - Received task Source: encounter[165] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_bc764cd8ddf7a0cff126f51c16239658_0_0), deploy into slot with allocation id 0e9d00d8da42dc96c4f8c4a1e15d40ca.
INFO  - ExecutionGraph             - Deploying Source: visit_type[191] -> Calc[192] (1/1) (attempt #0) with attempt id 08238906b158b0367ef377eedf0e5e8e_5c4ca2fea30dcf09bf3ee40c495fe808_0_0 and vertex id 5c4ca2fea30dcf09bf3ee40c495fe808_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id 0e9d00d8da42dc96c4f8c4a1e15d40ca
INFO  - Task                       - Source: encounter[165] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_bc764cd8ddf7a0cff126f51c16239658_0_0) switched from CREATED to DEPLOYING.
INFO  - TaskSlotTableImpl          - Activate slot 0e9d00d8da42dc96c4f8c4a1e15d40ca.
INFO  - ExecutionGraph             - Join[170] -> Calc[171] (1/1) (08238906b158b0367ef377eedf0e5e8e_13ff54467ae8d49b7c9f1ac12fb64224_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - Task                       - Loading JAR files for task Source: encounter[165] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_bc764cd8ddf7a0cff126f51c16239658_0_0) [DEPLOYING].
INFO  - ExecutionGraph             - Deploying Join[170] -> Calc[171] (1/1) (attempt #0) with attempt id 08238906b158b0367ef377eedf0e5e8e_13ff54467ae8d49b7c9f1ac12fb64224_0_0 and vertex id 13ff54467ae8d49b7c9f1ac12fb64224_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id 0e9d00d8da42dc96c4f8c4a1e15d40ca
INFO  - TaskExecutor               - Received task Source: encounter_type[167] -> Calc[168] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_6cdc5bb954874d922eaee11a8e7b5dd5_0_0), deploy into slot with allocation id 0e9d00d8da42dc96c4f8c4a1e15d40ca.
INFO  - TaskSlotTableImpl          - Activate slot 0e9d00d8da42dc96c4f8c4a1e15d40ca.
INFO  - ExecutionGraph             - Join[176] -> Calc[177] (1/1) (08238906b158b0367ef377eedf0e5e8e_f9afc738306b4169a24150490d8848b9_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - ExecutionGraph             - Deploying Join[176] -> Calc[177] (1/1) (attempt #0) with attempt id 08238906b158b0367ef377eedf0e5e8e_f9afc738306b4169a24150490d8848b9_0_0 and vertex id f9afc738306b4169a24150490d8848b9_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id 0e9d00d8da42dc96c4f8c4a1e15d40ca
INFO  - TaskExecutor               - Received task Source: location[173] -> Calc[174] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_2963852293169ba90d9d1e7d6308db5c_0_0), deploy into slot with allocation id 0e9d00d8da42dc96c4f8c4a1e15d40ca.
INFO  - Task                       - Source: encounter_type[167] -> Calc[168] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) switched from CREATED to DEPLOYING.
INFO  - Task                       - Loading JAR files for task Source: encounter_type[167] -> Calc[168] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) [DEPLOYING].
INFO  - Task                       - Source: location[173] -> Calc[174] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_2963852293169ba90d9d1e7d6308db5c_0_0) switched from CREATED to DEPLOYING.
INFO  - Task                       - Loading JAR files for task Source: location[173] -> Calc[174] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_2963852293169ba90d9d1e7d6308db5c_0_0) [DEPLOYING].
INFO  - ExecutionGraph             - Join[182] -> Calc[183] (1/1) (08238906b158b0367ef377eedf0e5e8e_94f730e433abfd15ea618c51df02d4b0_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - TaskSlotTableImpl          - Activate slot 0e9d00d8da42dc96c4f8c4a1e15d40ca.
INFO  - ExecutionGraph             - Deploying Join[182] -> Calc[183] (1/1) (attempt #0) with attempt id 08238906b158b0367ef377eedf0e5e8e_94f730e433abfd15ea618c51df02d4b0_0_0 and vertex id 94f730e433abfd15ea618c51df02d4b0_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id 0e9d00d8da42dc96c4f8c4a1e15d40ca
INFO  - TaskExecutor               - Received task Source: form[179] -> Calc[180] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_1171dea6747ab509fdaefbe74f7195af_0_0), deploy into slot with allocation id 0e9d00d8da42dc96c4f8c4a1e15d40ca.
INFO  - TaskSlotTableImpl          - Activate slot 0e9d00d8da42dc96c4f8c4a1e15d40ca.
INFO  - Task                       - Source: form[179] -> Calc[180] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_1171dea6747ab509fdaefbe74f7195af_0_0) switched from CREATED to DEPLOYING.
INFO  - Task                       - Loading JAR files for task Source: form[179] -> Calc[180] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_1171dea6747ab509fdaefbe74f7195af_0_0) [DEPLOYING].
INFO  - ExecutionGraph             - Join[188] -> Calc[189] (1/1) (08238906b158b0367ef377eedf0e5e8e_01389bc9e2643187cd29ee681db6e960_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - ExecutionGraph             - Deploying Join[188] -> Calc[189] (1/1) (attempt #0) with attempt id 08238906b158b0367ef377eedf0e5e8e_01389bc9e2643187cd29ee681db6e960_0_0 and vertex id 01389bc9e2643187cd29ee681db6e960_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id 0e9d00d8da42dc96c4f8c4a1e15d40ca
INFO  - TaskExecutor               - Received task Source: visit[185] -> Calc[186] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_2fa5fc7df17f61cb0e1946288970d799_0_0), deploy into slot with allocation id 0e9d00d8da42dc96c4f8c4a1e15d40ca.
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - Task                       - Source: visit[185] -> Calc[186] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_2fa5fc7df17f61cb0e1946288970d799_0_0) switched from CREATED to DEPLOYING.
INFO  - Task                       - Loading JAR files for task Source: visit[185] -> Calc[186] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_2fa5fc7df17f61cb0e1946288970d799_0_0) [DEPLOYING].
INFO  - Task                       - Source: encounter_type[167] -> Calc[168] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - Task                       - Source: location[173] -> Calc[174] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_2963852293169ba90d9d1e7d6308db5c_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - TaskSlotTableImpl          - Activate slot 0e9d00d8da42dc96c4f8c4a1e15d40ca.
INFO  - ExecutionGraph             - Join[194] -> Calc[195] -> ConstraintEnforcer[196] (1/1) (08238906b158b0367ef377eedf0e5e8e_1eb956e4b1189e52250876d9eaefba9a_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - ExecutionGraph             - Deploying Join[194] -> Calc[195] -> ConstraintEnforcer[196] (1/1) (attempt #0) with attempt id 08238906b158b0367ef377eedf0e5e8e_1eb956e4b1189e52250876d9eaefba9a_0_0 and vertex id 1eb956e4b1189e52250876d9eaefba9a_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id 0e9d00d8da42dc96c4f8c4a1e15d40ca
INFO  - TaskExecutor               - Received task Source: visit_type[191] -> Calc[192] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_5c4ca2fea30dcf09bf3ee40c495fe808_0_0), deploy into slot with allocation id 0e9d00d8da42dc96c4f8c4a1e15d40ca.
INFO  - Task                       - Source: encounter[165] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_bc764cd8ddf7a0cff126f51c16239658_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - Task                       - Source: form[179] -> Calc[180] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_1171dea6747ab509fdaefbe74f7195af_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - ExecutionGraph             - SinkMaterializer[196] -> Sink: encounters[196] (1/1) (08238906b158b0367ef377eedf0e5e8e_24dade4534f1f5ef5856c625ffee2704_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - Task                       - Source: visit_type[191] -> Calc[192] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_5c4ca2fea30dcf09bf3ee40c495fe808_0_0) switched from CREATED to DEPLOYING.
INFO  - Task                       - Loading JAR files for task Source: visit_type[191] -> Calc[192] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_5c4ca2fea30dcf09bf3ee40c495fe808_0_0) [DEPLOYING].
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - ExecutionGraph             - Deploying SinkMaterializer[196] -> Sink: encounters[196] (1/1) (attempt #0) with attempt id 08238906b158b0367ef377eedf0e5e8e_24dade4534f1f5ef5856c625ffee2704_0_0 and vertex id 24dade4534f1f5ef5856c625ffee2704_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id 0e9d00d8da42dc96c4f8c4a1e15d40ca
INFO  - Task                       - Source: visit[185] -> Calc[186] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_2fa5fc7df17f61cb0e1946288970d799_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - TaskSlotTableImpl          - Activate slot 0e9d00d8da42dc96c4f8c4a1e15d40ca.
INFO  - ExecutionGraph             - Source: encounter_type[167] -> Calc[168] (1/1) (08238906b158b0367ef377eedf0e5e8e_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - ExecutionGraph             - Source: location[173] -> Calc[174] (1/1) (08238906b158b0367ef377eedf0e5e8e_2963852293169ba90d9d1e7d6308db5c_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - ExecutionGraph             - Source: encounter[165] (1/1) (08238906b158b0367ef377eedf0e5e8e_bc764cd8ddf7a0cff126f51c16239658_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - ExecutionGraph             - Source: form[179] -> Calc[180] (1/1) (08238906b158b0367ef377eedf0e5e8e_1171dea6747ab509fdaefbe74f7195af_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - ExecutionGraph             - Source: visit[185] -> Calc[186] (1/1) (08238906b158b0367ef377eedf0e5e8e_2fa5fc7df17f61cb0e1946288970d799_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - TaskExecutor               - Received task Join[170] -> Calc[171] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_13ff54467ae8d49b7c9f1ac12fb64224_0_0), deploy into slot with allocation id 0e9d00d8da42dc96c4f8c4a1e15d40ca.
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - TaskSlotTableImpl          - Activate slot 0e9d00d8da42dc96c4f8c4a1e15d40ca.
INFO  - Task                       - Join[170] -> Calc[171] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_13ff54467ae8d49b7c9f1ac12fb64224_0_0) switched from CREATED to DEPLOYING.
INFO  - Task                       - Loading JAR files for task Join[170] -> Calc[171] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_13ff54467ae8d49b7c9f1ac12fb64224_0_0) [DEPLOYING].
INFO  - TaskExecutor               - Received task Join[176] -> Calc[177] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_f9afc738306b4169a24150490d8848b9_0_0), deploy into slot with allocation id 0e9d00d8da42dc96c4f8c4a1e15d40ca.
INFO  - Task                       - Join[176] -> Calc[177] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_f9afc738306b4169a24150490d8848b9_0_0) switched from CREATED to DEPLOYING.
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - TaskSlotTableImpl          - Activate slot 0e9d00d8da42dc96c4f8c4a1e15d40ca.
INFO  - Task                       - Loading JAR files for task Join[176] -> Calc[177] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_f9afc738306b4169a24150490d8848b9_0_0) [DEPLOYING].
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - SourceCoordinator          - Source Source: encounter[165] registering reader for parallel task 0 (#0) @ 
INFO  - KafkaSourceEnumerator      - Assigning splits to readers {0=[[Partition: openmrs.openmrs.encounter-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}
INFO  - TaskExecutor               - Received task Join[182] -> Calc[183] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_94f730e433abfd15ea618c51df02d4b0_0_0), deploy into slot with allocation id 0e9d00d8da42dc96c4f8c4a1e15d40ca.
INFO  - Task                       - Source: encounter[165] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_bc764cd8ddf7a0cff126f51c16239658_0_0) switched from INITIALIZING to RUNNING.
INFO  - Task                       - Source: visit_type[191] -> Calc[192] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_5c4ca2fea30dcf09bf3ee40c495fe808_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - ExecutionGraph             - Source: encounter[165] (1/1) (08238906b158b0367ef377eedf0e5e8e_bc764cd8ddf7a0cff126f51c16239658_0_0) switched from INITIALIZING to RUNNING.
INFO  - ExecutionGraph             - Source: visit_type[191] -> Calc[192] (1/1) (08238906b158b0367ef377eedf0e5e8e_5c4ca2fea30dcf09bf3ee40c495fe808_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - Task                       - Join[170] -> Calc[171] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_13ff54467ae8d49b7c9f1ac12fb64224_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - TaskSlotTableImpl          - Activate slot 0e9d00d8da42dc96c4f8c4a1e15d40ca.
INFO  - ExecutionGraph             - Join[170] -> Calc[171] (1/1) (08238906b158b0367ef377eedf0e5e8e_13ff54467ae8d49b7c9f1ac12fb64224_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - Task                       - Join[182] -> Calc[183] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_94f730e433abfd15ea618c51df02d4b0_0_0) switched from CREATED to DEPLOYING.
INFO  - Task                       - Loading JAR files for task Join[182] -> Calc[183] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_94f730e433abfd15ea618c51df02d4b0_0_0) [DEPLOYING].
INFO  - TaskExecutor               - Received task Join[188] -> Calc[189] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_01389bc9e2643187cd29ee681db6e960_0_0), deploy into slot with allocation id 0e9d00d8da42dc96c4f8c4a1e15d40ca.
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - Task                       - Join[176] -> Calc[177] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_f9afc738306b4169a24150490d8848b9_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - ExecutionGraph             - Join[176] -> Calc[177] (1/1) (08238906b158b0367ef377eedf0e5e8e_f9afc738306b4169a24150490d8848b9_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - Task                       - Join[182] -> Calc[183] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_94f730e433abfd15ea618c51df02d4b0_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - ExecutionGraph             - Join[182] -> Calc[183] (1/1) (08238906b158b0367ef377eedf0e5e8e_94f730e433abfd15ea618c51df02d4b0_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - TaskSlotTableImpl          - Activate slot 0e9d00d8da42dc96c4f8c4a1e15d40ca.
INFO  - Task                       - Join[188] -> Calc[189] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_01389bc9e2643187cd29ee681db6e960_0_0) switched from CREATED to DEPLOYING.
INFO  - Task                       - Loading JAR files for task Join[188] -> Calc[189] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_01389bc9e2643187cd29ee681db6e960_0_0) [DEPLOYING].
INFO  - TaskExecutor               - Received task Join[194] -> Calc[195] -> ConstraintEnforcer[196] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_1eb956e4b1189e52250876d9eaefba9a_0_0), deploy into slot with allocation id 0e9d00d8da42dc96c4f8c4a1e15d40ca.
INFO  - SourceCoordinator          - Source Source: visit[185] registering reader for parallel task 0 (#0) @ 
INFO  - KafkaSourceEnumerator      - Assigning splits to readers {0=[[Partition: openmrs.openmrs.visit-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}
INFO  - SourceCoordinator          - Source Source: encounter_type[167] registering reader for parallel task 0 (#0) @ 
INFO  - KafkaSourceEnumerator      - Assigning splits to readers {0=[[Partition: openmrs.openmrs.encounter_type-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}
INFO  - Task                       - Source: visit[185] -> Calc[186] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_2fa5fc7df17f61cb0e1946288970d799_0_0) switched from INITIALIZING to RUNNING.
INFO  - ExecutionGraph             - Source: visit[185] -> Calc[186] (1/1) (08238906b158b0367ef377eedf0e5e8e_2fa5fc7df17f61cb0e1946288970d799_0_0) switched from INITIALIZING to RUNNING.
INFO  - SourceCoordinator          - Source Source: visit_type[191] registering reader for parallel task 0 (#0) @ 
INFO  - KafkaSourceEnumerator      - Assigning splits to readers {0=[[Partition: openmrs.openmrs.visit_type-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - Task                       - Join[188] -> Calc[189] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_01389bc9e2643187cd29ee681db6e960_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - ExecutionGraph             - Join[188] -> Calc[189] (1/1) (08238906b158b0367ef377eedf0e5e8e_01389bc9e2643187cd29ee681db6e960_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - SourceCoordinator          - Source Source: location[173] registering reader for parallel task 0 (#0) @ 
INFO  - KafkaSourceEnumerator      - Assigning splits to readers {0=[[Partition: openmrs.openmrs.location-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}
INFO  - Task                       - Source: encounter_type[167] -> Calc[168] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) switched from INITIALIZING to RUNNING.
INFO  - ExecutionGraph             - Source: encounter_type[167] -> Calc[168] (1/1) (08238906b158b0367ef377eedf0e5e8e_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) switched from INITIALIZING to RUNNING.
INFO  - TaskSlotTableImpl          - Activate slot 0e9d00d8da42dc96c4f8c4a1e15d40ca.
INFO  - TaskExecutor               - Received task SinkMaterializer[196] -> Sink: encounters[196] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_24dade4534f1f5ef5856c625ffee2704_0_0), deploy into slot with allocation id 0e9d00d8da42dc96c4f8c4a1e15d40ca.
INFO  - mbeddedRocksDBStateBackend - Getting shared memory for RocksDB: shareScope=SLOT, managed=false
INFO  - mbeddedRocksDBStateBackend - Obtained shared RocksDB cache of size 6710886 bytes
INFO  - Task                       - Join[194] -> Calc[195] -> ConstraintEnforcer[196] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_1eb956e4b1189e52250876d9eaefba9a_0_0) switched from CREATED to DEPLOYING.
INFO  - Task                       - Loading JAR files for task Join[194] -> Calc[195] -> ConstraintEnforcer[196] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_1eb956e4b1189e52250876d9eaefba9a_0_0) [DEPLOYING].
INFO  - TaskSlotTableImpl          - Activate slot 0e9d00d8da42dc96c4f8c4a1e15d40ca.
INFO  - mbeddedRocksDBStateBackend - Getting shared memory for RocksDB: shareScope=SLOT, managed=false
INFO  - mbeddedRocksDBStateBackend - Obtained shared RocksDB cache of size 6710886 bytes
INFO  - SourceCoordinator          - Source Source: form[179] registering reader for parallel task 0 (#0) @ 
INFO  - KafkaSourceEnumerator      - Assigning splits to readers {0=[[Partition: openmrs.openmrs.form-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}
INFO  - Task                       - SinkMaterializer[196] -> Sink: encounters[196] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_24dade4534f1f5ef5856c625ffee2704_0_0) switched from CREATED to DEPLOYING.
INFO  - Task                       - Loading JAR files for task SinkMaterializer[196] -> Sink: encounters[196] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_24dade4534f1f5ef5856c625ffee2704_0_0) [DEPLOYING].
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - SourceReaderBase           - Adding split(s) to reader: [[Partition: openmrs.openmrs.encounter-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]
INFO  - ConsumerConfig             - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = flink-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

INFO  - SourceReaderBase           - Adding split(s) to reader: [[Partition: openmrs.openmrs.visit-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]
INFO  - SourceReaderBase           - Adding split(s) to reader: [[Partition: openmrs.openmrs.encounter_type-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]
INFO  - ConsumerConfig             - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = flink-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

INFO  - ConsumerConfig             - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = flink-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

INFO  - mbeddedRocksDBStateBackend - Getting shared memory for RocksDB: shareScope=SLOT, managed=false
INFO  - mbeddedRocksDBStateBackend - Obtained shared RocksDB cache of size 6710886 bytes
INFO  - Task                       - SinkMaterializer[196] -> Sink: encounters[196] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_24dade4534f1f5ef5856c625ffee2704_0_0) switched from DEPLOYING to INITIALIZING.
WARN  - ConsumerConfig             - The configuration 'client.id.prefix' was supplied but isn't a known config.
WARN  - ConsumerConfig             - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290634795
WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.consumer:type=app-info,id=flink-0
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:816)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:666)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:647)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:627)
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.<init>(KafkaPartitionSplitReader.java:88)
	at org.apache.flink.connector.kafka.source.KafkaSource.lambda$createReader$1(KafkaSource.java:160)
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager.createSplitFetcher(SplitFetcherManager.java:196)
	at org.apache.flink.connector.base.source.reader.fetcher.SingleThreadFetcherManager.addSplits(SingleThreadFetcherManager.java:107)
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.addSplits(SourceReaderBase.java:242)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleAddSplitsEvent(SourceOperator.java:584)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleOperatorEvent(SourceOperator.java:561)
	at org.apache.flink.streaming.runtime.tasks.OperatorEventDispatcherImpl.dispatchEventToHandlers(OperatorEventDispatcherImpl.java:72)
	at org.apache.flink.streaming.runtime.tasks.RegularOperatorChain.dispatchOperatorEvent(RegularOperatorChain.java:80)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$dispatchOperatorEvent$20(StreamTask.java:1473)
	at org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$1.runThrowing(StreamTaskActionExecutor.java:50)
	at org.apache.flink.streaming.runtime.tasks.mailbox.Mail.run(Mail.java:90)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMail(MailboxProcessor.java:398)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMailsWhenDefaultActionUnavailable(MailboxProcessor.java:367)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMail(MailboxProcessor.java:352)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:229)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:839)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:788)
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:952)
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:931)
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:745)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:562)
	at java.base/java.lang.Thread.run(Thread.java:829)
INFO  - ExecutionGraph             - SinkMaterializer[196] -> Sink: encounters[196] (1/1) (08238906b158b0367ef377eedf0e5e8e_24dade4534f1f5ef5856c625ffee2704_0_0) switched from DEPLOYING to INITIALIZING.
WARN  - ConsumerConfig             - The configuration 'client.id.prefix' was supplied but isn't a known config.
WARN  - ConsumerConfig             - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - DBKeyedStateBackendBuilder - Finished building RocksDB keyed state-backend at /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_c3c54da01848bf81457a865e46b38d18_op_StreamingJoinOperator_f9afc738306b4169a24150490d8848b9__1_1__uuid_95dfc71b-bc8b-4cae-bad6-9cabe5ab2640.
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290634796
WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.consumer:type=app-info,id=flink-0
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:816)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:666)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:647)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:627)
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.<init>(KafkaPartitionSplitReader.java:88)
	at org.apache.flink.connector.kafka.source.KafkaSource.lambda$createReader$1(KafkaSource.java:160)
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager.createSplitFetcher(SplitFetcherManager.java:196)
	at org.apache.flink.connector.base.source.reader.fetcher.SingleThreadFetcherManager.addSplits(SingleThreadFetcherManager.java:107)
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.addSplits(SourceReaderBase.java:242)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleAddSplitsEvent(SourceOperator.java:584)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleOperatorEvent(SourceOperator.java:561)
	at org.apache.flink.streaming.runtime.tasks.OperatorEventDispatcherImpl.dispatchEventToHandlers(OperatorEventDispatcherImpl.java:72)
	at org.apache.flink.streaming.runtime.tasks.RegularOperatorChain.dispatchOperatorEvent(RegularOperatorChain.java:80)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$dispatchOperatorEvent$20(StreamTask.java:1473)
	at org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$1.runThrowing(StreamTaskActionExecutor.java:50)
	at org.apache.flink.streaming.runtime.tasks.mailbox.Mail.run(Mail.java:90)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMail(MailboxProcessor.java:398)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMailsWhenDefaultActionUnavailable(MailboxProcessor.java:367)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMail(MailboxProcessor.java:352)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:229)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:839)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:788)
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:952)
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:931)
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:745)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:562)
	at java.base/java.lang.Thread.run(Thread.java:829)
WARN  - ConsumerConfig             - The configuration 'client.id.prefix' was supplied but isn't a known config.
WARN  - ConsumerConfig             - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290634797
WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.consumer:type=app-info,id=flink-0
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:816)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:666)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:647)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:627)
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.<init>(KafkaPartitionSplitReader.java:88)
	at org.apache.flink.connector.kafka.source.KafkaSource.lambda$createReader$1(KafkaSource.java:160)
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager.createSplitFetcher(SplitFetcherManager.java:196)
	at org.apache.flink.connector.base.source.reader.fetcher.SingleThreadFetcherManager.addSplits(SingleThreadFetcherManager.java:107)
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.addSplits(SourceReaderBase.java:242)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleAddSplitsEvent(SourceOperator.java:584)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleOperatorEvent(SourceOperator.java:561)
	at org.apache.flink.streaming.runtime.tasks.OperatorEventDispatcherImpl.dispatchEventToHandlers(OperatorEventDispatcherImpl.java:72)
	at org.apache.flink.streaming.runtime.tasks.RegularOperatorChain.dispatchOperatorEvent(RegularOperatorChain.java:80)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$dispatchOperatorEvent$20(StreamTask.java:1473)
	at org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$1.runThrowing(StreamTaskActionExecutor.java:50)
	at org.apache.flink.streaming.runtime.tasks.mailbox.Mail.run(Mail.java:90)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMail(MailboxProcessor.java:398)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMailsWhenDefaultActionUnavailable(MailboxProcessor.java:367)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMail(MailboxProcessor.java:352)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:229)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:839)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:788)
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:952)
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:931)
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:745)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:562)
	at java.base/java.lang.Thread.run(Thread.java:829)
INFO  - DBKeyedStateBackendBuilder - Finished building RocksDB keyed state-backend at /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_c3c54da01848bf81457a865e46b38d18_op_StreamingJoinOperator_13ff54467ae8d49b7c9f1ac12fb64224__1_1__uuid_1f204b39-10b0-454b-9004-dc6226a55ef0.
INFO  - SplitFetcher               - Starting split fetcher 0
INFO  - Task                       - Source: location[173] -> Calc[174] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_2963852293169ba90d9d1e7d6308db5c_0_0) switched from INITIALIZING to RUNNING.
INFO  - SourceReaderBase           - Adding split(s) to reader: [[Partition: openmrs.openmrs.location-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]
INFO  - ExecutionGraph             - Source: location[173] -> Calc[174] (1/1) (08238906b158b0367ef377eedf0e5e8e_2963852293169ba90d9d1e7d6308db5c_0_0) switched from INITIALIZING to RUNNING.
INFO  - Task                       - Source: visit_type[191] -> Calc[192] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_5c4ca2fea30dcf09bf3ee40c495fe808_0_0) switched from INITIALIZING to RUNNING.
INFO  - ConsumerConfig             - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = flink-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

INFO  - SplitFetcher               - Starting split fetcher 0
INFO  - ExecutionGraph             - Source: visit_type[191] -> Calc[192] (1/1) (08238906b158b0367ef377eedf0e5e8e_5c4ca2fea30dcf09bf3ee40c495fe808_0_0) switched from INITIALIZING to RUNNING.
INFO  - SourceReaderBase           - Adding split(s) to reader: [[Partition: openmrs.openmrs.visit_type-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]
WARN  - RocksDBOperationUtils      - RocksDBStateBackend performance will be poor because of the current Flink memory configuration! RocksDB will flush memtable constantly, causing high IO and CPU. Typically the easiest fix is to increase task manager managed memory size. If running locally, see the parameter taskmanager.memory.managed.size. Details: arenaBlockSize 8388608 > mutableLimit 1957341 (writeBufferSize = 67108864, arenaBlockSizeConfigured = 0, defaultArenaBlockSize = 8388608, writeBufferManagerCapacity = 2236962)
WARN  - RocksDBOperationUtils      - RocksDBStateBackend performance will be poor because of the current Flink memory configuration! RocksDB will flush memtable constantly, causing high IO and CPU. Typically the easiest fix is to increase task manager managed memory size. If running locally, see the parameter taskmanager.memory.managed.size. Details: arenaBlockSize 8388608 > mutableLimit 1957341 (writeBufferSize = 67108864, arenaBlockSizeConfigured = 0, defaultArenaBlockSize = 8388608, writeBufferManagerCapacity = 2236962)
INFO  - ConsumerConfig             - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = flink-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

INFO  - Task                       - Source: form[179] -> Calc[180] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_1171dea6747ab509fdaefbe74f7195af_0_0) switched from INITIALIZING to RUNNING.
INFO  - SourceReaderBase           - Adding split(s) to reader: [[Partition: openmrs.openmrs.form-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]
INFO  - ConsumerConfig             - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = flink-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

INFO  - DBKeyedStateBackendBuilder - Finished building RocksDB keyed state-backend at /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_c3c54da01848bf81457a865e46b38d18_op_StreamingJoinOperator_94f730e433abfd15ea618c51df02d4b0__1_1__uuid_24fdddbd-207b-4955-9a4c-e54cd465d647.
WARN  - ConsumerConfig             - The configuration 'client.id.prefix' was supplied but isn't a known config.
WARN  - ConsumerConfig             - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290634811
WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.consumer:type=app-info,id=flink-0
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:816)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:666)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:647)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:627)
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.<init>(KafkaPartitionSplitReader.java:88)
	at org.apache.flink.connector.kafka.source.KafkaSource.lambda$createReader$1(KafkaSource.java:160)
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager.createSplitFetcher(SplitFetcherManager.java:196)
	at org.apache.flink.connector.base.source.reader.fetcher.SingleThreadFetcherManager.addSplits(SingleThreadFetcherManager.java:107)
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.addSplits(SourceReaderBase.java:242)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleAddSplitsEvent(SourceOperator.java:584)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleOperatorEvent(SourceOperator.java:561)
	at org.apache.flink.streaming.runtime.tasks.OperatorEventDispatcherImpl.dispatchEventToHandlers(OperatorEventDispatcherImpl.java:72)
	at org.apache.flink.streaming.runtime.tasks.RegularOperatorChain.dispatchOperatorEvent(RegularOperatorChain.java:80)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$dispatchOperatorEvent$20(StreamTask.java:1473)
	at org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$1.runThrowing(StreamTaskActionExecutor.java:50)
	at org.apache.flink.streaming.runtime.tasks.mailbox.Mail.run(Mail.java:90)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMail(MailboxProcessor.java:398)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMailsNonBlocking(MailboxProcessor.java:383)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMail(MailboxProcessor.java:345)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:229)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:839)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:788)
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:952)
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:931)
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:745)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:562)
	at java.base/java.lang.Thread.run(Thread.java:829)
WARN  - RocksDBOperationUtils      - RocksDBStateBackend performance will be poor because of the current Flink memory configuration! RocksDB will flush memtable constantly, causing high IO and CPU. Typically the easiest fix is to increase task manager managed memory size. If running locally, see the parameter taskmanager.memory.managed.size. Details: arenaBlockSize 8388608 > mutableLimit 1957341 (writeBufferSize = 67108864, arenaBlockSizeConfigured = 0, defaultArenaBlockSize = 8388608, writeBufferManagerCapacity = 2236962)
INFO  - ClientCnxn                 - EventThread shut down for session: 0x10009b90d4f0009
INFO  - ZooKeeper                  - Session: 0x10009b90d4f0009 closed
INFO  - SplitFetcher               - Starting split fetcher 0
WARN  - RocksDBOperationUtils      - RocksDBStateBackend performance will be poor because of the current Flink memory configuration! RocksDB will flush memtable constantly, causing high IO and CPU. Typically the easiest fix is to increase task manager managed memory size. If running locally, see the parameter taskmanager.memory.managed.size. Details: arenaBlockSize 8388608 > mutableLimit 1957341 (writeBufferSize = 67108864, arenaBlockSizeConfigured = 0, defaultArenaBlockSize = 8388608, writeBufferManagerCapacity = 2236962)
INFO  - SplitFetcher               - Starting split fetcher 0
INFO  - KafkaConsumer              - [Consumer clientId=flink-0, groupId=flink] Subscribed to partition(s): openmrs.openmrs.encounter-0
WARN  - RocksDBOperationUtils      - RocksDBStateBackend performance will be poor because of the current Flink memory configuration! RocksDB will flush memtable constantly, causing high IO and CPU. Typically the easiest fix is to increase task manager managed memory size. If running locally, see the parameter taskmanager.memory.managed.size. Details: arenaBlockSize 8388608 > mutableLimit 1957341 (writeBufferSize = 67108864, arenaBlockSizeConfigured = 0, defaultArenaBlockSize = 8388608, writeBufferManagerCapacity = 2236962)
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - mbeddedRocksDBStateBackend - Getting shared memory for RocksDB: shareScope=SLOT, managed=false
INFO  - mbeddedRocksDBStateBackend - Obtained shared RocksDB cache of size 6710886 bytes
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - Task                       - Join[194] -> Calc[195] -> ConstraintEnforcer[196] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_1eb956e4b1189e52250876d9eaefba9a_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - ExecutionGraph             - Source: form[179] -> Calc[180] (1/1) (08238906b158b0367ef377eedf0e5e8e_1171dea6747ab509fdaefbe74f7195af_0_0) switched from INITIALIZING to RUNNING.
INFO  - KafkaConsumer              - [Consumer clientId=flink-0, groupId=flink] Subscribed to partition(s): openmrs.openmrs.encounter_type-0
INFO  - ExecutionGraph             - Join[194] -> Calc[195] -> ConstraintEnforcer[196] (1/1) (08238906b158b0367ef377eedf0e5e8e_1eb956e4b1189e52250876d9eaefba9a_0_0) switched from DEPLOYING to INITIALIZING.
WARN  - RocksDBOperationUtils      - RocksDBStateBackend performance will be poor because of the current Flink memory configuration! RocksDB will flush memtable constantly, causing high IO and CPU. Typically the easiest fix is to increase task manager managed memory size. If running locally, see the parameter taskmanager.memory.managed.size. Details: arenaBlockSize 8388608 > mutableLimit 1957341 (writeBufferSize = 67108864, arenaBlockSizeConfigured = 0, defaultArenaBlockSize = 8388608, writeBufferManagerCapacity = 2236962)
WARN  - ConsumerConfig             - The configuration 'client.id.prefix' was supplied but isn't a known config.
WARN  - ConsumerConfig             - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290634815
WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.consumer:type=app-info,id=flink-0
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:816)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:666)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:647)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:627)
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.<init>(KafkaPartitionSplitReader.java:88)
	at org.apache.flink.connector.kafka.source.KafkaSource.lambda$createReader$1(KafkaSource.java:160)
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager.createSplitFetcher(SplitFetcherManager.java:196)
	at org.apache.flink.connector.base.source.reader.fetcher.SingleThreadFetcherManager.addSplits(SingleThreadFetcherManager.java:107)
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.addSplits(SourceReaderBase.java:242)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleAddSplitsEvent(SourceOperator.java:584)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleOperatorEvent(SourceOperator.java:561)
	at org.apache.flink.streaming.runtime.tasks.OperatorEventDispatcherImpl.dispatchEventToHandlers(OperatorEventDispatcherImpl.java:72)
	at org.apache.flink.streaming.runtime.tasks.RegularOperatorChain.dispatchOperatorEvent(RegularOperatorChain.java:80)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$dispatchOperatorEvent$20(StreamTask.java:1473)
	at org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$1.runThrowing(StreamTaskActionExecutor.java:50)
	at org.apache.flink.streaming.runtime.tasks.mailbox.Mail.run(Mail.java:90)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMail(MailboxProcessor.java:398)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMailsNonBlocking(MailboxProcessor.java:383)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMail(MailboxProcessor.java:345)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:229)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:839)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:788)
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:952)
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:931)
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:745)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:562)
	at java.base/java.lang.Thread.run(Thread.java:829)
WARN  - ConsumerConfig             - The configuration 'client.id.prefix' was supplied but isn't a known config.
WARN  - ConsumerConfig             - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290634815
WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.consumer:type=app-info,id=flink-0
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:816)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:666)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:647)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:627)
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.<init>(KafkaPartitionSplitReader.java:88)
	at org.apache.flink.connector.kafka.source.KafkaSource.lambda$createReader$1(KafkaSource.java:160)
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager.createSplitFetcher(SplitFetcherManager.java:196)
	at org.apache.flink.connector.base.source.reader.fetcher.SingleThreadFetcherManager.addSplits(SingleThreadFetcherManager.java:107)
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.addSplits(SourceReaderBase.java:242)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleAddSplitsEvent(SourceOperator.java:584)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleOperatorEvent(SourceOperator.java:561)
	at org.apache.flink.streaming.runtime.tasks.OperatorEventDispatcherImpl.dispatchEventToHandlers(OperatorEventDispatcherImpl.java:72)
	at org.apache.flink.streaming.runtime.tasks.RegularOperatorChain.dispatchOperatorEvent(RegularOperatorChain.java:80)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$dispatchOperatorEvent$20(StreamTask.java:1473)
	at org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$1.runThrowing(StreamTaskActionExecutor.java:50)
	at org.apache.flink.streaming.runtime.tasks.mailbox.Mail.run(Mail.java:90)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMail(MailboxProcessor.java:398)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMailsNonBlocking(MailboxProcessor.java:383)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMail(MailboxProcessor.java:345)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:229)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:839)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:788)
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:952)
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:931)
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:745)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:562)
	at java.base/java.lang.Thread.run(Thread.java:829)
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Seeking to EARLIEST offset of partition openmrs.openmrs.encounter-0
INFO  - SplitFetcher               - Starting split fetcher 0
INFO  - KafkaConsumer              - [Consumer clientId=flink-0, groupId=flink] Subscribed to partition(s): openmrs.openmrs.visit_type-0
INFO  - SplitFetcher               - Starting split fetcher 0
INFO  - KafkaConsumer              - [Consumer clientId=flink-0, groupId=flink] Subscribed to partition(s): openmrs.openmrs.visit-0
INFO  - DBKeyedStateBackendBuilder - Finished building RocksDB keyed state-backend at /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_c3c54da01848bf81457a865e46b38d18_op_StreamingJoinOperator_01389bc9e2643187cd29ee681db6e960__1_1__uuid_76e5c05a-cfde-4bdd-9283-783525b6e3d6.
INFO  - Task                       - Join[170] -> Calc[171] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_13ff54467ae8d49b7c9f1ac12fb64224_0_0) switched from INITIALIZING to RUNNING.
INFO  - ExecutionGraph             - Join[170] -> Calc[171] (1/1) (08238906b158b0367ef377eedf0e5e8e_13ff54467ae8d49b7c9f1ac12fb64224_0_0) switched from INITIALIZING to RUNNING.
WARN  - RocksDBOperationUtils      - RocksDBStateBackend performance will be poor because of the current Flink memory configuration! RocksDB will flush memtable constantly, causing high IO and CPU. Typically the easiest fix is to increase task manager managed memory size. If running locally, see the parameter taskmanager.memory.managed.size. Details: arenaBlockSize 8388608 > mutableLimit 1957341 (writeBufferSize = 67108864, arenaBlockSizeConfigured = 0, defaultArenaBlockSize = 8388608, writeBufferManagerCapacity = 2236962)
INFO  - Task                       - Join[176] -> Calc[177] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_f9afc738306b4169a24150490d8848b9_0_0) switched from INITIALIZING to RUNNING.
INFO  - ExecutionGraph             - Join[176] -> Calc[177] (1/1) (08238906b158b0367ef377eedf0e5e8e_f9afc738306b4169a24150490d8848b9_0_0) switched from INITIALIZING to RUNNING.
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Seeking to EARLIEST offset of partition openmrs.openmrs.visit_type-0
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Seeking to EARLIEST offset of partition openmrs.openmrs.visit-0
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Seeking to EARLIEST offset of partition openmrs.openmrs.encounter_type-0
WARN  - RocksDBOperationUtils      - RocksDBStateBackend performance will be poor because of the current Flink memory configuration! RocksDB will flush memtable constantly, causing high IO and CPU. Typically the easiest fix is to increase task manager managed memory size. If running locally, see the parameter taskmanager.memory.managed.size. Details: arenaBlockSize 8388608 > mutableLimit 1957341 (writeBufferSize = 67108864, arenaBlockSizeConfigured = 0, defaultArenaBlockSize = 8388608, writeBufferManagerCapacity = 2236962)
INFO  - Task                       - Join[182] -> Calc[183] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_94f730e433abfd15ea618c51df02d4b0_0_0) switched from INITIALIZING to RUNNING.
INFO  - ExecutionGraph             - Join[182] -> Calc[183] (1/1) (08238906b158b0367ef377eedf0e5e8e_94f730e433abfd15ea618c51df02d4b0_0_0) switched from INITIALIZING to RUNNING.
INFO  - KafkaConsumer              - [Consumer clientId=flink-0, groupId=flink] Subscribed to partition(s): openmrs.openmrs.location-0
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Resetting the last seen epoch of partition openmrs.openmrs.encounter-0 to 0 since the associated topicId changed from null to zWxOkhYORpiMkF36dZ8hdw
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Cluster ID: 5Yr1SIgYQz-b-dgRabWx4g
INFO  - Task                       - Join[188] -> Calc[189] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_01389bc9e2643187cd29ee681db6e960_0_0) switched from INITIALIZING to RUNNING.
INFO  - ExecutionGraph             - Join[188] -> Calc[189] (1/1) (08238906b158b0367ef377eedf0e5e8e_01389bc9e2643187cd29ee681db6e960_0_0) switched from INITIALIZING to RUNNING.
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Seeking to EARLIEST offset of partition openmrs.openmrs.location-0
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Resetting the last seen epoch of partition openmrs.openmrs.encounter_type-0 to 0 since the associated topicId changed from null to 3O3oUm5rRvqkLZ4RLoiCYA
INFO  - KafkaConsumer              - [Consumer clientId=flink-0, groupId=flink] Subscribed to partition(s): openmrs.openmrs.form-0
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Cluster ID: 5Yr1SIgYQz-b-dgRabWx4g
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Seeking to EARLIEST offset of partition openmrs.openmrs.form-0
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Resetting the last seen epoch of partition openmrs.openmrs.visit-0 to 0 since the associated topicId changed from null to u28pspNHRmO5MJKK1_LAXw
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Cluster ID: 5Yr1SIgYQz-b-dgRabWx4g
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Resetting the last seen epoch of partition openmrs.openmrs.visit_type-0 to 0 since the associated topicId changed from null to 1AXMBPpnTz65Spybw8yL5Q
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Cluster ID: 5Yr1SIgYQz-b-dgRabWx4g
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Resetting the last seen epoch of partition openmrs.openmrs.form-0 to 0 since the associated topicId changed from null to bwEJ6eVJQdG9nZaPTr44Yw
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Cluster ID: 5Yr1SIgYQz-b-dgRabWx4g
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Resetting offset for partition openmrs.openmrs.encounter-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:29092 (id: 1 rack: null)], epoch=0}}.
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Resetting offset for partition openmrs.openmrs.visit-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:29092 (id: 1 rack: null)], epoch=0}}.
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Resetting offset for partition openmrs.openmrs.encounter_type-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:29092 (id: 1 rack: null)], epoch=0}}.
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Resetting the last seen epoch of partition openmrs.openmrs.location-0 to 0 since the associated topicId changed from null to SyQP9S-7S5OkuBrIseTAPw
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Cluster ID: 5Yr1SIgYQz-b-dgRabWx4g
INFO  - mbeddedRocksDBStateBackend - Getting shared memory for RocksDB: shareScope=SLOT, managed=false
INFO  - mbeddedRocksDBStateBackend - Obtained shared RocksDB cache of size 6710886 bytes
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Resetting offset for partition openmrs.openmrs.visit_type-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:29092 (id: 1 rack: null)], epoch=0}}.
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Resetting offset for partition openmrs.openmrs.form-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:29092 (id: 1 rack: null)], epoch=0}}.
INFO  - mbeddedRocksDBStateBackend - Getting shared memory for RocksDB: shareScope=SLOT, managed=false
INFO  - mbeddedRocksDBStateBackend - Obtained shared RocksDB cache of size 6710886 bytes
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Resetting offset for partition openmrs.openmrs.location-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:29092 (id: 1 rack: null)], epoch=0}}.
INFO  - DBKeyedStateBackendBuilder - Finished building RocksDB keyed state-backend at /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_c3c54da01848bf81457a865e46b38d18_op_SinkUpsertMaterializer_24dade4534f1f5ef5856c625ffee2704__1_1__uuid_8f59091a-83fc-47dd-a0a5-aa075db3fbb3.
INFO  - DBKeyedStateBackendBuilder - Finished building RocksDB keyed state-backend at /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_c3c54da01848bf81457a865e46b38d18_op_StreamingJoinOperator_1eb956e4b1189e52250876d9eaefba9a__1_1__uuid_1345803b-2271-4dae-b094-ad2df27ad43e.
WARN  - RocksDBOperationUtils      - RocksDBStateBackend performance will be poor because of the current Flink memory configuration! RocksDB will flush memtable constantly, causing high IO and CPU. Typically the easiest fix is to increase task manager managed memory size. If running locally, see the parameter taskmanager.memory.managed.size. Details: arenaBlockSize 8388608 > mutableLimit 1957341 (writeBufferSize = 67108864, arenaBlockSizeConfigured = 0, defaultArenaBlockSize = 8388608, writeBufferManagerCapacity = 2236962)
WARN  - RocksDBOperationUtils      - RocksDBStateBackend performance will be poor because of the current Flink memory configuration! RocksDB will flush memtable constantly, causing high IO and CPU. Typically the easiest fix is to increase task manager managed memory size. If running locally, see the parameter taskmanager.memory.managed.size. Details: arenaBlockSize 8388608 > mutableLimit 1957341 (writeBufferSize = 67108864, arenaBlockSizeConfigured = 0, defaultArenaBlockSize = 8388608, writeBufferManagerCapacity = 2236962)
WARN  - RocksDBOperationUtils      - RocksDBStateBackend performance will be poor because of the current Flink memory configuration! RocksDB will flush memtable constantly, causing high IO and CPU. Typically the easiest fix is to increase task manager managed memory size. If running locally, see the parameter taskmanager.memory.managed.size. Details: arenaBlockSize 8388608 > mutableLimit 1957341 (writeBufferSize = 67108864, arenaBlockSizeConfigured = 0, defaultArenaBlockSize = 8388608, writeBufferManagerCapacity = 2236962)
INFO  - Task                       - Join[194] -> Calc[195] -> ConstraintEnforcer[196] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_1eb956e4b1189e52250876d9eaefba9a_0_0) switched from INITIALIZING to RUNNING.
INFO  - ExecutionGraph             - Join[194] -> Calc[195] -> ConstraintEnforcer[196] (1/1) (08238906b158b0367ef377eedf0e5e8e_1eb956e4b1189e52250876d9eaefba9a_0_0) switched from INITIALIZING to RUNNING.
INFO  - Task                       - SinkMaterializer[196] -> Sink: encounters[196] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_24dade4534f1f5ef5856c625ffee2704_0_0) switched from INITIALIZING to RUNNING.
INFO  - ExecutionGraph             - SinkMaterializer[196] -> Sink: encounters[196] (1/1) (08238906b158b0367ef377eedf0e5e8e_24dade4534f1f5ef5856c625ffee2704_0_0) switched from INITIALIZING to RUNNING.
WARN  - Configuration              - Config uses deprecated configuration key 'high-availability' instead of proper key 'high-availability.type'
INFO  - ZooKeeperUtils             - Enforcing default ACL for ZK connections
INFO  - ZooKeeperUtils             - Using '/flink/default' as Zookeeper namespace.
INFO  - CuratorFrameworkImpl       - Starting
INFO  - ZooKeeper                  - Initiating client connection, connectString=localhost:2181 sessionTimeout=60000 watcher=org.apache.flink.shaded.curator5.org.apache.curator.ConnectionState@5d2088dd
INFO  - ClientCnxnSocket           - jute.maxbuffer value is 1048575 Bytes
INFO  - ClientCnxn                 - zookeeper.request.timeout value is 0. feature enabled=false
INFO  - ClientCnxn                 - Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181.
INFO  - ClientCnxn                 - SASL config status: Will not attempt to authenticate using SASL (unknown error)
INFO  - CuratorFrameworkImpl       - Default schema
INFO  - aultLeaderRetrievalService - Starting DefaultLeaderRetrievalService with ZookeeperLeaderRetrievalDriver{connectionInformationPath='/leader/rest_server/connection_info'}.
INFO  - ClientCnxn                 - Socket connection established, initiating session, client: /0:0:0:0:0:0:0:1:52416, server: localhost/0:0:0:0:0:0:0:1:2181
INFO  - RestClusterClient          - Submitting job 'insert-into_analytics.analytics.conditions' (a8681efc52437137d28ae75be94f64e1).
INFO  - ClientCnxn                 - Session establishment complete on server localhost/0:0:0:0:0:0:0:1:2181, session id = 0x10009b90d4f000a, negotiated timeout = 40000
INFO  - ConnectionStateManager     - State change: CONNECTED
INFO  - EnsembleTracker            - New config event received: {}
INFO  - EnsembleTracker            - New config event received: {}
INFO  - StandaloneDispatcher       - Received JobGraph submission 'insert-into_analytics.analytics.conditions' (a8681efc52437137d28ae75be94f64e1).
INFO  - StandaloneDispatcher       - Submitting job 'insert-into_analytics.analytics.conditions' (a8681efc52437137d28ae75be94f64e1).
INFO  - DefaultJobGraphStore       - Added JobGraph(jobId: a8681efc52437137d28ae75be94f64e1) to ZooKeeperStateHandleStore{namespace='flink/default/jobgraphs'}.
INFO  - faultLeaderElectionService - Starting DefaultLeaderElectionService with org.apache.flink.runtime.leaderelection.MultipleComponentLeaderElectionDriverAdapter@7ff15988.
INFO  - terServiceLeadershipRunner - JobMasterServiceLeadershipRunner for job a8681efc52437137d28ae75be94f64e1 was granted leadership with leader id 3a82a6ce-fb62-4610-b46c-7fb86bd673d4. Creating new JobMasterServiceProcess.
INFO  - AkkaRpcService             - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/rpc/jobmanager_12 .
INFO  - RestClusterClient          - Successfully submitted job 'insert-into_analytics.analytics.conditions' (a8681efc52437137d28ae75be94f64e1) to 'http://localhost:8081'.
INFO  - JobMaster                  - Initializing job 'insert-into_analytics.analytics.conditions' (a8681efc52437137d28ae75be94f64e1).
INFO  - JobMaster                  - Using restart back off time strategy ExponentialDelayRestartBackoffTimeStrategy(initialBackoffMS=1000, maxBackoffMS=300000, backoffMultiplier=2.0, resetBackoffThresholdMS=3600000, jitterFactor=0.1, currentBackoffMS=1000, lastFailureTimestamp=0) for insert-into_analytics.analytics.conditions (a8681efc52437137d28ae75be94f64e1).
INFO  - pletedCheckpointStoreUtils - Recovering checkpoints from ZooKeeperStateHandleStore{namespace='flink/default/jobs/a8681efc52437137d28ae75be94f64e1/checkpoints'}.
INFO  - pletedCheckpointStoreUtils - Found 0 checkpoints in ZooKeeperStateHandleStore{namespace='flink/default/jobs/a8681efc52437137d28ae75be94f64e1/checkpoints'}.
INFO  - pletedCheckpointStoreUtils - Trying to fetch 0 checkpoints from storage.
INFO  - ZooKeeperUtils             - Initialized DefaultCompletedCheckpointStore in 'ZooKeeperStateHandleStore{namespace='flink/default/jobs/a8681efc52437137d28ae75be94f64e1/checkpoints'}' with /checkpoints.
INFO  - ExecutionGraph             - Created execution graph 2fd09ed160f7916f71927426d340e423 for job a8681efc52437137d28ae75be94f64e1.
INFO  - JobMaster                  - Running initialization on master for job insert-into_analytics.analytics.conditions (a8681efc52437137d28ae75be94f64e1).
INFO  - JobMaster                  - Successfully ran initialization on master in 0 ms.
INFO  - DefaultExecutionTopology   - Built 1 new pipelined regions in 0 ms, total 1 pipelined regions currently.
INFO  - JobMaster                  - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - JobMaster                  - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - JobMaster                  - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - CheckpointCoordinator      - No checkpoint found during restore.
INFO  - JobMaster                  - Using failover strategy org.apache.flink.runtime.executiongraph.failover.flip1.RestartPipelinedRegionFailoverStrategy@68b7bb75 for insert-into_analytics.analytics.conditions (a8681efc52437137d28ae75be94f64e1).
INFO  - aultLeaderRetrievalService - Starting DefaultLeaderRetrievalService with ZookeeperLeaderRetrievalDriver{connectionInformationPath='/resource_manager/connection_info'}.
INFO  - JobMaster                  - Starting execution of job 'insert-into_analytics.analytics.conditions' (a8681efc52437137d28ae75be94f64e1) under job master id b46c7fb86bd673d43a82a6cefb624610.
INFO  - SourceCoordinator          - Starting split enumerator for source Source: conditions[197].
INFO  - JobMaster                  - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
INFO  - ExecutionGraph             - Job insert-into_analytics.analytics.conditions (a8681efc52437137d28ae75be94f64e1) switched from state CREATED to RUNNING.
INFO  - AdminClientConfig          - AdminClientConfig values: 
	bootstrap.servers = [localhost:29092]
	client.dns.lookup = use_all_dns_ips
	client.id = flink-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

INFO  - ExecutionGraph             - Source: conditions[197] -> DropUpdateBefore[198] -> Calc[199] -> ConstraintEnforcer[200] -> Sink: conditions[200] (1/1) (2fd09ed160f7916f71927426d340e423_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to SCHEDULED.
INFO  - JobMaster                  - Connecting to ResourceManager akka://flink/user/rpc/resourcemanager_1(b46c7fb86bd673d43a82a6cefb624610)
WARN  - AdminClientConfig          - The configuration 'key.deserializer' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'value.deserializer' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'enable.auto.commit' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'client.id.prefix' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'group.id' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'auto.offset.reset' was supplied but isn't a known config.
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290635116
WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.admin.client:type=app-info,id=flink-enumerator-admin-client
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.admin.KafkaAdminClient.<init>(KafkaAdminClient.java:597)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:539)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:478)
	at org.apache.kafka.clients.admin.Admin.create(Admin.java:133)
	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getKafkaAdminClient(KafkaSourceEnumerator.java:410)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.start(KafkaSourceEnumerator.java:151)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$start$1(SourceCoordinator.java:234)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$runInEventLoop$10(SourceCoordinator.java:458)
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
INFO  - JobMaster                  - Resolved ResourceManager address, beginning registration
INFO  - KafkaSourceEnumerator      - Starting the KafkaSourceEnumerator for consumer group flink without periodic partition discovery.
INFO  - aultLeaderRetrievalService - Starting DefaultLeaderRetrievalService with ZookeeperLeaderRetrievalDriver{connectionInformationPath='/a8681efc52437137d28ae75be94f64e1/connection_info'}.
INFO  - StandaloneResourceManager  - Registering job manager b46c7fb86bd673d43a82a6cefb624610@akka://flink/user/rpc/jobmanager_12 for job a8681efc52437137d28ae75be94f64e1.
INFO  - KafkaSourceEnumerator      - Discovered new partitions: [openmrs.openmrs.conditions-0]
INFO  - StandaloneResourceManager  - Registered job manager b46c7fb86bd673d43a82a6cefb624610@akka://flink/user/rpc/jobmanager_12 for job a8681efc52437137d28ae75be94f64e1.
INFO  - JobMaster                  - JobManager successfully registered at ResourceManager, leader id: b46c7fb86bd673d43a82a6cefb624610.
INFO  - DeclarativeSlotManager     - Received resource requirements from job a8681efc52437137d28ae75be94f64e1: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
INFO  - aultLeaderRetrievalService - Stopping DefaultLeaderRetrievalService.
INFO  - eeperLeaderRetrievalDriver - Closing ZookeeperLeaderRetrievalDriver{connectionInformationPath='/leader/rest_server/connection_info'}.
INFO  - CuratorFrameworkImpl       - backgroundOperationsLoop exiting
INFO  - TaskExecutor               - Receive slot request f33665d3b332f40dbad250e2d9f00d6d for job a8681efc52437137d28ae75be94f64e1 from resource manager with leader id b46c7fb86bd673d43a82a6cefb624610.
INFO  - TaskExecutor               - Allocated slot for f33665d3b332f40dbad250e2d9f00d6d.
INFO  - DefaultJobLeaderService    - Add job a8681efc52437137d28ae75be94f64e1 for job leader monitoring.
INFO  - aultLeaderRetrievalService - Starting DefaultLeaderRetrievalService with ZookeeperLeaderRetrievalDriver{connectionInformationPath='/a8681efc52437137d28ae75be94f64e1/connection_info'}.
INFO  - DefaultJobLeaderService    - Try to register at job manager akka://flink/user/rpc/jobmanager_12 with leader id 3a82a6ce-fb62-4610-b46c-7fb86bd673d4.
INFO  - DefaultJobLeaderService    - Resolved JobManager address, beginning registration
INFO  - DefaultJobLeaderService    - Successful registration at job manager akka://flink/user/rpc/jobmanager_12 for job a8681efc52437137d28ae75be94f64e1.
INFO  - TaskExecutor               - Establish JobManager connection for job a8681efc52437137d28ae75be94f64e1.
INFO  - TaskExecutor               - Offer reserved slots to the leader of job a8681efc52437137d28ae75be94f64e1.
INFO  - ExecutionGraph             - Source: conditions[197] -> DropUpdateBefore[198] -> Calc[199] -> ConstraintEnforcer[200] -> Sink: conditions[200] (1/1) (2fd09ed160f7916f71927426d340e423_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - ExecutionGraph             - Deploying Source: conditions[197] -> DropUpdateBefore[198] -> Calc[199] -> ConstraintEnforcer[200] -> Sink: conditions[200] (1/1) (attempt #0) with attempt id 2fd09ed160f7916f71927426d340e423_cbc357ccb763df2852fee8c4fc7d55f2_0_0 and vertex id cbc357ccb763df2852fee8c4fc7d55f2_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id f33665d3b332f40dbad250e2d9f00d6d
INFO  - TaskSlotTableImpl          - Activate slot f33665d3b332f40dbad250e2d9f00d6d.
INFO  - TaskSlotTableImpl          - Activate slot f33665d3b332f40dbad250e2d9f00d6d.
INFO  - tateChangelogStorageLoader - Creating a changelog storage with name 'memory'.
INFO  - tateExecutorFactoryManager - Creating the channel state executor factory for job id a8681efc52437137d28ae75be94f64e1
INFO  - TaskExecutor               - Received task Source: conditions[197] -> DropUpdateBefore[198] -> Calc[199] -> ConstraintEnforcer[200] -> Sink: conditions[200] (1/1)#0 (2fd09ed160f7916f71927426d340e423_cbc357ccb763df2852fee8c4fc7d55f2_0_0), deploy into slot with allocation id f33665d3b332f40dbad250e2d9f00d6d.
INFO  - Task                       - Source: conditions[197] -> DropUpdateBefore[198] -> Calc[199] -> ConstraintEnforcer[200] -> Sink: conditions[200] (1/1)#0 (2fd09ed160f7916f71927426d340e423_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CREATED to DEPLOYING.
INFO  - Task                       - Loading JAR files for task Source: conditions[197] -> DropUpdateBefore[198] -> Calc[199] -> ConstraintEnforcer[200] -> Sink: conditions[200] (1/1)#0 (2fd09ed160f7916f71927426d340e423_cbc357ccb763df2852fee8c4fc7d55f2_0_0) [DEPLOYING].
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - Task                       - Source: conditions[197] -> DropUpdateBefore[198] -> Calc[199] -> ConstraintEnforcer[200] -> Sink: conditions[200] (1/1)#0 (2fd09ed160f7916f71927426d340e423_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - ExecutionGraph             - Source: conditions[197] -> DropUpdateBefore[198] -> Calc[199] -> ConstraintEnforcer[200] -> Sink: conditions[200] (1/1) (2fd09ed160f7916f71927426d340e423_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - Task                       - Source: conditions[197] -> DropUpdateBefore[198] -> Calc[199] -> ConstraintEnforcer[200] -> Sink: conditions[200] (1/1)#0 (2fd09ed160f7916f71927426d340e423_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
INFO  - SourceCoordinator          - Source Source: conditions[197] registering reader for parallel task 0 (#0) @ 
INFO  - KafkaSourceEnumerator      - Assigning splits to readers {0=[[Partition: openmrs.openmrs.conditions-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}
INFO  - ExecutionGraph             - Source: conditions[197] -> DropUpdateBefore[198] -> Calc[199] -> ConstraintEnforcer[200] -> Sink: conditions[200] (1/1) (2fd09ed160f7916f71927426d340e423_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from INITIALIZING to RUNNING.
INFO  - SourceReaderBase           - Adding split(s) to reader: [[Partition: openmrs.openmrs.conditions-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]
INFO  - ConsumerConfig             - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = flink-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

WARN  - ConsumerConfig             - The configuration 'client.id.prefix' was supplied but isn't a known config.
WARN  - ConsumerConfig             - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290635222
WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.consumer:type=app-info,id=flink-0
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:816)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:666)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:647)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:627)
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.<init>(KafkaPartitionSplitReader.java:88)
	at org.apache.flink.connector.kafka.source.KafkaSource.lambda$createReader$1(KafkaSource.java:160)
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager.createSplitFetcher(SplitFetcherManager.java:196)
	at org.apache.flink.connector.base.source.reader.fetcher.SingleThreadFetcherManager.addSplits(SingleThreadFetcherManager.java:107)
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.addSplits(SourceReaderBase.java:242)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleAddSplitsEvent(SourceOperator.java:584)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleOperatorEvent(SourceOperator.java:561)
	at org.apache.flink.streaming.runtime.tasks.OperatorEventDispatcherImpl.dispatchEventToHandlers(OperatorEventDispatcherImpl.java:72)
	at org.apache.flink.streaming.runtime.tasks.RegularOperatorChain.dispatchOperatorEvent(RegularOperatorChain.java:80)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$dispatchOperatorEvent$20(StreamTask.java:1473)
	at org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$1.runThrowing(StreamTaskActionExecutor.java:50)
	at org.apache.flink.streaming.runtime.tasks.mailbox.Mail.run(Mail.java:90)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMail(MailboxProcessor.java:398)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMailsWhenDefaultActionUnavailable(MailboxProcessor.java:367)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMail(MailboxProcessor.java:352)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:229)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:839)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:788)
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:952)
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:931)
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:745)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:562)
	at java.base/java.lang.Thread.run(Thread.java:829)
INFO  - SplitFetcher               - Starting split fetcher 0
INFO  - KafkaConsumer              - [Consumer clientId=flink-0, groupId=flink] Subscribed to partition(s): openmrs.openmrs.conditions-0
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Seeking to EARLIEST offset of partition openmrs.openmrs.conditions-0
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Resetting the last seen epoch of partition openmrs.openmrs.conditions-0 to 0 since the associated topicId changed from null to N1oKHHQnR9WTl7L6WwB6pA
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Cluster ID: 5Yr1SIgYQz-b-dgRabWx4g
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Resetting offset for partition openmrs.openmrs.conditions-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:29092 (id: 1 rack: null)], epoch=0}}.
INFO  - ZooKeeper                  - Session: 0x10009b90d4f000a closed
INFO  - ClientCnxn                 - EventThread shut down for session: 0x10009b90d4f000a
WARN  - Configuration              - Config uses deprecated configuration key 'high-availability' instead of proper key 'high-availability.type'
INFO  - ZooKeeperUtils             - Enforcing default ACL for ZK connections
INFO  - ZooKeeperUtils             - Using '/flink/default' as Zookeeper namespace.
INFO  - CuratorFrameworkImpl       - Starting
INFO  - ZooKeeper                  - Initiating client connection, connectString=localhost:2181 sessionTimeout=60000 watcher=org.apache.flink.shaded.curator5.org.apache.curator.ConnectionState@36450009
INFO  - ClientCnxnSocket           - jute.maxbuffer value is 1048575 Bytes
INFO  - ClientCnxn                 - zookeeper.request.timeout value is 0. feature enabled=false
INFO  - CuratorFrameworkImpl       - Default schema
INFO  - ClientCnxn                 - Opening socket connection to server localhost/127.0.0.1:2181.
INFO  - ClientCnxn                 - SASL config status: Will not attempt to authenticate using SASL (unknown error)
INFO  - aultLeaderRetrievalService - Starting DefaultLeaderRetrievalService with ZookeeperLeaderRetrievalDriver{connectionInformationPath='/leader/rest_server/connection_info'}.
INFO  - ClientCnxn                 - Socket connection established, initiating session, client: /127.0.0.1:52429, server: localhost/127.0.0.1:2181
INFO  - ClientCnxn                 - Session establishment complete on server localhost/127.0.0.1:2181, session id = 0x10009b90d4f000b, negotiated timeout = 40000
INFO  - ConnectionStateManager     - State change: CONNECTED
INFO  - EnsembleTracker            - New config event received: {}
INFO  - RestClusterClient          - Submitting job 'insert-into_analytics.analytics.patient_programs' (8f9053c77be2be6dcb80fb69df68baf8).
INFO  - EnsembleTracker            - New config event received: {}
INFO  - StandaloneDispatcher       - Received JobGraph submission 'insert-into_analytics.analytics.patient_programs' (8f9053c77be2be6dcb80fb69df68baf8).
INFO  - StandaloneDispatcher       - Submitting job 'insert-into_analytics.analytics.patient_programs' (8f9053c77be2be6dcb80fb69df68baf8).
INFO  - DefaultJobGraphStore       - Added JobGraph(jobId: 8f9053c77be2be6dcb80fb69df68baf8) to ZooKeeperStateHandleStore{namespace='flink/default/jobgraphs'}.
INFO  - faultLeaderElectionService - Starting DefaultLeaderElectionService with org.apache.flink.runtime.leaderelection.MultipleComponentLeaderElectionDriverAdapter@1df842b4.
INFO  - terServiceLeadershipRunner - JobMasterServiceLeadershipRunner for job 8f9053c77be2be6dcb80fb69df68baf8 was granted leadership with leader id 3a82a6ce-fb62-4610-b46c-7fb86bd673d4. Creating new JobMasterServiceProcess.
INFO  - AkkaRpcService             - Starting RPC endpoint for org.apache.flink.runtime.jobmaster.JobMaster at akka://flink/user/rpc/jobmanager_13 .
INFO  - JobMaster                  - Initializing job 'insert-into_analytics.analytics.patient_programs' (8f9053c77be2be6dcb80fb69df68baf8).
INFO  - RestClusterClient          - Successfully submitted job 'insert-into_analytics.analytics.patient_programs' (8f9053c77be2be6dcb80fb69df68baf8) to 'http://localhost:8081'.
INFO  - JobMaster                  - Using restart back off time strategy ExponentialDelayRestartBackoffTimeStrategy(initialBackoffMS=1000, maxBackoffMS=300000, backoffMultiplier=2.0, resetBackoffThresholdMS=3600000, jitterFactor=0.1, currentBackoffMS=1000, lastFailureTimestamp=0) for insert-into_analytics.analytics.patient_programs (8f9053c77be2be6dcb80fb69df68baf8).
INFO  - pletedCheckpointStoreUtils - Recovering checkpoints from ZooKeeperStateHandleStore{namespace='flink/default/jobs/8f9053c77be2be6dcb80fb69df68baf8/checkpoints'}.
INFO  - pletedCheckpointStoreUtils - Found 0 checkpoints in ZooKeeperStateHandleStore{namespace='flink/default/jobs/8f9053c77be2be6dcb80fb69df68baf8/checkpoints'}.
INFO  - pletedCheckpointStoreUtils - Trying to fetch 0 checkpoints from storage.
INFO  - ZooKeeperUtils             - Initialized DefaultCompletedCheckpointStore in 'ZooKeeperStateHandleStore{namespace='flink/default/jobs/8f9053c77be2be6dcb80fb69df68baf8/checkpoints'}' with /checkpoints.
INFO  - ExecutionGraph             - Created execution graph 2ff118f32116f826e0d468907bf12d2a for job 8f9053c77be2be6dcb80fb69df68baf8.
INFO  - JobMaster                  - Running initialization on master for job insert-into_analytics.analytics.patient_programs (8f9053c77be2be6dcb80fb69df68baf8).
INFO  - JobMaster                  - Successfully ran initialization on master in 0 ms.
INFO  - DefaultExecutionTopology   - Built 1 new pipelined regions in 0 ms, total 1 pipelined regions currently.
INFO  - JobMaster                  - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - JobMaster                  - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - JobMaster                  - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - CheckpointCoordinator      - No checkpoint found during restore.
INFO  - JobMaster                  - Using failover strategy org.apache.flink.runtime.executiongraph.failover.flip1.RestartPipelinedRegionFailoverStrategy@4fc5e126 for insert-into_analytics.analytics.patient_programs (8f9053c77be2be6dcb80fb69df68baf8).
INFO  - aultLeaderRetrievalService - Starting DefaultLeaderRetrievalService with ZookeeperLeaderRetrievalDriver{connectionInformationPath='/resource_manager/connection_info'}.
INFO  - JobMaster                  - Starting execution of job 'insert-into_analytics.analytics.patient_programs' (8f9053c77be2be6dcb80fb69df68baf8) under job master id b46c7fb86bd673d43a82a6cefb624610.
INFO  - SourceCoordinator          - Starting split enumerator for source Source: patient_program[201].
INFO  - SourceCoordinator          - Starting split enumerator for source Source: program[203].
INFO  - SourceCoordinator          - Starting split enumerator for source Source: concept_name[209].
INFO  - AdminClientConfig          - AdminClientConfig values: 
	bootstrap.servers = [localhost:29092]
	client.dns.lookup = use_all_dns_ips
	client.id = flink-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

INFO  - JobMaster                  - Starting scheduling with scheduling strategy [org.apache.flink.runtime.scheduler.strategy.PipelinedRegionSchedulingStrategy]
INFO  - ExecutionGraph             - Job insert-into_analytics.analytics.patient_programs (8f9053c77be2be6dcb80fb69df68baf8) switched from state CREATED to RUNNING.
INFO  - AdminClientConfig          - AdminClientConfig values: 
	bootstrap.servers = [localhost:29092]
	client.dns.lookup = use_all_dns_ips
	client.id = flink-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

INFO  - AdminClientConfig          - AdminClientConfig values: 
	bootstrap.servers = [localhost:29092]
	client.dns.lookup = use_all_dns_ips
	client.id = flink-enumerator-admin-client
	connections.max.idle.ms = 300000
	default.api.timeout.ms = 60000
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retries = 2147483647
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS

INFO  - ExecutionGraph             - Source: patient_program[201] (1/1) (2ff118f32116f826e0d468907bf12d2a_bc764cd8ddf7a0cff126f51c16239658_0_0) switched from CREATED to SCHEDULED.
INFO  - ExecutionGraph             - Source: program[203] -> Calc[204] (1/1) (2ff118f32116f826e0d468907bf12d2a_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) switched from CREATED to SCHEDULED.
INFO  - ExecutionGraph             - Source: concept_name[209] -> Calc[210] (1/1) (2ff118f32116f826e0d468907bf12d2a_2963852293169ba90d9d1e7d6308db5c_0_0) switched from CREATED to SCHEDULED.
INFO  - ExecutionGraph             - Join[206] -> Calc[207] (1/1) (2ff118f32116f826e0d468907bf12d2a_5b6b7f98d5bff23034589a7675c38ac7_0_0) switched from CREATED to SCHEDULED.
INFO  - ExecutionGraph             - Join[212] -> Calc[213] (1/1) (2ff118f32116f826e0d468907bf12d2a_d7e78c81a38d2cce4433a75795131bcf_0_0) switched from CREATED to SCHEDULED.
INFO  - ExecutionGraph             - Join[215] -> Calc[216] -> ConstraintEnforcer[217] (1/1) (2ff118f32116f826e0d468907bf12d2a_27b913f6385bb0e404cc1ac792473af7_0_0) switched from CREATED to SCHEDULED.
INFO  - ExecutionGraph             - SinkMaterializer[217] -> Sink: patient_programs[217] (1/1) (2ff118f32116f826e0d468907bf12d2a_8fc3be823cc75a93eb3f11ae7a596b08_0_0) switched from CREATED to SCHEDULED.
WARN  - AdminClientConfig          - The configuration 'key.deserializer' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'value.deserializer' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'enable.auto.commit' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'client.id.prefix' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'group.id' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'auto.offset.reset' was supplied but isn't a known config.
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290635698
WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.admin.client:type=app-info,id=flink-enumerator-admin-client
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.admin.KafkaAdminClient.<init>(KafkaAdminClient.java:597)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:539)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:478)
	at org.apache.kafka.clients.admin.Admin.create(Admin.java:133)
	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getKafkaAdminClient(KafkaSourceEnumerator.java:410)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.start(KafkaSourceEnumerator.java:151)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$start$1(SourceCoordinator.java:234)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$runInEventLoop$10(SourceCoordinator.java:458)
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
INFO  - JobMaster                  - Connecting to ResourceManager akka://flink/user/rpc/resourcemanager_1(b46c7fb86bd673d43a82a6cefb624610)
WARN  - AdminClientConfig          - The configuration 'key.deserializer' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'value.deserializer' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'enable.auto.commit' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'client.id.prefix' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'group.id' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'auto.offset.reset' was supplied but isn't a known config.
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290635699
WARN  - AdminClientConfig          - The configuration 'key.deserializer' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'value.deserializer' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'enable.auto.commit' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'client.id.prefix' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'group.id' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
WARN  - AdminClientConfig          - The configuration 'auto.offset.reset' was supplied but isn't a known config.
WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.admin.client:type=app-info,id=flink-enumerator-admin-client
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.admin.KafkaAdminClient.<init>(KafkaAdminClient.java:597)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:539)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:478)
	at org.apache.kafka.clients.admin.Admin.create(Admin.java:133)
	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getKafkaAdminClient(KafkaSourceEnumerator.java:410)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.start(KafkaSourceEnumerator.java:151)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$start$1(SourceCoordinator.java:234)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$runInEventLoop$10(SourceCoordinator.java:458)
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
INFO  - KafkaSourceEnumerator      - Starting the KafkaSourceEnumerator for consumer group flink without periodic partition discovery.
INFO  - JobMaster                  - Resolved ResourceManager address, beginning registration
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290635699
WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.admin.client:type=app-info,id=flink-enumerator-admin-client
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.admin.KafkaAdminClient.<init>(KafkaAdminClient.java:597)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:539)
	at org.apache.kafka.clients.admin.KafkaAdminClient.createInternal(KafkaAdminClient.java:478)
	at org.apache.kafka.clients.admin.Admin.create(Admin.java:133)
	at org.apache.kafka.clients.admin.AdminClient.create(AdminClient.java:39)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.getKafkaAdminClient(KafkaSourceEnumerator.java:410)
	at org.apache.flink.connector.kafka.source.enumerator.KafkaSourceEnumerator.start(KafkaSourceEnumerator.java:151)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$start$1(SourceCoordinator.java:234)
	at org.apache.flink.runtime.source.coordinator.SourceCoordinator.lambda$runInEventLoop$10(SourceCoordinator.java:458)
	at org.apache.flink.util.ThrowableCatchingRunnable.run(ThrowableCatchingRunnable.java:40)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:304)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:829)
INFO  - aultLeaderRetrievalService - Starting DefaultLeaderRetrievalService with ZookeeperLeaderRetrievalDriver{connectionInformationPath='/8f9053c77be2be6dcb80fb69df68baf8/connection_info'}.
INFO  - StandaloneResourceManager  - Registering job manager b46c7fb86bd673d43a82a6cefb624610@akka://flink/user/rpc/jobmanager_13 for job 8f9053c77be2be6dcb80fb69df68baf8.
INFO  - KafkaSourceEnumerator      - Starting the KafkaSourceEnumerator for consumer group flink without periodic partition discovery.
INFO  - KafkaSourceEnumerator      - Starting the KafkaSourceEnumerator for consumer group flink without periodic partition discovery.
INFO  - KafkaSourceEnumerator      - Discovered new partitions: [openmrs.openmrs.patient_program-0]
INFO  - KafkaSourceEnumerator      - Discovered new partitions: [openmrs.openmrs.concept_name-0]
INFO  - KafkaSourceEnumerator      - Discovered new partitions: [openmrs.openmrs.program-0]
INFO  - StandaloneResourceManager  - Registered job manager b46c7fb86bd673d43a82a6cefb624610@akka://flink/user/rpc/jobmanager_13 for job 8f9053c77be2be6dcb80fb69df68baf8.
INFO  - aultLeaderRetrievalService - Stopping DefaultLeaderRetrievalService.
INFO  - eeperLeaderRetrievalDriver - Closing ZookeeperLeaderRetrievalDriver{connectionInformationPath='/leader/rest_server/connection_info'}.
INFO  - CuratorFrameworkImpl       - backgroundOperationsLoop exiting
INFO  - JobMaster                  - JobManager successfully registered at ResourceManager, leader id: b46c7fb86bd673d43a82a6cefb624610.
INFO  - DeclarativeSlotManager     - Received resource requirements from job 8f9053c77be2be6dcb80fb69df68baf8: [ResourceRequirement{resourceProfile=ResourceProfile{UNKNOWN}, numberOfRequiredSlots=1}]
INFO  - TaskExecutor               - Receive slot request 3fac7a41dd87f01504a131da610f53d4 for job 8f9053c77be2be6dcb80fb69df68baf8 from resource manager with leader id b46c7fb86bd673d43a82a6cefb624610.
INFO  - TaskExecutor               - Allocated slot for 3fac7a41dd87f01504a131da610f53d4.
INFO  - DefaultJobLeaderService    - Add job 8f9053c77be2be6dcb80fb69df68baf8 for job leader monitoring.
INFO  - aultLeaderRetrievalService - Starting DefaultLeaderRetrievalService with ZookeeperLeaderRetrievalDriver{connectionInformationPath='/8f9053c77be2be6dcb80fb69df68baf8/connection_info'}.
INFO  - DefaultJobLeaderService    - Try to register at job manager akka://flink/user/rpc/jobmanager_13 with leader id 3a82a6ce-fb62-4610-b46c-7fb86bd673d4.
INFO  - DefaultJobLeaderService    - Resolved JobManager address, beginning registration
INFO  - DefaultJobLeaderService    - Successful registration at job manager akka://flink/user/rpc/jobmanager_13 for job 8f9053c77be2be6dcb80fb69df68baf8.
INFO  - TaskExecutor               - Establish JobManager connection for job 8f9053c77be2be6dcb80fb69df68baf8.
INFO  - TaskExecutor               - Offer reserved slots to the leader of job 8f9053c77be2be6dcb80fb69df68baf8.
INFO  - ExecutionGraph             - Source: patient_program[201] (1/1) (2ff118f32116f826e0d468907bf12d2a_bc764cd8ddf7a0cff126f51c16239658_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - ExecutionGraph             - Deploying Source: patient_program[201] (1/1) (attempt #0) with attempt id 2ff118f32116f826e0d468907bf12d2a_bc764cd8ddf7a0cff126f51c16239658_0_0 and vertex id bc764cd8ddf7a0cff126f51c16239658_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id 3fac7a41dd87f01504a131da610f53d4
INFO  - ExecutionGraph             - Source: program[203] -> Calc[204] (1/1) (2ff118f32116f826e0d468907bf12d2a_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - ExecutionGraph             - Deploying Source: program[203] -> Calc[204] (1/1) (attempt #0) with attempt id 2ff118f32116f826e0d468907bf12d2a_6cdc5bb954874d922eaee11a8e7b5dd5_0_0 and vertex id 6cdc5bb954874d922eaee11a8e7b5dd5_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id 3fac7a41dd87f01504a131da610f53d4
INFO  - ExecutionGraph             - Source: concept_name[209] -> Calc[210] (1/1) (2ff118f32116f826e0d468907bf12d2a_2963852293169ba90d9d1e7d6308db5c_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - ExecutionGraph             - Deploying Source: concept_name[209] -> Calc[210] (1/1) (attempt #0) with attempt id 2ff118f32116f826e0d468907bf12d2a_2963852293169ba90d9d1e7d6308db5c_0_0 and vertex id 2963852293169ba90d9d1e7d6308db5c_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id 3fac7a41dd87f01504a131da610f53d4
INFO  - TaskSlotTableImpl          - Activate slot 3fac7a41dd87f01504a131da610f53d4.
INFO  - ExecutionGraph             - Join[206] -> Calc[207] (1/1) (2ff118f32116f826e0d468907bf12d2a_5b6b7f98d5bff23034589a7675c38ac7_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - ExecutionGraph             - Deploying Join[206] -> Calc[207] (1/1) (attempt #0) with attempt id 2ff118f32116f826e0d468907bf12d2a_5b6b7f98d5bff23034589a7675c38ac7_0_0 and vertex id 5b6b7f98d5bff23034589a7675c38ac7_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id 3fac7a41dd87f01504a131da610f53d4
INFO  - tateChangelogStorageLoader - Creating a changelog storage with name 'memory'.
INFO  - tateExecutorFactoryManager - Creating the channel state executor factory for job id 8f9053c77be2be6dcb80fb69df68baf8
INFO  - ExecutionGraph             - Join[212] -> Calc[213] (1/1) (2ff118f32116f826e0d468907bf12d2a_d7e78c81a38d2cce4433a75795131bcf_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - ExecutionGraph             - Deploying Join[212] -> Calc[213] (1/1) (attempt #0) with attempt id 2ff118f32116f826e0d468907bf12d2a_d7e78c81a38d2cce4433a75795131bcf_0_0 and vertex id d7e78c81a38d2cce4433a75795131bcf_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id 3fac7a41dd87f01504a131da610f53d4
INFO  - TaskExecutor               - Received task Source: patient_program[201] (1/1)#0 (2ff118f32116f826e0d468907bf12d2a_bc764cd8ddf7a0cff126f51c16239658_0_0), deploy into slot with allocation id 3fac7a41dd87f01504a131da610f53d4.
INFO  - ExecutionGraph             - Join[215] -> Calc[216] -> ConstraintEnforcer[217] (1/1) (2ff118f32116f826e0d468907bf12d2a_27b913f6385bb0e404cc1ac792473af7_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - ExecutionGraph             - Deploying Join[215] -> Calc[216] -> ConstraintEnforcer[217] (1/1) (attempt #0) with attempt id 2ff118f32116f826e0d468907bf12d2a_27b913f6385bb0e404cc1ac792473af7_0_0 and vertex id 27b913f6385bb0e404cc1ac792473af7_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id 3fac7a41dd87f01504a131da610f53d4
INFO  - Task                       - Source: patient_program[201] (1/1)#0 (2ff118f32116f826e0d468907bf12d2a_bc764cd8ddf7a0cff126f51c16239658_0_0) switched from CREATED to DEPLOYING.
INFO  - TaskSlotTableImpl          - Activate slot 3fac7a41dd87f01504a131da610f53d4.
INFO  - Task                       - Loading JAR files for task Source: patient_program[201] (1/1)#0 (2ff118f32116f826e0d468907bf12d2a_bc764cd8ddf7a0cff126f51c16239658_0_0) [DEPLOYING].
INFO  - ExecutionGraph             - SinkMaterializer[217] -> Sink: patient_programs[217] (1/1) (2ff118f32116f826e0d468907bf12d2a_8fc3be823cc75a93eb3f11ae7a596b08_0_0) switched from SCHEDULED to DEPLOYING.
INFO  - TaskExecutor               - Received task Source: program[203] -> Calc[204] (1/1)#0 (2ff118f32116f826e0d468907bf12d2a_6cdc5bb954874d922eaee11a8e7b5dd5_0_0), deploy into slot with allocation id 3fac7a41dd87f01504a131da610f53d4.
INFO  - ExecutionGraph             - Deploying SinkMaterializer[217] -> Sink: patient_programs[217] (1/1) (attempt #0) with attempt id 2ff118f32116f826e0d468907bf12d2a_8fc3be823cc75a93eb3f11ae7a596b08_0_0 and vertex id 8fc3be823cc75a93eb3f11ae7a596b08_0 to 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1) with allocation id 3fac7a41dd87f01504a131da610f53d4
INFO  - Task                       - Source: program[203] -> Calc[204] (1/1)#0 (2ff118f32116f826e0d468907bf12d2a_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) switched from CREATED to DEPLOYING.
INFO  - Task                       - Loading JAR files for task Source: program[203] -> Calc[204] (1/1)#0 (2ff118f32116f826e0d468907bf12d2a_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) [DEPLOYING].
INFO  - TaskSlotTableImpl          - Activate slot 3fac7a41dd87f01504a131da610f53d4.
INFO  - TaskExecutor               - Received task Source: concept_name[209] -> Calc[210] (1/1)#0 (2ff118f32116f826e0d468907bf12d2a_2963852293169ba90d9d1e7d6308db5c_0_0), deploy into slot with allocation id 3fac7a41dd87f01504a131da610f53d4.
INFO  - TaskSlotTableImpl          - Activate slot 3fac7a41dd87f01504a131da610f53d4.
INFO  - Task                       - Source: concept_name[209] -> Calc[210] (1/1)#0 (2ff118f32116f826e0d468907bf12d2a_2963852293169ba90d9d1e7d6308db5c_0_0) switched from CREATED to DEPLOYING.
INFO  - Task                       - Loading JAR files for task Source: concept_name[209] -> Calc[210] (1/1)#0 (2ff118f32116f826e0d468907bf12d2a_2963852293169ba90d9d1e7d6308db5c_0_0) [DEPLOYING].
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - TaskExecutor               - Received task Join[206] -> Calc[207] (1/1)#0 (2ff118f32116f826e0d468907bf12d2a_5b6b7f98d5bff23034589a7675c38ac7_0_0), deploy into slot with allocation id 3fac7a41dd87f01504a131da610f53d4.
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - TaskSlotTableImpl          - Activate slot 3fac7a41dd87f01504a131da610f53d4.
INFO  - Task                       - Join[206] -> Calc[207] (1/1)#0 (2ff118f32116f826e0d468907bf12d2a_5b6b7f98d5bff23034589a7675c38ac7_0_0) switched from CREATED to DEPLOYING.
INFO  - Task                       - Loading JAR files for task Join[206] -> Calc[207] (1/1)#0 (2ff118f32116f826e0d468907bf12d2a_5b6b7f98d5bff23034589a7675c38ac7_0_0) [DEPLOYING].
INFO  - Task                       - Source: program[203] -> Calc[204] (1/1)#0 (2ff118f32116f826e0d468907bf12d2a_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - Task                       - Source: concept_name[209] -> Calc[210] (1/1)#0 (2ff118f32116f826e0d468907bf12d2a_2963852293169ba90d9d1e7d6308db5c_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - ExecutionGraph             - Source: program[203] -> Calc[204] (1/1) (2ff118f32116f826e0d468907bf12d2a_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - Task                       - Source: patient_program[201] (1/1)#0 (2ff118f32116f826e0d468907bf12d2a_bc764cd8ddf7a0cff126f51c16239658_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - ExecutionGraph             - Source: concept_name[209] -> Calc[210] (1/1) (2ff118f32116f826e0d468907bf12d2a_2963852293169ba90d9d1e7d6308db5c_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - ExecutionGraph             - Source: patient_program[201] (1/1) (2ff118f32116f826e0d468907bf12d2a_bc764cd8ddf7a0cff126f51c16239658_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - TaskExecutor               - Received task Join[212] -> Calc[213] (1/1)#0 (2ff118f32116f826e0d468907bf12d2a_d7e78c81a38d2cce4433a75795131bcf_0_0), deploy into slot with allocation id 3fac7a41dd87f01504a131da610f53d4.
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - Task                       - Join[206] -> Calc[207] (1/1)#0 (2ff118f32116f826e0d468907bf12d2a_5b6b7f98d5bff23034589a7675c38ac7_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - ExecutionGraph             - Join[206] -> Calc[207] (1/1) (2ff118f32116f826e0d468907bf12d2a_5b6b7f98d5bff23034589a7675c38ac7_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - TaskSlotTableImpl          - Activate slot 3fac7a41dd87f01504a131da610f53d4.
INFO  - Task                       - Join[212] -> Calc[213] (1/1)#0 (2ff118f32116f826e0d468907bf12d2a_d7e78c81a38d2cce4433a75795131bcf_0_0) switched from CREATED to DEPLOYING.
INFO  - Task                       - Loading JAR files for task Join[212] -> Calc[213] (1/1)#0 (2ff118f32116f826e0d468907bf12d2a_d7e78c81a38d2cce4433a75795131bcf_0_0) [DEPLOYING].
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - TaskExecutor               - Received task Join[215] -> Calc[216] -> ConstraintEnforcer[217] (1/1)#0 (2ff118f32116f826e0d468907bf12d2a_27b913f6385bb0e404cc1ac792473af7_0_0), deploy into slot with allocation id 3fac7a41dd87f01504a131da610f53d4.
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - Task                       - Source: patient_program[201] (1/1)#0 (2ff118f32116f826e0d468907bf12d2a_bc764cd8ddf7a0cff126f51c16239658_0_0) switched from INITIALIZING to RUNNING.
INFO  - Task                       - Join[215] -> Calc[216] -> ConstraintEnforcer[217] (1/1)#0 (2ff118f32116f826e0d468907bf12d2a_27b913f6385bb0e404cc1ac792473af7_0_0) switched from CREATED to DEPLOYING.
INFO  - Task                       - Loading JAR files for task Join[215] -> Calc[216] -> ConstraintEnforcer[217] (1/1)#0 (2ff118f32116f826e0d468907bf12d2a_27b913f6385bb0e404cc1ac792473af7_0_0) [DEPLOYING].
INFO  - ExecutionGraph             - Source: patient_program[201] (1/1) (2ff118f32116f826e0d468907bf12d2a_bc764cd8ddf7a0cff126f51c16239658_0_0) switched from INITIALIZING to RUNNING.
INFO  - SourceCoordinator          - Source Source: patient_program[201] registering reader for parallel task 0 (#0) @ 
INFO  - KafkaSourceEnumerator      - Assigning splits to readers {0=[[Partition: openmrs.openmrs.patient_program-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}
INFO  - TaskSlotTableImpl          - Activate slot 3fac7a41dd87f01504a131da610f53d4.
INFO  - TaskSlotTableImpl          - Activate slot 3fac7a41dd87f01504a131da610f53d4.
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - Task                       - Join[215] -> Calc[216] -> ConstraintEnforcer[217] (1/1)#0 (2ff118f32116f826e0d468907bf12d2a_27b913f6385bb0e404cc1ac792473af7_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - TaskExecutor               - Received task SinkMaterializer[217] -> Sink: patient_programs[217] (1/1)#0 (2ff118f32116f826e0d468907bf12d2a_8fc3be823cc75a93eb3f11ae7a596b08_0_0), deploy into slot with allocation id 3fac7a41dd87f01504a131da610f53d4.
INFO  - ExecutionGraph             - Join[215] -> Calc[216] -> ConstraintEnforcer[217] (1/1) (2ff118f32116f826e0d468907bf12d2a_27b913f6385bb0e404cc1ac792473af7_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - SourceReaderBase           - Adding split(s) to reader: [[Partition: openmrs.openmrs.patient_program-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]
INFO  - Task                       - SinkMaterializer[217] -> Sink: patient_programs[217] (1/1)#0 (2ff118f32116f826e0d468907bf12d2a_8fc3be823cc75a93eb3f11ae7a596b08_0_0) switched from CREATED to DEPLOYING.
INFO  - Task                       - Loading JAR files for task SinkMaterializer[217] -> Sink: patient_programs[217] (1/1)#0 (2ff118f32116f826e0d468907bf12d2a_8fc3be823cc75a93eb3f11ae7a596b08_0_0) [DEPLOYING].
INFO  - ConsumerConfig             - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = flink-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

INFO  - Task                       - Join[212] -> Calc[213] (1/1)#0 (2ff118f32116f826e0d468907bf12d2a_d7e78c81a38d2cce4433a75795131bcf_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - StreamTask                 - Using job/cluster config to configure application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - mbeddedRocksDBStateBackend - Using predefined options: DEFAULT.
INFO  - StreamTask                 - Using application-defined state backend: EmbeddedRocksDBStateBackend{, localRocksDbDirectories=null, enableIncrementalCheckpointing=TRUE, numberOfTransferThreads=4, writeBatchSize=2097152}
INFO  - StateBackendLoader         - State backend loader loads the state backend as EmbeddedRocksDBStateBackend
INFO  - StreamTask                 - Using job/cluster config to configure application-defined checkpoint storage: org.apache.flink.runtime.state.storage.FileSystemCheckpointStorage@60693ea7
INFO  - Task                       - SinkMaterializer[217] -> Sink: patient_programs[217] (1/1)#0 (2ff118f32116f826e0d468907bf12d2a_8fc3be823cc75a93eb3f11ae7a596b08_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - ExecutionGraph             - Join[212] -> Calc[213] (1/1) (2ff118f32116f826e0d468907bf12d2a_d7e78c81a38d2cce4433a75795131bcf_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - ExecutionGraph             - SinkMaterializer[217] -> Sink: patient_programs[217] (1/1) (2ff118f32116f826e0d468907bf12d2a_8fc3be823cc75a93eb3f11ae7a596b08_0_0) switched from DEPLOYING to INITIALIZING.
INFO  - SourceCoordinator          - Source Source: program[203] registering reader for parallel task 0 (#0) @ 
INFO  - KafkaSourceEnumerator      - Assigning splits to readers {0=[[Partition: openmrs.openmrs.program-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}
WARN  - ConsumerConfig             - The configuration 'client.id.prefix' was supplied but isn't a known config.
WARN  - ConsumerConfig             - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290635807
WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.consumer:type=app-info,id=flink-0
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:816)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:666)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:647)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:627)
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.<init>(KafkaPartitionSplitReader.java:88)
	at org.apache.flink.connector.kafka.source.KafkaSource.lambda$createReader$1(KafkaSource.java:160)
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager.createSplitFetcher(SplitFetcherManager.java:196)
	at org.apache.flink.connector.base.source.reader.fetcher.SingleThreadFetcherManager.addSplits(SingleThreadFetcherManager.java:107)
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.addSplits(SourceReaderBase.java:242)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleAddSplitsEvent(SourceOperator.java:584)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleOperatorEvent(SourceOperator.java:561)
	at org.apache.flink.streaming.runtime.tasks.OperatorEventDispatcherImpl.dispatchEventToHandlers(OperatorEventDispatcherImpl.java:72)
	at org.apache.flink.streaming.runtime.tasks.RegularOperatorChain.dispatchOperatorEvent(RegularOperatorChain.java:80)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$dispatchOperatorEvent$20(StreamTask.java:1473)
	at org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$1.runThrowing(StreamTaskActionExecutor.java:50)
	at org.apache.flink.streaming.runtime.tasks.mailbox.Mail.run(Mail.java:90)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMail(MailboxProcessor.java:398)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMailsWhenDefaultActionUnavailable(MailboxProcessor.java:367)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMail(MailboxProcessor.java:352)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:229)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:839)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:788)
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:952)
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:931)
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:745)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:562)
	at java.base/java.lang.Thread.run(Thread.java:829)
INFO  - SourceCoordinator          - Source Source: concept_name[209] registering reader for parallel task 0 (#0) @ 
INFO  - KafkaSourceEnumerator      - Assigning splits to readers {0=[[Partition: openmrs.openmrs.concept_name-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]}
INFO  - Task                       - Source: program[203] -> Calc[204] (1/1)#0 (2ff118f32116f826e0d468907bf12d2a_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) switched from INITIALIZING to RUNNING.
INFO  - SourceReaderBase           - Adding split(s) to reader: [[Partition: openmrs.openmrs.program-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]
INFO  - ExecutionGraph             - Source: program[203] -> Calc[204] (1/1) (2ff118f32116f826e0d468907bf12d2a_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) switched from INITIALIZING to RUNNING.
INFO  - ConsumerConfig             - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = flink-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

INFO  - SplitFetcher               - Starting split fetcher 0
WARN  - ConsumerConfig             - The configuration 'client.id.prefix' was supplied but isn't a known config.
WARN  - ConsumerConfig             - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290635814
WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.consumer:type=app-info,id=flink-0
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:816)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:666)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:647)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:627)
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.<init>(KafkaPartitionSplitReader.java:88)
	at org.apache.flink.connector.kafka.source.KafkaSource.lambda$createReader$1(KafkaSource.java:160)
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager.createSplitFetcher(SplitFetcherManager.java:196)
	at org.apache.flink.connector.base.source.reader.fetcher.SingleThreadFetcherManager.addSplits(SingleThreadFetcherManager.java:107)
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.addSplits(SourceReaderBase.java:242)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleAddSplitsEvent(SourceOperator.java:584)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleOperatorEvent(SourceOperator.java:561)
	at org.apache.flink.streaming.runtime.tasks.OperatorEventDispatcherImpl.dispatchEventToHandlers(OperatorEventDispatcherImpl.java:72)
	at org.apache.flink.streaming.runtime.tasks.RegularOperatorChain.dispatchOperatorEvent(RegularOperatorChain.java:80)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$dispatchOperatorEvent$20(StreamTask.java:1473)
	at org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$1.runThrowing(StreamTaskActionExecutor.java:50)
	at org.apache.flink.streaming.runtime.tasks.mailbox.Mail.run(Mail.java:90)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMail(MailboxProcessor.java:398)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMailsNonBlocking(MailboxProcessor.java:383)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMail(MailboxProcessor.java:345)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:229)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:839)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:788)
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:952)
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:931)
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:745)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:562)
	at java.base/java.lang.Thread.run(Thread.java:829)
INFO  - KafkaConsumer              - [Consumer clientId=flink-0, groupId=flink] Subscribed to partition(s): openmrs.openmrs.patient_program-0
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Seeking to EARLIEST offset of partition openmrs.openmrs.patient_program-0
INFO  - mbeddedRocksDBStateBackend - Getting shared memory for RocksDB: shareScope=SLOT, managed=false
INFO  - mbeddedRocksDBStateBackend - Obtained shared RocksDB cache of size 6710886 bytes
INFO  - Task                       - Source: concept_name[209] -> Calc[210] (1/1)#0 (2ff118f32116f826e0d468907bf12d2a_2963852293169ba90d9d1e7d6308db5c_0_0) switched from INITIALIZING to RUNNING.
INFO  - SourceReaderBase           - Adding split(s) to reader: [[Partition: openmrs.openmrs.concept_name-0, StartingOffset: -2, StoppingOffset: -9223372036854775808]]
INFO  - ExecutionGraph             - Source: concept_name[209] -> Calc[210] (1/1) (2ff118f32116f826e0d468907bf12d2a_2963852293169ba90d9d1e7d6308db5c_0_0) switched from INITIALIZING to RUNNING.
INFO  - ConsumerConfig             - ConsumerConfig values: 
	allow.auto.create.topics = true
	auto.commit.interval.ms = 5000
	auto.offset.reset = earliest
	bootstrap.servers = [localhost:29092]
	check.crcs = true
	client.dns.lookup = use_all_dns_ips
	client.id = flink-0
	client.rack = 
	connections.max.idle.ms = 540000
	default.api.timeout.ms = 60000
	enable.auto.commit = false
	exclude.internal.topics = true
	fetch.max.bytes = 52428800
	fetch.max.wait.ms = 500
	fetch.min.bytes = 1
	group.id = flink
	group.instance.id = null
	heartbeat.interval.ms = 3000
	interceptor.classes = []
	internal.leave.group.on.close = true
	internal.throw.on.fetch.stable.offset.unsupported = false
	isolation.level = read_uncommitted
	key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
	max.partition.fetch.bytes = 1048576
	max.poll.interval.ms = 300000
	max.poll.records = 500
	metadata.max.age.ms = 300000
	metric.reporters = []
	metrics.num.samples = 2
	metrics.recording.level = INFO
	metrics.sample.window.ms = 30000
	partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor, class org.apache.kafka.clients.consumer.CooperativeStickyAssignor]
	receive.buffer.bytes = 65536
	reconnect.backoff.max.ms = 1000
	reconnect.backoff.ms = 50
	request.timeout.ms = 30000
	retry.backoff.ms = 100
	sasl.client.callback.handler.class = null
	sasl.jaas.config = null
	sasl.kerberos.kinit.cmd = /usr/bin/kinit
	sasl.kerberos.min.time.before.relogin = 60000
	sasl.kerberos.service.name = null
	sasl.kerberos.ticket.renew.jitter = 0.05
	sasl.kerberos.ticket.renew.window.factor = 0.8
	sasl.login.callback.handler.class = null
	sasl.login.class = null
	sasl.login.connect.timeout.ms = null
	sasl.login.read.timeout.ms = null
	sasl.login.refresh.buffer.seconds = 300
	sasl.login.refresh.min.period.seconds = 60
	sasl.login.refresh.window.factor = 0.8
	sasl.login.refresh.window.jitter = 0.05
	sasl.login.retry.backoff.max.ms = 10000
	sasl.login.retry.backoff.ms = 100
	sasl.mechanism = GSSAPI
	sasl.oauthbearer.clock.skew.seconds = 30
	sasl.oauthbearer.expected.audience = null
	sasl.oauthbearer.expected.issuer = null
	sasl.oauthbearer.jwks.endpoint.refresh.ms = 3600000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.max.ms = 10000
	sasl.oauthbearer.jwks.endpoint.retry.backoff.ms = 100
	sasl.oauthbearer.jwks.endpoint.url = null
	sasl.oauthbearer.scope.claim.name = scope
	sasl.oauthbearer.sub.claim.name = sub
	sasl.oauthbearer.token.endpoint.url = null
	security.protocol = PLAINTEXT
	security.providers = null
	send.buffer.bytes = 131072
	session.timeout.ms = 45000
	socket.connection.setup.timeout.max.ms = 30000
	socket.connection.setup.timeout.ms = 10000
	ssl.cipher.suites = null
	ssl.enabled.protocols = [TLSv1.2, TLSv1.3]
	ssl.endpoint.identification.algorithm = https
	ssl.engine.factory.class = null
	ssl.key.password = null
	ssl.keymanager.algorithm = SunX509
	ssl.keystore.certificate.chain = null
	ssl.keystore.key = null
	ssl.keystore.location = null
	ssl.keystore.password = null
	ssl.keystore.type = JKS
	ssl.protocol = TLSv1.3
	ssl.provider = null
	ssl.secure.random.implementation = null
	ssl.trustmanager.algorithm = PKIX
	ssl.truststore.certificates = null
	ssl.truststore.location = null
	ssl.truststore.password = null
	ssl.truststore.type = JKS
	value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer

WARN  - ConsumerConfig             - The configuration 'client.id.prefix' was supplied but isn't a known config.
WARN  - ConsumerConfig             - The configuration 'partition.discovery.interval.ms' was supplied but isn't a known config.
INFO  - AppInfoParser              - Kafka version: 3.2.3
INFO  - AppInfoParser              - Kafka commitId: 50029d3ed8ba576f
INFO  - AppInfoParser              - Kafka startTimeMs: 1699290635819
WARN  - AppInfoParser              - Error registering AppInfo mbean
javax.management.InstanceAlreadyExistsException: kafka.consumer:type=app-info,id=flink-0
	at java.management/com.sun.jmx.mbeanserver.Repository.addMBean(Repository.java:436)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerWithRepository(DefaultMBeanServerInterceptor.java:1855)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerDynamicMBean(DefaultMBeanServerInterceptor.java:955)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerObject(DefaultMBeanServerInterceptor.java:890)
	at java.management/com.sun.jmx.interceptor.DefaultMBeanServerInterceptor.registerMBean(DefaultMBeanServerInterceptor.java:320)
	at java.management/com.sun.jmx.mbeanserver.JmxMBeanServer.registerMBean(JmxMBeanServer.java:522)
	at org.apache.kafka.common.utils.AppInfoParser.registerAppInfo(AppInfoParser.java:64)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:816)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:666)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:647)
	at org.apache.kafka.clients.consumer.KafkaConsumer.<init>(KafkaConsumer.java:627)
	at org.apache.flink.connector.kafka.source.reader.KafkaPartitionSplitReader.<init>(KafkaPartitionSplitReader.java:88)
	at org.apache.flink.connector.kafka.source.KafkaSource.lambda$createReader$1(KafkaSource.java:160)
	at org.apache.flink.connector.base.source.reader.fetcher.SplitFetcherManager.createSplitFetcher(SplitFetcherManager.java:196)
	at org.apache.flink.connector.base.source.reader.fetcher.SingleThreadFetcherManager.addSplits(SingleThreadFetcherManager.java:107)
	at org.apache.flink.connector.base.source.reader.SourceReaderBase.addSplits(SourceReaderBase.java:242)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleAddSplitsEvent(SourceOperator.java:584)
	at org.apache.flink.streaming.api.operators.SourceOperator.handleOperatorEvent(SourceOperator.java:561)
	at org.apache.flink.streaming.runtime.tasks.OperatorEventDispatcherImpl.dispatchEventToHandlers(OperatorEventDispatcherImpl.java:72)
	at org.apache.flink.streaming.runtime.tasks.RegularOperatorChain.dispatchOperatorEvent(RegularOperatorChain.java:80)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.lambda$dispatchOperatorEvent$20(StreamTask.java:1473)
	at org.apache.flink.streaming.runtime.tasks.StreamTaskActionExecutor$1.runThrowing(StreamTaskActionExecutor.java:50)
	at org.apache.flink.streaming.runtime.tasks.mailbox.Mail.run(Mail.java:90)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMail(MailboxProcessor.java:398)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMailsNonBlocking(MailboxProcessor.java:383)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.processMail(MailboxProcessor.java:345)
	at org.apache.flink.streaming.runtime.tasks.mailbox.MailboxProcessor.runMailboxLoop(MailboxProcessor.java:229)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.runMailboxLoop(StreamTask.java:839)
	at org.apache.flink.streaming.runtime.tasks.StreamTask.invoke(StreamTask.java:788)
	at org.apache.flink.runtime.taskmanager.Task.runWithSystemExitMonitoring(Task.java:952)
	at org.apache.flink.runtime.taskmanager.Task.restoreAndInvoke(Task.java:931)
	at org.apache.flink.runtime.taskmanager.Task.doRun(Task.java:745)
	at org.apache.flink.runtime.taskmanager.Task.run(Task.java:562)
	at java.base/java.lang.Thread.run(Thread.java:829)
INFO  - SplitFetcher               - Starting split fetcher 0
INFO  - ZooKeeper                  - Session: 0x10009b90d4f000b closed
INFO  - SplitFetcher               - Starting split fetcher 0
INFO  - ClientCnxn                 - EventThread shut down for session: 0x10009b90d4f000b
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Resetting the last seen epoch of partition openmrs.openmrs.patient_program-0 to 0 since the associated topicId changed from null to AU8zcSfjQXS8rCABwGPHcA
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Cluster ID: 5Yr1SIgYQz-b-dgRabWx4g
INFO  - DBKeyedStateBackendBuilder - Finished building RocksDB keyed state-backend at /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_8f9053c77be2be6dcb80fb69df68baf8_op_StreamingJoinOperator_5b6b7f98d5bff23034589a7675c38ac7__1_1__uuid_61f08aa3-f498-490f-ba12-501d13e75a23.
INFO  - KafkaConsumer              - [Consumer clientId=flink-0, groupId=flink] Subscribed to partition(s): openmrs.openmrs.concept_name-0
INFO  - KafkaConsumer              - [Consumer clientId=flink-0, groupId=flink] Subscribed to partition(s): openmrs.openmrs.program-0
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Seeking to EARLIEST offset of partition openmrs.openmrs.concept_name-0
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Seeking to EARLIEST offset of partition openmrs.openmrs.program-0
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Resetting offset for partition openmrs.openmrs.patient_program-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:29092 (id: 1 rack: null)], epoch=0}}.
INFO  - mbeddedRocksDBStateBackend - Getting shared memory for RocksDB: shareScope=SLOT, managed=false
INFO  - mbeddedRocksDBStateBackend - Obtained shared RocksDB cache of size 6710886 bytes
WARN  - RocksDBOperationUtils      - RocksDBStateBackend performance will be poor because of the current Flink memory configuration! RocksDB will flush memtable constantly, causing high IO and CPU. Typically the easiest fix is to increase task manager managed memory size. If running locally, see the parameter taskmanager.memory.managed.size. Details: arenaBlockSize 8388608 > mutableLimit 1957341 (writeBufferSize = 67108864, arenaBlockSizeConfigured = 0, defaultArenaBlockSize = 8388608, writeBufferManagerCapacity = 2236962)
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Resetting the last seen epoch of partition openmrs.openmrs.program-0 to 0 since the associated topicId changed from null to E0LS2g3tQtuz2u4zWWmkCQ
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Cluster ID: 5Yr1SIgYQz-b-dgRabWx4g
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Resetting the last seen epoch of partition openmrs.openmrs.concept_name-0 to 0 since the associated topicId changed from null to 6V3PMGEHRjG76RMD32edGQ
INFO  - Metadata                   - [Consumer clientId=flink-0, groupId=flink] Cluster ID: 5Yr1SIgYQz-b-dgRabWx4g
WARN  - RocksDBOperationUtils      - RocksDBStateBackend performance will be poor because of the current Flink memory configuration! RocksDB will flush memtable constantly, causing high IO and CPU. Typically the easiest fix is to increase task manager managed memory size. If running locally, see the parameter taskmanager.memory.managed.size. Details: arenaBlockSize 8388608 > mutableLimit 1957341 (writeBufferSize = 67108864, arenaBlockSizeConfigured = 0, defaultArenaBlockSize = 8388608, writeBufferManagerCapacity = 2236962)
INFO  - mbeddedRocksDBStateBackend - Getting shared memory for RocksDB: shareScope=SLOT, managed=false
INFO  - mbeddedRocksDBStateBackend - Obtained shared RocksDB cache of size 6710886 bytes
INFO  - DBKeyedStateBackendBuilder - Finished building RocksDB keyed state-backend at /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_8f9053c77be2be6dcb80fb69df68baf8_op_StreamingJoinOperator_d7e78c81a38d2cce4433a75795131bcf__1_1__uuid_caf7728b-0369-4832-92ed-079fc8a4064a.
INFO  - mbeddedRocksDBStateBackend - Getting shared memory for RocksDB: shareScope=SLOT, managed=false
INFO  - mbeddedRocksDBStateBackend - Obtained shared RocksDB cache of size 6710886 bytes
INFO  - Task                       - Join[206] -> Calc[207] (1/1)#0 (2ff118f32116f826e0d468907bf12d2a_5b6b7f98d5bff23034589a7675c38ac7_0_0) switched from INITIALIZING to RUNNING.
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Resetting offset for partition openmrs.openmrs.concept_name-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:29092 (id: 1 rack: null)], epoch=0}}.
INFO  - ExecutionGraph             - Join[206] -> Calc[207] (1/1) (2ff118f32116f826e0d468907bf12d2a_5b6b7f98d5bff23034589a7675c38ac7_0_0) switched from INITIALIZING to RUNNING.
WARN  - RocksDBOperationUtils      - RocksDBStateBackend performance will be poor because of the current Flink memory configuration! RocksDB will flush memtable constantly, causing high IO and CPU. Typically the easiest fix is to increase task manager managed memory size. If running locally, see the parameter taskmanager.memory.managed.size. Details: arenaBlockSize 8388608 > mutableLimit 1957341 (writeBufferSize = 67108864, arenaBlockSizeConfigured = 0, defaultArenaBlockSize = 8388608, writeBufferManagerCapacity = 2236962)
INFO  - SubscriptionState          - [Consumer clientId=flink-0, groupId=flink] Resetting offset for partition openmrs.openmrs.program-0 to position FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[localhost:29092 (id: 1 rack: null)], epoch=0}}.
WARN  - RocksDBOperationUtils      - RocksDBStateBackend performance will be poor because of the current Flink memory configuration! RocksDB will flush memtable constantly, causing high IO and CPU. Typically the easiest fix is to increase task manager managed memory size. If running locally, see the parameter taskmanager.memory.managed.size. Details: arenaBlockSize 8388608 > mutableLimit 1957341 (writeBufferSize = 67108864, arenaBlockSizeConfigured = 0, defaultArenaBlockSize = 8388608, writeBufferManagerCapacity = 2236962)
INFO  - DBKeyedStateBackendBuilder - Finished building RocksDB keyed state-backend at /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_8f9053c77be2be6dcb80fb69df68baf8_op_StreamingJoinOperator_27b913f6385bb0e404cc1ac792473af7__1_1__uuid_ba09c669-1a23-48c1-9696-a86ec710f60a.
INFO  - DBKeyedStateBackendBuilder - Finished building RocksDB keyed state-backend at /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_8f9053c77be2be6dcb80fb69df68baf8_op_SinkUpsertMaterializer_8fc3be823cc75a93eb3f11ae7a596b08__1_1__uuid_89e0178a-70e3-4a1c-8523-6da7a7065cf2.
INFO  - Task                       - Join[212] -> Calc[213] (1/1)#0 (2ff118f32116f826e0d468907bf12d2a_d7e78c81a38d2cce4433a75795131bcf_0_0) switched from INITIALIZING to RUNNING.
INFO  - ExecutionGraph             - Join[212] -> Calc[213] (1/1) (2ff118f32116f826e0d468907bf12d2a_d7e78c81a38d2cce4433a75795131bcf_0_0) switched from INITIALIZING to RUNNING.
WARN  - RocksDBOperationUtils      - RocksDBStateBackend performance will be poor because of the current Flink memory configuration! RocksDB will flush memtable constantly, causing high IO and CPU. Typically the easiest fix is to increase task manager managed memory size. If running locally, see the parameter taskmanager.memory.managed.size. Details: arenaBlockSize 8388608 > mutableLimit 1957341 (writeBufferSize = 67108864, arenaBlockSizeConfigured = 0, defaultArenaBlockSize = 8388608, writeBufferManagerCapacity = 2236962)
WARN  - RocksDBOperationUtils      - RocksDBStateBackend performance will be poor because of the current Flink memory configuration! RocksDB will flush memtable constantly, causing high IO and CPU. Typically the easiest fix is to increase task manager managed memory size. If running locally, see the parameter taskmanager.memory.managed.size. Details: arenaBlockSize 8388608 > mutableLimit 1957341 (writeBufferSize = 67108864, arenaBlockSizeConfigured = 0, defaultArenaBlockSize = 8388608, writeBufferManagerCapacity = 2236962)
WARN  - RocksDBOperationUtils      - RocksDBStateBackend performance will be poor because of the current Flink memory configuration! RocksDB will flush memtable constantly, causing high IO and CPU. Typically the easiest fix is to increase task manager managed memory size. If running locally, see the parameter taskmanager.memory.managed.size. Details: arenaBlockSize 8388608 > mutableLimit 1957341 (writeBufferSize = 67108864, arenaBlockSizeConfigured = 0, defaultArenaBlockSize = 8388608, writeBufferManagerCapacity = 2236962)
INFO  - Task                       - SinkMaterializer[217] -> Sink: patient_programs[217] (1/1)#0 (2ff118f32116f826e0d468907bf12d2a_8fc3be823cc75a93eb3f11ae7a596b08_0_0) switched from INITIALIZING to RUNNING.
INFO  - ExecutionGraph             - SinkMaterializer[217] -> Sink: patient_programs[217] (1/1) (2ff118f32116f826e0d468907bf12d2a_8fc3be823cc75a93eb3f11ae7a596b08_0_0) switched from INITIALIZING to RUNNING.
INFO  - Task                       - Join[215] -> Calc[216] -> ConstraintEnforcer[217] (1/1)#0 (2ff118f32116f826e0d468907bf12d2a_27b913f6385bb0e404cc1ac792473af7_0_0) switched from INITIALIZING to RUNNING.
INFO  - ExecutionGraph             - Join[215] -> Calc[216] -> ConstraintEnforcer[217] (1/1) (2ff118f32116f826e0d468907bf12d2a_27b913f6385bb0e404cc1ac792473af7_0_0) switched from INITIALIZING to RUNNING.
INFO  - CheckpointCoordinator      - Triggering checkpoint 1 (type=CheckpointType{name='Checkpoint', sharingFilesStrategy=FORWARD_BACKWARD}) @ 1699290661228 for job 3450ce4e11df2cb7a382b3520dc37240.
INFO  - CheckpointCoordinator      - Completed checkpoint 1 for job 3450ce4e11df2cb7a382b3520dc37240 (354199 bytes, checkpointDuration=175 ms, finalizationTime=13 ms).
INFO  - SourceCoordinator          - Marking checkpoint 1 as completed for source Source: patient[75].
INFO  - SourceCoordinator          - Marking checkpoint 1 as completed for source Source: person_address[89].
INFO  - SourceCoordinator          - Marking checkpoint 1 as completed for source Source: person_name[83].
INFO  - SourceCoordinator          - Marking checkpoint 1 as completed for source Source: patient_identifier[95].
INFO  - SourceCoordinator          - Marking checkpoint 1 as completed for source Source: person[78].
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Discovered group coordinator localhost:29092 (id: 2147483646 rack: null)
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Discovered group coordinator localhost:29092 (id: 2147483646 rack: null)
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Discovered group coordinator localhost:29092 (id: 2147483646 rack: null)
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Discovered group coordinator localhost:29092 (id: 2147483646 rack: null)
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Discovered group coordinator localhost:29092 (id: 2147483646 rack: null)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Disconnecting from node 1 due to request timeout.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight FETCH request with correlation id 11 due to node 1 being disconnected (elapsed time since creation: 46678ms, elapsed time since send: 46678ms, request timeout: 30000ms)
INFO  - FetchSessionHandler        - [Consumer clientId=flink-0, groupId=flink] Error sending fetch request (sessionId=2092663801, epoch=7) to node 1:
org.apache.kafka.common.errors.DisconnectException
INFO  - CheckpointCoordinator      - Triggering checkpoint 1 (type=CheckpointType{name='Checkpoint', sharingFilesStrategy=FORWARD_BACKWARD}) @ 1699290773274 for job 30b4315f4dce6b8b0d1d34062dbea1c2.
INFO  - CheckpointCoordinator      - Completed checkpoint 1 for job 30b4315f4dce6b8b0d1d34062dbea1c2 (550220 bytes, checkpointDuration=94 ms, finalizationTime=16 ms).
INFO  - SourceCoordinator          - Marking checkpoint 1 as completed for source Source: patient_appointment[1].
INFO  - SourceCoordinator          - Marking checkpoint 1 as completed for source Source: appointment_service_type[9].
INFO  - SourceCoordinator          - Marking checkpoint 1 as completed for source Source: patient_appointment_provider[15].
INFO  - SourceCoordinator          - Marking checkpoint 1 as completed for source Source: appointment_service[4].
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Discovered group coordinator localhost:29092 (id: 2147483646 rack: null)
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Discovered group coordinator localhost:29092 (id: 2147483646 rack: null)
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Discovered group coordinator localhost:29092 (id: 2147483646 rack: null)
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Discovered group coordinator localhost:29092 (id: 2147483646 rack: null)
INFO  - CheckpointCoordinator      - Triggering checkpoint 1 (type=CheckpointType{name='Checkpoint', sharingFilesStrategy=FORWARD_BACKWARD}) @ 1699290788195 for job c3c54da01848bf81457a865e46b38d18.
INFO  - CheckpointCoordinator      - Completed checkpoint 1 for job c3c54da01848bf81457a865e46b38d18 (8629831 bytes, checkpointDuration=112 ms, finalizationTime=14 ms).
INFO  - SourceCoordinator          - Marking checkpoint 1 as completed for source Source: encounter[165].
INFO  - SourceCoordinator          - Marking checkpoint 1 as completed for source Source: location[173].
INFO  - SourceCoordinator          - Marking checkpoint 1 as completed for source Source: form[179].
INFO  - SourceCoordinator          - Marking checkpoint 1 as completed for source Source: visit_type[191].
INFO  - SourceCoordinator          - Marking checkpoint 1 as completed for source Source: encounter_type[167].
INFO  - SourceCoordinator          - Marking checkpoint 1 as completed for source Source: visit[185].
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Discovered group coordinator localhost:29092 (id: 2147483646 rack: null)
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Discovered group coordinator localhost:29092 (id: 2147483646 rack: null)
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Discovered group coordinator localhost:29092 (id: 2147483646 rack: null)
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Discovered group coordinator localhost:29092 (id: 2147483646 rack: null)
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Discovered group coordinator localhost:29092 (id: 2147483646 rack: null)
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Discovered group coordinator localhost:29092 (id: 2147483646 rack: null)
INFO  - CheckpointCoordinator      - Triggering checkpoint 1 (type=CheckpointType{name='Checkpoint', sharingFilesStrategy=FORWARD_BACKWARD}) @ 1699290873662 for job 6cadd3411b812f5aeb1f461ff6051653.
INFO  - CheckpointCoordinator      - Completed checkpoint 1 for job 6cadd3411b812f5aeb1f461ff6051653 (15258 bytes, checkpointDuration=32 ms, finalizationTime=13 ms).
INFO  - SourceCoordinator          - Marking checkpoint 1 as completed for source Source: sale_order[162].
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Discovered group coordinator localhost:29092 (id: 2147483646 rack: null)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Disconnecting from node 1 due to request timeout.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight FETCH request with correlation id 18 due to node 1 being disconnected (elapsed time since creation: 36912ms, elapsed time since send: 36912ms, request timeout: 30000ms)
INFO  - FetchSessionHandler        - [Consumer clientId=flink-0, groupId=flink] Error sending fetch request (sessionId=282309502, epoch=4) to node 1:
org.apache.kafka.common.errors.DisconnectException
INFO  - CheckpointCoordinator      - Triggering checkpoint 1 (type=CheckpointType{name='Checkpoint', sharingFilesStrategy=FORWARD_BACKWARD}) @ 1699290918777 for job 1d1394375e4908f94ef8c8210cd9a417.
INFO  - CheckpointCoordinator      - Completed checkpoint 1 for job 1d1394375e4908f94ef8c8210cd9a417 (2031201 bytes, checkpointDuration=101 ms, finalizationTime=15 ms).
INFO  - SourceCoordinator          - Marking checkpoint 1 as completed for source Source: orders[21].
INFO  - SourceCoordinator          - Marking checkpoint 1 as completed for source Source: encounter[36].
INFO  - SourceCoordinator          - Marking checkpoint 1 as completed for source Source: care_setting[30].
INFO  - SourceCoordinator          - Marking checkpoint 1 as completed for source Source: encounter_type[42].
INFO  - SourceCoordinator          - Marking checkpoint 1 as completed for source Source: order_type[24].
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Discovered group coordinator localhost:29092 (id: 2147483646 rack: null)
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Discovered group coordinator localhost:29092 (id: 2147483646 rack: null)
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Discovered group coordinator localhost:29092 (id: 2147483646 rack: null)
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Discovered group coordinator localhost:29092 (id: 2147483646 rack: null)
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Discovered group coordinator localhost:29092 (id: 2147483646 rack: null)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node -1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node -1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node -1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node -1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node -1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node -1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node -1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node -1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node -1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node -1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node -1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node -1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node -1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node -1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node -1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node -1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node -1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node -1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node -1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node -1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node -1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node -1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node -1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node -1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node -1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node -1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node -1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node -1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node -1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node -1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node -1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node -1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node -1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node -1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node -1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node -1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node -1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node -1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node -1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node -1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node -1 disconnected.
INFO  - CheckpointCoordinator      - Triggering checkpoint 1 (type=CheckpointType{name='Checkpoint', sharingFilesStrategy=FORWARD_BACKWARD}) @ 1699290949168 for job ee8b603bf5edab3af85b6467db69921f.
INFO  - CheckpointCoordinator      - Completed checkpoint 1 for job ee8b603bf5edab3af85b6467db69921f (116316843 bytes, checkpointDuration=468 ms, finalizationTime=17 ms).
INFO  - SourceCoordinator          - Marking checkpoint 1 as completed for source Source: obs[120].
INFO  - SourceCoordinator          - Marking checkpoint 1 as completed for source Source: visit[135].
INFO  - SourceCoordinator          - Marking checkpoint 1 as completed for source Source: concept_name[123].
INFO  - SourceCoordinator          - Marking checkpoint 1 as completed for source Source: location[153].
INFO  - SourceCoordinator          - Marking checkpoint 1 as completed for source Source: encounter[129].
INFO  - SourceCoordinator          - Marking checkpoint 1 as completed for source Source: visit_type[147].
INFO  - SourceCoordinator          - Marking checkpoint 1 as completed for source Source: encounter_type[141].
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Discovered group coordinator localhost:29092 (id: 2147483646 rack: null)
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Discovered group coordinator localhost:29092 (id: 2147483646 rack: null)
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Discovered group coordinator localhost:29092 (id: 2147483646 rack: null)
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Discovered group coordinator localhost:29092 (id: 2147483646 rack: null)
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Discovered group coordinator localhost:29092 (id: 2147483646 rack: null)
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Discovered group coordinator localhost:29092 (id: 2147483646 rack: null)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Disconnecting from node 1 due to request timeout.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight FETCH request with correlation id 22 due to node 1 being disconnected (elapsed time since creation: 59970ms, elapsed time since send: 59970ms, request timeout: 30000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight FIND_COORDINATOR request with correlation id 23 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 30000ms)
INFO  - FetchSessionHandler        - [Consumer clientId=flink-0, groupId=flink] Error sending fetch request (sessionId=554771904, epoch=1) to node 1:
org.apache.kafka.common.errors.DisconnectException
WARN  - KafkaSourceReader          - Failed to commit consumer offsets for checkpoint 1
org.apache.kafka.clients.consumer.RetriableCommitFailedException: Offset commit failed with a retriable exception. You should retry committing the latest consumed offsets.
Caused by: org.apache.kafka.clients.consumer.internals.NoAvailableBrokersException
INFO  - CheckpointCoordinator      - Triggering checkpoint 1 (type=CheckpointType{name='Checkpoint', sharingFilesStrategy=FORWARD_BACKWARD}) @ 1699291016781 for job 3b099420ea7206c78ac6154209036e81.
INFO  - CheckpointCoordinator      - Completed checkpoint 1 for job 3b099420ea7206c78ac6154209036e81 (359 bytes, checkpointDuration=30 ms, finalizationTime=10 ms).
INFO  - SourceCoordinator          - Marking checkpoint 1 as completed for source Source: encounter_diagnosis[101].
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Discovered group coordinator localhost:29092 (id: 2147483646 rack: null)
INFO  - CheckpointCoordinator      - Triggering checkpoint 1 (type=CheckpointType{name='Checkpoint', sharingFilesStrategy=FORWARD_BACKWARD}) @ 1699291068562 for job e08bfbac0c29fa3541fbb236ff4c9568.
INFO  - CheckpointCoordinator      - Completed checkpoint 1 for job e08bfbac0c29fa3541fbb236ff4c9568 (427083 bytes, checkpointDuration=80 ms, finalizationTime=7 ms).
INFO  - SourceCoordinator          - Marking checkpoint 1 as completed for source Source: visit[105].
INFO  - SourceCoordinator          - Marking checkpoint 1 as completed for source Source: visit_type[108].
INFO  - SourceCoordinator          - Marking checkpoint 1 as completed for source Source: person[114].
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Discovered group coordinator localhost:29092 (id: 2147483646 rack: null)
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Discovered group coordinator localhost:29092 (id: 2147483646 rack: null)
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Discovered group coordinator localhost:29092 (id: 2147483646 rack: null)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Disconnecting from node 1 due to request timeout.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight FETCH request with correlation id 28 due to node 1 being disconnected (elapsed time since creation: 30085ms, elapsed time since send: 30085ms, request timeout: 30000ms)
INFO  - FetchSessionHandler        - [Consumer clientId=flink-0, groupId=flink] Error sending fetch request (sessionId=1141709300, epoch=2) to node 1:
org.apache.kafka.common.errors.DisconnectException
INFO  - CheckpointCoordinator      - Triggering checkpoint 1 (type=CheckpointType{name='Checkpoint', sharingFilesStrategy=FORWARD_BACKWARD}) @ 1699291105362 for job a8681efc52437137d28ae75be94f64e1.
INFO  - CheckpointCoordinator      - Completed checkpoint 1 for job a8681efc52437137d28ae75be94f64e1 (341 bytes, checkpointDuration=28 ms, finalizationTime=8 ms).
INFO  - SourceCoordinator          - Marking checkpoint 1 as completed for source Source: conditions[197].
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Discovered group coordinator localhost:29092 (id: 2147483646 rack: null)
INFO  - CheckpointCoordinator      - Triggering checkpoint 1 (type=CheckpointType{name='Checkpoint', sharingFilesStrategy=FORWARD_BACKWARD}) @ 1699291125812 for job 8f9053c77be2be6dcb80fb69df68baf8.
INFO  - CheckpointCoordinator      - Completed checkpoint 1 for job 8f9053c77be2be6dcb80fb69df68baf8 (362987 bytes, checkpointDuration=72 ms, finalizationTime=17 ms).
INFO  - SourceCoordinator          - Marking checkpoint 1 as completed for source Source: patient_program[201].
INFO  - SourceCoordinator          - Marking checkpoint 1 as completed for source Source: program[203].
INFO  - SourceCoordinator          - Marking checkpoint 1 as completed for source Source: concept_name[209].
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Discovered group coordinator localhost:29092 (id: 2147483646 rack: null)
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Discovered group coordinator localhost:29092 (id: 2147483646 rack: null)
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Discovered group coordinator localhost:29092 (id: 2147483646 rack: null)
INFO  - CheckpointCoordinator      - Triggering checkpoint 1 (type=CheckpointType{name='Checkpoint', sharingFilesStrategy=FORWARD_BACKWARD}) @ 1699291152717 for job 9deef106e67c2b1f77d94f2e02251d44.
INFO  - CheckpointCoordinator      - Completed checkpoint 1 for job 9deef106e67c2b1f77d94f2e02251d44 (2909375 bytes, checkpointDuration=108 ms, finalizationTime=17 ms).
INFO  - SourceCoordinator          - Marking checkpoint 1 as completed for source Source: concept_reference_source[63].
INFO  - SourceCoordinator          - Marking checkpoint 1 as completed for source Source: concept[48].
INFO  - SourceCoordinator          - Marking checkpoint 1 as completed for source Source: concept_name[69].
INFO  - SourceCoordinator          - Marking checkpoint 1 as completed for source Source: concept_reference_map[51].
INFO  - SourceCoordinator          - Marking checkpoint 1 as completed for source Source: concept_reference_term[57].
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Discovered group coordinator localhost:29092 (id: 2147483646 rack: null)
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Discovered group coordinator localhost:29092 (id: 2147483646 rack: null)
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Discovered group coordinator localhost:29092 (id: 2147483646 rack: null)
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Discovered group coordinator localhost:29092 (id: 2147483646 rack: null)
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Discovered group coordinator localhost:29092 (id: 2147483646 rack: null)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node -1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node -1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node -1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node -1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node -1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node -1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node -1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node -1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node -1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node -1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node -1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node -1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node -1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node -1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node -1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node -1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node -1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node -1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node -1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node -1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node -1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node -1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node -1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node -1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node -1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node -1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node -1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node -1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node -1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node -1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node -1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node -1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node -1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node -1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node -1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node -1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node -1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node -1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node -1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node -1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node -1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Disconnecting from node 1 due to request timeout.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight FETCH request with correlation id 32 due to node 1 being disconnected (elapsed time since creation: 34473ms, elapsed time since send: 34473ms, request timeout: 30000ms)
INFO  - FetchSessionHandler        - [Consumer clientId=flink-0, groupId=flink] Error sending fetch request (sessionId=681577984, epoch=1) to node 1:
org.apache.kafka.common.errors.DisconnectException
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - CheckpointCoordinator      - Triggering checkpoint 2 (type=CheckpointType{name='Checkpoint', sharingFilesStrategy=FORWARD_BACKWARD}) @ 1699291261250 for job 3450ce4e11df2cb7a382b3520dc37240.
INFO  - CheckpointCoordinator      - Completed checkpoint 2 for job 3450ce4e11df2cb7a382b3520dc37240 (345830 bytes, checkpointDuration=94 ms, finalizationTime=9 ms).
INFO  - SourceCoordinator          - Marking checkpoint 2 as completed for source Source: patient[75].
INFO  - SourceCoordinator          - Marking checkpoint 2 as completed for source Source: person[78].
INFO  - SourceCoordinator          - Marking checkpoint 2 as completed for source Source: patient_identifier[95].
INFO  - SourceCoordinator          - Marking checkpoint 2 as completed for source Source: person_name[83].
INFO  - SourceCoordinator          - Marking checkpoint 2 as completed for source Source: person_address[89].
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Disconnecting from node 1 due to request timeout.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight FETCH request with correlation id 36 due to node 1 being disconnected (elapsed time since creation: 59727ms, elapsed time since send: 59727ms, request timeout: 30000ms)
INFO  - FetchSessionHandler        - [Consumer clientId=flink-0, groupId=flink] Error sending fetch request (sessionId=58075426, epoch=1) to node 1:
org.apache.kafka.common.errors.DisconnectException
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - CheckpointCoordinator      - Triggering checkpoint 2 (type=CheckpointType{name='Checkpoint', sharingFilesStrategy=FORWARD_BACKWARD}) @ 1699291373299 for job 30b4315f4dce6b8b0d1d34062dbea1c2.
INFO  - CheckpointCoordinator      - Completed checkpoint 2 for job 30b4315f4dce6b8b0d1d34062dbea1c2 (541449 bytes, checkpointDuration=79 ms, finalizationTime=32 ms).
INFO  - SourceCoordinator          - Marking checkpoint 2 as completed for source Source: patient_appointment[1].
INFO  - SourceCoordinator          - Marking checkpoint 2 as completed for source Source: appointment_service[4].
INFO  - SourceCoordinator          - Marking checkpoint 2 as completed for source Source: appointment_service_type[9].
INFO  - SourceCoordinator          - Marking checkpoint 2 as completed for source Source: patient_appointment_provider[15].
INFO  - CheckpointCoordinator      - Triggering checkpoint 2 (type=CheckpointType{name='Checkpoint', sharingFilesStrategy=FORWARD_BACKWARD}) @ 1699291388223 for job c3c54da01848bf81457a865e46b38d18.
INFO  - CheckpointCoordinator      - Completed checkpoint 2 for job c3c54da01848bf81457a865e46b38d18 (8629831 bytes, checkpointDuration=113 ms, finalizationTime=18 ms).
INFO  - SourceCoordinator          - Marking checkpoint 2 as completed for source Source: encounter[165].
INFO  - SourceCoordinator          - Marking checkpoint 2 as completed for source Source: encounter_type[167].
INFO  - SourceCoordinator          - Marking checkpoint 2 as completed for source Source: location[173].
INFO  - SourceCoordinator          - Marking checkpoint 2 as completed for source Source: visit[185].
INFO  - SourceCoordinator          - Marking checkpoint 2 as completed for source Source: visit_type[191].
INFO  - SourceCoordinator          - Marking checkpoint 2 as completed for source Source: form[179].
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - CheckpointCoordinator      - Triggering checkpoint 2 (type=CheckpointType{name='Checkpoint', sharingFilesStrategy=FORWARD_BACKWARD}) @ 1699291473684 for job 6cadd3411b812f5aeb1f461ff6051653.
INFO  - CheckpointCoordinator      - Completed checkpoint 2 for job 6cadd3411b812f5aeb1f461ff6051653 (15258 bytes, checkpointDuration=25 ms, finalizationTime=6 ms).
INFO  - SourceCoordinator          - Marking checkpoint 2 as completed for source Source: sale_order[162].
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - CheckpointCoordinator      - Triggering checkpoint 2 (type=CheckpointType{name='Checkpoint', sharingFilesStrategy=FORWARD_BACKWARD}) @ 1699291518806 for job 1d1394375e4908f94ef8c8210cd9a417.
INFO  - CheckpointCoordinator      - Completed checkpoint 2 for job 1d1394375e4908f94ef8c8210cd9a417 (2016817 bytes, checkpointDuration=92 ms, finalizationTime=18 ms).
INFO  - SourceCoordinator          - Marking checkpoint 2 as completed for source Source: orders[21].
INFO  - SourceCoordinator          - Marking checkpoint 2 as completed for source Source: encounter[36].
INFO  - SourceCoordinator          - Marking checkpoint 2 as completed for source Source: encounter_type[42].
INFO  - SourceCoordinator          - Marking checkpoint 2 as completed for source Source: care_setting[30].
INFO  - SourceCoordinator          - Marking checkpoint 2 as completed for source Source: order_type[24].
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - CheckpointCoordinator      - Triggering checkpoint 2 (type=CheckpointType{name='Checkpoint', sharingFilesStrategy=FORWARD_BACKWARD}) @ 1699291549190 for job ee8b603bf5edab3af85b6467db69921f.
INFO  - CheckpointCoordinator      - Completed checkpoint 2 for job ee8b603bf5edab3af85b6467db69921f (191717733 bytes, checkpointDuration=655 ms, finalizationTime=17 ms).
INFO  - SourceCoordinator          - Marking checkpoint 2 as completed for source Source: obs[120].
INFO  - SourceCoordinator          - Marking checkpoint 2 as completed for source Source: encounter_type[141].
INFO  - SourceCoordinator          - Marking checkpoint 2 as completed for source Source: location[153].
INFO  - SourceCoordinator          - Marking checkpoint 2 as completed for source Source: visit_type[147].
INFO  - SourceCoordinator          - Marking checkpoint 2 as completed for source Source: visit[135].
INFO  - SourceCoordinator          - Marking checkpoint 2 as completed for source Source: concept_name[123].
INFO  - SourceCoordinator          - Marking checkpoint 2 as completed for source Source: encounter[129].
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Discovered group coordinator localhost:29092 (id: 2147483646 rack: null)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - CheckpointCoordinator      - Triggering checkpoint 2 (type=CheckpointType{name='Checkpoint', sharingFilesStrategy=FORWARD_BACKWARD}) @ 1699291616808 for job 3b099420ea7206c78ac6154209036e81.
INFO  - CheckpointCoordinator      - Completed checkpoint 2 for job 3b099420ea7206c78ac6154209036e81 (359 bytes, checkpointDuration=17 ms, finalizationTime=7 ms).
INFO  - SourceCoordinator          - Marking checkpoint 2 as completed for source Source: encounter_diagnosis[101].
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - CheckpointCoordinator      - Triggering checkpoint 2 (type=CheckpointType{name='Checkpoint', sharingFilesStrategy=FORWARD_BACKWARD}) @ 1699291668587 for job e08bfbac0c29fa3541fbb236ff4c9568.
INFO  - CheckpointCoordinator      - Completed checkpoint 2 for job e08bfbac0c29fa3541fbb236ff4c9568 (419924 bytes, checkpointDuration=61 ms, finalizationTime=10 ms).
INFO  - SourceCoordinator          - Marking checkpoint 2 as completed for source Source: visit_type[108].
INFO  - SourceCoordinator          - Marking checkpoint 2 as completed for source Source: person[114].
INFO  - SourceCoordinator          - Marking checkpoint 2 as completed for source Source: visit[105].
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - CheckpointCoordinator      - Triggering checkpoint 2 (type=CheckpointType{name='Checkpoint', sharingFilesStrategy=FORWARD_BACKWARD}) @ 1699292719642 for job a8681efc52437137d28ae75be94f64e1.
INFO  - CheckpointCoordinator      - Completed checkpoint 2 for job a8681efc52437137d28ae75be94f64e1 (341 bytes, checkpointDuration=36 ms, finalizationTime=6 ms).
INFO  - SourceCoordinator          - Marking checkpoint 2 as completed for source Source: conditions[197].
INFO  - CheckpointCoordinator      - Triggering checkpoint 2 (type=CheckpointType{name='Checkpoint', sharingFilesStrategy=FORWARD_BACKWARD}) @ 1699292740048 for job 8f9053c77be2be6dcb80fb69df68baf8.
INFO  - CheckpointCoordinator      - Completed checkpoint 2 for job 8f9053c77be2be6dcb80fb69df68baf8 (359818 bytes, checkpointDuration=104 ms, finalizationTime=14 ms).
INFO  - SourceCoordinator          - Marking checkpoint 2 as completed for source Source: patient_program[201].
INFO  - SourceCoordinator          - Marking checkpoint 2 as completed for source Source: program[203].
INFO  - SourceCoordinator          - Marking checkpoint 2 as completed for source Source: concept_name[209].
INFO  - CheckpointCoordinator      - Triggering checkpoint 2 (type=CheckpointType{name='Checkpoint', sharingFilesStrategy=FORWARD_BACKWARD}) @ 1699292766941 for job 9deef106e67c2b1f77d94f2e02251d44.
INFO  - CheckpointCoordinator      - Completed checkpoint 2 for job 9deef106e67c2b1f77d94f2e02251d44 (2900369 bytes, checkpointDuration=90 ms, finalizationTime=17 ms).
INFO  - SourceCoordinator          - Marking checkpoint 2 as completed for source Source: concept[48].
INFO  - SourceCoordinator          - Marking checkpoint 2 as completed for source Source: concept_reference_term[57].
INFO  - SourceCoordinator          - Marking checkpoint 2 as completed for source Source: concept_reference_map[51].
INFO  - SourceCoordinator          - Marking checkpoint 2 as completed for source Source: concept_name[69].
INFO  - SourceCoordinator          - Marking checkpoint 2 as completed for source Source: concept_reference_source[63].
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - CheckpointCoordinator      - Triggering checkpoint 3 (type=CheckpointType{name='Checkpoint', sharingFilesStrategy=FORWARD_BACKWARD}) @ 1699293008731 for job 3450ce4e11df2cb7a382b3520dc37240.
INFO  - CheckpointCoordinator      - Completed checkpoint 3 for job 3450ce4e11df2cb7a382b3520dc37240 (345822 bytes, checkpointDuration=96 ms, finalizationTime=14 ms).
INFO  - SourceCoordinator          - Marking checkpoint 3 as completed for source Source: patient[75].
INFO  - SourceCoordinator          - Marking checkpoint 3 as completed for source Source: person_name[83].
INFO  - SourceCoordinator          - Marking checkpoint 3 as completed for source Source: person_address[89].
INFO  - SourceCoordinator          - Marking checkpoint 3 as completed for source Source: patient_identifier[95].
INFO  - SourceCoordinator          - Marking checkpoint 3 as completed for source Source: person[78].
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Disconnecting from node 1 due to request timeout.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Disconnecting from node 1 due to request timeout.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight FETCH request with correlation id 2446 due to node 1 being disconnected (elapsed time since creation: 70372ms, elapsed time since send: 70372ms, request timeout: 30000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight FETCH request with correlation id 2445 due to node 1 being disconnected (elapsed time since creation: 70360ms, elapsed time since send: 70360ms, request timeout: 30000ms)
INFO  - FetchSessionHandler        - [Consumer clientId=flink-0, groupId=flink] Error sending fetch request (sessionId=1091545469, epoch=2432) to node 1:
org.apache.kafka.common.errors.DisconnectException
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Disconnecting from node 1 due to request timeout.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight FETCH request with correlation id 2448 due to node 1 being disconnected (elapsed time since creation: 70370ms, elapsed time since send: 70370ms, request timeout: 30000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Disconnecting from node 1 due to request timeout.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Disconnecting from node 1 due to request timeout.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Disconnecting from node 1 due to request timeout.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight FETCH request with correlation id 2449 due to node 1 being disconnected (elapsed time since creation: 70375ms, elapsed time since send: 70375ms, request timeout: 30000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight FETCH request with correlation id 2447 due to node 1 being disconnected (elapsed time since creation: 70374ms, elapsed time since send: 70374ms, request timeout: 30000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Disconnecting from node 1 due to request timeout.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Disconnecting from node 1 due to request timeout.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Disconnecting from node 1 due to request timeout.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Disconnecting from node 1 due to request timeout.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Disconnecting from node 1 due to request timeout.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight FETCH request with correlation id 2448 due to node 1 being disconnected (elapsed time since creation: 70375ms, elapsed time since send: 70375ms, request timeout: 30000ms)
INFO  - FetchSessionHandler        - [Consumer clientId=flink-0, groupId=flink] Error sending fetch request (sessionId=882181269, epoch=2434) to node 1:
org.apache.kafka.common.errors.DisconnectException
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Disconnecting from node 1 due to request timeout.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight FETCH request with correlation id 2448 due to node 1 being disconnected (elapsed time since creation: 70363ms, elapsed time since send: 70363ms, request timeout: 30000ms)
INFO  - FetchSessionHandler        - [Consumer clientId=flink-0, groupId=flink] Error sending fetch request (sessionId=1655456094, epoch=2434) to node 1:
org.apache.kafka.common.errors.DisconnectException
INFO  - FetchSessionHandler        - [Consumer clientId=flink-0, groupId=flink] Error sending fetch request (sessionId=431340210, epoch=2431) to node 1:
org.apache.kafka.common.errors.DisconnectException
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Disconnecting from node 1 due to request timeout.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight FETCH request with correlation id 2445 due to node 1 being disconnected (elapsed time since creation: 70362ms, elapsed time since send: 70362ms, request timeout: 30000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight FETCH request with correlation id 2448 due to node 1 being disconnected (elapsed time since creation: 70363ms, elapsed time since send: 70363ms, request timeout: 30000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Disconnecting from node 1 due to request timeout.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight FETCH request with correlation id 2452 due to node 1 being disconnected (elapsed time since creation: 70373ms, elapsed time since send: 70373ms, request timeout: 30000ms)
INFO  - FetchSessionHandler        - [Consumer clientId=flink-0, groupId=flink] Error sending fetch request (sessionId=900258278, epoch=2439) to node 1:
org.apache.kafka.common.errors.DisconnectException
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight FETCH request with correlation id 2450 due to node 1 being disconnected (elapsed time since creation: 70375ms, elapsed time since send: 70375ms, request timeout: 30000ms)
INFO  - FetchSessionHandler        - [Consumer clientId=flink-0, groupId=flink] Error sending fetch request (sessionId=1336503995, epoch=2436) to node 1:
org.apache.kafka.common.errors.DisconnectException
INFO  - FetchSessionHandler        - [Consumer clientId=flink-0, groupId=flink] Error sending fetch request (sessionId=927089732, epoch=2435) to node 1:
org.apache.kafka.common.errors.DisconnectException
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight FETCH request with correlation id 2447 due to node 1 being disconnected (elapsed time since creation: 70374ms, elapsed time since send: 70374ms, request timeout: 30000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Disconnecting from node 1 due to request timeout.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight FETCH request with correlation id 2454 due to node 1 being disconnected (elapsed time since creation: 70367ms, elapsed time since send: 70367ms, request timeout: 30000ms)
INFO  - FetchSessionHandler        - [Consumer clientId=flink-0, groupId=flink] Error sending fetch request (sessionId=1497037877, epoch=2441) to node 1:
org.apache.kafka.common.errors.DisconnectException
INFO  - FetchSessionHandler        - [Consumer clientId=flink-0, groupId=flink] Error sending fetch request (sessionId=1315469622, epoch=2435) to node 1:
org.apache.kafka.common.errors.DisconnectException
INFO  - FetchSessionHandler        - [Consumer clientId=flink-0, groupId=flink] Error sending fetch request (sessionId=2076317807, epoch=2433) to node 1:
org.apache.kafka.common.errors.DisconnectException
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight FETCH request with correlation id 2451 due to node 1 being disconnected (elapsed time since creation: 70375ms, elapsed time since send: 70375ms, request timeout: 30000ms)
INFO  - FetchSessionHandler        - [Consumer clientId=flink-0, groupId=flink] Error sending fetch request (sessionId=1148327819, epoch=2434) to node 1:
org.apache.kafka.common.errors.DisconnectException
INFO  - FetchSessionHandler        - [Consumer clientId=flink-0, groupId=flink] Error sending fetch request (sessionId=1066732902, epoch=2437) to node 1:
org.apache.kafka.common.errors.DisconnectException
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Disconnecting from node 1 due to request timeout.
INFO  - FetchSessionHandler        - [Consumer clientId=flink-0, groupId=flink] Error sending fetch request (sessionId=298375412, epoch=2433) to node 1:
org.apache.kafka.common.errors.DisconnectException
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Disconnecting from node 1 due to request timeout.
INFO  - FetchSessionHandler        - [Consumer clientId=flink-0, groupId=flink] Error sending fetch request (sessionId=734232109, epoch=2431) to node 1:
org.apache.kafka.common.errors.DisconnectException
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight FETCH request with correlation id 2452 due to node 1 being disconnected (elapsed time since creation: 70376ms, elapsed time since send: 70376ms, request timeout: 30000ms)
INFO  - FetchSessionHandler        - [Consumer clientId=flink-0, groupId=flink] Error sending fetch request (sessionId=695936568, epoch=2438) to node 1:
org.apache.kafka.common.errors.DisconnectException
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight FETCH request with correlation id 2456 due to node 1 being disconnected (elapsed time since creation: 70378ms, elapsed time since send: 70378ms, request timeout: 30000ms)
INFO  - FetchSessionHandler        - [Consumer clientId=flink-0, groupId=flink] Error sending fetch request (sessionId=710823168, epoch=2443) to node 1:
org.apache.kafka.common.errors.DisconnectException
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight FETCH request with correlation id 2455 due to node 1 being disconnected (elapsed time since creation: 70369ms, elapsed time since send: 70369ms, request timeout: 30000ms)
INFO  - FetchSessionHandler        - [Consumer clientId=flink-0, groupId=flink] Error sending fetch request (sessionId=593744242, epoch=2441) to node 1:
org.apache.kafka.common.errors.DisconnectException
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - CheckpointCoordinator      - Triggering checkpoint 3 (type=CheckpointType{name='Checkpoint', sharingFilesStrategy=FORWARD_BACKWARD}) @ 1699293492284 for job 30b4315f4dce6b8b0d1d34062dbea1c2.
INFO  - CheckpointCoordinator      - Completed checkpoint 3 for job 30b4315f4dce6b8b0d1d34062dbea1c2 (541449 bytes, checkpointDuration=78 ms, finalizationTime=43 ms).
INFO  - SourceCoordinator          - Marking checkpoint 3 as completed for source Source: patient_appointment_provider[15].
INFO  - SourceCoordinator          - Marking checkpoint 3 as completed for source Source: patient_appointment[1].
INFO  - SourceCoordinator          - Marking checkpoint 3 as completed for source Source: appointment_service[4].
INFO  - SourceCoordinator          - Marking checkpoint 3 as completed for source Source: appointment_service_type[9].
INFO  - CheckpointCoordinator      - Triggering checkpoint 3 (type=CheckpointType{name='Checkpoint', sharingFilesStrategy=FORWARD_BACKWARD}) @ 1699293507215 for job c3c54da01848bf81457a865e46b38d18.
INFO  - CheckpointCoordinator      - Completed checkpoint 3 for job c3c54da01848bf81457a865e46b38d18 (8629799 bytes, checkpointDuration=113 ms, finalizationTime=21 ms).
INFO  - SourceCoordinator          - Marking checkpoint 3 as completed for source Source: encounter[165].
INFO  - SourceCoordinator          - Marking checkpoint 3 as completed for source Source: location[173].
INFO  - SourceCoordinator          - Marking checkpoint 3 as completed for source Source: visit_type[191].
INFO  - SourceCoordinator          - Marking checkpoint 3 as completed for source Source: form[179].
INFO  - SourceCoordinator          - Marking checkpoint 3 as completed for source Source: encounter_type[167].
INFO  - SourceCoordinator          - Marking checkpoint 3 as completed for source Source: visit[185].
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - CheckpointCoordinator      - Triggering checkpoint 3 (type=CheckpointType{name='Checkpoint', sharingFilesStrategy=FORWARD_BACKWARD}) @ 1699294827324 for job 6cadd3411b812f5aeb1f461ff6051653.
INFO  - CheckpointCoordinator      - Completed checkpoint 3 for job 6cadd3411b812f5aeb1f461ff6051653 (15258 bytes, checkpointDuration=34 ms, finalizationTime=11 ms).
INFO  - SourceCoordinator          - Marking checkpoint 3 as completed for source Source: sale_order[162].
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - CheckpointCoordinator      - Triggering checkpoint 3 (type=CheckpointType{name='Checkpoint', sharingFilesStrategy=FORWARD_BACKWARD}) @ 1699294872440 for job 1d1394375e4908f94ef8c8210cd9a417.
INFO  - CheckpointCoordinator      - Completed checkpoint 3 for job 1d1394375e4908f94ef8c8210cd9a417 (2016817 bytes, checkpointDuration=126 ms, finalizationTime=15 ms).
INFO  - SourceCoordinator          - Marking checkpoint 3 as completed for source Source: orders[21].
INFO  - SourceCoordinator          - Marking checkpoint 3 as completed for source Source: care_setting[30].
INFO  - SourceCoordinator          - Marking checkpoint 3 as completed for source Source: order_type[24].
INFO  - SourceCoordinator          - Marking checkpoint 3 as completed for source Source: encounter[36].
INFO  - SourceCoordinator          - Marking checkpoint 3 as completed for source Source: encounter_type[42].
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - CheckpointCoordinator      - Triggering checkpoint 3 (type=CheckpointType{name='Checkpoint', sharingFilesStrategy=FORWARD_BACKWARD}) @ 1699294902829 for job ee8b603bf5edab3af85b6467db69921f.
INFO  - CheckpointCoordinator      - Completed checkpoint 3 for job ee8b603bf5edab3af85b6467db69921f (225794687 bytes, checkpointDuration=425 ms, finalizationTime=10 ms).
INFO  - SourceCoordinator          - Marking checkpoint 3 as completed for source Source: obs[120].
INFO  - SourceCoordinator          - Marking checkpoint 3 as completed for source Source: concept_name[123].
INFO  - SourceCoordinator          - Marking checkpoint 3 as completed for source Source: visit[135].
INFO  - SourceCoordinator          - Marking checkpoint 3 as completed for source Source: encounter_type[141].
INFO  - SourceCoordinator          - Marking checkpoint 3 as completed for source Source: encounter[129].
INFO  - SourceCoordinator          - Marking checkpoint 3 as completed for source Source: location[153].
INFO  - SourceCoordinator          - Marking checkpoint 3 as completed for source Source: visit_type[147].
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - CheckpointCoordinator      - Triggering checkpoint 3 (type=CheckpointType{name='Checkpoint', sharingFilesStrategy=FORWARD_BACKWARD}) @ 1699294970447 for job 3b099420ea7206c78ac6154209036e81.
INFO  - CheckpointCoordinator      - Completed checkpoint 3 for job 3b099420ea7206c78ac6154209036e81 (359 bytes, checkpointDuration=38 ms, finalizationTime=9 ms).
INFO  - SourceCoordinator          - Marking checkpoint 3 as completed for source Source: encounter_diagnosis[101].
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - CheckpointCoordinator      - Triggering checkpoint 3 (type=CheckpointType{name='Checkpoint', sharingFilesStrategy=FORWARD_BACKWARD}) @ 1699295022225 for job e08bfbac0c29fa3541fbb236ff4c9568.
INFO  - CheckpointCoordinator      - Completed checkpoint 3 for job e08bfbac0c29fa3541fbb236ff4c9568 (419916 bytes, checkpointDuration=102 ms, finalizationTime=31 ms).
INFO  - SourceCoordinator          - Marking checkpoint 3 as completed for source Source: visit[105].
INFO  - SourceCoordinator          - Marking checkpoint 3 as completed for source Source: visit_type[108].
INFO  - SourceCoordinator          - Marking checkpoint 3 as completed for source Source: person[114].
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - CheckpointCoordinator      - Triggering checkpoint 3 (type=CheckpointType{name='Checkpoint', sharingFilesStrategy=FORWARD_BACKWARD}) @ 1699295059027 for job a8681efc52437137d28ae75be94f64e1.
INFO  - CheckpointCoordinator      - Completed checkpoint 3 for job a8681efc52437137d28ae75be94f64e1 (341 bytes, checkpointDuration=39 ms, finalizationTime=12 ms).
INFO  - SourceCoordinator          - Marking checkpoint 3 as completed for source Source: conditions[197].
INFO  - CheckpointCoordinator      - Triggering checkpoint 3 (type=CheckpointType{name='Checkpoint', sharingFilesStrategy=FORWARD_BACKWARD}) @ 1699295079471 for job 8f9053c77be2be6dcb80fb69df68baf8.
INFO  - CheckpointCoordinator      - Completed checkpoint 3 for job 8f9053c77be2be6dcb80fb69df68baf8 (359818 bytes, checkpointDuration=114 ms, finalizationTime=12 ms).
INFO  - SourceCoordinator          - Marking checkpoint 3 as completed for source Source: patient_program[201].
INFO  - SourceCoordinator          - Marking checkpoint 3 as completed for source Source: concept_name[209].
INFO  - SourceCoordinator          - Marking checkpoint 3 as completed for source Source: program[203].
INFO  - CheckpointCoordinator      - Triggering checkpoint 3 (type=CheckpointType{name='Checkpoint', sharingFilesStrategy=FORWARD_BACKWARD}) @ 1699295106356 for job 9deef106e67c2b1f77d94f2e02251d44.
INFO  - CheckpointCoordinator      - Completed checkpoint 3 for job 9deef106e67c2b1f77d94f2e02251d44 (2900369 bytes, checkpointDuration=135 ms, finalizationTime=15 ms).
INFO  - SourceCoordinator          - Marking checkpoint 3 as completed for source Source: concept[48].
INFO  - SourceCoordinator          - Marking checkpoint 3 as completed for source Source: concept_reference_source[63].
INFO  - SourceCoordinator          - Marking checkpoint 3 as completed for source Source: concept_name[69].
INFO  - SourceCoordinator          - Marking checkpoint 3 as completed for source Source: concept_reference_term[57].
INFO  - SourceCoordinator          - Marking checkpoint 3 as completed for source Source: concept_reference_map[51].
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - CheckpointCoordinator      - Triggering checkpoint 4 (type=CheckpointType{name='Checkpoint', sharingFilesStrategy=FORWARD_BACKWARD}) @ 1699295214889 for job 3450ce4e11df2cb7a382b3520dc37240.
INFO  - CheckpointCoordinator      - Completed checkpoint 4 for job 3450ce4e11df2cb7a382b3520dc37240 (345806 bytes, checkpointDuration=143 ms, finalizationTime=17 ms).
INFO  - SourceCoordinator          - Marking checkpoint 4 as completed for source Source: person_address[89].
INFO  - SourceCoordinator          - Marking checkpoint 4 as completed for source Source: patient_identifier[95].
INFO  - SourceCoordinator          - Marking checkpoint 4 as completed for source Source: person_name[83].
INFO  - SourceCoordinator          - Marking checkpoint 4 as completed for source Source: person[78].
INFO  - SourceCoordinator          - Marking checkpoint 4 as completed for source Source: patient[75].
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - CheckpointCoordinator      - Triggering checkpoint 4 (type=CheckpointType{name='Checkpoint', sharingFilesStrategy=FORWARD_BACKWARD}) @ 1699295326939 for job 30b4315f4dce6b8b0d1d34062dbea1c2.
INFO  - CheckpointCoordinator      - Completed checkpoint 4 for job 30b4315f4dce6b8b0d1d34062dbea1c2 (541449 bytes, checkpointDuration=118 ms, finalizationTime=26 ms).
INFO  - SourceCoordinator          - Marking checkpoint 4 as completed for source Source: patient_appointment[1].
INFO  - SourceCoordinator          - Marking checkpoint 4 as completed for source Source: appointment_service[4].
INFO  - SourceCoordinator          - Marking checkpoint 4 as completed for source Source: appointment_service_type[9].
INFO  - SourceCoordinator          - Marking checkpoint 4 as completed for source Source: patient_appointment_provider[15].
INFO  - CheckpointCoordinator      - Triggering checkpoint 4 (type=CheckpointType{name='Checkpoint', sharingFilesStrategy=FORWARD_BACKWARD}) @ 1699295341860 for job c3c54da01848bf81457a865e46b38d18.
INFO  - CheckpointCoordinator      - Completed checkpoint 4 for job c3c54da01848bf81457a865e46b38d18 (8629791 bytes, checkpointDuration=161 ms, finalizationTime=25 ms).
INFO  - SourceCoordinator          - Marking checkpoint 4 as completed for source Source: encounter[165].
INFO  - SourceCoordinator          - Marking checkpoint 4 as completed for source Source: encounter_type[167].
INFO  - SourceCoordinator          - Marking checkpoint 4 as completed for source Source: visit_type[191].
INFO  - SourceCoordinator          - Marking checkpoint 4 as completed for source Source: visit[185].
INFO  - SourceCoordinator          - Marking checkpoint 4 as completed for source Source: location[173].
INFO  - SourceCoordinator          - Marking checkpoint 4 as completed for source Source: form[179].
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - CheckpointCoordinator      - Triggering checkpoint 4 (type=CheckpointType{name='Checkpoint', sharingFilesStrategy=FORWARD_BACKWARD}) @ 1699295427331 for job 6cadd3411b812f5aeb1f461ff6051653.
INFO  - CheckpointCoordinator      - Completed checkpoint 4 for job 6cadd3411b812f5aeb1f461ff6051653 (15258 bytes, checkpointDuration=76 ms, finalizationTime=73 ms).
INFO  - SourceCoordinator          - Marking checkpoint 4 as completed for source Source: sale_order[162].
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - CheckpointCoordinator      - Triggering checkpoint 4 (type=CheckpointType{name='Checkpoint', sharingFilesStrategy=FORWARD_BACKWARD}) @ 1699295472449 for job 1d1394375e4908f94ef8c8210cd9a417.
INFO  - CheckpointCoordinator      - Completed checkpoint 4 for job 1d1394375e4908f94ef8c8210cd9a417 (2016817 bytes, checkpointDuration=134 ms, finalizationTime=15 ms).
INFO  - SourceCoordinator          - Marking checkpoint 4 as completed for source Source: orders[21].
INFO  - SourceCoordinator          - Marking checkpoint 4 as completed for source Source: encounter[36].
INFO  - SourceCoordinator          - Marking checkpoint 4 as completed for source Source: care_setting[30].
INFO  - SourceCoordinator          - Marking checkpoint 4 as completed for source Source: order_type[24].
INFO  - SourceCoordinator          - Marking checkpoint 4 as completed for source Source: encounter_type[42].
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - CheckpointCoordinator      - Triggering checkpoint 4 (type=CheckpointType{name='Checkpoint', sharingFilesStrategy=FORWARD_BACKWARD}) @ 1699295502835 for job ee8b603bf5edab3af85b6467db69921f.
INFO  - CheckpointCoordinator      - Completed checkpoint 4 for job ee8b603bf5edab3af85b6467db69921f (225789163 bytes, checkpointDuration=393 ms, finalizationTime=24 ms).
INFO  - SourceCoordinator          - Marking checkpoint 4 as completed for source Source: obs[120].
INFO  - SourceCoordinator          - Marking checkpoint 4 as completed for source Source: concept_name[123].
INFO  - SourceCoordinator          - Marking checkpoint 4 as completed for source Source: visit_type[147].
INFO  - SourceCoordinator          - Marking checkpoint 4 as completed for source Source: visit[135].
INFO  - SourceCoordinator          - Marking checkpoint 4 as completed for source Source: encounter[129].
INFO  - SourceCoordinator          - Marking checkpoint 4 as completed for source Source: encounter_type[141].
INFO  - SourceCoordinator          - Marking checkpoint 4 as completed for source Source: location[153].
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - CheckpointCoordinator      - Triggering checkpoint 4 (type=CheckpointType{name='Checkpoint', sharingFilesStrategy=FORWARD_BACKWARD}) @ 1699295570453 for job 3b099420ea7206c78ac6154209036e81.
INFO  - CheckpointCoordinator      - Completed checkpoint 4 for job 3b099420ea7206c78ac6154209036e81 (359 bytes, checkpointDuration=63 ms, finalizationTime=18 ms).
INFO  - SourceCoordinator          - Marking checkpoint 4 as completed for source Source: encounter_diagnosis[101].
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - CheckpointCoordinator      - Triggering checkpoint 4 (type=CheckpointType{name='Checkpoint', sharingFilesStrategy=FORWARD_BACKWARD}) @ 1699295622230 for job e08bfbac0c29fa3541fbb236ff4c9568.
INFO  - CheckpointCoordinator      - Completed checkpoint 4 for job e08bfbac0c29fa3541fbb236ff4c9568 (419916 bytes, checkpointDuration=87 ms, finalizationTime=9 ms).
INFO  - SourceCoordinator          - Marking checkpoint 4 as completed for source Source: visit[105].
INFO  - SourceCoordinator          - Marking checkpoint 4 as completed for source Source: visit_type[108].
INFO  - SourceCoordinator          - Marking checkpoint 4 as completed for source Source: person[114].
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - CheckpointCoordinator      - Triggering checkpoint 4 (type=CheckpointType{name='Checkpoint', sharingFilesStrategy=FORWARD_BACKWARD}) @ 1699295659032 for job a8681efc52437137d28ae75be94f64e1.
INFO  - CheckpointCoordinator      - Completed checkpoint 4 for job a8681efc52437137d28ae75be94f64e1 (341 bytes, checkpointDuration=40 ms, finalizationTime=14 ms).
INFO  - SourceCoordinator          - Marking checkpoint 4 as completed for source Source: conditions[197].
INFO  - CheckpointCoordinator      - Triggering checkpoint 4 (type=CheckpointType{name='Checkpoint', sharingFilesStrategy=FORWARD_BACKWARD}) @ 1699295679481 for job 8f9053c77be2be6dcb80fb69df68baf8.
INFO  - CheckpointCoordinator      - Completed checkpoint 4 for job 8f9053c77be2be6dcb80fb69df68baf8 (359818 bytes, checkpointDuration=111 ms, finalizationTime=20 ms).
INFO  - SourceCoordinator          - Marking checkpoint 4 as completed for source Source: patient_program[201].
INFO  - SourceCoordinator          - Marking checkpoint 4 as completed for source Source: program[203].
INFO  - SourceCoordinator          - Marking checkpoint 4 as completed for source Source: concept_name[209].
INFO  - CheckpointCoordinator      - Triggering checkpoint 4 (type=CheckpointType{name='Checkpoint', sharingFilesStrategy=FORWARD_BACKWARD}) @ 1699295706363 for job 9deef106e67c2b1f77d94f2e02251d44.
INFO  - CheckpointCoordinator      - Completed checkpoint 4 for job 9deef106e67c2b1f77d94f2e02251d44 (2900353 bytes, checkpointDuration=155 ms, finalizationTime=20 ms).
INFO  - SourceCoordinator          - Marking checkpoint 4 as completed for source Source: concept[48].
INFO  - SourceCoordinator          - Marking checkpoint 4 as completed for source Source: concept_name[69].
INFO  - SourceCoordinator          - Marking checkpoint 4 as completed for source Source: concept_reference_map[51].
INFO  - SourceCoordinator          - Marking checkpoint 4 as completed for source Source: concept_reference_source[63].
INFO  - SourceCoordinator          - Marking checkpoint 4 as completed for source Source: concept_reference_term[57].
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - CheckpointCoordinator      - Triggering checkpoint 5 (type=CheckpointType{name='Checkpoint', sharingFilesStrategy=FORWARD_BACKWARD}) @ 1699296398857 for job 3450ce4e11df2cb7a382b3520dc37240.
INFO  - CheckpointCoordinator      - Completed checkpoint 5 for job 3450ce4e11df2cb7a382b3520dc37240 (345806 bytes, checkpointDuration=138 ms, finalizationTime=31 ms).
INFO  - SourceCoordinator          - Marking checkpoint 5 as completed for source Source: patient[75].
INFO  - SourceCoordinator          - Marking checkpoint 5 as completed for source Source: patient_identifier[95].
INFO  - SourceCoordinator          - Marking checkpoint 5 as completed for source Source: person[78].
INFO  - SourceCoordinator          - Marking checkpoint 5 as completed for source Source: person_name[83].
INFO  - SourceCoordinator          - Marking checkpoint 5 as completed for source Source: person_address[89].
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - CheckpointCoordinator      - Triggering checkpoint 5 (type=CheckpointType{name='Checkpoint', sharingFilesStrategy=FORWARD_BACKWARD}) @ 1699296626938 for job 30b4315f4dce6b8b0d1d34062dbea1c2.
INFO  - CheckpointCoordinator      - Completed checkpoint 5 for job 30b4315f4dce6b8b0d1d34062dbea1c2 (541433 bytes, checkpointDuration=244 ms, finalizationTime=30 ms).
INFO  - SourceCoordinator          - Marking checkpoint 5 as completed for source Source: patient_appointment[1].
INFO  - SourceCoordinator          - Marking checkpoint 5 as completed for source Source: patient_appointment_provider[15].
INFO  - SourceCoordinator          - Marking checkpoint 5 as completed for source Source: appointment_service[4].
INFO  - SourceCoordinator          - Marking checkpoint 5 as completed for source Source: appointment_service_type[9].
INFO  - CheckpointCoordinator      - Triggering checkpoint 5 (type=CheckpointType{name='Checkpoint', sharingFilesStrategy=FORWARD_BACKWARD}) @ 1699296641858 for job c3c54da01848bf81457a865e46b38d18.
INFO  - CheckpointCoordinator      - Completed checkpoint 5 for job c3c54da01848bf81457a865e46b38d18 (8629775 bytes, checkpointDuration=134 ms, finalizationTime=14 ms).
INFO  - SourceCoordinator          - Marking checkpoint 5 as completed for source Source: encounter[165].
INFO  - SourceCoordinator          - Marking checkpoint 5 as completed for source Source: form[179].
INFO  - SourceCoordinator          - Marking checkpoint 5 as completed for source Source: location[173].
INFO  - SourceCoordinator          - Marking checkpoint 5 as completed for source Source: visit_type[191].
INFO  - SourceCoordinator          - Marking checkpoint 5 as completed for source Source: encounter_type[167].
INFO  - SourceCoordinator          - Marking checkpoint 5 as completed for source Source: visit[185].
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - CheckpointCoordinator      - Triggering checkpoint 5 (type=CheckpointType{name='Checkpoint', sharingFilesStrategy=FORWARD_BACKWARD}) @ 1699297103189 for job 6cadd3411b812f5aeb1f461ff6051653.
INFO  - CheckpointCoordinator      - Completed checkpoint 5 for job 6cadd3411b812f5aeb1f461ff6051653 (15258 bytes, checkpointDuration=78 ms, finalizationTime=30 ms).
INFO  - SourceCoordinator          - Marking checkpoint 5 as completed for source Source: sale_order[162].
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - CheckpointCoordinator      - Triggering checkpoint 5 (type=CheckpointType{name='Checkpoint', sharingFilesStrategy=FORWARD_BACKWARD}) @ 1699297174396 for job 1d1394375e4908f94ef8c8210cd9a417.
INFO  - CheckpointCoordinator      - Completed checkpoint 5 for job 1d1394375e4908f94ef8c8210cd9a417 (2016809 bytes, checkpointDuration=136 ms, finalizationTime=45 ms).
INFO  - SourceCoordinator          - Marking checkpoint 5 as completed for source Source: orders[21].
INFO  - SourceCoordinator          - Marking checkpoint 5 as completed for source Source: order_type[24].
INFO  - SourceCoordinator          - Marking checkpoint 5 as completed for source Source: care_setting[30].
INFO  - SourceCoordinator          - Marking checkpoint 5 as completed for source Source: encounter_type[42].
INFO  - SourceCoordinator          - Marking checkpoint 5 as completed for source Source: encounter[36].
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - CheckpointCoordinator      - Triggering checkpoint 5 (type=CheckpointType{name='Checkpoint', sharingFilesStrategy=FORWARD_BACKWARD}) @ 1699297204792 for job ee8b603bf5edab3af85b6467db69921f.
INFO  - CheckpointCoordinator      - Completed checkpoint 5 for job ee8b603bf5edab3af85b6467db69921f (225789155 bytes, checkpointDuration=366 ms, finalizationTime=32 ms).
INFO  - SourceCoordinator          - Marking checkpoint 5 as completed for source Source: obs[120].
INFO  - SourceCoordinator          - Marking checkpoint 5 as completed for source Source: visit[135].
INFO  - SourceCoordinator          - Marking checkpoint 5 as completed for source Source: location[153].
INFO  - SourceCoordinator          - Marking checkpoint 5 as completed for source Source: encounter_type[141].
INFO  - SourceCoordinator          - Marking checkpoint 5 as completed for source Source: encounter[129].
INFO  - SourceCoordinator          - Marking checkpoint 5 as completed for source Source: concept_name[123].
INFO  - SourceCoordinator          - Marking checkpoint 5 as completed for source Source: visit_type[147].
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - CheckpointCoordinator      - Triggering checkpoint 5 (type=CheckpointType{name='Checkpoint', sharingFilesStrategy=FORWARD_BACKWARD}) @ 1699297668776 for job 3b099420ea7206c78ac6154209036e81.
INFO  - CheckpointCoordinator      - Completed checkpoint 5 for job 3b099420ea7206c78ac6154209036e81 (359 bytes, checkpointDuration=86 ms, finalizationTime=17 ms).
INFO  - SourceCoordinator          - Marking checkpoint 5 as completed for source Source: encounter_diagnosis[101].
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - CheckpointCoordinator      - Triggering checkpoint 5 (type=CheckpointType{name='Checkpoint', sharingFilesStrategy=FORWARD_BACKWARD}) @ 1699297720550 for job e08bfbac0c29fa3541fbb236ff4c9568.
INFO  - CheckpointCoordinator      - Completed checkpoint 5 for job e08bfbac0c29fa3541fbb236ff4c9568 (419916 bytes, checkpointDuration=102 ms, finalizationTime=17 ms).
INFO  - SourceCoordinator          - Marking checkpoint 5 as completed for source Source: visit_type[108].
INFO  - SourceCoordinator          - Marking checkpoint 5 as completed for source Source: visit[105].
INFO  - SourceCoordinator          - Marking checkpoint 5 as completed for source Source: person[114].
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - CheckpointCoordinator      - Triggering checkpoint 5 (type=CheckpointType{name='Checkpoint', sharingFilesStrategy=FORWARD_BACKWARD}) @ 1699297757350 for job a8681efc52437137d28ae75be94f64e1.
INFO  - CheckpointCoordinator      - Completed checkpoint 5 for job a8681efc52437137d28ae75be94f64e1 (341 bytes, checkpointDuration=95 ms, finalizationTime=56 ms).
INFO  - SourceCoordinator          - Marking checkpoint 5 as completed for source Source: conditions[197].
INFO  - CheckpointCoordinator      - Triggering checkpoint 5 (type=CheckpointType{name='Checkpoint', sharingFilesStrategy=FORWARD_BACKWARD}) @ 1699297777800 for job 8f9053c77be2be6dcb80fb69df68baf8.
INFO  - CheckpointCoordinator      - Completed checkpoint 5 for job 8f9053c77be2be6dcb80fb69df68baf8 (359818 bytes, checkpointDuration=122 ms, finalizationTime=21 ms).
INFO  - SourceCoordinator          - Marking checkpoint 5 as completed for source Source: patient_program[201].
INFO  - SourceCoordinator          - Marking checkpoint 5 as completed for source Source: concept_name[209].
INFO  - SourceCoordinator          - Marking checkpoint 5 as completed for source Source: program[203].
INFO  - CheckpointCoordinator      - Triggering checkpoint 5 (type=CheckpointType{name='Checkpoint', sharingFilesStrategy=FORWARD_BACKWARD}) @ 1699297804691 for job 9deef106e67c2b1f77d94f2e02251d44.
INFO  - CheckpointCoordinator      - Completed checkpoint 5 for job 9deef106e67c2b1f77d94f2e02251d44 (2900353 bytes, checkpointDuration=122 ms, finalizationTime=24 ms).
INFO  - SourceCoordinator          - Marking checkpoint 5 as completed for source Source: concept_reference_map[51].
INFO  - SourceCoordinator          - Marking checkpoint 5 as completed for source Source: concept_reference_term[57].
INFO  - SourceCoordinator          - Marking checkpoint 5 as completed for source Source: concept[48].
INFO  - SourceCoordinator          - Marking checkpoint 5 as completed for source Source: concept_name[69].
INFO  - SourceCoordinator          - Marking checkpoint 5 as completed for source Source: concept_reference_source[63].
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - CheckpointCoordinator      - Triggering checkpoint 6 (type=CheckpointType{name='Checkpoint', sharingFilesStrategy=FORWARD_BACKWARD}) @ 1699297942231 for job 3450ce4e11df2cb7a382b3520dc37240.
INFO  - CheckpointCoordinator      - Completed checkpoint 6 for job 3450ce4e11df2cb7a382b3520dc37240 (345806 bytes, checkpointDuration=175 ms, finalizationTime=18 ms).
INFO  - SourceCoordinator          - Marking checkpoint 6 as completed for source Source: patient[75].
INFO  - SourceCoordinator          - Marking checkpoint 6 as completed for source Source: person_name[83].
INFO  - SourceCoordinator          - Marking checkpoint 6 as completed for source Source: person_address[89].
INFO  - SourceCoordinator          - Marking checkpoint 6 as completed for source Source: person[78].
INFO  - SourceCoordinator          - Marking checkpoint 6 as completed for source Source: patient_identifier[95].
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - CheckpointCoordinator      - Triggering checkpoint 6 (type=CheckpointType{name='Checkpoint', sharingFilesStrategy=FORWARD_BACKWARD}) @ 1699298054284 for job 30b4315f4dce6b8b0d1d34062dbea1c2.
INFO  - CheckpointCoordinator      - Completed checkpoint 6 for job 30b4315f4dce6b8b0d1d34062dbea1c2 (541425 bytes, checkpointDuration=184 ms, finalizationTime=63 ms).
INFO  - SourceCoordinator          - Marking checkpoint 6 as completed for source Source: appointment_service[4].
INFO  - SourceCoordinator          - Marking checkpoint 6 as completed for source Source: appointment_service_type[9].
INFO  - SourceCoordinator          - Marking checkpoint 6 as completed for source Source: patient_appointment_provider[15].
INFO  - SourceCoordinator          - Marking checkpoint 6 as completed for source Source: patient_appointment[1].
INFO  - CheckpointCoordinator      - Triggering checkpoint 6 (type=CheckpointType{name='Checkpoint', sharingFilesStrategy=FORWARD_BACKWARD}) @ 1699298069202 for job c3c54da01848bf81457a865e46b38d18.
INFO  - CheckpointCoordinator      - Completed checkpoint 6 for job c3c54da01848bf81457a865e46b38d18 (8629767 bytes, checkpointDuration=165 ms, finalizationTime=149 ms).
INFO  - SourceCoordinator          - Marking checkpoint 6 as completed for source Source: encounter_type[167].
INFO  - SourceCoordinator          - Marking checkpoint 6 as completed for source Source: encounter[165].
INFO  - SourceCoordinator          - Marking checkpoint 6 as completed for source Source: visit_type[191].
INFO  - SourceCoordinator          - Marking checkpoint 6 as completed for source Source: form[179].
INFO  - SourceCoordinator          - Marking checkpoint 6 as completed for source Source: location[173].
INFO  - SourceCoordinator          - Marking checkpoint 6 as completed for source Source: visit[185].
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - CheckpointCoordinator      - Triggering checkpoint 6 (type=CheckpointType{name='Checkpoint', sharingFilesStrategy=FORWARD_BACKWARD}) @ 1699298154663 for job 6cadd3411b812f5aeb1f461ff6051653.
INFO  - CheckpointCoordinator      - Completed checkpoint 6 for job 6cadd3411b812f5aeb1f461ff6051653 (15258 bytes, checkpointDuration=28 ms, finalizationTime=13 ms).
INFO  - SourceCoordinator          - Marking checkpoint 6 as completed for source Source: sale_order[162].
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - CheckpointCoordinator      - Triggering checkpoint 6 (type=CheckpointType{name='Checkpoint', sharingFilesStrategy=FORWARD_BACKWARD}) @ 1699298199789 for job 1d1394375e4908f94ef8c8210cd9a417.
INFO  - CheckpointCoordinator      - Completed checkpoint 6 for job 1d1394375e4908f94ef8c8210cd9a417 (2016809 bytes, checkpointDuration=95 ms, finalizationTime=16 ms).
INFO  - SourceCoordinator          - Marking checkpoint 6 as completed for source Source: orders[21].
INFO  - SourceCoordinator          - Marking checkpoint 6 as completed for source Source: order_type[24].
INFO  - SourceCoordinator          - Marking checkpoint 6 as completed for source Source: encounter_type[42].
INFO  - SourceCoordinator          - Marking checkpoint 6 as completed for source Source: encounter[36].
INFO  - SourceCoordinator          - Marking checkpoint 6 as completed for source Source: care_setting[30].
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - CheckpointCoordinator      - Triggering checkpoint 6 (type=CheckpointType{name='Checkpoint', sharingFilesStrategy=FORWARD_BACKWARD}) @ 1699298230176 for job ee8b603bf5edab3af85b6467db69921f.
INFO  - CheckpointCoordinator      - Completed checkpoint 6 for job ee8b603bf5edab3af85b6467db69921f (225848010 bytes, checkpointDuration=407 ms, finalizationTime=29 ms).
INFO  - SourceCoordinator          - Marking checkpoint 6 as completed for source Source: obs[120].
INFO  - SourceCoordinator          - Marking checkpoint 6 as completed for source Source: concept_name[123].
INFO  - SourceCoordinator          - Marking checkpoint 6 as completed for source Source: visit[135].
INFO  - SourceCoordinator          - Marking checkpoint 6 as completed for source Source: visit_type[147].
INFO  - SourceCoordinator          - Marking checkpoint 6 as completed for source Source: location[153].
INFO  - SourceCoordinator          - Marking checkpoint 6 as completed for source Source: encounter[129].
INFO  - SourceCoordinator          - Marking checkpoint 6 as completed for source Source: encounter_type[141].
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight FETCH request with correlation id 6648 due to node 1 being disconnected (elapsed time since creation: 181ms, elapsed time since send: 181ms, request timeout: 30000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight FETCH request with correlation id 6645 due to node 1 being disconnected (elapsed time since creation: 66ms, elapsed time since send: 66ms, request timeout: 30000ms)
INFO  - FetchSessionHandler        - [Consumer clientId=flink-0, groupId=flink] Error sending fetch request (sessionId=64572831, epoch=4175) to node 1:
org.apache.kafka.common.errors.DisconnectException
INFO  - FetchSessionHandler        - [Consumer clientId=flink-0, groupId=flink] Error sending fetch request (sessionId=938000085, epoch=6611) to node 1:
org.apache.kafka.common.errors.DisconnectException
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight FETCH request with correlation id 6636 due to node 1 being disconnected (elapsed time since creation: 30ms, elapsed time since send: 30ms, request timeout: 30000ms)
INFO  - FetchSessionHandler        - [Consumer clientId=flink-0, groupId=flink] Error sending fetch request (sessionId=1415277380, epoch=4163) to node 1:
org.apache.kafka.common.errors.DisconnectException
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight FETCH request with correlation id 6640 due to node 1 being disconnected (elapsed time since creation: 31ms, elapsed time since send: 31ms, request timeout: 30000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - FetchSessionHandler        - [Consumer clientId=flink-0, groupId=flink] Error sending fetch request (sessionId=1410968537, epoch=6603) to node 1:
org.apache.kafka.common.errors.DisconnectException
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight FETCH request with correlation id 6634 due to node 1 being disconnected (elapsed time since creation: 30ms, elapsed time since send: 30ms, request timeout: 30000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight FETCH request with correlation id 6654 due to node 1 being disconnected (elapsed time since creation: 33ms, elapsed time since send: 33ms, request timeout: 30000ms)
INFO  - FetchSessionHandler        - [Consumer clientId=flink-0, groupId=flink] Error sending fetch request (sessionId=1731824349, epoch=4171) to node 1:
org.apache.kafka.common.errors.DisconnectException
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight FETCH request with correlation id 6649 due to node 1 being disconnected (elapsed time since creation: 153ms, elapsed time since send: 153ms, request timeout: 30000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - FetchSessionHandler        - [Consumer clientId=flink-0, groupId=flink] Error sending fetch request (sessionId=1086184133, epoch=6615) to node 1:
org.apache.kafka.common.errors.DisconnectException
INFO  - FetchSessionHandler        - [Consumer clientId=flink-0, groupId=flink] Error sending fetch request (sessionId=2075581798, epoch=6599) to node 1:
org.apache.kafka.common.errors.DisconnectException
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight FETCH request with correlation id 6646 due to node 1 being disconnected (elapsed time since creation: 31ms, elapsed time since send: 31ms, request timeout: 30000ms)
INFO  - FetchSessionHandler        - [Consumer clientId=flink-0, groupId=flink] Error sending fetch request (sessionId=608540715, epoch=4165) to node 1:
org.apache.kafka.common.errors.DisconnectException
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight FETCH request with correlation id 6645 due to node 1 being disconnected (elapsed time since creation: 31ms, elapsed time since send: 31ms, request timeout: 30000ms)
INFO  - FetchSessionHandler        - [Consumer clientId=flink-0, groupId=flink] Error sending fetch request (sessionId=265722358, epoch=6607) to node 1:
org.apache.kafka.common.errors.DisconnectException
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight FETCH request with correlation id 6640 due to node 1 being disconnected (elapsed time since creation: 31ms, elapsed time since send: 31ms, request timeout: 30000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight METADATA request with correlation id 6641 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 30000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - FetchSessionHandler        - [Consumer clientId=flink-0, groupId=flink] Error sending fetch request (sessionId=341468408, epoch=6606) to node 1:
org.apache.kafka.common.errors.DisconnectException
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight FETCH request with correlation id 6644 due to node 1 being disconnected (elapsed time since creation: 33ms, elapsed time since send: 33ms, request timeout: 30000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight FETCH request with correlation id 6638 due to node 1 being disconnected (elapsed time since creation: 144ms, elapsed time since send: 144ms, request timeout: 30000ms)
INFO  - FetchSessionHandler        - [Consumer clientId=flink-0, groupId=flink] Error sending fetch request (sessionId=1164289105, epoch=4166) to node 1:
org.apache.kafka.common.errors.DisconnectException
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight FETCH request with correlation id 6633 due to node 1 being disconnected (elapsed time since creation: 33ms, elapsed time since send: 33ms, request timeout: 30000ms)
INFO  - FetchSessionHandler        - [Consumer clientId=flink-0, groupId=flink] Error sending fetch request (sessionId=48018061, epoch=6607) to node 1:
org.apache.kafka.common.errors.DisconnectException
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight FETCH request with correlation id 6639 due to node 1 being disconnected (elapsed time since creation: 145ms, elapsed time since send: 145ms, request timeout: 30000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - FetchSessionHandler        - [Consumer clientId=flink-0, groupId=flink] Error sending fetch request (sessionId=615489712, epoch=4165) to node 1:
org.apache.kafka.common.errors.DisconnectException
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - FetchSessionHandler        - [Consumer clientId=flink-0, groupId=flink] Error sending fetch request (sessionId=1970009091, epoch=6603) to node 1:
org.apache.kafka.common.errors.DisconnectException
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight FETCH request with correlation id 6641 due to node 1 being disconnected (elapsed time since creation: 36ms, elapsed time since send: 36ms, request timeout: 30000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight METADATA request with correlation id 6642 due to node 1 being disconnected (elapsed time since creation: 13ms, elapsed time since send: 13ms, request timeout: 30000ms)
INFO  - FetchSessionHandler        - [Consumer clientId=flink-0, groupId=flink] Error sending fetch request (sessionId=1208572957, epoch=4169) to node 1:
org.apache.kafka.common.errors.DisconnectException
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight FETCH request with correlation id 6637 due to node 1 being disconnected (elapsed time since creation: 35ms, elapsed time since send: 35ms, request timeout: 30000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - FetchSessionHandler        - [Consumer clientId=flink-0, groupId=flink] Error sending fetch request (sessionId=1733237647, epoch=6601) to node 1:
org.apache.kafka.common.errors.DisconnectException
WARN  - ClientCnxn                 - Session 0x10009b90d4f0000 for server localhost/0:0:0:0:0:0:0:1:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException.
EndOfStreamException: Unable to read additional data from server sessionid 0x10009b90d4f0000, likely server has closed socket
	at org.apache.flink.shaded.zookeeper3.org.apache.zookeeper.ClientCnxnSocketNIO.doIO(ClientCnxnSocketNIO.java:77)
	at org.apache.flink.shaded.zookeeper3.org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:350)
	at org.apache.flink.shaded.zookeeper3.org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1283)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight FETCH request with correlation id 6646 due to node 1 being disconnected (elapsed time since creation: 73ms, elapsed time since send: 73ms, request timeout: 30000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight METADATA request with correlation id 6647 due to node 1 being disconnected (elapsed time since creation: 6ms, elapsed time since send: 6ms, request timeout: 30000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight FETCH request with correlation id 6642 due to node 1 being disconnected (elapsed time since creation: 73ms, elapsed time since send: 73ms, request timeout: 30000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight METADATA request with correlation id 6643 due to node 1 being disconnected (elapsed time since creation: 17ms, elapsed time since send: 17ms, request timeout: 30000ms)
INFO  - FetchSessionHandler        - [Consumer clientId=flink-0, groupId=flink] Error sending fetch request (sessionId=246398844, epoch=4167) to node 1:
org.apache.kafka.common.errors.DisconnectException
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight FETCH request with correlation id 6639 due to node 1 being disconnected (elapsed time since creation: 27ms, elapsed time since send: 27ms, request timeout: 30000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - FetchSessionHandler        - [Consumer clientId=flink-0, groupId=flink] Error sending fetch request (sessionId=1719470783, epoch=6609) to node 1:
org.apache.kafka.common.errors.DisconnectException
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight FETCH request with correlation id 6641 due to node 1 being disconnected (elapsed time since creation: 193ms, elapsed time since send: 193ms, request timeout: 30000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight METADATA request with correlation id 6640 due to node 1 being disconnected (elapsed time since creation: 7ms, elapsed time since send: 7ms, request timeout: 30000ms)
INFO  - FetchSessionHandler        - [Consumer clientId=flink-0, groupId=flink] Error sending fetch request (sessionId=985822046, epoch=6602) to node 1:
org.apache.kafka.common.errors.DisconnectException
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - FetchSessionHandler        - [Consumer clientId=flink-0, groupId=flink] Error sending fetch request (sessionId=195673535, epoch=6607) to node 1:
org.apache.kafka.common.errors.DisconnectException
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight FETCH request with correlation id 6648 due to node 1 being disconnected (elapsed time since creation: 78ms, elapsed time since send: 78ms, request timeout: 30000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight METADATA request with correlation id 6649 due to node 1 being disconnected (elapsed time since creation: 31ms, elapsed time since send: 31ms, request timeout: 30000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight FETCH request with correlation id 6636 due to node 1 being disconnected (elapsed time since creation: 51ms, elapsed time since send: 51ms, request timeout: 30000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - FetchSessionHandler        - [Consumer clientId=flink-0, groupId=flink] Error sending fetch request (sessionId=1599058344, epoch=4167) to node 1:
org.apache.kafka.common.errors.DisconnectException
INFO  - FetchSessionHandler        - [Consumer clientId=flink-0, groupId=flink] Error sending fetch request (sessionId=1773172377, epoch=4169) to node 1:
org.apache.kafka.common.errors.DisconnectException
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight FETCH request with correlation id 6646 due to node 1 being disconnected (elapsed time since creation: 54ms, elapsed time since send: 54ms, request timeout: 30000ms)
INFO  - FetchSessionHandler        - [Consumer clientId=flink-0, groupId=flink] Error sending fetch request (sessionId=1180973813, epoch=6609) to node 1:
org.apache.kafka.common.errors.DisconnectException
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight FETCH request with correlation id 6652 due to node 1 being disconnected (elapsed time since creation: 207ms, elapsed time since send: 207ms, request timeout: 30000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight METADATA request with correlation id 6653 due to node 1 being disconnected (elapsed time since creation: 36ms, elapsed time since send: 36ms, request timeout: 30000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight FETCH request with correlation id 6648 due to node 1 being disconnected (elapsed time since creation: 57ms, elapsed time since send: 57ms, request timeout: 30000ms)
INFO  - FetchSessionHandler        - [Consumer clientId=flink-0, groupId=flink] Error sending fetch request (sessionId=1115006175, epoch=6614) to node 1:
org.apache.kafka.common.errors.DisconnectException
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight METADATA request with correlation id 6649 due to node 1 being disconnected (elapsed time since creation: 23ms, elapsed time since send: 23ms, request timeout: 30000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - FetchSessionHandler        - [Consumer clientId=flink-0, groupId=flink] Error sending fetch request (sessionId=469634186, epoch=6612) to node 1:
org.apache.kafka.common.errors.DisconnectException
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight FETCH request with correlation id 6645 due to node 1 being disconnected (elapsed time since creation: 170ms, elapsed time since send: 170ms, request timeout: 30000ms)
INFO  - FetchSessionHandler        - [Consumer clientId=flink-0, groupId=flink] Error sending fetch request (sessionId=1266392180, epoch=4173) to node 1:
org.apache.kafka.common.errors.DisconnectException
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight FETCH request with correlation id 6638 due to node 1 being disconnected (elapsed time since creation: 219ms, elapsed time since send: 219ms, request timeout: 30000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight METADATA request with correlation id 6639 due to node 1 being disconnected (elapsed time since creation: 7ms, elapsed time since send: 7ms, request timeout: 30000ms)
INFO  - FetchSessionHandler        - [Consumer clientId=flink-0, groupId=flink] Error sending fetch request (sessionId=1742685388, epoch=4166) to node 1:
org.apache.kafka.common.errors.DisconnectException
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight FETCH request with correlation id 6649 due to node 1 being disconnected (elapsed time since creation: 58ms, elapsed time since send: 58ms, request timeout: 30000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight METADATA request with correlation id 6650 due to node 1 being disconnected (elapsed time since creation: 37ms, elapsed time since send: 37ms, request timeout: 30000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - FetchSessionHandler        - [Consumer clientId=flink-0, groupId=flink] Error sending fetch request (sessionId=1304826656, epoch=6612) to node 1:
org.apache.kafka.common.errors.DisconnectException
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight FETCH request with correlation id 6640 due to node 1 being disconnected (elapsed time since creation: 57ms, elapsed time since send: 57ms, request timeout: 30000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight METADATA request with correlation id 6641 due to node 1 being disconnected (elapsed time since creation: 28ms, elapsed time since send: 28ms, request timeout: 30000ms)
INFO  - FetchSessionHandler        - [Consumer clientId=flink-0, groupId=flink] Error sending fetch request (sessionId=224818672, epoch=4166) to node 1:
org.apache.kafka.common.errors.DisconnectException
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight FETCH request with correlation id 6642 due to node 1 being disconnected (elapsed time since creation: 85ms, elapsed time since send: 85ms, request timeout: 30000ms)
INFO  - FetchSessionHandler        - [Consumer clientId=flink-0, groupId=flink] Error sending fetch request (sessionId=280005020, epoch=6608) to node 1:
org.apache.kafka.common.errors.DisconnectException
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight FETCH request with correlation id 6655 due to node 1 being disconnected (elapsed time since creation: 220ms, elapsed time since send: 220ms, request timeout: 30000ms)
INFO  - FetchSessionHandler        - [Consumer clientId=flink-0, groupId=flink] Error sending fetch request (sessionId=1297463223, epoch=4175) to node 1:
org.apache.kafka.common.errors.DisconnectException
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight FETCH request with correlation id 6639 due to node 1 being disconnected (elapsed time since creation: 49ms, elapsed time since send: 49ms, request timeout: 30000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight METADATA request with correlation id 6640 due to node 1 being disconnected (elapsed time since creation: 27ms, elapsed time since send: 27ms, request timeout: 30000ms)
INFO  - FetchSessionHandler        - [Consumer clientId=flink-0, groupId=flink] Error sending fetch request (sessionId=1816412449, epoch=6604) to node 1:
org.apache.kafka.common.errors.DisconnectException
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight FETCH request with correlation id 6640 due to node 1 being disconnected (elapsed time since creation: 218ms, elapsed time since send: 218ms, request timeout: 30000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight METADATA request with correlation id 6641 due to node 1 being disconnected (elapsed time since creation: 31ms, elapsed time since send: 31ms, request timeout: 30000ms)
INFO  - FetchSessionHandler        - [Consumer clientId=flink-0, groupId=flink] Error sending fetch request (sessionId=942806470, epoch=6603) to node 1:
org.apache.kafka.common.errors.DisconnectException
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight FETCH request with correlation id 6642 due to node 1 being disconnected (elapsed time since creation: 102ms, elapsed time since send: 102ms, request timeout: 30000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight METADATA request with correlation id 6643 due to node 1 being disconnected (elapsed time since creation: 35ms, elapsed time since send: 35ms, request timeout: 30000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - FetchSessionHandler        - [Consumer clientId=flink-0, groupId=flink] Error sending fetch request (sessionId=2035892408, epoch=6605) to node 1:
org.apache.kafka.common.errors.DisconnectException
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight FETCH request with correlation id 4806 due to node 1 being disconnected (elapsed time since creation: 188ms, elapsed time since send: 188ms, request timeout: 30000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight METADATA request with correlation id 4807 due to node 1 being disconnected (elapsed time since creation: 46ms, elapsed time since send: 46ms, request timeout: 30000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight FETCH request with correlation id 6639 due to node 1 being disconnected (elapsed time since creation: 113ms, elapsed time since send: 113ms, request timeout: 30000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight METADATA request with correlation id 6640 due to node 1 being disconnected (elapsed time since creation: 9ms, elapsed time since send: 9ms, request timeout: 30000ms)
INFO  - FetchSessionHandler        - [Consumer clientId=flink-0, groupId=flink] Error sending fetch request (sessionId=1393710635, epoch=4163) to node 1:
org.apache.kafka.common.errors.DisconnectException
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight FETCH request with correlation id 6637 due to node 1 being disconnected (elapsed time since creation: 52ms, elapsed time since send: 52ms, request timeout: 30000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight METADATA request with correlation id 6638 due to node 1 being disconnected (elapsed time since creation: 10ms, elapsed time since send: 10ms, request timeout: 30000ms)
INFO  - FetchSessionHandler        - [Consumer clientId=flink-0, groupId=flink] Error sending fetch request (sessionId=491450140, epoch=4164) to node 1:
org.apache.kafka.common.errors.DisconnectException
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight FETCH request with correlation id 6647 due to node 1 being disconnected (elapsed time since creation: 113ms, elapsed time since send: 113ms, request timeout: 30000ms)
INFO  - FetchSessionHandler        - [Consumer clientId=flink-0, groupId=flink] Error sending fetch request (sessionId=1961014501, epoch=4740) to node 1:
org.apache.kafka.common.errors.DisconnectException
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight METADATA request with correlation id 6648 due to node 1 being disconnected (elapsed time since creation: 34ms, elapsed time since send: 34ms, request timeout: 30000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight FETCH request with correlation id 6637 due to node 1 being disconnected (elapsed time since creation: 224ms, elapsed time since send: 224ms, request timeout: 30000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight METADATA request with correlation id 6638 due to node 1 being disconnected (elapsed time since creation: 6ms, elapsed time since send: 6ms, request timeout: 30000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - FetchSessionHandler        - [Consumer clientId=flink-0, groupId=flink] Error sending fetch request (sessionId=730708495, epoch=6600) to node 1:
org.apache.kafka.common.errors.DisconnectException
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight FETCH request with correlation id 6650 due to node 1 being disconnected (elapsed time since creation: 91ms, elapsed time since send: 91ms, request timeout: 30000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight METADATA request with correlation id 6651 due to node 1 being disconnected (elapsed time since creation: 34ms, elapsed time since send: 34ms, request timeout: 30000ms)
INFO  - FetchSessionHandler        - [Consumer clientId=flink-0, groupId=flink] Error sending fetch request (sessionId=1201561274, epoch=6616) to node 1:
org.apache.kafka.common.errors.DisconnectException
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 2147483646 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight FETCH request with correlation id 6640 due to node 1 being disconnected (elapsed time since creation: 57ms, elapsed time since send: 57ms, request timeout: 30000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight METADATA request with correlation id 6641 due to node 1 being disconnected (elapsed time since creation: 38ms, elapsed time since send: 38ms, request timeout: 30000ms)
INFO  - FetchSessionHandler        - [Consumer clientId=flink-0, groupId=flink] Error sending fetch request (sessionId=621245002, epoch=4173) to node 1:
org.apache.kafka.common.errors.DisconnectException
INFO  - FetchSessionHandler        - [Consumer clientId=flink-0, groupId=flink] Error sending fetch request (sessionId=1279499233, epoch=6604) to node 1:
org.apache.kafka.common.errors.DisconnectException
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6640 due to node 1 being disconnected (elapsed time since creation: 4ms, elapsed time since send: 4ms, request timeout: 30000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 25 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 25 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 25 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 25 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 25 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 25 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 25 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 25 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 25 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6642 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 30000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6646 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 30000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 25 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 25 due to node 1 being disconnected (elapsed time since creation: 0ms, elapsed time since send: 0ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 25 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 25 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 25 due to node 1 being disconnected (elapsed time since creation: 0ms, elapsed time since send: 0ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 25 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 25 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6643 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 30000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 25 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 25 due to node 1 being disconnected (elapsed time since creation: 0ms, elapsed time since send: 0ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 25 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 25 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6644 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 30000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6642 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 30000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6648 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 30000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 25 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6641 due to node 1 being disconnected (elapsed time since creation: 0ms, elapsed time since send: 0ms, request timeout: 30000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 25 due to node 1 being disconnected (elapsed time since creation: 6ms, elapsed time since send: 6ms, request timeout: 3600000ms)
INFO  - ConnectionStateManager     - State change: SUSPENDED
WARN  - eeperLeaderRetrievalDriver - Connection to ZooKeeper suspended, waiting for reconnection.
WARN  - eeperLeaderRetrievalDriver - Connection to ZooKeeper suspended, waiting for reconnection.
INFO  - TaskExecutor               - JobManager for job 8f9053c77be2be6dcb80fb69df68baf8 with leader id b46c7fb86bd673d43a82a6cefb624610 lost leadership.
INFO  - StandaloneResourceManager  - Disconnect job manager b46c7fb86bd673d43a82a6cefb624610@akka://flink/user/rpc/jobmanager_10 for job 6cadd3411b812f5aeb1f461ff6051653 from the resource manager.
INFO  - JobMaster                  - Close ResourceManager connection 6e4eb064b0070507828e621c049921bd: Job leader lost leadership.
INFO  - JobMaster                  - Connecting to ResourceManager akka://flink/user/rpc/resourcemanager_1(b46c7fb86bd673d43a82a6cefb624610)
WARN  - eeperLeaderRetrievalDriver - Connection to ZooKeeper suspended, waiting for reconnection.
INFO  - TaskExecutor               - JobManager for job a8681efc52437137d28ae75be94f64e1 with leader id b46c7fb86bd673d43a82a6cefb624610 lost leadership.
WARN  - eeperLeaderRetrievalDriver - Connection to ZooKeeper suspended, waiting for reconnection.
INFO  - TaskExecutor               - Close JobManager connection for job 8f9053c77be2be6dcb80fb69df68baf8.
WARN  - eeperLeaderRetrievalDriver - Connection to ZooKeeper suspended, waiting for reconnection.
INFO  - TaskExecutor               - JobManager for job 3b099420ea7206c78ac6154209036e81 with leader id b46c7fb86bd673d43a82a6cefb624610 lost leadership.
WARN  - eeperLeaderRetrievalDriver - Connection to ZooKeeper suspended, waiting for reconnection.
WARN  - KeeperJobGraphStoreWatcher - ZooKeeper connection SUSPENDING. Changes to the submitted job graphs are not monitored (temporarily).
INFO  - Task                       - Attempting to fail task externally Source: concept_name[209] -> Calc[210] (1/1)#0 (2ff118f32116f826e0d468907bf12d2a_2963852293169ba90d9d1e7d6308db5c_0_0).
INFO  - JobMaster                  - Close ResourceManager connection 6e4eb064b0070507828e621c049921bd: ResourceManager leader changed to new address null
INFO  - StandaloneResourceManager  - Disconnect job manager b46c7fb86bd673d43a82a6cefb624610@akka://flink/user/rpc/jobmanager_5 for job 9deef106e67c2b1f77d94f2e02251d44 from the resource manager.
WARN  - ponentLeaderElectionDriver - Connection to ZooKeeper suspended, waiting for reconnection.
WARN  - eeperLeaderRetrievalDriver - Connection to ZooKeeper suspended, waiting for reconnection.
WARN  - eeperLeaderRetrievalDriver - Connection to ZooKeeper suspended, waiting for reconnection.
WARN  - eeperLeaderRetrievalDriver - Connection to ZooKeeper suspended, waiting for reconnection.
INFO  - TaskExecutor               - JobManager for job 9deef106e67c2b1f77d94f2e02251d44 with leader id b46c7fb86bd673d43a82a6cefb624610 lost leadership.
WARN  - eeperLeaderRetrievalDriver - Connection to ZooKeeper suspended, waiting for reconnection.
WARN  - eeperLeaderRetrievalDriver - Connection to ZooKeeper suspended, waiting for reconnection.
WARN  - eeperLeaderRetrievalDriver - Connection to ZooKeeper suspended, waiting for reconnection.
INFO  - StandaloneResourceManager  - Disconnect job manager b46c7fb86bd673d43a82a6cefb624610@akka://flink/user/rpc/jobmanager_9 for job ee8b603bf5edab3af85b6467db69921f from the resource manager.
INFO  - StandaloneResourceManager  - Disconnect job manager b46c7fb86bd673d43a82a6cefb624610@akka://flink/user/rpc/jobmanager_6 for job 3450ce4e11df2cb7a382b3520dc37240 from the resource manager.
WARN  - eeperLeaderRetrievalDriver - Connection to ZooKeeper suspended, waiting for reconnection.
INFO  - StandaloneResourceManager  - Disconnect job manager b46c7fb86bd673d43a82a6cefb624610@akka://flink/user/rpc/jobmanager_13 for job 8f9053c77be2be6dcb80fb69df68baf8 from the resource manager.
INFO  - JobMaster                  - Close ResourceManager connection 6e4eb064b0070507828e621c049921bd: Job leader lost leadership.
INFO  - JobMaster                  - Close ResourceManager connection 6e4eb064b0070507828e621c049921bd: Job leader lost leadership.
WARN  - eeperLeaderRetrievalDriver - Connection to ZooKeeper suspended, waiting for reconnection.
WARN  - eeperLeaderRetrievalDriver - Connection to ZooKeeper suspended, waiting for reconnection.
INFO  - JobMaster                  - Connecting to ResourceManager akka://flink/user/rpc/resourcemanager_1(b46c7fb86bd673d43a82a6cefb624610)
INFO  - JobMaster                  - Connecting to ResourceManager akka://flink/user/rpc/resourcemanager_1(b46c7fb86bd673d43a82a6cefb624610)
WARN  - eeperLeaderRetrievalDriver - Connection to ZooKeeper suspended, waiting for reconnection.
WARN  - eeperLeaderRetrievalDriver - Connection to ZooKeeper suspended, waiting for reconnection.
INFO  - StandaloneResourceManager  - Disconnect job manager b46c7fb86bd673d43a82a6cefb624610@akka://flink/user/rpc/jobmanager_11 for job c3c54da01848bf81457a865e46b38d18 from the resource manager.
WARN  - eeperLeaderRetrievalDriver - Connection to ZooKeeper suspended, waiting for reconnection.
INFO  - TaskExecutor               - JobManager for job 6cadd3411b812f5aeb1f461ff6051653 with leader id b46c7fb86bd673d43a82a6cefb624610 lost leadership.
WARN  - eeperLeaderRetrievalDriver - Connection to ZooKeeper suspended, waiting for reconnection.
INFO  - TaskExecutor               - JobManager for job 30b4315f4dce6b8b0d1d34062dbea1c2 with leader id b46c7fb86bd673d43a82a6cefb624610 lost leadership.
INFO  - JobMaster                  - Close ResourceManager connection 6e4eb064b0070507828e621c049921bd: Job leader lost leadership.
WARN  - eeperLeaderRetrievalDriver - Connection to ZooKeeper suspended, waiting for reconnection.
INFO  - JobMaster                  - Connecting to ResourceManager akka://flink/user/rpc/resourcemanager_1(b46c7fb86bd673d43a82a6cefb624610)
WARN  - eeperLeaderRetrievalDriver - Connection to ZooKeeper suspended, waiting for reconnection.
INFO  - JobMaster                  - Close ResourceManager connection 6e4eb064b0070507828e621c049921bd: Job leader lost leadership.
INFO  - TaskExecutor               - JobManager for job 3450ce4e11df2cb7a382b3520dc37240 with leader id b46c7fb86bd673d43a82a6cefb624610 lost leadership.
INFO  - JobMaster                  - Connecting to ResourceManager akka://flink/user/rpc/resourcemanager_1(b46c7fb86bd673d43a82a6cefb624610)
INFO  - StandaloneResourceManager  - Disconnect job manager b46c7fb86bd673d43a82a6cefb624610@akka://flink/user/rpc/jobmanager_3 for job 30b4315f4dce6b8b0d1d34062dbea1c2 from the resource manager.
WARN  - eeperLeaderRetrievalDriver - Connection to ZooKeeper suspended, waiting for reconnection.
INFO  - TaskExecutor               - JobManager for job e08bfbac0c29fa3541fbb236ff4c9568 with leader id b46c7fb86bd673d43a82a6cefb624610 lost leadership.
INFO  - JobMaster                  - Close ResourceManager connection 6e4eb064b0070507828e621c049921bd: Job leader lost leadership.
INFO  - JobMaster                  - Connecting to ResourceManager akka://flink/user/rpc/resourcemanager_1(b46c7fb86bd673d43a82a6cefb624610)
INFO  - JobMaster                  - Close ResourceManager connection 6e4eb064b0070507828e621c049921bd: ResourceManager leader changed to new address null
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 25 due to node 1 being disconnected (elapsed time since creation: 5ms, elapsed time since send: 5ms, request timeout: 3600000ms)
INFO  - StandaloneResourceManager  - Disconnect job manager b46c7fb86bd673d43a82a6cefb624610@akka://flink/user/rpc/jobmanager_7 for job 3b099420ea7206c78ac6154209036e81 from the resource manager.
INFO  - JobMaster                  - Resolved ResourceManager address, beginning registration
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6650 due to node 1 being disconnected (elapsed time since creation: 6ms, elapsed time since send: 6ms, request timeout: 30000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6641 due to node 1 being disconnected (elapsed time since creation: 6ms, elapsed time since send: 6ms, request timeout: 30000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 25 due to node 1 being disconnected (elapsed time since creation: 7ms, elapsed time since send: 7ms, request timeout: 3600000ms)
WARN  - Task                       - Source: concept_name[209] -> Calc[210] (1/1)#0 (2ff118f32116f826e0d468907bf12d2a_2963852293169ba90d9d1e7d6308db5c_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for 8f9053c77be2be6dcb80fb69df68baf8.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id 8f9053c77be2be6dcb80fb69df68baf8 lost leadership.
	... 29 more
WARN  - eeperLeaderRetrievalDriver - Connection to ZooKeeper suspended, waiting for reconnection.
INFO  - JobMaster                  - Resolved ResourceManager address, beginning registration
INFO  - JobMaster                  - Resolved ResourceManager address, beginning registration
INFO  - JobMaster                  - Resolved ResourceManager address, beginning registration
WARN  - eeperLeaderRetrievalDriver - Connection to ZooKeeper suspended, waiting for reconnection.
WARN  - eeperLeaderRetrievalDriver - Connection to ZooKeeper suspended, waiting for reconnection.
INFO  - Task                       - Triggering cancellation of task code Source: concept_name[209] -> Calc[210] (1/1)#0 (2ff118f32116f826e0d468907bf12d2a_2963852293169ba90d9d1e7d6308db5c_0_0).
WARN  - eeperLeaderRetrievalDriver - Connection to ZooKeeper suspended, waiting for reconnection.
WARN  - eeperLeaderRetrievalDriver - Connection to ZooKeeper suspended, waiting for reconnection.
WARN  - eeperLeaderRetrievalDriver - Connection to ZooKeeper suspended, waiting for reconnection.
WARN  - eeperLeaderRetrievalDriver - Connection to ZooKeeper suspended, waiting for reconnection.
INFO  - JobMaster                  - Resolved ResourceManager address, beginning registration
WARN  - eeperLeaderRetrievalDriver - Connection to ZooKeeper suspended, waiting for reconnection.
WARN  - eeperLeaderRetrievalDriver - Connection to ZooKeeper suspended, waiting for reconnection.
WARN  - eeperLeaderRetrievalDriver - Connection to ZooKeeper suspended, waiting for reconnection.
INFO  - TaskExecutor               - JobManager for job 1d1394375e4908f94ef8c8210cd9a417 with leader id b46c7fb86bd673d43a82a6cefb624610 lost leadership.
WARN  - eeperLeaderRetrievalDriver - Connection to ZooKeeper suspended, waiting for reconnection.
WARN  - eeperLeaderRetrievalDriver - Connection to ZooKeeper suspended, waiting for reconnection.
WARN  - eeperLeaderRetrievalDriver - Connection to ZooKeeper suspended, waiting for reconnection.
WARN  - eeperLeaderRetrievalDriver - Connection to ZooKeeper suspended, waiting for reconnection.
WARN  - eeperLeaderRetrievalDriver - Connection to ZooKeeper suspended, waiting for reconnection.
INFO  - TaskExecutor               - JobManager for job ee8b603bf5edab3af85b6467db69921f with leader id b46c7fb86bd673d43a82a6cefb624610 lost leadership.
WARN  - eeperLeaderRetrievalDriver - Connection to ZooKeeper suspended, waiting for reconnection.
WARN  - eeperLeaderRetrievalDriver - Connection to ZooKeeper suspended, waiting for reconnection.
INFO  - TaskExecutor               - JobManager for job c3c54da01848bf81457a865e46b38d18 with leader id b46c7fb86bd673d43a82a6cefb624610 lost leadership.
INFO  - JobMaster                  - Resolved ResourceManager address, beginning registration
INFO  - JobMaster                  - Close ResourceManager connection 6e4eb064b0070507828e621c049921bd: ResourceManager leader changed to new address null
INFO  - StandaloneResourceManager  - Disconnect job manager b46c7fb86bd673d43a82a6cefb624610@akka://flink/user/rpc/jobmanager_12 for job a8681efc52437137d28ae75be94f64e1 from the resource manager.
INFO  - JobMaster                  - Close ResourceManager connection 6e4eb064b0070507828e621c049921bd: ResourceManager leader changed to new address null
INFO  - JobMaster                  - Close ResourceManager connection 6e4eb064b0070507828e621c049921bd: ResourceManager leader changed to new address null
INFO  - StandaloneResourceManager  - Disconnect job manager b46c7fb86bd673d43a82a6cefb624610@akka://flink/user/rpc/jobmanager_4 for job 1d1394375e4908f94ef8c8210cd9a417 from the resource manager.
INFO  - StandaloneResourceManager  - Disconnect job manager b46c7fb86bd673d43a82a6cefb624610@akka://flink/user/rpc/jobmanager_8 for job e08bfbac0c29fa3541fbb236ff4c9568 from the resource manager.
INFO  - StandaloneResourceManager  - Registering job manager b46c7fb86bd673d43a82a6cefb624610@akka://flink/user/rpc/jobmanager_6 for job 3450ce4e11df2cb7a382b3520dc37240.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 25 due to node 1 being disconnected (elapsed time since creation: 12ms, elapsed time since send: 12ms, request timeout: 3600000ms)
INFO  - StandaloneResourceManager  - Registering job manager b46c7fb86bd673d43a82a6cefb624610@akka://flink/user/rpc/jobmanager_11 for job c3c54da01848bf81457a865e46b38d18.
INFO  - terServiceLeadershipRunner - JobMasterServiceLeadershipRunner for job 30b4315f4dce6b8b0d1d34062dbea1c2 was revoked leadership with leader id 3a82a6ce-fb62-4610-b46c-7fb86bd673d4. Stopping current JobMasterServiceProcess.
INFO  - StandaloneResourceManager  - Registering job manager b46c7fb86bd673d43a82a6cefb624610@akka://flink/user/rpc/jobmanager_9 for job ee8b603bf5edab3af85b6467db69921f.
INFO  - StandaloneResourceManager  - Registering job manager b46c7fb86bd673d43a82a6cefb624610@akka://flink/user/rpc/jobmanager_3 for job 30b4315f4dce6b8b0d1d34062dbea1c2.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6650 due to node 1 being disconnected (elapsed time since creation: 9ms, elapsed time since send: 9ms, request timeout: 30000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6649 due to node 1 being disconnected (elapsed time since creation: 10ms, elapsed time since send: 10ms, request timeout: 30000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 25 due to node 1 being disconnected (elapsed time since creation: 9ms, elapsed time since send: 9ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6634 due to node 1 being disconnected (elapsed time since creation: 9ms, elapsed time since send: 9ms, request timeout: 30000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6647 due to node 1 being disconnected (elapsed time since creation: 11ms, elapsed time since send: 11ms, request timeout: 30000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 25 due to node 1 being disconnected (elapsed time since creation: 12ms, elapsed time since send: 12ms, request timeout: 3600000ms)
INFO  - Task                       - Attempting to fail task externally Join[212] -> Calc[213] (1/1)#0 (2ff118f32116f826e0d468907bf12d2a_d7e78c81a38d2cce4433a75795131bcf_0_0).
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 25 due to node 1 being disconnected (elapsed time since creation: 8ms, elapsed time since send: 8ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6654 due to node 1 being disconnected (elapsed time since creation: 9ms, elapsed time since send: 9ms, request timeout: 30000ms)
WARN  - Task                       - Join[212] -> Calc[213] (1/1)#0 (2ff118f32116f826e0d468907bf12d2a_d7e78c81a38d2cce4433a75795131bcf_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for 8f9053c77be2be6dcb80fb69df68baf8.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id 8f9053c77be2be6dcb80fb69df68baf8 lost leadership.
	... 29 more
INFO  - Task                       - Triggering cancellation of task code Join[212] -> Calc[213] (1/1)#0 (2ff118f32116f826e0d468907bf12d2a_d7e78c81a38d2cce4433a75795131bcf_0_0).
INFO  - Task                       - Attempting to fail task externally SinkMaterializer[217] -> Sink: patient_programs[217] (1/1)#0 (2ff118f32116f826e0d468907bf12d2a_8fc3be823cc75a93eb3f11ae7a596b08_0_0).
WARN  - Task                       - SinkMaterializer[217] -> Sink: patient_programs[217] (1/1)#0 (2ff118f32116f826e0d468907bf12d2a_8fc3be823cc75a93eb3f11ae7a596b08_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for 8f9053c77be2be6dcb80fb69df68baf8.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id 8f9053c77be2be6dcb80fb69df68baf8 lost leadership.
	... 29 more
INFO  - Task                       - Triggering cancellation of task code SinkMaterializer[217] -> Sink: patient_programs[217] (1/1)#0 (2ff118f32116f826e0d468907bf12d2a_8fc3be823cc75a93eb3f11ae7a596b08_0_0).
INFO  - terServiceLeadershipRunner - JobMasterServiceLeadershipRunner for job 3450ce4e11df2cb7a382b3520dc37240 was revoked leadership with leader id 3a82a6ce-fb62-4610-b46c-7fb86bd673d4. Stopping current JobMasterServiceProcess.
INFO  - JobMaster                  - Stopping the JobMaster for job 'insert-into_analytics.analytics.appointments' (30b4315f4dce6b8b0d1d34062dbea1c2).
INFO  - ResourceManagerServiceImpl - Resource manager service is revoked leadership with session id 3a82a6ce-fb62-4610-b46c-7fb86bd673d4.
INFO  - terServiceLeadershipRunner - JobMasterServiceLeadershipRunner for job ee8b603bf5edab3af85b6467db69921f was revoked leadership with leader id 3a82a6ce-fb62-4610-b46c-7fb86bd673d4. Stopping current JobMasterServiceProcess.
INFO  - JobMaster                  - Stopping the JobMaster for job 'insert-into_analytics.analytics.patients' (3450ce4e11df2cb7a382b3520dc37240).
INFO  - Task                       - Attempting to fail task externally Join[215] -> Calc[216] -> ConstraintEnforcer[217] (1/1)#0 (2ff118f32116f826e0d468907bf12d2a_27b913f6385bb0e404cc1ac792473af7_0_0).
WARN  - Task                       - Join[215] -> Calc[216] -> ConstraintEnforcer[217] (1/1)#0 (2ff118f32116f826e0d468907bf12d2a_27b913f6385bb0e404cc1ac792473af7_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for 8f9053c77be2be6dcb80fb69df68baf8.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id 8f9053c77be2be6dcb80fb69df68baf8 lost leadership.
	... 29 more
INFO  - Task                       - Triggering cancellation of task code Join[215] -> Calc[216] -> ConstraintEnforcer[217] (1/1)#0 (2ff118f32116f826e0d468907bf12d2a_27b913f6385bb0e404cc1ac792473af7_0_0).
INFO  - DispatcherRestEndpoint     - http://localhost:8081 lost leadership
INFO  - terServiceLeadershipRunner - JobMasterServiceLeadershipRunner for job 1d1394375e4908f94ef8c8210cd9a417 was revoked leadership with leader id 3a82a6ce-fb62-4610-b46c-7fb86bd673d4. Stopping current JobMasterServiceProcess.
INFO  - terServiceLeadershipRunner - JobMasterServiceLeadershipRunner for job 3b099420ea7206c78ac6154209036e81 was revoked leadership with leader id 3a82a6ce-fb62-4610-b46c-7fb86bd673d4. Stopping current JobMasterServiceProcess.
INFO  - terServiceLeadershipRunner - JobMasterServiceLeadershipRunner for job c3c54da01848bf81457a865e46b38d18 was revoked leadership with leader id 3a82a6ce-fb62-4610-b46c-7fb86bd673d4. Stopping current JobMasterServiceProcess.
INFO  - terServiceLeadershipRunner - JobMasterServiceLeadershipRunner for job e08bfbac0c29fa3541fbb236ff4c9568 was revoked leadership with leader id 3a82a6ce-fb62-4610-b46c-7fb86bd673d4. Stopping current JobMasterServiceProcess.
INFO  - teWriteRequestExecutorImpl - discarding 1 drained requests
INFO  - aultDelegationTokenManager - Stopping credential renewal
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - aultDelegationTokenManager - Stopped credential renewal
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6640 due to node 1 being disconnected (elapsed time since creation: 13ms, elapsed time since send: 13ms, request timeout: 30000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6642 due to node 1 being disconnected (elapsed time since creation: 13ms, elapsed time since send: 13ms, request timeout: 30000ms)
INFO  - DeclarativeSlotManager     - Closing the slot manager.
INFO  - DeclarativeSlotManager     - Suspending the slot manager.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6646 due to node 1 being disconnected (elapsed time since creation: 13ms, elapsed time since send: 13ms, request timeout: 30000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6651 due to node 1 being disconnected (elapsed time since creation: 13ms, elapsed time since send: 13ms, request timeout: 30000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6650 due to node 1 being disconnected (elapsed time since creation: 13ms, elapsed time since send: 13ms, request timeout: 30000ms)
INFO  - Task                       - Attempting to fail task externally Join[206] -> Calc[207] (1/1)#0 (2ff118f32116f826e0d468907bf12d2a_5b6b7f98d5bff23034589a7675c38ac7_0_0).
WARN  - Task                       - Join[206] -> Calc[207] (1/1)#0 (2ff118f32116f826e0d468907bf12d2a_5b6b7f98d5bff23034589a7675c38ac7_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for 8f9053c77be2be6dcb80fb69df68baf8.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id 8f9053c77be2be6dcb80fb69df68baf8 lost leadership.
	... 29 more
INFO  - Task                       - Triggering cancellation of task code Join[206] -> Calc[207] (1/1)#0 (2ff118f32116f826e0d468907bf12d2a_5b6b7f98d5bff23034589a7675c38ac7_0_0).
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6641 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 30000ms)
INFO  - aultLeaderRetrievalService - Stopping DefaultLeaderRetrievalService.
INFO  - eeperLeaderRetrievalDriver - Closing ZookeeperLeaderRetrievalDriver{connectionInformationPath='/6cadd3411b812f5aeb1f461ff6051653/connection_info'}.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 25 due to node 1 being disconnected (elapsed time since creation: 51ms, elapsed time since send: 51ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 25 due to node 1 being disconnected (elapsed time since creation: 59ms, elapsed time since send: 59ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 25 due to node 1 being disconnected (elapsed time since creation: 54ms, elapsed time since send: 54ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6641 due to node 1 being disconnected (elapsed time since creation: 52ms, elapsed time since send: 52ms, request timeout: 30000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6655 due to node 1 being disconnected (elapsed time since creation: 50ms, elapsed time since send: 50ms, request timeout: 30000ms)
INFO  - Task                       - Attempting to fail task externally Source: patient_program[201] (1/1)#0 (2ff118f32116f826e0d468907bf12d2a_bc764cd8ddf7a0cff126f51c16239658_0_0).
INFO  - SourceReaderBase           - Closing Source Reader.
WARN  - Task                       - Source: patient_program[201] (1/1)#0 (2ff118f32116f826e0d468907bf12d2a_bc764cd8ddf7a0cff126f51c16239658_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for 8f9053c77be2be6dcb80fb69df68baf8.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id 8f9053c77be2be6dcb80fb69df68baf8 lost leadership.
	... 29 more
INFO  - Task                       - Triggering cancellation of task code Source: patient_program[201] (1/1)#0 (2ff118f32116f826e0d468907bf12d2a_bc764cd8ddf7a0cff126f51c16239658_0_0).
INFO  - aultLeaderRetrievalService - Stopping DefaultLeaderRetrievalService.
INFO  - eeperLeaderRetrievalDriver - Closing ZookeeperLeaderRetrievalDriver{connectionInformationPath='/8f9053c77be2be6dcb80fb69df68baf8/connection_info'}.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 25 due to node 1 being disconnected (elapsed time since creation: 52ms, elapsed time since send: 52ms, request timeout: 3600000ms)
INFO  - aultLeaderRetrievalService - Stopping DefaultLeaderRetrievalService.
INFO  - eeperLeaderRetrievalDriver - Closing ZookeeperLeaderRetrievalDriver{connectionInformationPath='/e08bfbac0c29fa3541fbb236ff4c9568/connection_info'}.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 25 due to node 1 being disconnected (elapsed time since creation: 52ms, elapsed time since send: 52ms, request timeout: 3600000ms)
INFO  - SplitFetcher               - Shutting down split fetcher 0
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 25 due to node 1 being disconnected (elapsed time since creation: 52ms, elapsed time since send: 52ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 25 due to node 1 being disconnected (elapsed time since creation: 53ms, elapsed time since send: 53ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 25 due to node 1 being disconnected (elapsed time since creation: 53ms, elapsed time since send: 53ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6647 due to node 1 being disconnected (elapsed time since creation: 53ms, elapsed time since send: 53ms, request timeout: 30000ms)
INFO  - Task                       - Attempting to fail task externally Source: program[203] -> Calc[204] (1/1)#0 (2ff118f32116f826e0d468907bf12d2a_6cdc5bb954874d922eaee11a8e7b5dd5_0_0).
WARN  - Task                       - Source: program[203] -> Calc[204] (1/1)#0 (2ff118f32116f826e0d468907bf12d2a_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for 8f9053c77be2be6dcb80fb69df68baf8.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id 8f9053c77be2be6dcb80fb69df68baf8 lost leadership.
	... 29 more
INFO  - Task                       - Triggering cancellation of task code Source: program[203] -> Calc[204] (1/1)#0 (2ff118f32116f826e0d468907bf12d2a_6cdc5bb954874d922eaee11a8e7b5dd5_0_0).
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 25 due to node 1 being disconnected (elapsed time since creation: 53ms, elapsed time since send: 53ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6635 due to node 1 being disconnected (elapsed time since creation: 53ms, elapsed time since send: 53ms, request timeout: 30000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - ExecutionGraph             - Job insert-into_analytics.analytics.appointments (30b4315f4dce6b8b0d1d34062dbea1c2) switched from state RUNNING to SUSPENDED.
org.apache.flink.util.FlinkException: Scheduler is being stopped.
	at org.apache.flink.runtime.scheduler.SchedulerBase.closeAsync(SchedulerBase.java:646)
	at org.apache.flink.runtime.jobmaster.JobMaster.stopScheduling(JobMaster.java:1051)
	at org.apache.flink.runtime.jobmaster.JobMaster.stopJobExecution(JobMaster.java:1014)
	at org.apache.flink.runtime.jobmaster.JobMaster.onStop(JobMaster.java:442)
	at org.apache.flink.runtime.rpc.RpcEndpoint.internalCallOnStop(RpcEndpoint.java:239)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor$StartedState.lambda$terminate$0(AkkaRpcActor.java:578)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:83)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor$StartedState.terminate(AkkaRpcActor.java:577)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleControlMessage(AkkaRpcActor.java:196)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6637 due to node 1 being disconnected (elapsed time since creation: 54ms, elapsed time since send: 54ms, request timeout: 30000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6646 due to node 1 being disconnected (elapsed time since creation: 53ms, elapsed time since send: 53ms, request timeout: 30000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6638 due to node 1 being disconnected (elapsed time since creation: 44ms, elapsed time since send: 44ms, request timeout: 30000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 25 due to node 1 being disconnected (elapsed time since creation: 54ms, elapsed time since send: 54ms, request timeout: 3600000ms)
INFO  - teWriteRequestExecutorImpl - discarding 1 drained requests
INFO  - SourceReaderBase           - Closing Source Reader.
INFO  - SplitFetcher               - Shutting down split fetcher 0
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6639 due to node 1 being disconnected (elapsed time since creation: 43ms, elapsed time since send: 43ms, request timeout: 30000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 4808 due to node 1 being disconnected (elapsed time since creation: 45ms, elapsed time since send: 45ms, request timeout: 30000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 25 due to node 1 being disconnected (elapsed time since creation: 43ms, elapsed time since send: 43ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6644 due to node 1 being disconnected (elapsed time since creation: 43ms, elapsed time since send: 43ms, request timeout: 30000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Request joining group due to: consumer pro-actively leaving the group
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 25 due to node 1 being disconnected (elapsed time since creation: 48ms, elapsed time since send: 48ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6645 due to node 1 being disconnected (elapsed time since creation: 43ms, elapsed time since send: 43ms, request timeout: 30000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6637 due to node 1 being disconnected (elapsed time since creation: 43ms, elapsed time since send: 43ms, request timeout: 30000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6656 due to node 1 being disconnected (elapsed time since creation: 44ms, elapsed time since send: 44ms, request timeout: 30000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6641 due to node 1 being disconnected (elapsed time since creation: 45ms, elapsed time since send: 45ms, request timeout: 30000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6652 due to node 1 being disconnected (elapsed time since creation: 43ms, elapsed time since send: 43ms, request timeout: 30000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6643 due to node 1 being disconnected (elapsed time since creation: 44ms, elapsed time since send: 44ms, request timeout: 30000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - TaskExecutor               - Close JobManager connection for job a8681efc52437137d28ae75be94f64e1.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6642 due to node 1 being disconnected (elapsed time since creation: 43ms, elapsed time since send: 43ms, request timeout: 30000ms)
INFO  - Task                       - Attempting to fail task externally Source: conditions[197] -> DropUpdateBefore[198] -> Calc[199] -> ConstraintEnforcer[200] -> Sink: conditions[200] (1/1)#0 (2fd09ed160f7916f71927426d340e423_cbc357ccb763df2852fee8c4fc7d55f2_0_0).
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 25 due to node 1 being disconnected (elapsed time since creation: 44ms, elapsed time since send: 44ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6639 due to node 1 being disconnected (elapsed time since creation: 43ms, elapsed time since send: 43ms, request timeout: 30000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6649 due to node 1 being disconnected (elapsed time since creation: 43ms, elapsed time since send: 43ms, request timeout: 30000ms)
INFO  - terServiceLeadershipRunner - JobMasterServiceLeadershipRunner for job 8f9053c77be2be6dcb80fb69df68baf8 was revoked leadership with leader id 3a82a6ce-fb62-4610-b46c-7fb86bd673d4. Stopping current JobMasterServiceProcess.
INFO  - Metrics                    - Metrics scheduler closed
WARN  - Task                       - Source: conditions[197] -> DropUpdateBefore[198] -> Calc[199] -> ConstraintEnforcer[200] -> Sink: conditions[200] (1/1)#0 (2fd09ed160f7916f71927426d340e423_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for a8681efc52437137d28ae75be94f64e1.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id a8681efc52437137d28ae75be94f64e1 lost leadership.
	... 29 more
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6639 due to node 1 being disconnected (elapsed time since creation: 43ms, elapsed time since send: 43ms, request timeout: 30000ms)
INFO  - terServiceLeadershipRunner - JobMasterServiceLeadershipRunner for job 6cadd3411b812f5aeb1f461ff6051653 was revoked leadership with leader id 3a82a6ce-fb62-4610-b46c-7fb86bd673d4. Stopping current JobMasterServiceProcess.
INFO  - SourceReaderBase           - Closing Source Reader.
INFO  - SplitFetcher               - Shutting down split fetcher 0
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Request joining group due to: consumer pro-actively leaving the group
INFO  - terServiceLeadershipRunner - JobMasterServiceLeadershipRunner for job a8681efc52437137d28ae75be94f64e1 was revoked leadership with leader id 3a82a6ce-fb62-4610-b46c-7fb86bd673d4. Stopping current JobMasterServiceProcess.
INFO  - ExecutionGraph             - Job insert-into_analytics.analytics.patients (3450ce4e11df2cb7a382b3520dc37240) switched from state RUNNING to SUSPENDED.
org.apache.flink.util.FlinkException: Scheduler is being stopped.
	at org.apache.flink.runtime.scheduler.SchedulerBase.closeAsync(SchedulerBase.java:646)
	at org.apache.flink.runtime.jobmaster.JobMaster.stopScheduling(JobMaster.java:1051)
	at org.apache.flink.runtime.jobmaster.JobMaster.stopJobExecution(JobMaster.java:1014)
	at org.apache.flink.runtime.jobmaster.JobMaster.onStop(JobMaster.java:442)
	at org.apache.flink.runtime.rpc.RpcEndpoint.internalCallOnStop(RpcEndpoint.java:239)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor$StartedState.lambda$terminate$0(AkkaRpcActor.java:578)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:83)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor$StartedState.terminate(AkkaRpcActor.java:577)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleControlMessage(AkkaRpcActor.java:196)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6642 due to node 1 being disconnected (elapsed time since creation: 50ms, elapsed time since send: 50ms, request timeout: 30000ms)
INFO  - aultLeaderRetrievalService - Stopping DefaultLeaderRetrievalService.
INFO  - eeperLeaderRetrievalDriver - Closing ZookeeperLeaderRetrievalDriver{connectionInformationPath='/1d1394375e4908f94ef8c8210cd9a417/connection_info'}.
INFO  - Metrics                    - Metrics scheduler closed
INFO  - Metrics                    - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Request joining group due to: consumer pro-actively leaving the group
INFO  - Task                       - Triggering cancellation of task code Source: conditions[197] -> DropUpdateBefore[198] -> Calc[199] -> ConstraintEnforcer[200] -> Sink: conditions[200] (1/1)#0 (2fd09ed160f7916f71927426d340e423_cbc357ccb763df2852fee8c4fc7d55f2_0_0).
INFO  - Metrics                    - Metrics reporters closed
INFO  - Metrics                    - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  - Metrics                    - Metrics reporters closed
INFO  - aultLeaderRetrievalService - Stopping DefaultLeaderRetrievalService.
INFO  - eeperLeaderRetrievalDriver - Closing ZookeeperLeaderRetrievalDriver{connectionInformationPath='/c3c54da01848bf81457a865e46b38d18/connection_info'}.
INFO  - Metrics                    - Metrics scheduler closed
INFO  - Metrics                    - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6651 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 30000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - DefaultDispatcherRunner    - DefaultDispatcherRunner was revoked the leadership with leader id 3a82a6ce-fb62-4610-b46c-7fb86bd673d4. Stopping the DispatcherLeaderProcess.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 26 due to node 1 being disconnected (elapsed time since creation: 22ms, elapsed time since send: 22ms, request timeout: 3600000ms)
INFO  - teWriteRequestExecutorImpl - discarding 1 drained requests
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6645 due to node 1 being disconnected (elapsed time since creation: 23ms, elapsed time since send: 23ms, request timeout: 30000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6652 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 30000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6643 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 30000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6643 due to node 1 being disconnected (elapsed time since creation: 27ms, elapsed time since send: 27ms, request timeout: 30000ms)
INFO  - aultLeaderRetrievalService - Stopping DefaultLeaderRetrievalService.
INFO  - eeperLeaderRetrievalDriver - Closing ZookeeperLeaderRetrievalDriver{connectionInformationPath='/3450ce4e11df2cb7a382b3520dc37240/connection_info'}.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 26 due to node 1 being disconnected (elapsed time since creation: 5ms, elapsed time since send: 5ms, request timeout: 3600000ms)
INFO  - aultLeaderRetrievalService - Stopping DefaultLeaderRetrievalService.
INFO  - eeperLeaderRetrievalDriver - Closing ZookeeperLeaderRetrievalDriver{connectionInformationPath='/30b4315f4dce6b8b0d1d34062dbea1c2/connection_info'}.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6649 due to node 1 being disconnected (elapsed time since creation: 23ms, elapsed time since send: 23ms, request timeout: 30000ms)
INFO  - aultLeaderRetrievalService - Stopping DefaultLeaderRetrievalService.
INFO  - eeperLeaderRetrievalDriver - Closing ZookeeperLeaderRetrievalDriver{connectionInformationPath='/3b099420ea7206c78ac6154209036e81/connection_info'}.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 26 due to node 1 being disconnected (elapsed time since creation: 5ms, elapsed time since send: 5ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 26 due to node 1 being disconnected (elapsed time since creation: 29ms, elapsed time since send: 29ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 26 due to node 1 being disconnected (elapsed time since creation: 29ms, elapsed time since send: 29ms, request timeout: 3600000ms)
INFO  - StandaloneResourceManager  - Registration of job manager b46c7fb86bd673d43a82a6cefb624610@akka://flink/user/rpc/jobmanager_11 failed.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 26 due to node 1 being disconnected (elapsed time since creation: 28ms, elapsed time since send: 28ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6650 due to node 1 being disconnected (elapsed time since creation: 31ms, elapsed time since send: 31ms, request timeout: 30000ms)
INFO  - StandaloneResourceManager  - Registration of job manager b46c7fb86bd673d43a82a6cefb624610@akka://flink/user/rpc/jobmanager_3 failed.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - StandaloneResourceManager  - Registration of job manager b46c7fb86bd673d43a82a6cefb624610@akka://flink/user/rpc/jobmanager_6 failed.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6651 due to node 1 being disconnected (elapsed time since creation: 30ms, elapsed time since send: 30ms, request timeout: 30000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 26 due to node 1 being disconnected (elapsed time since creation: 28ms, elapsed time since send: 28ms, request timeout: 3600000ms)
INFO  - TaskExecutor               - Close JobManager connection for job 3b099420ea7206c78ac6154209036e81.
INFO  - aultLeaderRetrievalService - Stopping DefaultLeaderRetrievalService.
INFO  - eeperLeaderRetrievalDriver - Closing ZookeeperLeaderRetrievalDriver{connectionInformationPath='/9deef106e67c2b1f77d94f2e02251d44/connection_info'}.
INFO  - Task                       - Attempting to fail task externally Source: encounter_diagnosis[101] -> DropUpdateBefore[102] -> Calc[103] -> ConstraintEnforcer[104] -> Sink: encounter_diagnoses[104] (1/1)#0 (6d9d8d9b1d918481a134ea752ea88d14_cbc357ccb763df2852fee8c4fc7d55f2_0_0).
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 26 due to node 1 being disconnected (elapsed time since creation: 5ms, elapsed time since send: 5ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 26 due to node 1 being disconnected (elapsed time since creation: 5ms, elapsed time since send: 5ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 26 due to node 1 being disconnected (elapsed time since creation: 30ms, elapsed time since send: 30ms, request timeout: 3600000ms)
INFO  - RocksDBKeyedStateBackend   - Closed RocksDB State Backend. Cleaning up RocksDB working directory /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_8f9053c77be2be6dcb80fb69df68baf8_op_StreamingJoinOperator_d7e78c81a38d2cce4433a75795131bcf__1_1__uuid_caf7728b-0369-4832-92ed-079fc8a4064a.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6648 due to node 1 being disconnected (elapsed time since creation: 30ms, elapsed time since send: 30ms, request timeout: 30000ms)
INFO  - SourceReaderBase           - Closing Source Reader.
INFO  - SplitFetcher               - Shutting down split fetcher 0
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6642 due to node 1 being disconnected (elapsed time since creation: 29ms, elapsed time since send: 29ms, request timeout: 30000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6640 due to node 1 being disconnected (elapsed time since creation: 0ms, elapsed time since send: 0ms, request timeout: 30000ms)
INFO  - aultLeaderRetrievalService - Stopping DefaultLeaderRetrievalService.
INFO  - eeperLeaderRetrievalDriver - Closing ZookeeperLeaderRetrievalDriver{connectionInformationPath='/ee8b603bf5edab3af85b6467db69921f/connection_info'}.
WARN  - Task                       - Source: encounter_diagnosis[101] -> DropUpdateBefore[102] -> Calc[103] -> ConstraintEnforcer[104] -> Sink: encounter_diagnoses[104] (1/1)#0 (6d9d8d9b1d918481a134ea752ea88d14_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for 3b099420ea7206c78ac6154209036e81.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id 3b099420ea7206c78ac6154209036e81 lost leadership.
	... 29 more
INFO  - Task                       - Triggering cancellation of task code Source: encounter_diagnosis[101] -> DropUpdateBefore[102] -> Calc[103] -> ConstraintEnforcer[104] -> Sink: encounter_diagnoses[104] (1/1)#0 (6d9d8d9b1d918481a134ea752ea88d14_cbc357ccb763df2852fee8c4fc7d55f2_0_0).
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 26 due to node 1 being disconnected (elapsed time since creation: 28ms, elapsed time since send: 28ms, request timeout: 3600000ms)
INFO  - ionDispatcherLeaderProcess - Stopping SessionDispatcherLeaderProcess.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6647 due to node 1 being disconnected (elapsed time since creation: 31ms, elapsed time since send: 31ms, request timeout: 30000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 26 due to node 1 being disconnected (elapsed time since creation: 34ms, elapsed time since send: 34ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 26 due to node 1 being disconnected (elapsed time since creation: 31ms, elapsed time since send: 31ms, request timeout: 3600000ms)
INFO  - ExecutionGraph             - Source: patient[75] -> Calc[76] (1/1) (588c992944dd31552e175761339ab856_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to CANCELING.
INFO  - ExecutionGraph             - Source: patient_appointment[1] -> Calc[2] (1/1) (5d2b85ced63db2be7a46b4ce2f567a3c_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to CANCELING.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 26 due to node 1 being disconnected (elapsed time since creation: 31ms, elapsed time since send: 31ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 26 due to node 1 being disconnected (elapsed time since creation: 27ms, elapsed time since send: 27ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 26 due to node 1 being disconnected (elapsed time since creation: 34ms, elapsed time since send: 34ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 26 due to node 1 being disconnected (elapsed time since creation: 0ms, elapsed time since send: 0ms, request timeout: 3600000ms)
INFO  - SourceReaderBase           - Closing Source Reader.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - SplitFetcher               - Shutting down split fetcher 0
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6655 due to node 1 being disconnected (elapsed time since creation: 34ms, elapsed time since send: 34ms, request timeout: 30000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Request joining group due to: consumer pro-actively leaving the group
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6651 due to node 1 being disconnected (elapsed time since creation: 34ms, elapsed time since send: 34ms, request timeout: 30000ms)
INFO  - Metrics                    - Metrics scheduler closed
INFO  - Metrics                    - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  - Metrics                    - Metrics reporters closed
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6644 due to node 1 being disconnected (elapsed time since creation: 0ms, elapsed time since send: 0ms, request timeout: 30000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 26 due to node 1 being disconnected (elapsed time since creation: 32ms, elapsed time since send: 32ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 26 due to node 1 being disconnected (elapsed time since creation: 0ms, elapsed time since send: 0ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 26 due to node 1 being disconnected (elapsed time since creation: 0ms, elapsed time since send: 0ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 26 due to node 1 being disconnected (elapsed time since creation: 0ms, elapsed time since send: 0ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 26 due to node 1 being disconnected (elapsed time since creation: 0ms, elapsed time since send: 0ms, request timeout: 3600000ms)
INFO  - Metrics                    - Metrics reporters closed
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6643 due to node 1 being disconnected (elapsed time since creation: 0ms, elapsed time since send: 0ms, request timeout: 30000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 26 due to node 1 being disconnected (elapsed time since creation: 0ms, elapsed time since send: 0ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 26 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - ExecutionGraph             - Source: patient[75] -> Calc[76] (1/1) (588c992944dd31552e175761339ab856_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CANCELING to CANCELED.
INFO  - ExecutionGraph             - Source: patient_appointment[1] -> Calc[2] (1/1) (5d2b85ced63db2be7a46b4ce2f567a3c_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CANCELING to CANCELED.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6647 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 30000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 26 due to node 1 being disconnected (elapsed time since creation: 0ms, elapsed time since send: 0ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 26 due to node 1 being disconnected (elapsed time since creation: 0ms, elapsed time since send: 0ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6641 due to node 1 being disconnected (elapsed time since creation: 33ms, elapsed time since send: 33ms, request timeout: 30000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6642 due to node 1 being disconnected (elapsed time since creation: 33ms, elapsed time since send: 33ms, request timeout: 30000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 26 due to node 1 being disconnected (elapsed time since creation: 31ms, elapsed time since send: 31ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 26 due to node 1 being disconnected (elapsed time since creation: 4ms, elapsed time since send: 4ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6643 due to node 1 being disconnected (elapsed time since creation: 4ms, elapsed time since send: 4ms, request timeout: 30000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 26 due to node 1 being disconnected (elapsed time since creation: 4ms, elapsed time since send: 4ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6638 due to node 1 being disconnected (elapsed time since creation: 4ms, elapsed time since send: 4ms, request timeout: 30000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 26 due to node 1 being disconnected (elapsed time since creation: 4ms, elapsed time since send: 4ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 26 due to node 1 being disconnected (elapsed time since creation: 4ms, elapsed time since send: 4ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6640 due to node 1 being disconnected (elapsed time since creation: 4ms, elapsed time since send: 4ms, request timeout: 30000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 26 due to node 1 being disconnected (elapsed time since creation: 4ms, elapsed time since send: 4ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 26 due to node 1 being disconnected (elapsed time since creation: 34ms, elapsed time since send: 34ms, request timeout: 3600000ms)
INFO  - terServiceLeadershipRunner - JobMasterServiceLeadershipRunner for job 9deef106e67c2b1f77d94f2e02251d44 was revoked leadership with leader id 3a82a6ce-fb62-4610-b46c-7fb86bd673d4. Stopping current JobMasterServiceProcess.
INFO  - AppInfoParser              - App info kafka.consumer for flink-0 unregistered
INFO  - SplitFetcher               - Split fetcher 0 exited.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - TaskExecutor               - Close JobManager connection for job 9deef106e67c2b1f77d94f2e02251d44.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6650 due to node 1 being disconnected (elapsed time since creation: 0ms, elapsed time since send: 0ms, request timeout: 30000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 26 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6653 due to node 1 being disconnected (elapsed time since creation: 0ms, elapsed time since send: 0ms, request timeout: 30000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6645 due to node 1 being disconnected (elapsed time since creation: 0ms, elapsed time since send: 0ms, request timeout: 30000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6639 due to node 1 being disconnected (elapsed time since creation: 0ms, elapsed time since send: 0ms, request timeout: 30000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6647 due to node 1 being disconnected (elapsed time since creation: 0ms, elapsed time since send: 0ms, request timeout: 30000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6642 due to node 1 being disconnected (elapsed time since creation: 0ms, elapsed time since send: 0ms, request timeout: 30000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6648 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 30000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 26 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Request joining group due to: consumer pro-actively leaving the group
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 26 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6657 due to node 1 being disconnected (elapsed time since creation: 0ms, elapsed time since send: 0ms, request timeout: 30000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 26 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - ExecutionGraph             - Discarding the results produced by task execution 588c992944dd31552e175761339ab856_cbc357ccb763df2852fee8c4fc7d55f2_0_0.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6646 due to node 1 being disconnected (elapsed time since creation: 7ms, elapsed time since send: 7ms, request timeout: 30000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6640 due to node 1 being disconnected (elapsed time since creation: 0ms, elapsed time since send: 0ms, request timeout: 30000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 4809 due to node 1 being disconnected (elapsed time since creation: 0ms, elapsed time since send: 0ms, request timeout: 30000ms)
INFO  - teWriteRequestExecutorImpl - discarding 1 drained requests
INFO  - RocksDBKeyedStateBackend   - Closed RocksDB State Backend. Cleaning up RocksDB working directory /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_8f9053c77be2be6dcb80fb69df68baf8_op_SinkUpsertMaterializer_8fc3be823cc75a93eb3f11ae7a596b08__1_1__uuid_89e0178a-70e3-4a1c-8523-6da7a7065cf2.
INFO  - Task                       - Freeing task resources for Source: concept_name[209] -> Calc[210] (1/1)#0 (2ff118f32116f826e0d468907bf12d2a_2963852293169ba90d9d1e7d6308db5c_0_0).
INFO  - StandaloneResourceManager  - Registration of job manager b46c7fb86bd673d43a82a6cefb624610@akka://flink/user/rpc/jobmanager_9 failed.
INFO  - aultLeaderRetrievalService - Stopping DefaultLeaderRetrievalService.
INFO  - RocksDBKeyedStateBackend   - Closed RocksDB State Backend. Cleaning up RocksDB working directory /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_8f9053c77be2be6dcb80fb69df68baf8_op_StreamingJoinOperator_27b913f6385bb0e404cc1ac792473af7__1_1__uuid_ba09c669-1a23-48c1-9696-a86ec710f60a.
INFO  - RocksDBKeyedStateBackend   - Closed RocksDB State Backend. Cleaning up RocksDB working directory /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_8f9053c77be2be6dcb80fb69df68baf8_op_StreamingJoinOperator_5b6b7f98d5bff23034589a7675c38ac7__1_1__uuid_61f08aa3-f498-490f-ba12-501d13e75a23.
INFO  - eeperLeaderRetrievalDriver - Closing ZookeeperLeaderRetrievalDriver{connectionInformationPath='/a8681efc52437137d28ae75be94f64e1/connection_info'}.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 26 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - ExecutionGraph             - Discarding the results produced by task execution 5d2b85ced63db2be7a46b4ce2f567a3c_cbc357ccb763df2852fee8c4fc7d55f2_0_0.
INFO  - Metrics                    - Metrics scheduler closed
INFO  - Metrics                    - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  - Metrics                    - Metrics reporters closed
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6644 due to node 1 being disconnected (elapsed time since creation: 0ms, elapsed time since send: 0ms, request timeout: 30000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 26 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - Task                       - Attempting to fail task externally Source: concept_reference_source[63] -> Calc[64] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_1171dea6747ab509fdaefbe74f7195af_0_0).
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6643 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 30000ms)
WARN  - Task                       - Source: concept_reference_source[63] -> Calc[64] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_1171dea6747ab509fdaefbe74f7195af_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for 9deef106e67c2b1f77d94f2e02251d44.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id 9deef106e67c2b1f77d94f2e02251d44 lost leadership.
	... 29 more
INFO  - Task                       - Triggering cancellation of task code Source: concept_reference_source[63] -> Calc[64] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_1171dea6747ab509fdaefbe74f7195af_0_0).
INFO  - AppInfoParser              - App info kafka.consumer for flink-0 unregistered
INFO  - SplitFetcher               - Split fetcher 0 exited.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 26 due to node 1 being disconnected (elapsed time since creation: 4ms, elapsed time since send: 4ms, request timeout: 3600000ms)
INFO  - ExecutionGraph             - Discarding the results produced by task execution 588c992944dd31552e175761339ab856_cbc357ccb763df2852fee8c4fc7d55f2_0_0.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6656 due to node 1 being disconnected (elapsed time since creation: 4ms, elapsed time since send: 4ms, request timeout: 30000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 26 due to node 1 being disconnected (elapsed time since creation: 4ms, elapsed time since send: 4ms, request timeout: 3600000ms)
INFO  - Task                       - Freeing task resources for Source: program[203] -> Calc[204] (1/1)#0 (2ff118f32116f826e0d468907bf12d2a_6cdc5bb954874d922eaee11a8e7b5dd5_0_0).
INFO  - AppInfoParser              - App info kafka.consumer for flink-0 unregistered
INFO  - SplitFetcher               - Split fetcher 0 exited.
INFO  - ExecutionGraph             - Discarding the results produced by task execution 5d2b85ced63db2be7a46b4ce2f567a3c_cbc357ccb763df2852fee8c4fc7d55f2_0_0.
INFO  - AppInfoParser              - App info kafka.consumer for flink-0 unregistered
INFO  - SplitFetcher               - Split fetcher 0 exited.
INFO  - Task                       - Freeing task resources for Source: encounter_diagnosis[101] -> DropUpdateBefore[102] -> Calc[103] -> ConstraintEnforcer[104] -> Sink: encounter_diagnoses[104] (1/1)#0 (6d9d8d9b1d918481a134ea752ea88d14_cbc357ccb763df2852fee8c4fc7d55f2_0_0).
INFO  - AppInfoParser              - App info kafka.consumer for flink-0 unregistered
INFO  - SplitFetcher               - Split fetcher 0 exited.
INFO  - Task                       - Attempting to fail task externally SinkMaterializer[74] -> Sink: concepts[74] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_4595a980807a13db332f9917535d0424_0_0).
WARN  - Task                       - SinkMaterializer[74] -> Sink: concepts[74] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_4595a980807a13db332f9917535d0424_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for 9deef106e67c2b1f77d94f2e02251d44.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id 9deef106e67c2b1f77d94f2e02251d44 lost leadership.
	... 29 more
INFO  - Task                       - Triggering cancellation of task code SinkMaterializer[74] -> Sink: concepts[74] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_4595a980807a13db332f9917535d0424_0_0).
INFO  - Task                       - Freeing task resources for Source: conditions[197] -> DropUpdateBefore[198] -> Calc[199] -> ConstraintEnforcer[200] -> Sink: conditions[200] (1/1)#0 (2fd09ed160f7916f71927426d340e423_cbc357ccb763df2852fee8c4fc7d55f2_0_0).
INFO  - SourceReaderBase           - Closing Source Reader.
INFO  - SplitFetcher               - Shutting down split fetcher 0
INFO  - Task                       - Freeing task resources for Source: patient_program[201] (1/1)#0 (2ff118f32116f826e0d468907bf12d2a_bc764cd8ddf7a0cff126f51c16239658_0_0).
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Request joining group due to: consumer pro-actively leaving the group
INFO  - Metrics                    - Metrics scheduler closed
INFO  - Metrics                    - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  - Metrics                    - Metrics reporters closed
INFO  - Task                       - Attempting to fail task externally Source: concept[48] -> Calc[49] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_cbc357ccb763df2852fee8c4fc7d55f2_0_0).
WARN  - Task                       - Source: concept[48] -> Calc[49] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for 9deef106e67c2b1f77d94f2e02251d44.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id 9deef106e67c2b1f77d94f2e02251d44 lost leadership.
	... 29 more
INFO  - Task                       - Triggering cancellation of task code Source: concept[48] -> Calc[49] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_cbc357ccb763df2852fee8c4fc7d55f2_0_0).
INFO  - AppInfoParser              - App info kafka.consumer for flink-0 unregistered
INFO  - SplitFetcher               - Split fetcher 0 exited.
INFO  - ExecutionGraph             - Source: appointment_service[4] -> Calc[5] (1/1) (5d2b85ced63db2be7a46b4ce2f567a3c_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) switched from RUNNING to CANCELING.
INFO  - ExecutionGraph             - Source: person[78] -> Calc[79] (1/1) (588c992944dd31552e175761339ab856_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) switched from RUNNING to CANCELING.
INFO  - ExecutionGraph             - Source: person[78] -> Calc[79] (1/1) (588c992944dd31552e175761339ab856_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) switched from CANCELING to CANCELED.
INFO  - ExecutionGraph             - Source: appointment_service[4] -> Calc[5] (1/1) (5d2b85ced63db2be7a46b4ce2f567a3c_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) switched from CANCELING to CANCELED.
INFO  - ExecutionGraph             - Discarding the results produced by task execution 588c992944dd31552e175761339ab856_6cdc5bb954874d922eaee11a8e7b5dd5_0_0.
INFO  - ExecutionGraph             - Discarding the results produced by task execution 588c992944dd31552e175761339ab856_6cdc5bb954874d922eaee11a8e7b5dd5_0_0.
INFO  - ExecutionGraph             - Source: person_name[83] -> Calc[84] (1/1) (588c992944dd31552e175761339ab856_2963852293169ba90d9d1e7d6308db5c_0_0) switched from RUNNING to CANCELING.
INFO  - Task                       - Freeing task resources for Source: concept_reference_source[63] -> Calc[64] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_1171dea6747ab509fdaefbe74f7195af_0_0).
INFO  - ExecutionGraph             - Source: person_name[83] -> Calc[84] (1/1) (588c992944dd31552e175761339ab856_2963852293169ba90d9d1e7d6308db5c_0_0) switched from CANCELING to CANCELED.
INFO  - ExecutionGraph             - Discarding the results produced by task execution 5d2b85ced63db2be7a46b4ce2f567a3c_6cdc5bb954874d922eaee11a8e7b5dd5_0_0.
INFO  - ExecutionGraph             - Discarding the results produced by task execution 5d2b85ced63db2be7a46b4ce2f567a3c_6cdc5bb954874d922eaee11a8e7b5dd5_0_0.
INFO  - ExecutionGraph             - Source: appointment_service_type[9] -> Calc[10] (1/1) (5d2b85ced63db2be7a46b4ce2f567a3c_2963852293169ba90d9d1e7d6308db5c_0_0) switched from RUNNING to CANCELING.
INFO  - ExecutionGraph             - Discarding the results produced by task execution 588c992944dd31552e175761339ab856_2963852293169ba90d9d1e7d6308db5c_0_0.
INFO  - SourceReaderBase           - Closing Source Reader.
INFO  - SplitFetcher               - Shutting down split fetcher 0
INFO  - ExecutionGraph             - Discarding the results produced by task execution 588c992944dd31552e175761339ab856_2963852293169ba90d9d1e7d6308db5c_0_0.
INFO  - ExecutionGraph             - Source: person_address[89] -> Calc[90] (1/1) (588c992944dd31552e175761339ab856_1171dea6747ab509fdaefbe74f7195af_0_0) switched from RUNNING to CANCELING.
INFO  - ExecutionGraph             - Source: person_address[89] -> Calc[90] (1/1) (588c992944dd31552e175761339ab856_1171dea6747ab509fdaefbe74f7195af_0_0) switched from CANCELING to CANCELED.
INFO  - ExecutionGraph             - Discarding the results produced by task execution 588c992944dd31552e175761339ab856_1171dea6747ab509fdaefbe74f7195af_0_0.
INFO  - ExecutionGraph             - Source: appointment_service_type[9] -> Calc[10] (1/1) (5d2b85ced63db2be7a46b4ce2f567a3c_2963852293169ba90d9d1e7d6308db5c_0_0) switched from CANCELING to CANCELED.
INFO  - ExecutionGraph             - Discarding the results produced by task execution 5d2b85ced63db2be7a46b4ce2f567a3c_2963852293169ba90d9d1e7d6308db5c_0_0.
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Request joining group due to: consumer pro-actively leaving the group
INFO  - ExecutionGraph             - Discarding the results produced by task execution 588c992944dd31552e175761339ab856_1171dea6747ab509fdaefbe74f7195af_0_0.
INFO  - Metrics                    - Metrics scheduler closed
INFO  - Metrics                    - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  - Metrics                    - Metrics reporters closed
INFO  - ExecutionGraph             - Discarding the results produced by task execution 5d2b85ced63db2be7a46b4ce2f567a3c_2963852293169ba90d9d1e7d6308db5c_0_0.
INFO  - RocksDBKeyedStateBackend   - Closed RocksDB State Backend. Cleaning up RocksDB working directory /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_9deef106e67c2b1f77d94f2e02251d44_op_SinkUpsertMaterializer_4595a980807a13db332f9917535d0424__1_1__uuid_80814085-681b-47ed-972d-ffc8ce8cd50f.
INFO  - ExecutionGraph             - Source: patient_appointment_provider[15] -> Calc[16] (1/1) (5d2b85ced63db2be7a46b4ce2f567a3c_1171dea6747ab509fdaefbe74f7195af_0_0) switched from RUNNING to CANCELING.
INFO  - ExecutionGraph             - Source: patient_identifier[95] -> Calc[96] (1/1) (588c992944dd31552e175761339ab856_2fa5fc7df17f61cb0e1946288970d799_0_0) switched from RUNNING to CANCELING.
INFO  - ExecutionGraph             - Source: patient_appointment_provider[15] -> Calc[16] (1/1) (5d2b85ced63db2be7a46b4ce2f567a3c_1171dea6747ab509fdaefbe74f7195af_0_0) switched from CANCELING to CANCELED.
INFO  - Task                       - Attempting to fail task externally Source: concept_reference_term[57] -> Calc[58] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_2963852293169ba90d9d1e7d6308db5c_0_0).
INFO  - ExecutionGraph             - Discarding the results produced by task execution 5d2b85ced63db2be7a46b4ce2f567a3c_1171dea6747ab509fdaefbe74f7195af_0_0.
WARN  - Task                       - Source: concept_reference_term[57] -> Calc[58] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_2963852293169ba90d9d1e7d6308db5c_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for 9deef106e67c2b1f77d94f2e02251d44.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id 9deef106e67c2b1f77d94f2e02251d44 lost leadership.
	... 29 more
INFO  - Task                       - Triggering cancellation of task code Source: concept_reference_term[57] -> Calc[58] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_2963852293169ba90d9d1e7d6308db5c_0_0).
INFO  - ExecutionGraph             - Source: patient_identifier[95] -> Calc[96] (1/1) (588c992944dd31552e175761339ab856_2fa5fc7df17f61cb0e1946288970d799_0_0) switched from CANCELING to CANCELED.
INFO  - ExecutionGraph             - Discarding the results produced by task execution 5d2b85ced63db2be7a46b4ce2f567a3c_1171dea6747ab509fdaefbe74f7195af_0_0.
INFO  - ExecutionGraph             - Discarding the results produced by task execution 588c992944dd31552e175761339ab856_2fa5fc7df17f61cb0e1946288970d799_0_0.
INFO  - ExecutionGraph             - Discarding the results produced by task execution 588c992944dd31552e175761339ab856_2fa5fc7df17f61cb0e1946288970d799_0_0.
INFO  - ExecutionGraph             - Join[7] (1/1) (5d2b85ced63db2be7a46b4ce2f567a3c_5caeaa5e379e7348564aaaaf5ae0d6a6_0_0) switched from RUNNING to CANCELING.
INFO  - ExecutionGraph             - Join[81] (1/1) (588c992944dd31552e175761339ab856_e6807280e63afa30c980423999b48cc6_0_0) switched from RUNNING to CANCELING.
INFO  - ExecutionGraph             - Join[7] (1/1) (5d2b85ced63db2be7a46b4ce2f567a3c_5caeaa5e379e7348564aaaaf5ae0d6a6_0_0) switched from CANCELING to CANCELED.
INFO  - AppInfoParser              - App info kafka.consumer for flink-0 unregistered
INFO  - SplitFetcher               - Split fetcher 0 exited.
INFO  - ExecutionGraph             - Join[81] (1/1) (588c992944dd31552e175761339ab856_e6807280e63afa30c980423999b48cc6_0_0) switched from CANCELING to CANCELED.
INFO  - ExecutionGraph             - Discarding the results produced by task execution 5d2b85ced63db2be7a46b4ce2f567a3c_5caeaa5e379e7348564aaaaf5ae0d6a6_0_0.
INFO  - ExecutionGraph             - Discarding the results produced by task execution 588c992944dd31552e175761339ab856_e6807280e63afa30c980423999b48cc6_0_0.
INFO  - ExecutionGraph             - Discarding the results produced by task execution 5d2b85ced63db2be7a46b4ce2f567a3c_5caeaa5e379e7348564aaaaf5ae0d6a6_0_0.
INFO  - ExecutionGraph             - Discarding the results produced by task execution 588c992944dd31552e175761339ab856_e6807280e63afa30c980423999b48cc6_0_0.
INFO  - ExecutionGraph             - Join[12] -> Calc[13] (1/1) (5d2b85ced63db2be7a46b4ce2f567a3c_ccd2f3173f602e66f6767720952cb258_0_0) switched from RUNNING to CANCELING.
INFO  - ExecutionGraph             - Join[86] -> Calc[87] (1/1) (588c992944dd31552e175761339ab856_eb7d99873eea63dacba8fd9c596677e3_0_0) switched from RUNNING to CANCELING.
INFO  - ExecutionGraph             - Join[12] -> Calc[13] (1/1) (5d2b85ced63db2be7a46b4ce2f567a3c_ccd2f3173f602e66f6767720952cb258_0_0) switched from CANCELING to CANCELED.
INFO  - ExecutionGraph             - Join[86] -> Calc[87] (1/1) (588c992944dd31552e175761339ab856_eb7d99873eea63dacba8fd9c596677e3_0_0) switched from CANCELING to CANCELED.
INFO  - ExecutionGraph             - Discarding the results produced by task execution 5d2b85ced63db2be7a46b4ce2f567a3c_ccd2f3173f602e66f6767720952cb258_0_0.
INFO  - ExecutionGraph             - Discarding the results produced by task execution 588c992944dd31552e175761339ab856_eb7d99873eea63dacba8fd9c596677e3_0_0.
INFO  - ExecutionGraph             - Discarding the results produced by task execution 5d2b85ced63db2be7a46b4ce2f567a3c_ccd2f3173f602e66f6767720952cb258_0_0.
INFO  - ExecutionGraph             - Join[18] -> Calc[19] -> ConstraintEnforcer[20] (1/1) (5d2b85ced63db2be7a46b4ce2f567a3c_23e521ac8efce918f328250afebbe45c_0_0) switched from RUNNING to CANCELING.
INFO  - Task                       - Freeing task resources for Source: concept[48] -> Calc[49] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_cbc357ccb763df2852fee8c4fc7d55f2_0_0).
INFO  - ExecutionGraph             - Join[18] -> Calc[19] -> ConstraintEnforcer[20] (1/1) (5d2b85ced63db2be7a46b4ce2f567a3c_23e521ac8efce918f328250afebbe45c_0_0) switched from CANCELING to CANCELED.
INFO  - ExecutionGraph             - Discarding the results produced by task execution 5d2b85ced63db2be7a46b4ce2f567a3c_23e521ac8efce918f328250afebbe45c_0_0.
INFO  - ExecutionGraph             - Discarding the results produced by task execution 588c992944dd31552e175761339ab856_eb7d99873eea63dacba8fd9c596677e3_0_0.
INFO  - ExecutionGraph             - Discarding the results produced by task execution 5d2b85ced63db2be7a46b4ce2f567a3c_23e521ac8efce918f328250afebbe45c_0_0.
INFO  - ExecutionGraph             - Join[92] -> Calc[93] (1/1) (588c992944dd31552e175761339ab856_fa7571c07da635c59ba82f92b55840d8_0_0) switched from RUNNING to CANCELING.
INFO  - Task                       - Attempting to fail task externally Join[66] -> Calc[67] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_ab06fe1c886f2b2a7030a8ed4a30b46a_0_0).
WARN  - Task                       - Join[66] -> Calc[67] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_ab06fe1c886f2b2a7030a8ed4a30b46a_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for 9deef106e67c2b1f77d94f2e02251d44.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id 9deef106e67c2b1f77d94f2e02251d44 lost leadership.
	... 29 more
INFO  - Task                       - Triggering cancellation of task code Join[66] -> Calc[67] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_ab06fe1c886f2b2a7030a8ed4a30b46a_0_0).
INFO  - SourceReaderBase           - Closing Source Reader.
INFO  - SplitFetcher               - Shutting down split fetcher 0
INFO  - ExecutionGraph             - SinkMaterializer[20] -> Sink: appointments[20] (1/1) (5d2b85ced63db2be7a46b4ce2f567a3c_fd907ffb7425150fb379978eab0e6d37_0_0) switched from RUNNING to CANCELING.
INFO  - ExecutionGraph             - Join[92] -> Calc[93] (1/1) (588c992944dd31552e175761339ab856_fa7571c07da635c59ba82f92b55840d8_0_0) switched from CANCELING to CANCELED.
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Request joining group due to: consumer pro-actively leaving the group
INFO  - ExecutionGraph             - Discarding the results produced by task execution 588c992944dd31552e175761339ab856_fa7571c07da635c59ba82f92b55840d8_0_0.
INFO  - ExecutionGraph             - SinkMaterializer[20] -> Sink: appointments[20] (1/1) (5d2b85ced63db2be7a46b4ce2f567a3c_fd907ffb7425150fb379978eab0e6d37_0_0) switched from CANCELING to CANCELED.
INFO  - ExecutionGraph             - Discarding the results produced by task execution 588c992944dd31552e175761339ab856_fa7571c07da635c59ba82f92b55840d8_0_0.
INFO  - JobMaster                  - Stopping the JobMaster for job 'insert-into_analytics.analytics.concepts' (9deef106e67c2b1f77d94f2e02251d44).
INFO  - ExecutionGraph             - Join[98] -> Calc[99] -> ConstraintEnforcer[100] (1/1) (588c992944dd31552e175761339ab856_c6adced987710239013e40eb9ab41362_0_0) switched from RUNNING to CANCELING.
INFO  - ExecutionGraph             - Join[98] -> Calc[99] -> ConstraintEnforcer[100] (1/1) (588c992944dd31552e175761339ab856_c6adced987710239013e40eb9ab41362_0_0) switched from CANCELING to CANCELED.
INFO  - ExecutionGraph             - Discarding the results produced by task execution 588c992944dd31552e175761339ab856_c6adced987710239013e40eb9ab41362_0_0.
INFO  - ExecutionGraph             - Discarding the results produced by task execution 588c992944dd31552e175761339ab856_c6adced987710239013e40eb9ab41362_0_0.
INFO  - Metrics                    - Metrics scheduler closed
INFO  - Metrics                    - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  - Metrics                    - Metrics reporters closed
INFO  - ExecutionGraph             - SinkMaterializer[100] -> Sink: patients[100] (1/1) (588c992944dd31552e175761339ab856_4969848647857cea5647cb2eb2d99d6b_0_0) switched from RUNNING to CANCELING.
INFO  - ExecutionGraph             - Job insert-into_analytics.analytics.concepts (9deef106e67c2b1f77d94f2e02251d44) switched from state RUNNING to SUSPENDED.
org.apache.flink.util.FlinkException: Scheduler is being stopped.
	at org.apache.flink.runtime.scheduler.SchedulerBase.closeAsync(SchedulerBase.java:646)
	at org.apache.flink.runtime.jobmaster.JobMaster.stopScheduling(JobMaster.java:1051)
	at org.apache.flink.runtime.jobmaster.JobMaster.stopJobExecution(JobMaster.java:1014)
	at org.apache.flink.runtime.jobmaster.JobMaster.onStop(JobMaster.java:442)
	at org.apache.flink.runtime.rpc.RpcEndpoint.internalCallOnStop(RpcEndpoint.java:239)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor$StartedState.lambda$terminate$0(AkkaRpcActor.java:578)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:83)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor$StartedState.terminate(AkkaRpcActor.java:577)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleControlMessage(AkkaRpcActor.java:196)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
INFO  - Task                       - Attempting to fail task externally Join[60] -> Calc[61] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_2e54324c2d6d30259944e7ab21f8249d_0_0).
INFO  - ExecutionGraph             - SinkMaterializer[100] -> Sink: patients[100] (1/1) (588c992944dd31552e175761339ab856_4969848647857cea5647cb2eb2d99d6b_0_0) switched from CANCELING to CANCELED.
INFO  - AppInfoParser              - App info kafka.consumer for flink-0 unregistered
INFO  - SplitFetcher               - Split fetcher 0 exited.
WARN  - Task                       - Join[60] -> Calc[61] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_2e54324c2d6d30259944e7ab21f8249d_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for 9deef106e67c2b1f77d94f2e02251d44.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id 9deef106e67c2b1f77d94f2e02251d44 lost leadership.
	... 29 more
INFO  - Task                       - Triggering cancellation of task code Join[60] -> Calc[61] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_2e54324c2d6d30259944e7ab21f8249d_0_0).
INFO  - ExecutionGraph             - Source: concept[48] -> Calc[49] (1/1) (80aa942084eddc41f7baf859b5ecb269_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to CANCELING.
INFO  - Task                       - Freeing task resources for Source: concept_reference_term[57] -> Calc[58] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_2963852293169ba90d9d1e7d6308db5c_0_0).
INFO  - ExecutionGraph             - Source: concept[48] -> Calc[49] (1/1) (80aa942084eddc41f7baf859b5ecb269_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from CANCELING to CANCELED.
INFO  - ExecutionGraph             - Discarding the results produced by task execution 80aa942084eddc41f7baf859b5ecb269_cbc357ccb763df2852fee8c4fc7d55f2_0_0.
INFO  - ExecutionGraph             - Discarding the results produced by task execution 80aa942084eddc41f7baf859b5ecb269_cbc357ccb763df2852fee8c4fc7d55f2_0_0.
INFO  - ExecutionGraph             - Source: concept_reference_map[51] -> Calc[52] (1/1) (80aa942084eddc41f7baf859b5ecb269_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) switched from RUNNING to CANCELING.
INFO  - ExecutionGraph             - Source: concept_reference_map[51] -> Calc[52] (1/1) (80aa942084eddc41f7baf859b5ecb269_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) switched from CANCELING to CANCELED.
INFO  - ExecutionGraph             - Discarding the results produced by task execution 80aa942084eddc41f7baf859b5ecb269_6cdc5bb954874d922eaee11a8e7b5dd5_0_0.
INFO  - ExecutionGraph             - Discarding the results produced by task execution 80aa942084eddc41f7baf859b5ecb269_6cdc5bb954874d922eaee11a8e7b5dd5_0_0.
INFO  - ExecutionGraph             - Source: concept_reference_term[57] -> Calc[58] (1/1) (80aa942084eddc41f7baf859b5ecb269_2963852293169ba90d9d1e7d6308db5c_0_0) switched from RUNNING to CANCELING.
INFO  - ExecutionGraph             - Source: concept_reference_term[57] -> Calc[58] (1/1) (80aa942084eddc41f7baf859b5ecb269_2963852293169ba90d9d1e7d6308db5c_0_0) switched from CANCELING to CANCELED.
INFO  - ExecutionGraph             - Discarding the results produced by task execution 80aa942084eddc41f7baf859b5ecb269_2963852293169ba90d9d1e7d6308db5c_0_0.
INFO  - ExecutionGraph             - Discarding the results produced by task execution 80aa942084eddc41f7baf859b5ecb269_2963852293169ba90d9d1e7d6308db5c_0_0.
INFO  - ExecutionGraph             - Source: concept_reference_source[63] -> Calc[64] (1/1) (80aa942084eddc41f7baf859b5ecb269_1171dea6747ab509fdaefbe74f7195af_0_0) switched from RUNNING to CANCELING.
INFO  - RocksDBKeyedStateBackend   - Closed RocksDB State Backend. Cleaning up RocksDB working directory /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_9deef106e67c2b1f77d94f2e02251d44_op_StreamingJoinOperator_ab06fe1c886f2b2a7030a8ed4a30b46a__1_1__uuid_5bd3fab9-09c1-4b85-b0ab-a24d8d861204.
INFO  - ExecutionGraph             - Source: concept_reference_source[63] -> Calc[64] (1/1) (80aa942084eddc41f7baf859b5ecb269_1171dea6747ab509fdaefbe74f7195af_0_0) switched from CANCELING to CANCELED.
INFO  - ExecutionGraph             - Discarding the results produced by task execution 80aa942084eddc41f7baf859b5ecb269_1171dea6747ab509fdaefbe74f7195af_0_0.
INFO  - ExecutionGraph             - Discarding the results produced by task execution 80aa942084eddc41f7baf859b5ecb269_1171dea6747ab509fdaefbe74f7195af_0_0.
INFO  - ExecutionGraph             - Source: concept_name[69] -> Calc[70] (1/1) (80aa942084eddc41f7baf859b5ecb269_2fa5fc7df17f61cb0e1946288970d799_0_0) switched from RUNNING to CANCELING.
INFO  - ExecutionGraph             - Source: concept_name[69] -> Calc[70] (1/1) (80aa942084eddc41f7baf859b5ecb269_2fa5fc7df17f61cb0e1946288970d799_0_0) switched from CANCELING to CANCELED.
INFO  - ExecutionGraph             - Discarding the results produced by task execution 80aa942084eddc41f7baf859b5ecb269_2fa5fc7df17f61cb0e1946288970d799_0_0.
INFO  - ExecutionGraph             - Discarding the results produced by task execution 80aa942084eddc41f7baf859b5ecb269_2fa5fc7df17f61cb0e1946288970d799_0_0.
INFO  - ExecutionGraph             - Join[54] -> Calc[55] (1/1) (80aa942084eddc41f7baf859b5ecb269_55d7dd5010de5a0cb7f3223050a51b73_0_0) switched from RUNNING to CANCELING.
INFO  - ExecutionGraph             - Join[54] -> Calc[55] (1/1) (80aa942084eddc41f7baf859b5ecb269_55d7dd5010de5a0cb7f3223050a51b73_0_0) switched from CANCELING to CANCELED.
INFO  - ExecutionGraph             - Discarding the results produced by task execution 80aa942084eddc41f7baf859b5ecb269_55d7dd5010de5a0cb7f3223050a51b73_0_0.
INFO  - ExecutionGraph             - Discarding the results produced by task execution 80aa942084eddc41f7baf859b5ecb269_55d7dd5010de5a0cb7f3223050a51b73_0_0.
INFO  - ExecutionGraph             - Join[60] -> Calc[61] (1/1) (80aa942084eddc41f7baf859b5ecb269_2e54324c2d6d30259944e7ab21f8249d_0_0) switched from RUNNING to CANCELING.
INFO  - ExecutionGraph             - Join[60] -> Calc[61] (1/1) (80aa942084eddc41f7baf859b5ecb269_2e54324c2d6d30259944e7ab21f8249d_0_0) switched from CANCELING to CANCELED.
INFO  - ExecutionGraph             - Discarding the results produced by task execution 80aa942084eddc41f7baf859b5ecb269_2e54324c2d6d30259944e7ab21f8249d_0_0.
INFO  - ExecutionGraph             - Discarding the results produced by task execution 80aa942084eddc41f7baf859b5ecb269_2e54324c2d6d30259944e7ab21f8249d_0_0.
INFO  - ExecutionGraph             - Join[66] -> Calc[67] (1/1) (80aa942084eddc41f7baf859b5ecb269_ab06fe1c886f2b2a7030a8ed4a30b46a_0_0) switched from RUNNING to CANCELING.
INFO  - ExecutionGraph             - Join[66] -> Calc[67] (1/1) (80aa942084eddc41f7baf859b5ecb269_ab06fe1c886f2b2a7030a8ed4a30b46a_0_0) switched from CANCELING to CANCELED.
INFO  - ExecutionGraph             - Discarding the results produced by task execution 80aa942084eddc41f7baf859b5ecb269_ab06fe1c886f2b2a7030a8ed4a30b46a_0_0.
INFO  - ExecutionGraph             - Discarding the results produced by task execution 80aa942084eddc41f7baf859b5ecb269_ab06fe1c886f2b2a7030a8ed4a30b46a_0_0.
INFO  - ExecutionGraph             - Join[72] -> Calc[73] -> ConstraintEnforcer[74] (1/1) (80aa942084eddc41f7baf859b5ecb269_6d4fd8dcc30b46c08121fc16d7e07e79_0_0) switched from RUNNING to CANCELING.
INFO  - ExecutionGraph             - Join[72] -> Calc[73] -> ConstraintEnforcer[74] (1/1) (80aa942084eddc41f7baf859b5ecb269_6d4fd8dcc30b46c08121fc16d7e07e79_0_0) switched from CANCELING to CANCELED.
INFO  - ExecutionGraph             - Discarding the results produced by task execution 80aa942084eddc41f7baf859b5ecb269_6d4fd8dcc30b46c08121fc16d7e07e79_0_0.
INFO  - ExecutionGraph             - Discarding the results produced by task execution 80aa942084eddc41f7baf859b5ecb269_6d4fd8dcc30b46c08121fc16d7e07e79_0_0.
INFO  - ExecutionGraph             - SinkMaterializer[74] -> Sink: concepts[74] (1/1) (80aa942084eddc41f7baf859b5ecb269_4595a980807a13db332f9917535d0424_0_0) switched from RUNNING to CANCELING.
INFO  - ExecutionGraph             - SinkMaterializer[74] -> Sink: concepts[74] (1/1) (80aa942084eddc41f7baf859b5ecb269_4595a980807a13db332f9917535d0424_0_0) switched from CANCELING to CANCELED.
INFO  - ExecutionGraph             - Discarding the results produced by task execution 588c992944dd31552e175761339ab856_4969848647857cea5647cb2eb2d99d6b_0_0.
INFO  - ExecutionGraph             - Discarding the results produced by task execution 80aa942084eddc41f7baf859b5ecb269_4595a980807a13db332f9917535d0424_0_0.
INFO  - ExecutionGraph             - Discarding the results produced by task execution 5d2b85ced63db2be7a46b4ce2f567a3c_fd907ffb7425150fb379978eab0e6d37_0_0.
INFO  - Task                       - Attempting to fail task externally Join[72] -> Calc[73] -> ConstraintEnforcer[74] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_6d4fd8dcc30b46c08121fc16d7e07e79_0_0).
WARN  - Task                       - Join[72] -> Calc[73] -> ConstraintEnforcer[74] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_6d4fd8dcc30b46c08121fc16d7e07e79_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for 9deef106e67c2b1f77d94f2e02251d44.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id 9deef106e67c2b1f77d94f2e02251d44 lost leadership.
	... 29 more
INFO  - CheckpointCoordinator      - Stopping checkpoint coordinator for job 30b4315f4dce6b8b0d1d34062dbea1c2.
INFO  - CheckpointCoordinator      - Stopping checkpoint coordinator for job 3450ce4e11df2cb7a382b3520dc37240.
INFO  - RocksDBKeyedStateBackend   - Closed RocksDB State Backend. Cleaning up RocksDB working directory /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_9deef106e67c2b1f77d94f2e02251d44_op_StreamingJoinOperator_2e54324c2d6d30259944e7ab21f8249d__1_1__uuid_c2b36257-c314-4fa2-bda0-79bf040f0528.
INFO  - CheckpointCoordinator      - Stopping checkpoint coordinator for job 9deef106e67c2b1f77d94f2e02251d44.
INFO  - Task                       - Triggering cancellation of task code Join[72] -> Calc[73] -> ConstraintEnforcer[74] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_6d4fd8dcc30b46c08121fc16d7e07e79_0_0).
INFO  - ExecutionGraph             - Job 3450ce4e11df2cb7a382b3520dc37240 has been suspended.
INFO  - ExecutionGraph             - Job 30b4315f4dce6b8b0d1d34062dbea1c2 has been suspended.
INFO  - ExecutionGraph             - Job 9deef106e67c2b1f77d94f2e02251d44 has been suspended.
INFO  - Task                       - Attempting to fail task externally Source: concept_reference_map[51] -> Calc[52] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_6cdc5bb954874d922eaee11a8e7b5dd5_0_0).
WARN  - Task                       - Source: concept_reference_map[51] -> Calc[52] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for 9deef106e67c2b1f77d94f2e02251d44.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id 9deef106e67c2b1f77d94f2e02251d44 lost leadership.
	... 29 more
INFO  - Task                       - Triggering cancellation of task code Source: concept_reference_map[51] -> Calc[52] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_6cdc5bb954874d922eaee11a8e7b5dd5_0_0).
INFO  - Task                       - Attempting to fail task externally Source: concept_name[69] -> Calc[70] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_2fa5fc7df17f61cb0e1946288970d799_0_0).
WARN  - Task                       - Source: concept_name[69] -> Calc[70] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_2fa5fc7df17f61cb0e1946288970d799_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for 9deef106e67c2b1f77d94f2e02251d44.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id 9deef106e67c2b1f77d94f2e02251d44 lost leadership.
	... 29 more
INFO  - Task                       - Triggering cancellation of task code Source: concept_name[69] -> Calc[70] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_2fa5fc7df17f61cb0e1946288970d799_0_0).
INFO  - SourceReaderBase           - Closing Source Reader.
INFO  - SplitFetcher               - Shutting down split fetcher 0
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Request joining group due to: consumer pro-actively leaving the group
INFO  - teWriteRequestExecutorImpl - discarding 1 drained requests
INFO  - Task                       - Attempting to fail task externally Join[54] -> Calc[55] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_55d7dd5010de5a0cb7f3223050a51b73_0_0).
INFO  - Metrics                    - Metrics scheduler closed
INFO  - RocksDBKeyedStateBackend   - Closed RocksDB State Backend. Cleaning up RocksDB working directory /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_9deef106e67c2b1f77d94f2e02251d44_op_StreamingJoinOperator_6d4fd8dcc30b46c08121fc16d7e07e79__1_1__uuid_e8bcb993-885c-451e-9c59-2fc082124329.
WARN  - Task                       - Join[54] -> Calc[55] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_55d7dd5010de5a0cb7f3223050a51b73_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for 9deef106e67c2b1f77d94f2e02251d44.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id 9deef106e67c2b1f77d94f2e02251d44 lost leadership.
	... 29 more
INFO  - Task                       - Triggering cancellation of task code Join[54] -> Calc[55] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_55d7dd5010de5a0cb7f3223050a51b73_0_0).
INFO  - SourceReaderBase           - Closing Source Reader.
INFO  - Metrics                    - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  - SplitFetcher               - Shutting down split fetcher 0
INFO  - Metrics                    - Metrics reporters closed
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Request joining group due to: consumer pro-actively leaving the group
INFO  - Metrics                    - Metrics scheduler closed
INFO  - Metrics                    - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  - SourceCoordinator          - Closing SourceCoordinator for source Source: concept[48].
INFO  - Metrics                    - Metrics reporters closed
INFO  - Task                       - Freeing task resources for Join[212] -> Calc[213] (1/1)#0 (2ff118f32116f826e0d468907bf12d2a_d7e78c81a38d2cce4433a75795131bcf_0_0).
INFO  - SourceCoordinator          - Closing SourceCoordinator for source Source: patient[75].
INFO  - AppInfoParser              - App info kafka.consumer for flink-0 unregistered
INFO  - SplitFetcher               - Split fetcher 0 exited.
INFO  - SourceCoordinator          - Closing SourceCoordinator for source Source: patient_appointment[1].
INFO  - Task                       - Freeing task resources for Source: concept_reference_map[51] -> Calc[52] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_6cdc5bb954874d922eaee11a8e7b5dd5_0_0).
INFO  - AppInfoParser              - App info kafka.consumer for flink-0 unregistered
INFO  - SplitFetcher               - Split fetcher 0 exited.
INFO  - SourceCoordinator          - Closing SourceCoordinator for source Source: patient_appointment_provider[15].
INFO  - AppInfoParser              - App info kafka.admin.client for flink-enumerator-admin-client unregistered
INFO  - SourceCoordinator          - Closing SourceCoordinator for source Source: appointment_service[4].
INFO  - AppInfoParser              - App info kafka.admin.client for flink-enumerator-admin-client unregistered
INFO  - AdminMetadataManager       - [AdminClient clientId=flink-enumerator-admin-client] Metadata update failed
org.apache.kafka.common.errors.TimeoutException: The AdminClient thread has exited. Call: fetchMetadata
INFO  - KafkaAdminClient           - [AdminClient clientId=flink-enumerator-admin-client] Timed out 1 remaining operation(s) during close.
INFO  - Task                       - Freeing task resources for Source: concept_name[69] -> Calc[70] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_2fa5fc7df17f61cb0e1946288970d799_0_0).
INFO  - AdminMetadataManager       - [AdminClient clientId=flink-enumerator-admin-client] Metadata update failed
org.apache.kafka.common.errors.TimeoutException: The AdminClient thread has exited. Call: fetchMetadata
INFO  - KafkaAdminClient           - [AdminClient clientId=flink-enumerator-admin-client] Timed out 1 remaining operation(s) during close.
INFO  - SourceCoordinator          - Closing SourceCoordinator for source Source: appointment_service_type[9].
INFO  - AppInfoParser              - App info kafka.admin.client for flink-enumerator-admin-client unregistered
INFO  - AdminMetadataManager       - [AdminClient clientId=flink-enumerator-admin-client] Metadata update failed
org.apache.kafka.common.errors.TimeoutException: The AdminClient thread has exited. Call: fetchMetadata
INFO  - KafkaAdminClient           - [AdminClient clientId=flink-enumerator-admin-client] Timed out 1 remaining operation(s) during close.
INFO  - teWriteRequestExecutorImpl - discarding 1 drained requests
INFO  - AppInfoParser              - App info kafka.admin.client for flink-enumerator-admin-client unregistered
INFO  - AdminMetadataManager       - [AdminClient clientId=flink-enumerator-admin-client] Metadata update failed
org.apache.kafka.common.errors.TimeoutException: The AdminClient thread has exited. Call: fetchMetadata
INFO  - KafkaAdminClient           - [AdminClient clientId=flink-enumerator-admin-client] Timed out 1 remaining operation(s) during close.
INFO  - ltCompletedCheckpointStore - Suspending
INFO  - SourceCoordinator          - Closing SourceCoordinator for source Source: person_address[89].
INFO  - AppInfoParser              - App info kafka.admin.client for flink-enumerator-admin-client unregistered
INFO  - AdminMetadataManager       - [AdminClient clientId=flink-enumerator-admin-client] Metadata update failed
org.apache.kafka.common.errors.TimeoutException: The AdminClient thread has exited. Call: fetchMetadata
INFO  - KafkaAdminClient           - [AdminClient clientId=flink-enumerator-admin-client] Timed out 1 remaining operation(s) during close.
INFO  - AppInfoParser              - App info kafka.admin.client for flink-enumerator-admin-client unregistered
INFO  - AdminMetadataManager       - [AdminClient clientId=flink-enumerator-admin-client] Metadata update failed
org.apache.kafka.common.errors.TimeoutException: The AdminClient thread has exited. Call: fetchMetadata
INFO  - KafkaAdminClient           - [AdminClient clientId=flink-enumerator-admin-client] Timed out 1 remaining operation(s) during close.
INFO  - RocksDBKeyedStateBackend   - Closed RocksDB State Backend. Cleaning up RocksDB working directory /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_9deef106e67c2b1f77d94f2e02251d44_op_StreamingJoinOperator_55d7dd5010de5a0cb7f3223050a51b73__1_1__uuid_0a0c929e-3274-4bf4-9e84-2dd433c44390.
INFO  - AppInfoParser              - App info kafka.admin.client for flink-enumerator-admin-client unregistered
INFO  - AdminMetadataManager       - [AdminClient clientId=flink-enumerator-admin-client] Metadata update failed
org.apache.kafka.common.errors.TimeoutException: The AdminClient thread has exited. Call: fetchMetadata
INFO  - KafkaAdminClient           - [AdminClient clientId=flink-enumerator-admin-client] Timed out 1 remaining operation(s) during close.
INFO  - SourceCoordinator          - Closing SourceCoordinator for source Source: concept_reference_source[63].
INFO  - SourceCoordinator          - Closing SourceCoordinator for source Source: concept_name[69].
INFO  - SourceCoordinator          - Closing SourceCoordinator for source Source: concept_reference_map[51].
INFO  - AppInfoParser              - App info kafka.admin.client for flink-enumerator-admin-client unregistered
INFO  - AdminMetadataManager       - [AdminClient clientId=flink-enumerator-admin-client] Metadata update failed
org.apache.kafka.common.errors.TimeoutException: The AdminClient thread has exited. Call: fetchMetadata
INFO  - KafkaAdminClient           - [AdminClient clientId=flink-enumerator-admin-client] Timed out 1 remaining operation(s) during close.
INFO  - AppInfoParser              - App info kafka.admin.client for flink-enumerator-admin-client unregistered
INFO  - AdminMetadataManager       - [AdminClient clientId=flink-enumerator-admin-client] Metadata update failed
org.apache.kafka.common.errors.TimeoutException: The AdminClient thread has exited. Call: fetchMetadata
INFO  - KafkaAdminClient           - [AdminClient clientId=flink-enumerator-admin-client] Timed out 1 remaining operation(s) during close.
INFO  - AppInfoParser              - App info kafka.admin.client for flink-enumerator-admin-client unregistered
INFO  - AdminMetadataManager       - [AdminClient clientId=flink-enumerator-admin-client] Metadata update failed
org.apache.kafka.common.errors.TimeoutException: The AdminClient thread has exited. Call: fetchMetadata
INFO  - KafkaAdminClient           - [AdminClient clientId=flink-enumerator-admin-client] Timed out 1 remaining operation(s) during close.
INFO  - ltCompletedCheckpointStore - Suspending
INFO  - SourceCoordinator          - Closing SourceCoordinator for source Source: concept_reference_term[57].
INFO  - SourceCoordinator          - Closing SourceCoordinator for source Source: patient_identifier[95].
INFO  - ltCompletedCheckpointStore - Suspending
INFO  - SourceCoordinator          - Closing SourceCoordinator for source Source: person_name[83].
INFO  - AppInfoParser              - App info kafka.admin.client for flink-enumerator-admin-client unregistered
INFO  - AdminMetadataManager       - [AdminClient clientId=flink-enumerator-admin-client] Metadata update failed
org.apache.kafka.common.errors.TimeoutException: The AdminClient thread has exited. Call: fetchMetadata
INFO  - KafkaAdminClient           - [AdminClient clientId=flink-enumerator-admin-client] Timed out 1 remaining operation(s) during close.
INFO  - SourceCoordinator          - Closing SourceCoordinator for source Source: person[78].
INFO  - TaskExecutor               - Close JobManager connection for job 6cadd3411b812f5aeb1f461ff6051653.
INFO  - Task                       - Attempting to fail task externally SinkMaterializer[164] -> Sink: sale_order[164] (1/1)#0 (a1c2895d942138a93658723314479d9c_c27dcf7b54ef6bfd6cff02ca8870b681_0_0).
WARN  - Task                       - SinkMaterializer[164] -> Sink: sale_order[164] (1/1)#0 (a1c2895d942138a93658723314479d9c_c27dcf7b54ef6bfd6cff02ca8870b681_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for 6cadd3411b812f5aeb1f461ff6051653.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id 6cadd3411b812f5aeb1f461ff6051653 lost leadership.
	... 29 more
INFO  - Task                       - Triggering cancellation of task code SinkMaterializer[164] -> Sink: sale_order[164] (1/1)#0 (a1c2895d942138a93658723314479d9c_c27dcf7b54ef6bfd6cff02ca8870b681_0_0).
INFO  - AppInfoParser              - App info kafka.admin.client for flink-enumerator-admin-client unregistered
INFO  - AdminMetadataManager       - [AdminClient clientId=flink-enumerator-admin-client] Metadata update failed
org.apache.kafka.common.errors.TimeoutException: The AdminClient thread has exited. Call: fetchMetadata
INFO  - KafkaAdminClient           - [AdminClient clientId=flink-enumerator-admin-client] Timed out 1 remaining operation(s) during close.
INFO  - AppInfoParser              - App info kafka.admin.client for flink-enumerator-admin-client unregistered
INFO  - AdminMetadataManager       - [AdminClient clientId=flink-enumerator-admin-client] Metadata update failed
org.apache.kafka.common.errors.TimeoutException: The AdminClient thread has exited. Call: fetchMetadata
INFO  - KafkaAdminClient           - [AdminClient clientId=flink-enumerator-admin-client] Timed out 1 remaining operation(s) during close.
INFO  - AppInfoParser              - App info kafka.admin.client for flink-enumerator-admin-client unregistered
INFO  - Metrics                    - Metrics scheduler closed
INFO  - Metrics                    - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  - Metrics                    - Metrics reporters closed
INFO  - AdminMetadataManager       - [AdminClient clientId=flink-enumerator-admin-client] Metadata update failed
org.apache.kafka.common.errors.TimeoutException: The AdminClient thread has exited. Call: fetchMetadata
INFO  - KafkaAdminClient           - [AdminClient clientId=flink-enumerator-admin-client] Timed out 1 remaining operation(s) during close.
INFO  - Metrics                    - Metrics scheduler closed
INFO  - Metrics                    - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  - Task                       - Attempting to fail task externally Source: sale_order[162] -> Calc[163] -> ConstraintEnforcer[164] (1/1)#0 (a1c2895d942138a93658723314479d9c_cbc357ccb763df2852fee8c4fc7d55f2_0_0).
WARN  - Task                       - Source: sale_order[162] -> Calc[163] -> ConstraintEnforcer[164] (1/1)#0 (a1c2895d942138a93658723314479d9c_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for 6cadd3411b812f5aeb1f461ff6051653.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id 6cadd3411b812f5aeb1f461ff6051653 lost leadership.
	... 29 more
INFO  - Task                       - Triggering cancellation of task code Source: sale_order[162] -> Calc[163] -> ConstraintEnforcer[164] (1/1)#0 (a1c2895d942138a93658723314479d9c_cbc357ccb763df2852fee8c4fc7d55f2_0_0).
INFO  - Metrics                    - Metrics scheduler closed
INFO  - Metrics                    - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  - Metrics                    - Metrics reporters closed
INFO  - TaskExecutor               - Close JobManager connection for job 30b4315f4dce6b8b0d1d34062dbea1c2.
INFO  - Task                       - Attempting to fail task externally SinkMaterializer[20] -> Sink: appointments[20] (1/1)#0 (5d2b85ced63db2be7a46b4ce2f567a3c_fd907ffb7425150fb379978eab0e6d37_0_0).
WARN  - Task                       - SinkMaterializer[20] -> Sink: appointments[20] (1/1)#0 (5d2b85ced63db2be7a46b4ce2f567a3c_fd907ffb7425150fb379978eab0e6d37_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for 30b4315f4dce6b8b0d1d34062dbea1c2.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id 30b4315f4dce6b8b0d1d34062dbea1c2 lost leadership.
	... 29 more
INFO  - Task                       - Triggering cancellation of task code SinkMaterializer[20] -> Sink: appointments[20] (1/1)#0 (5d2b85ced63db2be7a46b4ce2f567a3c_fd907ffb7425150fb379978eab0e6d37_0_0).
INFO  - SourceCoordinator          - Source coordinator for source Source: concept_name[69] closed.
INFO  - teWriteRequestExecutorImpl - discarding 1 drained requests
INFO  - SourceReaderBase           - Closing Source Reader.
INFO  - SplitFetcher               - Shutting down split fetcher 0
INFO  - Metrics                    - Metrics scheduler closed
INFO  - Metrics                    - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  - Metrics                    - Metrics reporters closed
INFO  - Metrics                    - Metrics scheduler closed
INFO  - Metrics                    - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  - Metrics                    - Metrics reporters closed
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Request joining group due to: consumer pro-actively leaving the group
INFO  - Metrics                    - Metrics scheduler closed
INFO  - Metrics                    - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  - Task                       - Attempting to fail task externally Source: patient_appointment_provider[15] -> Calc[16] (1/1)#0 (5d2b85ced63db2be7a46b4ce2f567a3c_1171dea6747ab509fdaefbe74f7195af_0_0).
INFO  - Metrics                    - Metrics reporters closed
WARN  - Task                       - Source: patient_appointment_provider[15] -> Calc[16] (1/1)#0 (5d2b85ced63db2be7a46b4ce2f567a3c_1171dea6747ab509fdaefbe74f7195af_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for 30b4315f4dce6b8b0d1d34062dbea1c2.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id 30b4315f4dce6b8b0d1d34062dbea1c2 lost leadership.
	... 29 more
INFO  - Task                       - Triggering cancellation of task code Source: patient_appointment_provider[15] -> Calc[16] (1/1)#0 (5d2b85ced63db2be7a46b4ce2f567a3c_1171dea6747ab509fdaefbe74f7195af_0_0).
INFO  - Metrics                    - Metrics reporters closed
INFO  - Task                       - Attempting to fail task externally Join[7] (1/1)#0 (5d2b85ced63db2be7a46b4ce2f567a3c_5caeaa5e379e7348564aaaaf5ae0d6a6_0_0).
WARN  - Task                       - Join[7] (1/1)#0 (5d2b85ced63db2be7a46b4ce2f567a3c_5caeaa5e379e7348564aaaaf5ae0d6a6_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for 30b4315f4dce6b8b0d1d34062dbea1c2.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id 30b4315f4dce6b8b0d1d34062dbea1c2 lost leadership.
	... 29 more
INFO  - Task                       - Triggering cancellation of task code Join[7] (1/1)#0 (5d2b85ced63db2be7a46b4ce2f567a3c_5caeaa5e379e7348564aaaaf5ae0d6a6_0_0).
INFO  - SourceReaderBase           - Closing Source Reader.
INFO  - SplitFetcher               - Shutting down split fetcher 0
INFO  - Metrics                    - Metrics scheduler closed
INFO  - Metrics                    - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  - Metrics                    - Metrics reporters closed
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Request joining group due to: consumer pro-actively leaving the group
INFO  - RocksDBKeyedStateBackend   - Closed RocksDB State Backend. Cleaning up RocksDB working directory /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_30b4315f4dce6b8b0d1d34062dbea1c2_op_SinkUpsertMaterializer_fd907ffb7425150fb379978eab0e6d37__1_1__uuid_2c7989c6-a514-489a-aa40-81ea0801e938.
INFO  - Task                       - Attempting to fail task externally Source: appointment_service[4] -> Calc[5] (1/1)#0 (5d2b85ced63db2be7a46b4ce2f567a3c_6cdc5bb954874d922eaee11a8e7b5dd5_0_0).
WARN  - Task                       - Source: appointment_service[4] -> Calc[5] (1/1)#0 (5d2b85ced63db2be7a46b4ce2f567a3c_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for 30b4315f4dce6b8b0d1d34062dbea1c2.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id 30b4315f4dce6b8b0d1d34062dbea1c2 lost leadership.
	... 29 more
INFO  - Task                       - Triggering cancellation of task code Source: appointment_service[4] -> Calc[5] (1/1)#0 (5d2b85ced63db2be7a46b4ce2f567a3c_6cdc5bb954874d922eaee11a8e7b5dd5_0_0).
INFO  - Metrics                    - Metrics scheduler closed
INFO  - Metrics                    - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  - RocksDBKeyedStateBackend   - Closed RocksDB State Backend. Cleaning up RocksDB working directory /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_30b4315f4dce6b8b0d1d34062dbea1c2_op_StreamingJoinOperator_5caeaa5e379e7348564aaaaf5ae0d6a6__1_1__uuid_280b4c67-4fc0-49c2-a92a-f03f9639c840.
INFO  - Metrics                    - Metrics scheduler closed
INFO  - Metrics                    - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  - Metrics                    - Metrics reporters closed
INFO  - RocksDBKeyedStateBackend   - Closed RocksDB State Backend. Cleaning up RocksDB working directory /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_6cadd3411b812f5aeb1f461ff6051653_op_SinkUpsertMaterializer_c27dcf7b54ef6bfd6cff02ca8870b681__1_1__uuid_bd9c7b06-ec9e-4d19-aa5a-7ce30a053ac6.
INFO  - SourceReaderBase           - Closing Source Reader.
INFO  - SplitFetcher               - Shutting down split fetcher 0
INFO  - SourceCoordinator          - Source coordinator for source Source: concept_reference_map[51] closed.
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Request joining group due to: consumer pro-actively leaving the group
INFO  - Metrics                    - Metrics scheduler closed
INFO  - Metrics                    - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  - Metrics                    - Metrics reporters closed
INFO  - SourceCoordinator          - Source coordinator for source Source: concept_reference_term[57] closed.
INFO  - Task                       - Attempting to fail task externally Join[12] -> Calc[13] (1/1)#0 (5d2b85ced63db2be7a46b4ce2f567a3c_ccd2f3173f602e66f6767720952cb258_0_0).
WARN  - Task                       - Join[12] -> Calc[13] (1/1)#0 (5d2b85ced63db2be7a46b4ce2f567a3c_ccd2f3173f602e66f6767720952cb258_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for 30b4315f4dce6b8b0d1d34062dbea1c2.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id 30b4315f4dce6b8b0d1d34062dbea1c2 lost leadership.
	... 29 more
INFO  - Task                       - Triggering cancellation of task code Join[12] -> Calc[13] (1/1)#0 (5d2b85ced63db2be7a46b4ce2f567a3c_ccd2f3173f602e66f6767720952cb258_0_0).
INFO  - Metrics                    - Metrics scheduler closed
INFO  - Metrics                    - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  - SourceCoordinator          - Source coordinator for source Source: appointment_service[4] closed.
INFO  - Metrics                    - Metrics scheduler closed
INFO  - Metrics                    - Metrics reporters closed
INFO  - SourceCoordinator          - Source coordinator for source Source: patient_appointment[1] closed.
INFO  - SourceCoordinator          - Source coordinator for source Source: person[78] closed.
INFO  - SourceCoordinator          - Source coordinator for source Source: person_address[89] closed.
INFO  - SourceCoordinator          - Source coordinator for source Source: patient[75] closed.
INFO  - SourceCoordinator          - Source coordinator for source Source: patient_appointment_provider[15] closed.
INFO  - Metrics                    - Metrics scheduler closed
INFO  - Metrics                    - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  - Metrics                    - Metrics reporters closed
INFO  - Task                       - Attempting to fail task externally Source: appointment_service_type[9] -> Calc[10] (1/1)#0 (5d2b85ced63db2be7a46b4ce2f567a3c_2963852293169ba90d9d1e7d6308db5c_0_0).
WARN  - Task                       - Source: appointment_service_type[9] -> Calc[10] (1/1)#0 (5d2b85ced63db2be7a46b4ce2f567a3c_2963852293169ba90d9d1e7d6308db5c_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for 30b4315f4dce6b8b0d1d34062dbea1c2.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id 30b4315f4dce6b8b0d1d34062dbea1c2 lost leadership.
	... 29 more
INFO  - Task                       - Triggering cancellation of task code Source: appointment_service_type[9] -> Calc[10] (1/1)#0 (5d2b85ced63db2be7a46b4ce2f567a3c_2963852293169ba90d9d1e7d6308db5c_0_0).
INFO  - Metrics                    - Metrics scheduler closed
INFO  - Metrics                    - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  - Metrics                    - Metrics reporters closed
INFO  - SourceCoordinator          - Source coordinator for source Source: patient_identifier[95] closed.
INFO  - Metrics                    - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  - Metrics                    - Metrics reporters closed
INFO  - Metrics                    - Metrics scheduler closed
INFO  - Metrics                    - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  - Metrics                    - Metrics reporters closed
INFO  - SourceCoordinator          - Source coordinator for source Source: appointment_service_type[9] closed.
INFO  - SourceCoordinator          - Source coordinator for source Source: concept_reference_source[63] closed.
INFO  - AppInfoParser              - App info kafka.consumer for flink-0 unregistered
INFO  - SplitFetcher               - Split fetcher 0 exited.
INFO  - Metrics                    - Metrics reporters closed
INFO  - RocksDBKeyedStateBackend   - Closed RocksDB State Backend. Cleaning up RocksDB working directory /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_30b4315f4dce6b8b0d1d34062dbea1c2_op_StreamingJoinOperator_ccd2f3173f602e66f6767720952cb258__1_1__uuid_cfa4b98b-4efd-446a-8002-5533645b412a.
INFO  - Task                       - Freeing task resources for Source: patient_appointment_provider[15] -> Calc[16] (1/1)#0 (5d2b85ced63db2be7a46b4ce2f567a3c_1171dea6747ab509fdaefbe74f7195af_0_0).
INFO  - AppInfoParser              - App info kafka.consumer for flink-0 unregistered
INFO  - SplitFetcher               - Split fetcher 0 exited.
INFO  - AppInfoParser              - App info kafka.consumer for flink-0 unregistered
INFO  - SplitFetcher               - Split fetcher 0 exited.
INFO  - Task                       - Attempting to fail task externally Join[18] -> Calc[19] -> ConstraintEnforcer[20] (1/1)#0 (5d2b85ced63db2be7a46b4ce2f567a3c_23e521ac8efce918f328250afebbe45c_0_0).
WARN  - Task                       - Join[18] -> Calc[19] -> ConstraintEnforcer[20] (1/1)#0 (5d2b85ced63db2be7a46b4ce2f567a3c_23e521ac8efce918f328250afebbe45c_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for 30b4315f4dce6b8b0d1d34062dbea1c2.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id 30b4315f4dce6b8b0d1d34062dbea1c2 lost leadership.
	... 29 more
INFO  - Task                       - Triggering cancellation of task code Join[18] -> Calc[19] -> ConstraintEnforcer[20] (1/1)#0 (5d2b85ced63db2be7a46b4ce2f567a3c_23e521ac8efce918f328250afebbe45c_0_0).
INFO  - SourceReaderBase           - Closing Source Reader.
INFO  - SplitFetcher               - Shutting down split fetcher 0
INFO  - Task                       - Freeing task resources for Source: appointment_service[4] -> Calc[5] (1/1)#0 (5d2b85ced63db2be7a46b4ce2f567a3c_6cdc5bb954874d922eaee11a8e7b5dd5_0_0).
INFO  - Metrics                    - Metrics scheduler closed
INFO  - Metrics                    - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  - Metrics                    - Metrics reporters closed
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Request joining group due to: consumer pro-actively leaving the group
INFO  - Metrics                    - Metrics scheduler closed
INFO  - Metrics                    - Metrics scheduler closed
INFO  - Metrics                    - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  - Task                       - Freeing task resources for Source: sale_order[162] -> Calc[163] -> ConstraintEnforcer[164] (1/1)#0 (a1c2895d942138a93658723314479d9c_cbc357ccb763df2852fee8c4fc7d55f2_0_0).
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6653 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 30000ms)
INFO  - SourceCoordinator          - Source coordinator for source Source: person_name[83] closed.
INFO  - Metrics                    - Metrics reporters closed
INFO  - Metrics                    - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  - SourceCoordinator          - Source coordinator for source Source: concept[48] closed.
INFO  - Metrics                    - Metrics reporters closed
INFO  - AppInfoParser              - App info kafka.consumer for flink-0 unregistered
INFO  - SplitFetcher               - Split fetcher 0 exited.
INFO  - Task                       - Freeing task resources for Source: appointment_service_type[9] -> Calc[10] (1/1)#0 (5d2b85ced63db2be7a46b4ce2f567a3c_2963852293169ba90d9d1e7d6308db5c_0_0).
INFO  - teWriteRequestExecutorImpl - discarding 1 drained requests
INFO  - Task                       - Attempting to fail task externally Source: patient_appointment[1] -> Calc[2] (1/1)#0 (5d2b85ced63db2be7a46b4ce2f567a3c_cbc357ccb763df2852fee8c4fc7d55f2_0_0).
WARN  - Task                       - Source: patient_appointment[1] -> Calc[2] (1/1)#0 (5d2b85ced63db2be7a46b4ce2f567a3c_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for 30b4315f4dce6b8b0d1d34062dbea1c2.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id 30b4315f4dce6b8b0d1d34062dbea1c2 lost leadership.
	... 29 more
INFO  - Task                       - Triggering cancellation of task code Source: patient_appointment[1] -> Calc[2] (1/1)#0 (5d2b85ced63db2be7a46b4ce2f567a3c_cbc357ccb763df2852fee8c4fc7d55f2_0_0).
INFO  - teWriteRequestExecutorImpl - discarding 1 drained requests
INFO  - SourceReaderBase           - Closing Source Reader.
INFO  - SplitFetcher               - Shutting down split fetcher 0
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Request joining group due to: consumer pro-actively leaving the group
INFO  - Metrics                    - Metrics scheduler closed
INFO  - Metrics                    - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  - Metrics                    - Metrics reporters closed
INFO  - AppInfoParser              - App info kafka.consumer for flink-0 unregistered
INFO  - SplitFetcher               - Split fetcher 0 exited.
INFO  - Task                       - Freeing task resources for Source: patient_appointment[1] -> Calc[2] (1/1)#0 (5d2b85ced63db2be7a46b4ce2f567a3c_cbc357ccb763df2852fee8c4fc7d55f2_0_0).
INFO  - RocksDBKeyedStateBackend   - Closed RocksDB State Backend. Cleaning up RocksDB working directory /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_30b4315f4dce6b8b0d1d34062dbea1c2_op_StreamingJoinOperator_23e521ac8efce918f328250afebbe45c__1_1__uuid_f640805e-7f52-4049-bba2-0dd6bfefef7f.
INFO  - TaskExecutor               - Close JobManager connection for job 3450ce4e11df2cb7a382b3520dc37240.
INFO  - Task                       - Attempting to fail task externally Source: person_address[89] -> Calc[90] (1/1)#0 (588c992944dd31552e175761339ab856_1171dea6747ab509fdaefbe74f7195af_0_0).
WARN  - Task                       - Source: person_address[89] -> Calc[90] (1/1)#0 (588c992944dd31552e175761339ab856_1171dea6747ab509fdaefbe74f7195af_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for 3450ce4e11df2cb7a382b3520dc37240.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id 3450ce4e11df2cb7a382b3520dc37240 lost leadership.
	... 29 more
INFO  - Task                       - Triggering cancellation of task code Source: person_address[89] -> Calc[90] (1/1)#0 (588c992944dd31552e175761339ab856_1171dea6747ab509fdaefbe74f7195af_0_0).
INFO  - Task                       - Attempting to fail task externally Source: person_name[83] -> Calc[84] (1/1)#0 (588c992944dd31552e175761339ab856_2963852293169ba90d9d1e7d6308db5c_0_0).
WARN  - Task                       - Source: person_name[83] -> Calc[84] (1/1)#0 (588c992944dd31552e175761339ab856_2963852293169ba90d9d1e7d6308db5c_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for 3450ce4e11df2cb7a382b3520dc37240.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id 3450ce4e11df2cb7a382b3520dc37240 lost leadership.
	... 29 more
INFO  - SourceReaderBase           - Closing Source Reader.
INFO  - Task                       - Triggering cancellation of task code Source: person_name[83] -> Calc[84] (1/1)#0 (588c992944dd31552e175761339ab856_2963852293169ba90d9d1e7d6308db5c_0_0).
INFO  - SplitFetcher               - Shutting down split fetcher 0
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Request joining group due to: consumer pro-actively leaving the group
INFO  - Metrics                    - Metrics scheduler closed
INFO  - Metrics                    - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  - Metrics                    - Metrics reporters closed
INFO  - Task                       - Attempting to fail task externally Join[92] -> Calc[93] (1/1)#0 (588c992944dd31552e175761339ab856_fa7571c07da635c59ba82f92b55840d8_0_0).
WARN  - Task                       - Join[92] -> Calc[93] (1/1)#0 (588c992944dd31552e175761339ab856_fa7571c07da635c59ba82f92b55840d8_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for 3450ce4e11df2cb7a382b3520dc37240.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id 3450ce4e11df2cb7a382b3520dc37240 lost leadership.
	... 29 more
INFO  - Task                       - Triggering cancellation of task code Join[92] -> Calc[93] (1/1)#0 (588c992944dd31552e175761339ab856_fa7571c07da635c59ba82f92b55840d8_0_0).
INFO  - SourceReaderBase           - Closing Source Reader.
INFO  - SplitFetcher               - Shutting down split fetcher 0
INFO  - AppInfoParser              - App info kafka.consumer for flink-0 unregistered
INFO  - SplitFetcher               - Split fetcher 0 exited.
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Request joining group due to: consumer pro-actively leaving the group
INFO  - Task                       - Attempting to fail task externally SinkMaterializer[100] -> Sink: patients[100] (1/1)#0 (588c992944dd31552e175761339ab856_4969848647857cea5647cb2eb2d99d6b_0_0).
WARN  - Task                       - SinkMaterializer[100] -> Sink: patients[100] (1/1)#0 (588c992944dd31552e175761339ab856_4969848647857cea5647cb2eb2d99d6b_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for 3450ce4e11df2cb7a382b3520dc37240.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id 3450ce4e11df2cb7a382b3520dc37240 lost leadership.
	... 29 more
INFO  - Task                       - Triggering cancellation of task code SinkMaterializer[100] -> Sink: patients[100] (1/1)#0 (588c992944dd31552e175761339ab856_4969848647857cea5647cb2eb2d99d6b_0_0).
INFO  - Metrics                    - Metrics scheduler closed
INFO  - Metrics                    - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  - Task                       - Freeing task resources for Source: person_address[89] -> Calc[90] (1/1)#0 (588c992944dd31552e175761339ab856_1171dea6747ab509fdaefbe74f7195af_0_0).
INFO  - Metrics                    - Metrics reporters closed
INFO  - Task                       - Attempting to fail task externally Join[81] (1/1)#0 (588c992944dd31552e175761339ab856_e6807280e63afa30c980423999b48cc6_0_0).
WARN  - Task                       - Join[81] (1/1)#0 (588c992944dd31552e175761339ab856_e6807280e63afa30c980423999b48cc6_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for 3450ce4e11df2cb7a382b3520dc37240.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id 3450ce4e11df2cb7a382b3520dc37240 lost leadership.
	... 29 more
INFO  - Task                       - Triggering cancellation of task code Join[81] (1/1)#0 (588c992944dd31552e175761339ab856_e6807280e63afa30c980423999b48cc6_0_0).
INFO  - AppInfoParser              - App info kafka.consumer for flink-0 unregistered
INFO  - SplitFetcher               - Split fetcher 0 exited.
INFO  - RocksDBKeyedStateBackend   - Closed RocksDB State Backend. Cleaning up RocksDB working directory /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_3450ce4e11df2cb7a382b3520dc37240_op_StreamingJoinOperator_fa7571c07da635c59ba82f92b55840d8__1_1__uuid_05066527-5cf8-494c-bafc-822db9006a2d.
INFO  - Task                       - Attempting to fail task externally Join[98] -> Calc[99] -> ConstraintEnforcer[100] (1/1)#0 (588c992944dd31552e175761339ab856_c6adced987710239013e40eb9ab41362_0_0).
WARN  - Task                       - Join[98] -> Calc[99] -> ConstraintEnforcer[100] (1/1)#0 (588c992944dd31552e175761339ab856_c6adced987710239013e40eb9ab41362_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for 3450ce4e11df2cb7a382b3520dc37240.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id 3450ce4e11df2cb7a382b3520dc37240 lost leadership.
	... 29 more
INFO  - Task                       - Triggering cancellation of task code Join[98] -> Calc[99] -> ConstraintEnforcer[100] (1/1)#0 (588c992944dd31552e175761339ab856_c6adced987710239013e40eb9ab41362_0_0).
INFO  - Task                       - Freeing task resources for Source: person_name[83] -> Calc[84] (1/1)#0 (588c992944dd31552e175761339ab856_2963852293169ba90d9d1e7d6308db5c_0_0).
INFO  - RocksDBKeyedStateBackend   - Closed RocksDB State Backend. Cleaning up RocksDB working directory /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_3450ce4e11df2cb7a382b3520dc37240_op_SinkUpsertMaterializer_4969848647857cea5647cb2eb2d99d6b__1_1__uuid_ee0391e6-5d5b-454e-b383-582e12feea44.
INFO  - Task                       - Attempting to fail task externally Source: patient[75] -> Calc[76] (1/1)#0 (588c992944dd31552e175761339ab856_cbc357ccb763df2852fee8c4fc7d55f2_0_0).
WARN  - Task                       - Source: patient[75] -> Calc[76] (1/1)#0 (588c992944dd31552e175761339ab856_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for 3450ce4e11df2cb7a382b3520dc37240.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id 3450ce4e11df2cb7a382b3520dc37240 lost leadership.
	... 29 more
INFO  - Task                       - Triggering cancellation of task code Source: patient[75] -> Calc[76] (1/1)#0 (588c992944dd31552e175761339ab856_cbc357ccb763df2852fee8c4fc7d55f2_0_0).
INFO  - RocksDBKeyedStateBackend   - Closed RocksDB State Backend. Cleaning up RocksDB working directory /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_3450ce4e11df2cb7a382b3520dc37240_op_StreamingJoinOperator_e6807280e63afa30c980423999b48cc6__1_1__uuid_ac3d83a8-2b9c-4f39-9696-bc0d78b435bf.
INFO  - SourceReaderBase           - Closing Source Reader.
INFO  - SplitFetcher               - Shutting down split fetcher 0
INFO  - RocksDBKeyedStateBackend   - Closed RocksDB State Backend. Cleaning up RocksDB working directory /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_3450ce4e11df2cb7a382b3520dc37240_op_StreamingJoinOperator_c6adced987710239013e40eb9ab41362__1_1__uuid_47fbfd74-6bb2-4080-881b-2f892599cabc.
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Request joining group due to: consumer pro-actively leaving the group
INFO  - Task                       - Attempting to fail task externally Source: person[78] -> Calc[79] (1/1)#0 (588c992944dd31552e175761339ab856_6cdc5bb954874d922eaee11a8e7b5dd5_0_0).
INFO  - Metrics                    - Metrics scheduler closed
WARN  - Task                       - Source: person[78] -> Calc[79] (1/1)#0 (588c992944dd31552e175761339ab856_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for 3450ce4e11df2cb7a382b3520dc37240.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id 3450ce4e11df2cb7a382b3520dc37240 lost leadership.
	... 29 more
INFO  - Metrics                    - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  - Metrics                    - Metrics reporters closed
INFO  - Task                       - Triggering cancellation of task code Source: person[78] -> Calc[79] (1/1)#0 (588c992944dd31552e175761339ab856_6cdc5bb954874d922eaee11a8e7b5dd5_0_0).
INFO  - Task                       - Freeing task resources for Join[72] -> Calc[73] -> ConstraintEnforcer[74] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_6d4fd8dcc30b46c08121fc16d7e07e79_0_0).
INFO  - SourceReaderBase           - Closing Source Reader.
INFO  - SplitFetcher               - Shutting down split fetcher 0
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Request joining group due to: consumer pro-actively leaving the group
INFO  - AppInfoParser              - App info kafka.consumer for flink-0 unregistered
INFO  - SplitFetcher               - Split fetcher 0 exited.
INFO  - Metrics                    - Metrics scheduler closed
INFO  - Metrics                    - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  - Metrics                    - Metrics reporters closed
INFO  - Task                       - Attempting to fail task externally Source: patient_identifier[95] -> Calc[96] (1/1)#0 (588c992944dd31552e175761339ab856_2fa5fc7df17f61cb0e1946288970d799_0_0).
WARN  - Task                       - Source: patient_identifier[95] -> Calc[96] (1/1)#0 (588c992944dd31552e175761339ab856_2fa5fc7df17f61cb0e1946288970d799_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for 3450ce4e11df2cb7a382b3520dc37240.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id 3450ce4e11df2cb7a382b3520dc37240 lost leadership.
	... 29 more
INFO  - Task                       - Triggering cancellation of task code Source: patient_identifier[95] -> Calc[96] (1/1)#0 (588c992944dd31552e175761339ab856_2fa5fc7df17f61cb0e1946288970d799_0_0).
INFO  - Task                       - Freeing task resources for Source: patient[75] -> Calc[76] (1/1)#0 (588c992944dd31552e175761339ab856_cbc357ccb763df2852fee8c4fc7d55f2_0_0).
INFO  - teWriteRequestExecutorImpl - discarding 1 drained requests
INFO  - Task                       - Attempting to fail task externally Join[86] -> Calc[87] (1/1)#0 (588c992944dd31552e175761339ab856_eb7d99873eea63dacba8fd9c596677e3_0_0).
WARN  - Task                       - Join[86] -> Calc[87] (1/1)#0 (588c992944dd31552e175761339ab856_eb7d99873eea63dacba8fd9c596677e3_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for 3450ce4e11df2cb7a382b3520dc37240.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id 3450ce4e11df2cb7a382b3520dc37240 lost leadership.
	... 29 more
INFO  - Task                       - Triggering cancellation of task code Join[86] -> Calc[87] (1/1)#0 (588c992944dd31552e175761339ab856_eb7d99873eea63dacba8fd9c596677e3_0_0).
INFO  - AppInfoParser              - App info kafka.consumer for flink-0 unregistered
INFO  - SplitFetcher               - Split fetcher 0 exited.
INFO  - SourceReaderBase           - Closing Source Reader.
INFO  - SplitFetcher               - Shutting down split fetcher 0
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Request joining group due to: consumer pro-actively leaving the group
INFO  - Metrics                    - Metrics scheduler closed
INFO  - Metrics                    - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  - Metrics                    - Metrics reporters closed
INFO  - TaskExecutor               - Close JobManager connection for job e08bfbac0c29fa3541fbb236ff4c9568.
INFO  - Task                       - Freeing task resources for Source: person[78] -> Calc[79] (1/1)#0 (588c992944dd31552e175761339ab856_6cdc5bb954874d922eaee11a8e7b5dd5_0_0).
INFO  - teWriteRequestExecutorImpl - discarding 1 drained requests
INFO  - Task                       - Attempting to fail task externally Source: visit_type[108] -> Calc[109] (1/1)#0 (42d00b36fc131a16543be5485c916ea3_6cdc5bb954874d922eaee11a8e7b5dd5_0_0).
WARN  - Task                       - Source: visit_type[108] -> Calc[109] (1/1)#0 (42d00b36fc131a16543be5485c916ea3_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for e08bfbac0c29fa3541fbb236ff4c9568.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id e08bfbac0c29fa3541fbb236ff4c9568 lost leadership.
	... 29 more
INFO  - Task                       - Triggering cancellation of task code Source: visit_type[108] -> Calc[109] (1/1)#0 (42d00b36fc131a16543be5485c916ea3_6cdc5bb954874d922eaee11a8e7b5dd5_0_0).
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6646 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 30000ms)
INFO  - AppInfoParser              - App info kafka.consumer for flink-0 unregistered
INFO  - SplitFetcher               - Split fetcher 0 exited.
INFO  - Task                       - Freeing task resources for Source: patient_identifier[95] -> Calc[96] (1/1)#0 (588c992944dd31552e175761339ab856_2fa5fc7df17f61cb0e1946288970d799_0_0).
INFO  - Task                       - Attempting to fail task externally SinkMaterializer[119] -> Sink: visits[119] (1/1)#0 (42d00b36fc131a16543be5485c916ea3_b6b54abcd38d0cf242f4ba4c18cb7ed5_0_0).
WARN  - Task                       - SinkMaterializer[119] -> Sink: visits[119] (1/1)#0 (42d00b36fc131a16543be5485c916ea3_b6b54abcd38d0cf242f4ba4c18cb7ed5_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for e08bfbac0c29fa3541fbb236ff4c9568.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id e08bfbac0c29fa3541fbb236ff4c9568 lost leadership.
	... 29 more
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - SourceReaderBase           - Closing Source Reader.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6652 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 30000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6643 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 30000ms)
INFO  - SplitFetcher               - Shutting down split fetcher 0
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6648 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 30000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 27 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - Task                       - Triggering cancellation of task code SinkMaterializer[119] -> Sink: visits[119] (1/1)#0 (42d00b36fc131a16543be5485c916ea3_b6b54abcd38d0cf242f4ba4c18cb7ed5_0_0).
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Request joining group due to: consumer pro-actively leaving the group
INFO  - Metrics                    - Metrics scheduler closed
INFO  - Metrics                    - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  - Metrics                    - Metrics reporters closed
INFO  - RocksDBKeyedStateBackend   - Closed RocksDB State Backend. Cleaning up RocksDB working directory /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_3450ce4e11df2cb7a382b3520dc37240_op_StreamingJoinOperator_eb7d99873eea63dacba8fd9c596677e3__1_1__uuid_a29cd578-e03c-42f3-b4ad-9e2c379595fd.
INFO  - teWriteRequestExecutorImpl - discarding 1 drained requests
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 27 due to node 1 being disconnected (elapsed time since creation: 3ms, elapsed time since send: 3ms, request timeout: 3600000ms)
INFO  - AppInfoParser              - App info kafka.consumer for flink-0 unregistered
INFO  - SplitFetcher               - Split fetcher 0 exited.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - Task                       - Attempting to fail task externally Join[111] -> Calc[112] (1/1)#0 (42d00b36fc131a16543be5485c916ea3_bd51d758b4efb5e2f06d8b93962c12d2_0_0).
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 27 due to node 1 being disconnected (elapsed time since creation: 3ms, elapsed time since send: 3ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 27 due to node 1 being disconnected (elapsed time since creation: 3ms, elapsed time since send: 3ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6648 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 30000ms)
WARN  - Task                       - Join[111] -> Calc[112] (1/1)#0 (42d00b36fc131a16543be5485c916ea3_bd51d758b4efb5e2f06d8b93962c12d2_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for e08bfbac0c29fa3541fbb236ff4c9568.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id e08bfbac0c29fa3541fbb236ff4c9568 lost leadership.
	... 29 more
INFO  - Task                       - Triggering cancellation of task code Join[111] -> Calc[112] (1/1)#0 (42d00b36fc131a16543be5485c916ea3_bd51d758b4efb5e2f06d8b93962c12d2_0_0).
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6642 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 30000ms)
INFO  - Task                       - Freeing task resources for Source: visit_type[108] -> Calc[109] (1/1)#0 (42d00b36fc131a16543be5485c916ea3_6cdc5bb954874d922eaee11a8e7b5dd5_0_0).
INFO  - Task                       - Attempting to fail task externally Source: person[114] -> Calc[115] (1/1)#0 (42d00b36fc131a16543be5485c916ea3_2963852293169ba90d9d1e7d6308db5c_0_0).
WARN  - Task                       - Source: person[114] -> Calc[115] (1/1)#0 (42d00b36fc131a16543be5485c916ea3_2963852293169ba90d9d1e7d6308db5c_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for e08bfbac0c29fa3541fbb236ff4c9568.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id e08bfbac0c29fa3541fbb236ff4c9568 lost leadership.
	... 29 more
INFO  - Task                       - Triggering cancellation of task code Source: person[114] -> Calc[115] (1/1)#0 (42d00b36fc131a16543be5485c916ea3_2963852293169ba90d9d1e7d6308db5c_0_0).
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6645 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 30000ms)
INFO  - SourceReaderBase           - Closing Source Reader.
INFO  - SplitFetcher               - Shutting down split fetcher 0
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Request joining group due to: consumer pro-actively leaving the group
INFO  - Metrics                    - Metrics scheduler closed
INFO  - Metrics                    - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  - Metrics                    - Metrics reporters closed
INFO  - Task                       - Attempting to fail task externally Join[117] -> Calc[118] -> ConstraintEnforcer[119] (1/1)#0 (42d00b36fc131a16543be5485c916ea3_2e97d77449c913cf0f6bfb4cb4497fa8_0_0).
WARN  - Task                       - Join[117] -> Calc[118] -> ConstraintEnforcer[119] (1/1)#0 (42d00b36fc131a16543be5485c916ea3_2e97d77449c913cf0f6bfb4cb4497fa8_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for e08bfbac0c29fa3541fbb236ff4c9568.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id e08bfbac0c29fa3541fbb236ff4c9568 lost leadership.
	... 29 more
INFO  - Task                       - Triggering cancellation of task code Join[117] -> Calc[118] -> ConstraintEnforcer[119] (1/1)#0 (42d00b36fc131a16543be5485c916ea3_2e97d77449c913cf0f6bfb4cb4497fa8_0_0).
INFO  - AppInfoParser              - App info kafka.consumer for flink-0 unregistered
INFO  - SplitFetcher               - Split fetcher 0 exited.
INFO  - RocksDBKeyedStateBackend   - Closed RocksDB State Backend. Cleaning up RocksDB working directory /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_e08bfbac0c29fa3541fbb236ff4c9568_op_SinkUpsertMaterializer_b6b54abcd38d0cf242f4ba4c18cb7ed5__1_1__uuid_a32c743c-1674-4ab4-9885-0793ca97bc88.
INFO  - RocksDBKeyedStateBackend   - Closed RocksDB State Backend. Cleaning up RocksDB working directory /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_e08bfbac0c29fa3541fbb236ff4c9568_op_StreamingJoinOperator_bd51d758b4efb5e2f06d8b93962c12d2__1_1__uuid_1249d7f7-f4e9-4e45-ad3e-db5266c4ea1f.
INFO  - Task                       - Freeing task resources for Source: person[114] -> Calc[115] (1/1)#0 (42d00b36fc131a16543be5485c916ea3_2963852293169ba90d9d1e7d6308db5c_0_0).
INFO  - Task                       - Attempting to fail task externally Source: visit[105] -> Calc[106] (1/1)#0 (42d00b36fc131a16543be5485c916ea3_cbc357ccb763df2852fee8c4fc7d55f2_0_0).
WARN  - Task                       - Source: visit[105] -> Calc[106] (1/1)#0 (42d00b36fc131a16543be5485c916ea3_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for e08bfbac0c29fa3541fbb236ff4c9568.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id e08bfbac0c29fa3541fbb236ff4c9568 lost leadership.
	... 29 more
INFO  - Task                       - Triggering cancellation of task code Source: visit[105] -> Calc[106] (1/1)#0 (42d00b36fc131a16543be5485c916ea3_cbc357ccb763df2852fee8c4fc7d55f2_0_0).
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6656 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 30000ms)
INFO  - teWriteRequestExecutorImpl - discarding 1 drained requests
INFO  - TaskExecutor               - Close JobManager connection for job 1d1394375e4908f94ef8c8210cd9a417.
INFO  - Task                       - Attempting to fail task externally Source: orders[21] -> Calc[22] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_cbc357ccb763df2852fee8c4fc7d55f2_0_0).
WARN  - Task                       - Source: orders[21] -> Calc[22] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for 1d1394375e4908f94ef8c8210cd9a417.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id 1d1394375e4908f94ef8c8210cd9a417 lost leadership.
	... 29 more
INFO  - Task                       - Triggering cancellation of task code Source: orders[21] -> Calc[22] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_cbc357ccb763df2852fee8c4fc7d55f2_0_0).
INFO  - SourceReaderBase           - Closing Source Reader.
INFO  - SplitFetcher               - Shutting down split fetcher 0
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Request joining group due to: consumer pro-actively leaving the group
INFO  - Metrics                    - Metrics scheduler closed
INFO  - Metrics                    - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  - Metrics                    - Metrics reporters closed
INFO  - Task                       - Attempting to fail task externally Source: order_type[24] -> Calc[25] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_6cdc5bb954874d922eaee11a8e7b5dd5_0_0).
WARN  - Task                       - Source: order_type[24] -> Calc[25] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for 1d1394375e4908f94ef8c8210cd9a417.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id 1d1394375e4908f94ef8c8210cd9a417 lost leadership.
	... 29 more
INFO  - Task                       - Triggering cancellation of task code Source: order_type[24] -> Calc[25] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_6cdc5bb954874d922eaee11a8e7b5dd5_0_0).
INFO  - SourceReaderBase           - Closing Source Reader.
INFO  - SplitFetcher               - Shutting down split fetcher 0
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Request joining group due to: consumer pro-actively leaving the group
INFO  - AppInfoParser              - App info kafka.consumer for flink-0 unregistered
INFO  - SplitFetcher               - Split fetcher 0 exited.
INFO  - Metrics                    - Metrics scheduler closed
INFO  - Metrics                    - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  - Metrics                    - Metrics reporters closed
INFO  - Task                       - Freeing task resources for Source: visit[105] -> Calc[106] (1/1)#0 (42d00b36fc131a16543be5485c916ea3_cbc357ccb763df2852fee8c4fc7d55f2_0_0).
INFO  - Task                       - Attempting to fail task externally Join[39] -> Calc[40] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_ab06fe1c886f2b2a7030a8ed4a30b46a_0_0).
WARN  - Task                       - Join[39] -> Calc[40] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_ab06fe1c886f2b2a7030a8ed4a30b46a_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for 1d1394375e4908f94ef8c8210cd9a417.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id 1d1394375e4908f94ef8c8210cd9a417 lost leadership.
	... 29 more
INFO  - Task                       - Triggering cancellation of task code Join[39] -> Calc[40] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_ab06fe1c886f2b2a7030a8ed4a30b46a_0_0).
INFO  - AppInfoParser              - App info kafka.consumer for flink-0 unregistered
INFO  - SplitFetcher               - Split fetcher 0 exited.
INFO  - SourceReaderBase           - Closing Source Reader.
INFO  - SplitFetcher               - Shutting down split fetcher 0
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Request joining group due to: consumer pro-actively leaving the group
INFO  - Metrics                    - Metrics scheduler closed
INFO  - Metrics                    - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  - Metrics                    - Metrics reporters closed
INFO  - AppInfoParser              - App info kafka.consumer for flink-0 unregistered
INFO  - SplitFetcher               - Split fetcher 0 exited.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6641 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 30000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 27 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - RocksDBKeyedStateBackend   - Closed RocksDB State Backend. Cleaning up RocksDB working directory /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_e08bfbac0c29fa3541fbb236ff4c9568_op_StreamingJoinOperator_2e97d77449c913cf0f6bfb4cb4497fa8__1_1__uuid_3233301e-d8f8-441d-a92c-70366ed50a90.
INFO  - Task                       - Freeing task resources for Source: orders[21] -> Calc[22] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_cbc357ccb763df2852fee8c4fc7d55f2_0_0).
INFO  - Task                       - Attempting to fail task externally Join[45] -> Calc[46] -> ConstraintEnforcer[47] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_6d4fd8dcc30b46c08121fc16d7e07e79_0_0).
WARN  - Task                       - Join[45] -> Calc[46] -> ConstraintEnforcer[47] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_6d4fd8dcc30b46c08121fc16d7e07e79_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for 1d1394375e4908f94ef8c8210cd9a417.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id 1d1394375e4908f94ef8c8210cd9a417 lost leadership.
	... 29 more
INFO  - Task                       - Triggering cancellation of task code Join[45] -> Calc[46] -> ConstraintEnforcer[47] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_6d4fd8dcc30b46c08121fc16d7e07e79_0_0).
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 27 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - Task                       - Freeing task resources for Source: order_type[24] -> Calc[25] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_6cdc5bb954874d922eaee11a8e7b5dd5_0_0).
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 27 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6641 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 30000ms)
INFO  - Task                       - Freeing task resources for Join[60] -> Calc[61] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_2e54324c2d6d30259944e7ab21f8249d_0_0).
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 4810 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 30000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6651 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 30000ms)
INFO  - Task                       - Attempting to fail task externally Source: care_setting[30] -> Calc[31] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_2963852293169ba90d9d1e7d6308db5c_0_0).
WARN  - Task                       - Source: care_setting[30] -> Calc[31] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_2963852293169ba90d9d1e7d6308db5c_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for 1d1394375e4908f94ef8c8210cd9a417.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id 1d1394375e4908f94ef8c8210cd9a417 lost leadership.
	... 29 more
INFO  - Task                       - Triggering cancellation of task code Source: care_setting[30] -> Calc[31] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_2963852293169ba90d9d1e7d6308db5c_0_0).
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6648 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 30000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6644 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 30000ms)
INFO  - RocksDBKeyedStateBackend   - Closed RocksDB State Backend. Cleaning up RocksDB working directory /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_1d1394375e4908f94ef8c8210cd9a417_op_StreamingJoinOperator_ab06fe1c886f2b2a7030a8ed4a30b46a__1_1__uuid_701dc00f-3081-4196-8205-fd8593d3b816.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 27 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - RocksDBKeyedStateBackend   - Closed RocksDB State Backend. Cleaning up RocksDB working directory /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_1d1394375e4908f94ef8c8210cd9a417_op_StreamingJoinOperator_6d4fd8dcc30b46c08121fc16d7e07e79__1_1__uuid_3c7e9d33-ea34-457e-ad27-d0aed0f12ed7.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 27 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - Task                       - Attempting to fail task externally Source: encounter[36] -> Calc[37] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_1171dea6747ab509fdaefbe74f7195af_0_0).
WARN  - Task                       - Source: encounter[36] -> Calc[37] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_1171dea6747ab509fdaefbe74f7195af_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for 1d1394375e4908f94ef8c8210cd9a417.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id 1d1394375e4908f94ef8c8210cd9a417 lost leadership.
	... 29 more
INFO  - Task                       - Triggering cancellation of task code Source: encounter[36] -> Calc[37] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_1171dea6747ab509fdaefbe74f7195af_0_0).
INFO  - SourceReaderBase           - Closing Source Reader.
INFO  - SplitFetcher               - Shutting down split fetcher 0
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Request joining group due to: consumer pro-actively leaving the group
INFO  - Metrics                    - Metrics scheduler closed
INFO  - Metrics                    - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  - Metrics                    - Metrics reporters closed
INFO  - SourceReaderBase           - Closing Source Reader.
INFO  - SplitFetcher               - Shutting down split fetcher 0
INFO  - Task                       - Attempting to fail task externally Source: encounter_type[42] -> Calc[43] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_2fa5fc7df17f61cb0e1946288970d799_0_0).
WARN  - Task                       - Source: encounter_type[42] -> Calc[43] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_2fa5fc7df17f61cb0e1946288970d799_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for 1d1394375e4908f94ef8c8210cd9a417.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id 1d1394375e4908f94ef8c8210cd9a417 lost leadership.
	... 29 more
INFO  - Task                       - Triggering cancellation of task code Source: encounter_type[42] -> Calc[43] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_2fa5fc7df17f61cb0e1946288970d799_0_0).
INFO  - AppInfoParser              - App info kafka.consumer for flink-0 unregistered
INFO  - SplitFetcher               - Split fetcher 0 exited.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6657 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 30000ms)
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Request joining group due to: consumer pro-actively leaving the group
INFO  - teWriteRequestExecutorImpl - discarding 1 drained requests
INFO  - Task                       - Freeing task resources for Source: care_setting[30] -> Calc[31] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_2963852293169ba90d9d1e7d6308db5c_0_0).
INFO  - Task                       - Attempting to fail task externally Join[33] -> Calc[34] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_2e54324c2d6d30259944e7ab21f8249d_0_0).
WARN  - Task                       - Join[33] -> Calc[34] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_2e54324c2d6d30259944e7ab21f8249d_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for 1d1394375e4908f94ef8c8210cd9a417.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id 1d1394375e4908f94ef8c8210cd9a417 lost leadership.
	... 29 more
INFO  - Task                       - Triggering cancellation of task code Join[33] -> Calc[34] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_2e54324c2d6d30259944e7ab21f8249d_0_0).
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 27 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - SourceReaderBase           - Closing Source Reader.
INFO  - SplitFetcher               - Shutting down split fetcher 0
INFO  - Metrics                    - Metrics scheduler closed
INFO  - Metrics                    - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  - Metrics                    - Metrics reporters closed
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 27 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6639 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 30000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 27 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 27 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Node 1 disconnected.
INFO  - NetworkClient              - [Consumer clientId=flink-0, groupId=flink] Cancelled in-flight API_VERSIONS request with correlation id 6641 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 30000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 27 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 27 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 27 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Request joining group due to: consumer pro-actively leaving the group
INFO  - AppInfoParser              - App info kafka.consumer for flink-0 unregistered
INFO  - SplitFetcher               - Split fetcher 0 exited.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 27 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - Task                       - Attempting to fail task externally Join[27] -> Calc[28] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_55d7dd5010de5a0cb7f3223050a51b73_0_0).
WARN  - Task                       - Join[27] -> Calc[28] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_55d7dd5010de5a0cb7f3223050a51b73_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for 1d1394375e4908f94ef8c8210cd9a417.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id 1d1394375e4908f94ef8c8210cd9a417 lost leadership.
	... 29 more
INFO  - Task                       - Triggering cancellation of task code Join[27] -> Calc[28] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_55d7dd5010de5a0cb7f3223050a51b73_0_0).
INFO  - Metrics                    - Metrics scheduler closed
INFO  - Metrics                    - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  - Metrics                    - Metrics reporters closed
INFO  - Task                       - Freeing task resources for Source: encounter[36] -> Calc[37] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_1171dea6747ab509fdaefbe74f7195af_0_0).
INFO  - AppInfoParser              - App info kafka.consumer for flink-0 unregistered
INFO  - SplitFetcher               - Split fetcher 0 exited.
INFO  - Task                       - Freeing task resources for Source: encounter_type[42] -> Calc[43] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_2fa5fc7df17f61cb0e1946288970d799_0_0).
INFO  - Task                       - Attempting to fail task externally SinkMaterializer[47] -> Sink: orders[47] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_4595a980807a13db332f9917535d0424_0_0).
WARN  - Task                       - SinkMaterializer[47] -> Sink: orders[47] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_4595a980807a13db332f9917535d0424_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for 1d1394375e4908f94ef8c8210cd9a417.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id 1d1394375e4908f94ef8c8210cd9a417 lost leadership.
	... 29 more
INFO  - Task                       - Triggering cancellation of task code SinkMaterializer[47] -> Sink: orders[47] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_4595a980807a13db332f9917535d0424_0_0).
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 27 due to node 1 being disconnected (elapsed time since creation: 4ms, elapsed time since send: 4ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 27 due to node 1 being disconnected (elapsed time since creation: 4ms, elapsed time since send: 4ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 27 due to node 1 being disconnected (elapsed time since creation: 3ms, elapsed time since send: 3ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 27 due to node 1 being disconnected (elapsed time since creation: 3ms, elapsed time since send: 3ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 27 due to node 1 being disconnected (elapsed time since creation: 4ms, elapsed time since send: 4ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 27 due to node 1 being disconnected (elapsed time since creation: 3ms, elapsed time since send: 3ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 27 due to node 1 being disconnected (elapsed time since creation: 3ms, elapsed time since send: 3ms, request timeout: 3600000ms)
INFO  - RocksDBKeyedStateBackend   - Closed RocksDB State Backend. Cleaning up RocksDB working directory /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_1d1394375e4908f94ef8c8210cd9a417_op_StreamingJoinOperator_2e54324c2d6d30259944e7ab21f8249d__1_1__uuid_6c423438-a367-4e56-be2e-b9174b3d9678.
INFO  - teWriteRequestExecutorImpl - discarding 1 drained requests
INFO  - RocksDBKeyedStateBackend   - Closed RocksDB State Backend. Cleaning up RocksDB working directory /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_1d1394375e4908f94ef8c8210cd9a417_op_StreamingJoinOperator_55d7dd5010de5a0cb7f3223050a51b73__1_1__uuid_363f05b0-51d6-4cfa-989d-e540a324e94b.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 27 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 27 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - TaskExecutor               - Close ResourceManager connection 6e4eb064b0070507828e621c049921bd.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 27 due to node 1 being disconnected (elapsed time since creation: 0ms, elapsed time since send: 0ms, request timeout: 3600000ms)
INFO  - RocksDBKeyedStateBackend   - Closed RocksDB State Backend. Cleaning up RocksDB working directory /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_1d1394375e4908f94ef8c8210cd9a417_op_SinkUpsertMaterializer_4595a980807a13db332f9917535d0424__1_1__uuid_82150774-3961-4072-97a7-e1857004c6b4.
INFO  - TaskExecutor               - Close JobManager connection for job ee8b603bf5edab3af85b6467db69921f.
INFO  - Task                       - Attempting to fail task externally Source: visit[135] -> Calc[136] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_1171dea6747ab509fdaefbe74f7195af_0_0).
WARN  - Task                       - Source: visit[135] -> Calc[136] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_1171dea6747ab509fdaefbe74f7195af_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for ee8b603bf5edab3af85b6467db69921f.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id ee8b603bf5edab3af85b6467db69921f lost leadership.
	... 29 more
INFO  - Task                       - Triggering cancellation of task code Source: visit[135] -> Calc[136] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_1171dea6747ab509fdaefbe74f7195af_0_0).
INFO  - Task                       - Attempting to fail task externally Join[132] -> Calc[133] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_e2fa199699a83ccdc9109b613d7b5bcb_0_0).
WARN  - Task                       - Join[132] -> Calc[133] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_e2fa199699a83ccdc9109b613d7b5bcb_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for ee8b603bf5edab3af85b6467db69921f.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id ee8b603bf5edab3af85b6467db69921f lost leadership.
	... 29 more
INFO  - Task                       - Triggering cancellation of task code Join[132] -> Calc[133] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_e2fa199699a83ccdc9109b613d7b5bcb_0_0).
INFO  - SourceReaderBase           - Closing Source Reader.
INFO  - SplitFetcher               - Shutting down split fetcher 0
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Request joining group due to: consumer pro-actively leaving the group
INFO  - Metrics                    - Metrics scheduler closed
INFO  - Metrics                    - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  - Metrics                    - Metrics reporters closed
INFO  - AppInfoParser              - App info kafka.consumer for flink-0 unregistered
INFO  - SplitFetcher               - Split fetcher 0 exited.
INFO  - Task                       - Attempting to fail task externally Join[156] -> Calc[157] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_922a00317cf5b7bf8065287dc182322e_0_0).
WARN  - Task                       - Join[156] -> Calc[157] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_922a00317cf5b7bf8065287dc182322e_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for ee8b603bf5edab3af85b6467db69921f.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id ee8b603bf5edab3af85b6467db69921f lost leadership.
	... 29 more
INFO  - Task                       - Triggering cancellation of task code Join[156] -> Calc[157] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_922a00317cf5b7bf8065287dc182322e_0_0).
INFO  - Task                       - Freeing task resources for Source: visit[135] -> Calc[136] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_1171dea6747ab509fdaefbe74f7195af_0_0).
INFO  - Task                       - Attempting to fail task externally Join[126] -> Calc[127] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_3619c62de06dab71ff39a3a74a9f2151_0_0).
WARN  - Task                       - Join[126] -> Calc[127] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_3619c62de06dab71ff39a3a74a9f2151_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for ee8b603bf5edab3af85b6467db69921f.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id ee8b603bf5edab3af85b6467db69921f lost leadership.
	... 29 more
INFO  - Task                       - Triggering cancellation of task code Join[126] -> Calc[127] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_3619c62de06dab71ff39a3a74a9f2151_0_0).
INFO  - Task                       - Attempting to fail task externally Join[159] -> Calc[160] -> ConstraintEnforcer[161] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_a9f432d42f94da06ca5ecfb8d49d422a_0_0).
WARN  - Task                       - Join[159] -> Calc[160] -> ConstraintEnforcer[161] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_a9f432d42f94da06ca5ecfb8d49d422a_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for ee8b603bf5edab3af85b6467db69921f.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id ee8b603bf5edab3af85b6467db69921f lost leadership.
	... 29 more
INFO  - RocksDBKeyedStateBackend   - Closed RocksDB State Backend. Cleaning up RocksDB working directory /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_ee8b603bf5edab3af85b6467db69921f_op_StreamingJoinOperator_e2fa199699a83ccdc9109b613d7b5bcb__1_1__uuid_cc7fc9b4-a652-467c-93a6-09b5569a6d7b.
INFO  - RocksDBKeyedStateBackend   - Closed RocksDB State Backend. Cleaning up RocksDB working directory /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_ee8b603bf5edab3af85b6467db69921f_op_StreamingJoinOperator_922a00317cf5b7bf8065287dc182322e__1_1__uuid_810b464f-f49d-4d22-bd0d-602b08dc4284.
INFO  - Task                       - Triggering cancellation of task code Join[159] -> Calc[160] -> ConstraintEnforcer[161] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_a9f432d42f94da06ca5ecfb8d49d422a_0_0).
INFO  - Task                       - Attempting to fail task externally Source: encounter[129] -> Calc[130] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_2963852293169ba90d9d1e7d6308db5c_0_0).
WARN  - Task                       - Source: encounter[129] -> Calc[130] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_2963852293169ba90d9d1e7d6308db5c_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for ee8b603bf5edab3af85b6467db69921f.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id ee8b603bf5edab3af85b6467db69921f lost leadership.
	... 29 more
INFO  - Task                       - Triggering cancellation of task code Source: encounter[129] -> Calc[130] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_2963852293169ba90d9d1e7d6308db5c_0_0).
INFO  - Task                       - Attempting to fail task externally Source: visit_type[147] -> Calc[148] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_5c4ca2fea30dcf09bf3ee40c495fe808_0_0).
WARN  - Task                       - Source: visit_type[147] -> Calc[148] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_5c4ca2fea30dcf09bf3ee40c495fe808_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for ee8b603bf5edab3af85b6467db69921f.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id ee8b603bf5edab3af85b6467db69921f lost leadership.
	... 29 more
INFO  - Task                       - Triggering cancellation of task code Source: visit_type[147] -> Calc[148] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_5c4ca2fea30dcf09bf3ee40c495fe808_0_0).
INFO  - SourceReaderBase           - Closing Source Reader.
INFO  - SplitFetcher               - Shutting down split fetcher 0
INFO  - RocksDBKeyedStateBackend   - Closed RocksDB State Backend. Cleaning up RocksDB working directory /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_ee8b603bf5edab3af85b6467db69921f_op_StreamingJoinOperator_3619c62de06dab71ff39a3a74a9f2151__1_1__uuid_fddeb50c-52ce-4530-b407-2bcaae53fdb9.
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Request joining group due to: consumer pro-actively leaving the group
INFO  - Metrics                    - Metrics scheduler closed
INFO  - Metrics                    - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  - Metrics                    - Metrics reporters closed
INFO  - SourceReaderBase           - Closing Source Reader.
INFO  - Task                       - Attempting to fail task externally Source: encounter_type[141] -> Calc[142] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_2fa5fc7df17f61cb0e1946288970d799_0_0).
INFO  - SplitFetcher               - Shutting down split fetcher 0
WARN  - Task                       - Source: encounter_type[141] -> Calc[142] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_2fa5fc7df17f61cb0e1946288970d799_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for ee8b603bf5edab3af85b6467db69921f.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id ee8b603bf5edab3af85b6467db69921f lost leadership.
	... 29 more
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Request joining group due to: consumer pro-actively leaving the group
INFO  - Task                       - Triggering cancellation of task code Source: encounter_type[141] -> Calc[142] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_2fa5fc7df17f61cb0e1946288970d799_0_0).
INFO  - AppInfoParser              - App info kafka.consumer for flink-0 unregistered
INFO  - SplitFetcher               - Split fetcher 0 exited.
INFO  - Metrics                    - Metrics scheduler closed
INFO  - Metrics                    - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  - Metrics                    - Metrics reporters closed
INFO  - Task                       - Freeing task resources for Join[66] -> Calc[67] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_ab06fe1c886f2b2a7030a8ed4a30b46a_0_0).
INFO  - RocksDBKeyedStateBackend   - Closed RocksDB State Backend. Cleaning up RocksDB working directory /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_ee8b603bf5edab3af85b6467db69921f_op_StreamingJoinOperator_a9f432d42f94da06ca5ecfb8d49d422a__1_1__uuid_b9d4c66e-6cb3-44ff-877f-761e385740fc.
INFO  - Task                       - Attempting to fail task externally Join[144] -> Calc[145] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_5a4f0cabf832f59a1be42827a99c3e0b_0_0).
INFO  - Task                       - Freeing task resources for Source: encounter[129] -> Calc[130] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_2963852293169ba90d9d1e7d6308db5c_0_0).
WARN  - Task                       - Join[144] -> Calc[145] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_5a4f0cabf832f59a1be42827a99c3e0b_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for ee8b603bf5edab3af85b6467db69921f.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id ee8b603bf5edab3af85b6467db69921f lost leadership.
	... 29 more
INFO  - Task                       - Triggering cancellation of task code Join[144] -> Calc[145] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_5a4f0cabf832f59a1be42827a99c3e0b_0_0).
INFO  - AppInfoParser              - App info kafka.consumer for flink-0 unregistered
INFO  - SplitFetcher               - Split fetcher 0 exited.
INFO  - SourceReaderBase           - Closing Source Reader.
INFO  - SplitFetcher               - Shutting down split fetcher 0
INFO  - Task                       - Freeing task resources for Source: visit_type[147] -> Calc[148] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_5c4ca2fea30dcf09bf3ee40c495fe808_0_0).
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Request joining group due to: consumer pro-actively leaving the group
INFO  - Metrics                    - Metrics scheduler closed
INFO  - Metrics                    - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  - Metrics                    - Metrics reporters closed
INFO  - AppInfoParser              - App info kafka.consumer for flink-0 unregistered
INFO  - SplitFetcher               - Split fetcher 0 exited.
INFO  - Task                       - Attempting to fail task externally Source: location[153] -> Calc[154] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_6dc0226b15c44c9c2e1f9ea1a65fd400_0_0).
WARN  - Task                       - Source: location[153] -> Calc[154] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_6dc0226b15c44c9c2e1f9ea1a65fd400_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for ee8b603bf5edab3af85b6467db69921f.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id ee8b603bf5edab3af85b6467db69921f lost leadership.
	... 29 more
INFO  - Task                       - Triggering cancellation of task code Source: location[153] -> Calc[154] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_6dc0226b15c44c9c2e1f9ea1a65fd400_0_0).
INFO  - Task                       - Freeing task resources for Source: encounter_type[141] -> Calc[142] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_2fa5fc7df17f61cb0e1946288970d799_0_0).
INFO  - SourceReaderBase           - Closing Source Reader.
INFO  - SplitFetcher               - Shutting down split fetcher 0
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Request joining group due to: consumer pro-actively leaving the group
INFO  - Metrics                    - Metrics scheduler closed
INFO  - Metrics                    - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  - Metrics                    - Metrics reporters closed
INFO  - Task                       - Attempting to fail task externally SinkMaterializer[161] -> Sink: observations[161] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_f4513f6c8f56192fb7e41d1eacfc44d9_0_0).
WARN  - Task                       - SinkMaterializer[161] -> Sink: observations[161] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_f4513f6c8f56192fb7e41d1eacfc44d9_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for ee8b603bf5edab3af85b6467db69921f.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id ee8b603bf5edab3af85b6467db69921f lost leadership.
	... 29 more
INFO  - Task                       - Triggering cancellation of task code SinkMaterializer[161] -> Sink: observations[161] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_f4513f6c8f56192fb7e41d1eacfc44d9_0_0).
INFO  - Task                       - Attempting to fail task externally Source: obs[120] -> Calc[121] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_cbc357ccb763df2852fee8c4fc7d55f2_0_0).
WARN  - Task                       - Source: obs[120] -> Calc[121] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_cbc357ccb763df2852fee8c4fc7d55f2_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for ee8b603bf5edab3af85b6467db69921f.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id ee8b603bf5edab3af85b6467db69921f lost leadership.
	... 29 more
INFO  - Task                       - Triggering cancellation of task code Source: obs[120] -> Calc[121] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_cbc357ccb763df2852fee8c4fc7d55f2_0_0).
INFO  - SourceReaderBase           - Closing Source Reader.
INFO  - SplitFetcher               - Shutting down split fetcher 0
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Request joining group due to: consumer pro-actively leaving the group
INFO  - Task                       - Attempting to fail task externally Source: concept_name[123] -> Calc[124] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_6cdc5bb954874d922eaee11a8e7b5dd5_0_0).
WARN  - Task                       - Source: concept_name[123] -> Calc[124] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for ee8b603bf5edab3af85b6467db69921f.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id ee8b603bf5edab3af85b6467db69921f lost leadership.
	... 29 more
INFO  - Task                       - Triggering cancellation of task code Source: concept_name[123] -> Calc[124] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_6cdc5bb954874d922eaee11a8e7b5dd5_0_0).
INFO  - RocksDBKeyedStateBackend   - Closed RocksDB State Backend. Cleaning up RocksDB working directory /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_ee8b603bf5edab3af85b6467db69921f_op_StreamingJoinOperator_5a4f0cabf832f59a1be42827a99c3e0b__1_1__uuid_5b562fbb-dc2c-466d-81c7-9784f62345d3.
INFO  - AppInfoParser              - App info kafka.consumer for flink-0 unregistered
INFO  - SplitFetcher               - Split fetcher 0 exited.
INFO  - Metrics                    - Metrics scheduler closed
INFO  - Metrics                    - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  - Metrics                    - Metrics reporters closed
INFO  - teWriteRequestExecutorImpl - discarding 1 drained requests
INFO  - Task                       - Freeing task resources for Source: location[153] -> Calc[154] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_6dc0226b15c44c9c2e1f9ea1a65fd400_0_0).
INFO  - Task                       - Attempting to fail task externally Join[150] -> Calc[151] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_962215956b0b799dc86f9b7cf721b29f_0_0).
INFO  - AppInfoParser              - App info kafka.consumer for flink-0 unregistered
INFO  - SplitFetcher               - Split fetcher 0 exited.
WARN  - Task                       - Join[150] -> Calc[151] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_962215956b0b799dc86f9b7cf721b29f_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for ee8b603bf5edab3af85b6467db69921f.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id ee8b603bf5edab3af85b6467db69921f lost leadership.
	... 29 more
INFO  - Task                       - Triggering cancellation of task code Join[150] -> Calc[151] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_962215956b0b799dc86f9b7cf721b29f_0_0).
INFO  - RocksDBKeyedStateBackend   - Closed RocksDB State Backend. Cleaning up RocksDB working directory /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_ee8b603bf5edab3af85b6467db69921f_op_SinkUpsertMaterializer_f4513f6c8f56192fb7e41d1eacfc44d9__1_1__uuid_972fc070-ae5d-464f-9ef7-51d6d6dd18c5.
INFO  - SourceReaderBase           - Closing Source Reader.
INFO  - SplitFetcher               - Shutting down split fetcher 0
INFO  - Task                       - Freeing task resources for Source: obs[120] -> Calc[121] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_cbc357ccb763df2852fee8c4fc7d55f2_0_0).
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Request joining group due to: consumer pro-actively leaving the group
INFO  - Metrics                    - Metrics scheduler closed
INFO  - Metrics                    - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  - Metrics                    - Metrics reporters closed
INFO  - teWriteRequestExecutorImpl - discarding 1 drained requests
INFO  - AppInfoParser              - App info kafka.consumer for flink-0 unregistered
INFO  - SplitFetcher               - Split fetcher 0 exited.
INFO  - Task                       - Attempting to fail task externally Join[138] -> Calc[139] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_a180dc35eba3df5d9593070701e62815_0_0).
WARN  - Task                       - Join[138] -> Calc[139] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_a180dc35eba3df5d9593070701e62815_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for ee8b603bf5edab3af85b6467db69921f.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id ee8b603bf5edab3af85b6467db69921f lost leadership.
	... 29 more
INFO  - Task                       - Triggering cancellation of task code Join[138] -> Calc[139] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_a180dc35eba3df5d9593070701e62815_0_0).
INFO  - Task                       - Freeing task resources for Source: concept_name[123] -> Calc[124] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_6cdc5bb954874d922eaee11a8e7b5dd5_0_0).
INFO  - RocksDBKeyedStateBackend   - Closed RocksDB State Backend. Cleaning up RocksDB working directory /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_ee8b603bf5edab3af85b6467db69921f_op_StreamingJoinOperator_962215956b0b799dc86f9b7cf721b29f__1_1__uuid_9d390c89-33af-4e7d-b703-2006f0c070b3.
INFO  - teWriteRequestExecutorImpl - discarding 1 drained requests
INFO  - TaskExecutor               - Close JobManager connection for job c3c54da01848bf81457a865e46b38d18.
INFO  - Task                       - Attempting to fail task externally Source: encounter_type[167] -> Calc[168] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_6cdc5bb954874d922eaee11a8e7b5dd5_0_0).
WARN  - Task                       - Source: encounter_type[167] -> Calc[168] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for c3c54da01848bf81457a865e46b38d18.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id c3c54da01848bf81457a865e46b38d18 lost leadership.
	... 29 more
INFO  - Task                       - Triggering cancellation of task code Source: encounter_type[167] -> Calc[168] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_6cdc5bb954874d922eaee11a8e7b5dd5_0_0).
INFO  - Task                       - Attempting to fail task externally Source: visit_type[191] -> Calc[192] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_5c4ca2fea30dcf09bf3ee40c495fe808_0_0).
WARN  - Task                       - Source: visit_type[191] -> Calc[192] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_5c4ca2fea30dcf09bf3ee40c495fe808_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for c3c54da01848bf81457a865e46b38d18.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id c3c54da01848bf81457a865e46b38d18 lost leadership.
	... 29 more
INFO  - Task                       - Triggering cancellation of task code Source: visit_type[191] -> Calc[192] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_5c4ca2fea30dcf09bf3ee40c495fe808_0_0).
INFO  - SourceReaderBase           - Closing Source Reader.
INFO  - SplitFetcher               - Shutting down split fetcher 0
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Request joining group due to: consumer pro-actively leaving the group
INFO  - SourceReaderBase           - Closing Source Reader.
INFO  - Task                       - Attempting to fail task externally Source: encounter[165] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_bc764cd8ddf7a0cff126f51c16239658_0_0).
INFO  - Metrics                    - Metrics scheduler closed
INFO  - Metrics                    - Closing reporter org.apache.kafka.common.metrics.JmxReporter
WARN  - Task                       - Source: encounter[165] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_bc764cd8ddf7a0cff126f51c16239658_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for c3c54da01848bf81457a865e46b38d18.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id c3c54da01848bf81457a865e46b38d18 lost leadership.
	... 29 more
INFO  - Task                       - Triggering cancellation of task code Source: encounter[165] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_bc764cd8ddf7a0cff126f51c16239658_0_0).
INFO  - SplitFetcher               - Shutting down split fetcher 0
INFO  - Metrics                    - Metrics reporters closed
INFO  - RocksDBKeyedStateBackend   - Closed RocksDB State Backend. Cleaning up RocksDB working directory /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_ee8b603bf5edab3af85b6467db69921f_op_StreamingJoinOperator_a180dc35eba3df5d9593070701e62815__1_1__uuid_c79cb389-d3b6-40c3-8b29-2785dcccd66f.
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Request joining group due to: consumer pro-actively leaving the group
INFO  - Task                       - Attempting to fail task externally Join[176] -> Calc[177] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_f9afc738306b4169a24150490d8848b9_0_0).
WARN  - Task                       - Join[176] -> Calc[177] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_f9afc738306b4169a24150490d8848b9_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for c3c54da01848bf81457a865e46b38d18.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id c3c54da01848bf81457a865e46b38d18 lost leadership.
	... 29 more
INFO  - Task                       - Triggering cancellation of task code Join[176] -> Calc[177] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_f9afc738306b4169a24150490d8848b9_0_0).
INFO  - SourceReaderBase           - Closing Source Reader.
INFO  - SplitFetcher               - Shutting down split fetcher 0
INFO  - Metrics                    - Metrics scheduler closed
INFO  - Metrics                    - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  - Metrics                    - Metrics reporters closed
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Request joining group due to: consumer pro-actively leaving the group
INFO  - Task                       - Attempting to fail task externally Join[188] -> Calc[189] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_01389bc9e2643187cd29ee681db6e960_0_0).
WARN  - Task                       - Join[188] -> Calc[189] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_01389bc9e2643187cd29ee681db6e960_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for c3c54da01848bf81457a865e46b38d18.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id c3c54da01848bf81457a865e46b38d18 lost leadership.
	... 29 more
INFO  - Task                       - Triggering cancellation of task code Join[188] -> Calc[189] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_01389bc9e2643187cd29ee681db6e960_0_0).
INFO  - AppInfoParser              - App info kafka.consumer for flink-0 unregistered
INFO  - SplitFetcher               - Split fetcher 0 exited.
INFO  - Task                       - Freeing task resources for Source: encounter_type[167] -> Calc[168] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_6cdc5bb954874d922eaee11a8e7b5dd5_0_0).
INFO  - Metrics                    - Metrics scheduler closed
INFO  - Metrics                    - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  - Task                       - Attempting to fail task externally Source: location[173] -> Calc[174] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_2963852293169ba90d9d1e7d6308db5c_0_0).
WARN  - Task                       - Source: location[173] -> Calc[174] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_2963852293169ba90d9d1e7d6308db5c_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for c3c54da01848bf81457a865e46b38d18.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id c3c54da01848bf81457a865e46b38d18 lost leadership.
	... 29 more
INFO  - Task                       - Triggering cancellation of task code Source: location[173] -> Calc[174] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_2963852293169ba90d9d1e7d6308db5c_0_0).
INFO  - Task                       - Attempting to fail task externally Source: visit[185] -> Calc[186] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_2fa5fc7df17f61cb0e1946288970d799_0_0).
WARN  - Task                       - Source: visit[185] -> Calc[186] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_2fa5fc7df17f61cb0e1946288970d799_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for c3c54da01848bf81457a865e46b38d18.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id c3c54da01848bf81457a865e46b38d18 lost leadership.
	... 29 more
INFO  - AppInfoParser              - App info kafka.consumer for flink-0 unregistered
INFO  - SplitFetcher               - Split fetcher 0 exited.
INFO  - Task                       - Triggering cancellation of task code Source: visit[185] -> Calc[186] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_2fa5fc7df17f61cb0e1946288970d799_0_0).
INFO  - SourceReaderBase           - Closing Source Reader.
INFO  - SplitFetcher               - Shutting down split fetcher 0
INFO  - RocksDBKeyedStateBackend   - Closed RocksDB State Backend. Cleaning up RocksDB working directory /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_c3c54da01848bf81457a865e46b38d18_op_StreamingJoinOperator_f9afc738306b4169a24150490d8848b9__1_1__uuid_95dfc71b-bc8b-4cae-bad6-9cabe5ab2640.
INFO  - Metrics                    - Metrics reporters closed
INFO  - Task                       - Freeing task resources for Source: visit_type[191] -> Calc[192] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_5c4ca2fea30dcf09bf3ee40c495fe808_0_0).
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Request joining group due to: consumer pro-actively leaving the group
INFO  - Task                       - Attempting to fail task externally SinkMaterializer[196] -> Sink: encounters[196] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_24dade4534f1f5ef5856c625ffee2704_0_0).
INFO  - Metrics                    - Metrics scheduler closed
INFO  - Metrics                    - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  - Metrics                    - Metrics reporters closed
WARN  - Task                       - SinkMaterializer[196] -> Sink: encounters[196] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_24dade4534f1f5ef5856c625ffee2704_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for c3c54da01848bf81457a865e46b38d18.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id c3c54da01848bf81457a865e46b38d18 lost leadership.
	... 29 more
INFO  - SourceReaderBase           - Closing Source Reader.
INFO  - SplitFetcher               - Shutting down split fetcher 0
INFO  - Task                       - Triggering cancellation of task code SinkMaterializer[196] -> Sink: encounters[196] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_24dade4534f1f5ef5856c625ffee2704_0_0).
INFO  - RocksDBKeyedStateBackend   - Closed RocksDB State Backend. Cleaning up RocksDB working directory /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_c3c54da01848bf81457a865e46b38d18_op_StreamingJoinOperator_01389bc9e2643187cd29ee681db6e960__1_1__uuid_76e5c05a-cfde-4bdd-9283-783525b6e3d6.
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Request joining group due to: consumer pro-actively leaving the group
INFO  - Metrics                    - Metrics scheduler closed
INFO  - Metrics                    - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  - Metrics                    - Metrics reporters closed
INFO  - Task                       - Attempting to fail task externally Join[194] -> Calc[195] -> ConstraintEnforcer[196] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_1eb956e4b1189e52250876d9eaefba9a_0_0).
WARN  - Task                       - Join[194] -> Calc[195] -> ConstraintEnforcer[196] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_1eb956e4b1189e52250876d9eaefba9a_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for c3c54da01848bf81457a865e46b38d18.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id c3c54da01848bf81457a865e46b38d18 lost leadership.
	... 29 more
INFO  - Task                       - Triggering cancellation of task code Join[194] -> Calc[195] -> ConstraintEnforcer[196] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_1eb956e4b1189e52250876d9eaefba9a_0_0).
INFO  - teWriteRequestExecutorImpl - discarding 1 drained requests
INFO  - AppInfoParser              - App info kafka.consumer for flink-0 unregistered
INFO  - SplitFetcher               - Split fetcher 0 exited.
INFO  - AppInfoParser              - App info kafka.consumer for flink-0 unregistered
INFO  - SplitFetcher               - Split fetcher 0 exited.
INFO  - Task                       - Attempting to fail task externally Join[170] -> Calc[171] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_13ff54467ae8d49b7c9f1ac12fb64224_0_0).
WARN  - Task                       - Join[170] -> Calc[171] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_13ff54467ae8d49b7c9f1ac12fb64224_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for c3c54da01848bf81457a865e46b38d18.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id c3c54da01848bf81457a865e46b38d18 lost leadership.
	... 29 more
INFO  - Task                       - Triggering cancellation of task code Join[170] -> Calc[171] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_13ff54467ae8d49b7c9f1ac12fb64224_0_0).
INFO  - Task                       - Freeing task resources for Source: location[173] -> Calc[174] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_2963852293169ba90d9d1e7d6308db5c_0_0).
INFO  - Task                       - Freeing task resources for Source: encounter[165] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_bc764cd8ddf7a0cff126f51c16239658_0_0).
INFO  - AppInfoParser              - App info kafka.consumer for flink-0 unregistered
INFO  - SplitFetcher               - Split fetcher 0 exited.
INFO  - RocksDBKeyedStateBackend   - Closed RocksDB State Backend. Cleaning up RocksDB working directory /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_c3c54da01848bf81457a865e46b38d18_op_SinkUpsertMaterializer_24dade4534f1f5ef5856c625ffee2704__1_1__uuid_8f59091a-83fc-47dd-a0a5-aa075db3fbb3.
INFO  - Task                       - Attempting to fail task externally Source: form[179] -> Calc[180] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_1171dea6747ab509fdaefbe74f7195af_0_0).
WARN  - Task                       - Source: form[179] -> Calc[180] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_1171dea6747ab509fdaefbe74f7195af_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for c3c54da01848bf81457a865e46b38d18.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id c3c54da01848bf81457a865e46b38d18 lost leadership.
	... 29 more
INFO  - Task                       - Triggering cancellation of task code Source: form[179] -> Calc[180] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_1171dea6747ab509fdaefbe74f7195af_0_0).
INFO  - Task                       - Freeing task resources for Source: visit[185] -> Calc[186] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_2fa5fc7df17f61cb0e1946288970d799_0_0).
INFO  - RocksDBKeyedStateBackend   - Closed RocksDB State Backend. Cleaning up RocksDB working directory /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_c3c54da01848bf81457a865e46b38d18_op_StreamingJoinOperator_1eb956e4b1189e52250876d9eaefba9a__1_1__uuid_1345803b-2271-4dae-b094-ad2df27ad43e.
INFO  - RocksDBKeyedStateBackend   - Closed RocksDB State Backend. Cleaning up RocksDB working directory /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_c3c54da01848bf81457a865e46b38d18_op_StreamingJoinOperator_13ff54467ae8d49b7c9f1ac12fb64224__1_1__uuid_1f204b39-10b0-454b-9004-dc6226a55ef0.
INFO  - teWriteRequestExecutorImpl - discarding 1 drained requests
INFO  - Task                       - Attempting to fail task externally Join[182] -> Calc[183] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_94f730e433abfd15ea618c51df02d4b0_0_0).
WARN  - Task                       - Join[182] -> Calc[183] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_94f730e433abfd15ea618c51df02d4b0_0_0) switched from RUNNING to FAILED with failure cause:
org.apache.flink.util.FlinkException: Disconnect from JobManager responsible for c3c54da01848bf81457a865e46b38d18.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.disconnectJobManagerConnection(TaskExecutor.java:1757)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor.access$1700(TaskExecutor.java:186)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
Caused by: java.lang.Exception: Job leader for job id c3c54da01848bf81457a865e46b38d18 lost leadership.
	... 29 more
INFO  - Task                       - Triggering cancellation of task code Join[182] -> Calc[183] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_94f730e433abfd15ea618c51df02d4b0_0_0).
INFO  - SourceReaderBase           - Closing Source Reader.
INFO  - SplitFetcher               - Shutting down split fetcher 0
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Resetting generation and member id due to: consumer pro-actively leaving the group
INFO  - ConsumerCoordinator        - [Consumer clientId=flink-0, groupId=flink] Request joining group due to: consumer pro-actively leaving the group
INFO  - teWriteRequestExecutorImpl - discarding 1 drained requests
INFO  - Metrics                    - Metrics scheduler closed
INFO  - Metrics                    - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  - Metrics                    - Metrics reporters closed
INFO  - Task                       - Attempting to cancel task Source: patient_appointment[1] -> Calc[2] (1/1)#0 (5d2b85ced63db2be7a46b4ce2f567a3c_cbc357ccb763df2852fee8c4fc7d55f2_0_0).
INFO  - Task                       - Task Source: patient_appointment[1] -> Calc[2] (1/1)#0 is already in state FAILED
INFO  - Task                       - Attempting to cancel task Source: patient[75] -> Calc[76] (1/1)#0 (588c992944dd31552e175761339ab856_cbc357ccb763df2852fee8c4fc7d55f2_0_0).
INFO  - Task                       - Task Source: patient[75] -> Calc[76] (1/1)#0 is already in state FAILED
INFO  - JobMaster                  - Disconnect TaskExecutor 586b9eac-aa0b-41ab-ae70-a614854e7a0e because: Job leader for job id 8f9053c77be2be6dcb80fb69df68baf8 lost leadership.
INFO  - AppInfoParser              - App info kafka.consumer for flink-0 unregistered
INFO  - SplitFetcher               - Split fetcher 0 exited.
INFO  - Task                       - Freeing task resources for SinkMaterializer[74] -> Sink: concepts[74] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_4595a980807a13db332f9917535d0424_0_0).
INFO  - Task                       - Freeing task resources for Source: form[179] -> Calc[180] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_1171dea6747ab509fdaefbe74f7195af_0_0).
INFO  - ExecutionGraph             - Source: patient_program[201] (1/1) (2ff118f32116f826e0d468907bf12d2a_bc764cd8ddf7a0cff126f51c16239658_0_0) switched from RUNNING to FAILED on 586b9eac-aa0b-41ab-ae70-a614854e7a0e @ localhost (dataPort=-1).
java.lang.Exception: Job leader for job id 8f9053c77be2be6dcb80fb69df68baf8 lost leadership.
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$null$2(TaskExecutor.java:2366)
	at java.base/java.util.Optional.ifPresent(Optional.java:183)
	at org.apache.flink.runtime.taskexecutor.TaskExecutor$JobLeaderListenerImpl.lambda$jobManagerLostLeadership$3(TaskExecutor.java:2364)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.lambda$handleRunAsync$4(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:68)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRunAsync(AkkaRpcActor.java:453)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleRpcMessage(AkkaRpcActor.java:218)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleMessage(AkkaRpcActor.java:168)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
INFO  - ExecutionGraph             - Discarding the results produced by task execution 2ff118f32116f826e0d468907bf12d2a_bc764cd8ddf7a0cff126f51c16239658_0_0.
INFO  - ExecutionGraph             - Discarding the results produced by task execution 2ff118f32116f826e0d468907bf12d2a_bc764cd8ddf7a0cff126f51c16239658_0_0.
INFO  - RocksDBKeyedStateBackend   - Closed RocksDB State Backend. Cleaning up RocksDB working directory /tmp/temp/minicluster_132858a0227c748917ce3a4bcc3d9fff/tm_0/tmp/job_c3c54da01848bf81457a865e46b38d18_op_StreamingJoinOperator_94f730e433abfd15ea618c51df02d4b0__1_1__uuid_24fdddbd-207b-4955-9a4c-e54cd465d647.
INFO  - SourceCoordinator          - Removing registered reader after failure for subtask 0 (#0) of source Source: patient_program[201].
INFO  - JobMaster                  - 7 tasks will be restarted to recover the failed task 2ff118f32116f826e0d468907bf12d2a_bc764cd8ddf7a0cff126f51c16239658_0_0.
INFO  - ExecutionGraph             - Job insert-into_analytics.analytics.patient_programs (8f9053c77be2be6dcb80fb69df68baf8) switched from state RUNNING to RESTARTING.
INFO  - ExecutionGraph             - Join[212] -> Calc[213] (1/1) (2ff118f32116f826e0d468907bf12d2a_d7e78c81a38d2cce4433a75795131bcf_0_0) switched from RUNNING to CANCELING.
INFO  - ExecutionGraph             - Join[206] -> Calc[207] (1/1) (2ff118f32116f826e0d468907bf12d2a_5b6b7f98d5bff23034589a7675c38ac7_0_0) switched from RUNNING to CANCELING.
INFO  - ExecutionGraph             - SinkMaterializer[217] -> Sink: patient_programs[217] (1/1) (2ff118f32116f826e0d468907bf12d2a_8fc3be823cc75a93eb3f11ae7a596b08_0_0) switched from RUNNING to CANCELING.
INFO  - ExecutionGraph             - Join[215] -> Calc[216] -> ConstraintEnforcer[217] (1/1) (2ff118f32116f826e0d468907bf12d2a_27b913f6385bb0e404cc1ac792473af7_0_0) switched from RUNNING to CANCELING.
INFO  - ExecutionGraph             - Source: program[203] -> Calc[204] (1/1) (2ff118f32116f826e0d468907bf12d2a_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) switched from RUNNING to CANCELING.
INFO  - SourceCoordinator          - Removing registered reader after failure for subtask 0 (#0) of source Source: program[203].
INFO  - ExecutionGraph             - Source: concept_name[209] -> Calc[210] (1/1) (2ff118f32116f826e0d468907bf12d2a_2963852293169ba90d9d1e7d6308db5c_0_0) switched from RUNNING to CANCELING.
INFO  - SourceCoordinator          - Removing registered reader after failure for subtask 0 (#0) of source Source: concept_name[209].
INFO  - ExecutionGraph             - Join[212] -> Calc[213] (1/1) (2ff118f32116f826e0d468907bf12d2a_d7e78c81a38d2cce4433a75795131bcf_0_0) switched from CANCELING to CANCELED.
INFO  - ExecutionGraph             - Discarding the results produced by task execution 2ff118f32116f826e0d468907bf12d2a_d7e78c81a38d2cce4433a75795131bcf_0_0.
INFO  - ExecutionGraph             - Discarding the results produced by task execution 2ff118f32116f826e0d468907bf12d2a_d7e78c81a38d2cce4433a75795131bcf_0_0.
INFO  - ExecutionGraph             - Join[206] -> Calc[207] (1/1) (2ff118f32116f826e0d468907bf12d2a_5b6b7f98d5bff23034589a7675c38ac7_0_0) switched from CANCELING to CANCELED.
INFO  - ExecutionGraph             - Discarding the results produced by task execution 2ff118f32116f826e0d468907bf12d2a_5b6b7f98d5bff23034589a7675c38ac7_0_0.
INFO  - ExecutionGraph             - Discarding the results produced by task execution 2ff118f32116f826e0d468907bf12d2a_5b6b7f98d5bff23034589a7675c38ac7_0_0.
INFO  - ExecutionGraph             - Join[215] -> Calc[216] -> ConstraintEnforcer[217] (1/1) (2ff118f32116f826e0d468907bf12d2a_27b913f6385bb0e404cc1ac792473af7_0_0) switched from CANCELING to CANCELED.
INFO  - ExecutionGraph             - Discarding the results produced by task execution 2ff118f32116f826e0d468907bf12d2a_27b913f6385bb0e404cc1ac792473af7_0_0.
INFO  - ExecutionGraph             - Discarding the results produced by task execution 2ff118f32116f826e0d468907bf12d2a_27b913f6385bb0e404cc1ac792473af7_0_0.
INFO  - ExecutionGraph             - SinkMaterializer[217] -> Sink: patient_programs[217] (1/1) (2ff118f32116f826e0d468907bf12d2a_8fc3be823cc75a93eb3f11ae7a596b08_0_0) switched from CANCELING to CANCELED.
INFO  - ExecutionGraph             - Discarding the results produced by task execution 2ff118f32116f826e0d468907bf12d2a_8fc3be823cc75a93eb3f11ae7a596b08_0_0.
INFO  - ExecutionGraph             - Source: program[203] -> Calc[204] (1/1) (2ff118f32116f826e0d468907bf12d2a_6cdc5bb954874d922eaee11a8e7b5dd5_0_0) switched from CANCELING to CANCELED.
INFO  - ExecutionGraph             - Discarding the results produced by task execution 2ff118f32116f826e0d468907bf12d2a_6cdc5bb954874d922eaee11a8e7b5dd5_0_0.
INFO  - ExecutionGraph             - Discarding the results produced by task execution 2ff118f32116f826e0d468907bf12d2a_6cdc5bb954874d922eaee11a8e7b5dd5_0_0.
INFO  - ExecutionGraph             - Source: concept_name[209] -> Calc[210] (1/1) (2ff118f32116f826e0d468907bf12d2a_2963852293169ba90d9d1e7d6308db5c_0_0) switched from CANCELING to CANCELED.
INFO  - ExecutionGraph             - Discarding the results produced by task execution 2ff118f32116f826e0d468907bf12d2a_2963852293169ba90d9d1e7d6308db5c_0_0.
INFO  - ExecutionGraph             - Discarding the results produced by task execution 2ff118f32116f826e0d468907bf12d2a_2963852293169ba90d9d1e7d6308db5c_0_0.
INFO  - DefaultDeclarativeSlotPool - Releasing slot [3fac7a41dd87f01504a131da610f53d4].
INFO  - JobMaster                  - Stopping the JobMaster for job 'insert-into_analytics.analytics.patient_programs' (8f9053c77be2be6dcb80fb69df68baf8).
INFO  - ExecutionGraph             - Job insert-into_analytics.analytics.patient_programs (8f9053c77be2be6dcb80fb69df68baf8) switched from state RESTARTING to SUSPENDED.
org.apache.flink.util.FlinkException: Scheduler is being stopped.
	at org.apache.flink.runtime.scheduler.SchedulerBase.closeAsync(SchedulerBase.java:646)
	at org.apache.flink.runtime.jobmaster.JobMaster.stopScheduling(JobMaster.java:1051)
	at org.apache.flink.runtime.jobmaster.JobMaster.stopJobExecution(JobMaster.java:1014)
	at org.apache.flink.runtime.jobmaster.JobMaster.onStop(JobMaster.java:442)
	at org.apache.flink.runtime.rpc.RpcEndpoint.internalCallOnStop(RpcEndpoint.java:239)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor$StartedState.lambda$terminate$0(AkkaRpcActor.java:578)
	at org.apache.flink.runtime.concurrent.akka.ClassLoadingUtils.runWithContextClassLoader(ClassLoadingUtils.java:83)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor$StartedState.terminate(AkkaRpcActor.java:577)
	at org.apache.flink.runtime.rpc.akka.AkkaRpcActor.handleControlMessage(AkkaRpcActor.java:196)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:24)
	at akka.japi.pf.UnitCaseStatement.apply(CaseStatements.scala:20)
	at scala.PartialFunction.applyOrElse(PartialFunction.scala:127)
	at scala.PartialFunction.applyOrElse$(PartialFunction.scala:126)
	at akka.japi.pf.UnitCaseStatement.applyOrElse(CaseStatements.scala:20)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:175)
	at scala.PartialFunction$OrElse.applyOrElse(PartialFunction.scala:176)
	at akka.actor.Actor.aroundReceive(Actor.scala:537)
	at akka.actor.Actor.aroundReceive$(Actor.scala:535)
	at akka.actor.AbstractActor.aroundReceive(AbstractActor.scala:220)
	at akka.actor.ActorCell.receiveMessage(ActorCell.scala:579)
	at akka.actor.ActorCell.invoke(ActorCell.scala:547)
	at akka.dispatch.Mailbox.processMailbox(Mailbox.scala:270)
	at akka.dispatch.Mailbox.run(Mailbox.scala:231)
	at akka.dispatch.Mailbox.exec(Mailbox.scala:243)
	at java.base/java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:290)
	at java.base/java.util.concurrent.ForkJoinPool$WorkQueue.topLevelExec(ForkJoinPool.java:1020)
	at java.base/java.util.concurrent.ForkJoinPool.scan(ForkJoinPool.java:1656)
	at java.base/java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1594)
	at java.base/java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:183)
INFO  - CheckpointCoordinator      - Stopping checkpoint coordinator for job 8f9053c77be2be6dcb80fb69df68baf8.
INFO  - ExecutionGraph             - Job 8f9053c77be2be6dcb80fb69df68baf8 has been suspended.
INFO  - SourceCoordinator          - Closing SourceCoordinator for source Source: patient_program[201].
INFO  - SourceCoordinator          - Closing SourceCoordinator for source Source: program[203].
INFO  - AppInfoParser              - App info kafka.admin.client for flink-enumerator-admin-client unregistered
INFO  - ltCompletedCheckpointStore - Suspending
INFO  - SourceCoordinator          - Closing SourceCoordinator for source Source: concept_name[209].
INFO  - AppInfoParser              - App info kafka.admin.client for flink-enumerator-admin-client unregistered
INFO  - AdminMetadataManager       - [AdminClient clientId=flink-enumerator-admin-client] Metadata update failed
org.apache.kafka.common.errors.TimeoutException: The AdminClient thread has exited. Call: fetchMetadata
INFO  - AdminMetadataManager       - [AdminClient clientId=flink-enumerator-admin-client] Metadata update failed
org.apache.kafka.common.errors.TimeoutException: The AdminClient thread has exited. Call: fetchMetadata
INFO  - KafkaAdminClient           - [AdminClient clientId=flink-enumerator-admin-client] Timed out 1 remaining operation(s) during close.
INFO  - KafkaAdminClient           - [AdminClient clientId=flink-enumerator-admin-client] Timed out 1 remaining operation(s) during close.
INFO  - AppInfoParser              - App info kafka.admin.client for flink-enumerator-admin-client unregistered
INFO  - AdminMetadataManager       - [AdminClient clientId=flink-enumerator-admin-client] Metadata update failed
org.apache.kafka.common.errors.TimeoutException: The AdminClient thread has exited. Call: fetchMetadata
INFO  - KafkaAdminClient           - [AdminClient clientId=flink-enumerator-admin-client] Timed out 1 remaining operation(s) during close.
INFO  - Metrics                    - Metrics scheduler closed
INFO  - Metrics                    - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  - Metrics                    - Metrics reporters closed
INFO  - SourceCoordinator          - Source coordinator for source Source: concept_name[209] closed.
INFO  - Metrics                    - Metrics scheduler closed
INFO  - Metrics                    - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  - Metrics                    - Metrics reporters closed
INFO  - SourceCoordinator          - Source coordinator for source Source: program[203] closed.
INFO  - Metrics                    - Metrics scheduler closed
INFO  - Metrics                    - Closing reporter org.apache.kafka.common.metrics.JmxReporter
INFO  - Metrics                    - Metrics reporters closed
INFO  - SourceCoordinator          - Source coordinator for source Source: patient_program[201] closed.
INFO  - Task                       - Freeing task resources for Join[206] -> Calc[207] (1/1)#0 (2ff118f32116f826e0d468907bf12d2a_5b6b7f98d5bff23034589a7675c38ac7_0_0).
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 28 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - Task                       - Freeing task resources for Join[215] -> Calc[216] -> ConstraintEnforcer[217] (1/1)#0 (2ff118f32116f826e0d468907bf12d2a_27b913f6385bb0e404cc1ac792473af7_0_0).
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 28 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 28 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 28 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 28 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 28 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 28 due to node 1 being disconnected (elapsed time since creation: 0ms, elapsed time since send: 0ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 28 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 28 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - Task                       - Freeing task resources for SinkMaterializer[217] -> Sink: patient_programs[217] (1/1)#0 (2ff118f32116f826e0d468907bf12d2a_8fc3be823cc75a93eb3f11ae7a596b08_0_0).
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 28 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 28 due to node 1 being disconnected (elapsed time since creation: 3ms, elapsed time since send: 3ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 28 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 28 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 28 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 28 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 28 due to node 1 being disconnected (elapsed time since creation: 3ms, elapsed time since send: 3ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 28 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 28 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 28 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 28 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 28 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 28 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 28 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 28 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - Task                       - Freeing task resources for Join[182] -> Calc[183] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_94f730e433abfd15ea618c51df02d4b0_0_0).
INFO  - Task                       - Freeing task resources for Join[170] -> Calc[171] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_13ff54467ae8d49b7c9f1ac12fb64224_0_0).
INFO  - Task                       - Freeing task resources for Join[194] -> Calc[195] -> ConstraintEnforcer[196] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_1eb956e4b1189e52250876d9eaefba9a_0_0).
INFO  - Task                       - Freeing task resources for SinkMaterializer[196] -> Sink: encounters[196] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_24dade4534f1f5ef5856c625ffee2704_0_0).
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 29 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 29 due to node 1 being disconnected (elapsed time since creation: 0ms, elapsed time since send: 0ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 29 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 29 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 29 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 29 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 29 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 29 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 29 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 29 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 29 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 29 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 29 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 29 due to node 1 being disconnected (elapsed time since creation: 0ms, elapsed time since send: 0ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 29 due to node 1 being disconnected (elapsed time since creation: 0ms, elapsed time since send: 0ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 29 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - Task                       - Freeing task resources for Join[188] -> Calc[189] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_01389bc9e2643187cd29ee681db6e960_0_0).
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 29 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 29 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 29 due to node 1 being disconnected (elapsed time since creation: 0ms, elapsed time since send: 0ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 29 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 29 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 29 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 29 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 29 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - Task                       - Freeing task resources for Join[176] -> Calc[177] (1/1)#0 (08238906b158b0367ef377eedf0e5e8e_f9afc738306b4169a24150490d8848b9_0_0).
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 30 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 30 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 30 due to node 1 being disconnected (elapsed time since creation: 0ms, elapsed time since send: 0ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 30 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 30 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 30 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 30 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 30 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 30 due to node 1 being disconnected (elapsed time since creation: 0ms, elapsed time since send: 0ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 30 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 30 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 30 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 30 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 30 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 30 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 30 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 30 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 30 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 30 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 30 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 30 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 30 due to node 1 being disconnected (elapsed time since creation: 0ms, elapsed time since send: 0ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 30 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 30 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - Task                       - Freeing task resources for Join[138] -> Calc[139] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_a180dc35eba3df5d9593070701e62815_0_0).
INFO  - Task                       - Freeing task resources for Join[150] -> Calc[151] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_962215956b0b799dc86f9b7cf721b29f_0_0).
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 31 due to node 1 being disconnected (elapsed time since creation: 3ms, elapsed time since send: 3ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 31 due to node 1 being disconnected (elapsed time since creation: 3ms, elapsed time since send: 3ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 31 due to node 1 being disconnected (elapsed time since creation: 3ms, elapsed time since send: 3ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 31 due to node 1 being disconnected (elapsed time since creation: 3ms, elapsed time since send: 3ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 31 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 31 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 31 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 31 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 31 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 31 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 31 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 31 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 31 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 31 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 31 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 31 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 31 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 31 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 31 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 31 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 31 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 31 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 31 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 31 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - Task                       - Freeing task resources for SinkMaterializer[161] -> Sink: observations[161] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_f4513f6c8f56192fb7e41d1eacfc44d9_0_0).
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 32 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 32 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 32 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 32 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 32 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 32 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 32 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 32 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 32 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 32 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 32 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 32 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 32 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 32 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 32 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 32 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 32 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 32 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 32 due to node 1 being disconnected (elapsed time since creation: 3ms, elapsed time since send: 3ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 32 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 32 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 32 due to node 1 being disconnected (elapsed time since creation: 3ms, elapsed time since send: 3ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 32 due to node 1 being disconnected (elapsed time since creation: 3ms, elapsed time since send: 3ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 32 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - Task                       - Freeing task resources for Join[144] -> Calc[145] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_5a4f0cabf832f59a1be42827a99c3e0b_0_0).
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 33 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 33 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 33 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 33 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 33 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 33 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 33 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 33 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 33 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - Task                       - Freeing task resources for Join[159] -> Calc[160] -> ConstraintEnforcer[161] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_a9f432d42f94da06ca5ecfb8d49d422a_0_0).
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 33 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 33 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 33 due to node 1 being disconnected (elapsed time since creation: 3ms, elapsed time since send: 3ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 33 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 33 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 33 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 33 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 33 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 33 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 33 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 33 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 33 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 33 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 33 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 33 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - Task                       - Freeing task resources for Join[126] -> Calc[127] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_3619c62de06dab71ff39a3a74a9f2151_0_0).
INFO  - Task                       - Freeing task resources for Join[156] -> Calc[157] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_922a00317cf5b7bf8065287dc182322e_0_0).
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 34 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 34 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 34 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 34 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 34 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 34 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 34 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 34 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 34 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 34 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 34 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 34 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 34 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 34 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 34 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 34 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 34 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 34 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 34 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 34 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 34 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 34 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 34 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 34 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - Task                       - Freeing task resources for Join[132] -> Calc[133] (1/1)#0 (580277ceefe8efaa1a64deb029a01c5c_e2fa199699a83ccdc9109b613d7b5bcb_0_0).
INFO  - Task                       - Freeing task resources for SinkMaterializer[47] -> Sink: orders[47] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_4595a980807a13db332f9917535d0424_0_0).
INFO  - Task                       - Freeing task resources for Join[27] -> Calc[28] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_55d7dd5010de5a0cb7f3223050a51b73_0_0).
INFO  - Task                       - Freeing task resources for Join[33] -> Calc[34] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_2e54324c2d6d30259944e7ab21f8249d_0_0).
INFO  - Task                       - Freeing task resources for Join[45] -> Calc[46] -> ConstraintEnforcer[47] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_6d4fd8dcc30b46c08121fc16d7e07e79_0_0).
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 35 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 35 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 35 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 35 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 35 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 35 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 35 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 35 due to node 1 being disconnected (elapsed time since creation: 0ms, elapsed time since send: 0ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 35 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 35 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 35 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 35 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 35 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 35 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 35 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 35 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - Task                       - Freeing task resources for Join[39] -> Calc[40] (1/1)#0 (a5db4d5da596a9c0b858e30fe60e5a2e_ab06fe1c886f2b2a7030a8ed4a30b46a_0_0).
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 35 due to node 1 being disconnected (elapsed time since creation: 8ms, elapsed time since send: 8ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 35 due to node 1 being disconnected (elapsed time since creation: 8ms, elapsed time since send: 8ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 35 due to node 1 being disconnected (elapsed time since creation: 8ms, elapsed time since send: 8ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 35 due to node 1 being disconnected (elapsed time since creation: 8ms, elapsed time since send: 8ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 35 due to node 1 being disconnected (elapsed time since creation: 9ms, elapsed time since send: 9ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 35 due to node 1 being disconnected (elapsed time since creation: 9ms, elapsed time since send: 9ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 35 due to node 1 being disconnected (elapsed time since creation: 9ms, elapsed time since send: 9ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 35 due to node 1 being disconnected (elapsed time since creation: 14ms, elapsed time since send: 14ms, request timeout: 3600000ms)
INFO  - Task                       - Freeing task resources for Join[117] -> Calc[118] -> ConstraintEnforcer[119] (1/1)#0 (42d00b36fc131a16543be5485c916ea3_2e97d77449c913cf0f6bfb4cb4497fa8_0_0).
INFO  - Task                       - Freeing task resources for Join[111] -> Calc[112] (1/1)#0 (42d00b36fc131a16543be5485c916ea3_bd51d758b4efb5e2f06d8b93962c12d2_0_0).
INFO  - Task                       - Freeing task resources for SinkMaterializer[119] -> Sink: visits[119] (1/1)#0 (42d00b36fc131a16543be5485c916ea3_b6b54abcd38d0cf242f4ba4c18cb7ed5_0_0).
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 36 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 36 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 36 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 36 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - Task                       - Freeing task resources for Join[86] -> Calc[87] (1/1)#0 (588c992944dd31552e175761339ab856_eb7d99873eea63dacba8fd9c596677e3_0_0).
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 36 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 36 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 36 due to node 1 being disconnected (elapsed time since creation: 0ms, elapsed time since send: 0ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 36 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 36 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 36 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 36 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 36 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 36 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 36 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 36 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 36 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - Task                       - Freeing task resources for Join[98] -> Calc[99] -> ConstraintEnforcer[100] (1/1)#0 (588c992944dd31552e175761339ab856_c6adced987710239013e40eb9ab41362_0_0).
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 36 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 36 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 36 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 36 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 36 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 36 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 36 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 36 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - Task                       - Freeing task resources for Join[81] (1/1)#0 (588c992944dd31552e175761339ab856_e6807280e63afa30c980423999b48cc6_0_0).
INFO  - Task                       - Freeing task resources for SinkMaterializer[100] -> Sink: patients[100] (1/1)#0 (588c992944dd31552e175761339ab856_4969848647857cea5647cb2eb2d99d6b_0_0).
INFO  - Task                       - Freeing task resources for Join[92] -> Calc[93] (1/1)#0 (588c992944dd31552e175761339ab856_fa7571c07da635c59ba82f92b55840d8_0_0).
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 37 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 37 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 37 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 37 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - Task                       - Freeing task resources for Join[18] -> Calc[19] -> ConstraintEnforcer[20] (1/1)#0 (5d2b85ced63db2be7a46b4ce2f567a3c_23e521ac8efce918f328250afebbe45c_0_0).
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 37 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 37 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 37 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 37 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 37 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 37 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 37 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 37 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 37 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 37 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 37 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 37 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - Task                       - Freeing task resources for Join[12] -> Calc[13] (1/1)#0 (5d2b85ced63db2be7a46b4ce2f567a3c_ccd2f3173f602e66f6767720952cb258_0_0).
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 37 due to node 1 being disconnected (elapsed time since creation: 0ms, elapsed time since send: 0ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 37 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 37 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 37 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 37 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 37 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 37 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 37 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 38 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 38 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 38 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 38 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 38 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 38 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 38 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 38 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 38 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 38 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 38 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 38 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 38 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 38 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 38 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 38 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 38 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - Task                       - Freeing task resources for SinkMaterializer[164] -> Sink: sale_order[164] (1/1)#0 (a1c2895d942138a93658723314479d9c_c27dcf7b54ef6bfd6cff02ca8870b681_0_0).
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 38 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 38 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 38 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 38 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 38 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 38 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 38 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - Task                       - Freeing task resources for Join[7] (1/1)#0 (5d2b85ced63db2be7a46b4ce2f567a3c_5caeaa5e379e7348564aaaaf5ae0d6a6_0_0).
INFO  - Task                       - Freeing task resources for SinkMaterializer[20] -> Sink: appointments[20] (1/1)#0 (5d2b85ced63db2be7a46b4ce2f567a3c_fd907ffb7425150fb379978eab0e6d37_0_0).
INFO  - Task                       - Freeing task resources for Join[54] -> Calc[55] (1/1)#0 (80aa942084eddc41f7baf859b5ecb269_55d7dd5010de5a0cb7f3223050a51b73_0_0).
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 39 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 39 due to node 1 being disconnected (elapsed time since creation: 4ms, elapsed time since send: 4ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 39 due to node 1 being disconnected (elapsed time since creation: 3ms, elapsed time since send: 3ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 39 due to node 1 being disconnected (elapsed time since creation: 4ms, elapsed time since send: 4ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 39 due to node 1 being disconnected (elapsed time since creation: 3ms, elapsed time since send: 3ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 39 due to node 1 being disconnected (elapsed time since creation: 3ms, elapsed time since send: 3ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 39 due to node 1 being disconnected (elapsed time since creation: 4ms, elapsed time since send: 4ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 39 due to node 1 being disconnected (elapsed time since creation: 4ms, elapsed time since send: 4ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 39 due to node 1 being disconnected (elapsed time since creation: 4ms, elapsed time since send: 4ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 39 due to node 1 being disconnected (elapsed time since creation: 3ms, elapsed time since send: 3ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 39 due to node 1 being disconnected (elapsed time since creation: 3ms, elapsed time since send: 3ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 39 due to node 1 being disconnected (elapsed time since creation: 3ms, elapsed time since send: 3ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 39 due to node 1 being disconnected (elapsed time since creation: 3ms, elapsed time since send: 3ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 39 due to node 1 being disconnected (elapsed time since creation: 3ms, elapsed time since send: 3ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 39 due to node 1 being disconnected (elapsed time since creation: 4ms, elapsed time since send: 4ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 39 due to node 1 being disconnected (elapsed time since creation: 4ms, elapsed time since send: 4ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 39 due to node 1 being disconnected (elapsed time since creation: 4ms, elapsed time since send: 4ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 39 due to node 1 being disconnected (elapsed time since creation: 26ms, elapsed time since send: 26ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 39 due to node 1 being disconnected (elapsed time since creation: 26ms, elapsed time since send: 26ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 39 due to node 1 being disconnected (elapsed time since creation: 27ms, elapsed time since send: 27ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 39 due to node 1 being disconnected (elapsed time since creation: 26ms, elapsed time since send: 26ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 39 due to node 1 being disconnected (elapsed time since creation: 26ms, elapsed time since send: 26ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 39 due to node 1 being disconnected (elapsed time since creation: 26ms, elapsed time since send: 26ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 39 due to node 1 being disconnected (elapsed time since creation: 26ms, elapsed time since send: 26ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 40 due to node 1 being disconnected (elapsed time since creation: 0ms, elapsed time since send: 0ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 40 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 40 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 40 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 40 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 40 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 40 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 40 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 40 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 40 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 40 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 40 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 40 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 40 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 40 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 40 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 40 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 40 due to node 1 being disconnected (elapsed time since creation: 3ms, elapsed time since send: 3ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 40 due to node 1 being disconnected (elapsed time since creation: 3ms, elapsed time since send: 3ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 40 due to node 1 being disconnected (elapsed time since creation: 3ms, elapsed time since send: 3ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 40 due to node 1 being disconnected (elapsed time since creation: 3ms, elapsed time since send: 3ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 40 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 40 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 40 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - ClientCnxn                 - Opening socket connection to server localhost/127.0.0.1:2181.
INFO  - ClientCnxn                 - SASL config status: Will not attempt to authenticate using SASL (unknown error)
WARN  - ClientCnxn                 - Session 0x10009b90d4f0000 for server localhost/127.0.0.1:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException.
java.net.ConnectException: Connection refused
	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)
	at org.apache.flink.shaded.zookeeper3.org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
	at org.apache.flink.shaded.zookeeper3.org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1283)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 41 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 41 due to node 1 being disconnected (elapsed time since creation: 5ms, elapsed time since send: 5ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 41 due to node 1 being disconnected (elapsed time since creation: 7ms, elapsed time since send: 7ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 41 due to node 1 being disconnected (elapsed time since creation: 5ms, elapsed time since send: 5ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 41 due to node 1 being disconnected (elapsed time since creation: 7ms, elapsed time since send: 7ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 41 due to node 1 being disconnected (elapsed time since creation: 7ms, elapsed time since send: 7ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 41 due to node 1 being disconnected (elapsed time since creation: 7ms, elapsed time since send: 7ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 41 due to node 1 being disconnected (elapsed time since creation: 8ms, elapsed time since send: 8ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 41 due to node 1 being disconnected (elapsed time since creation: 8ms, elapsed time since send: 8ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 41 due to node 1 being disconnected (elapsed time since creation: 9ms, elapsed time since send: 9ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 41 due to node 1 being disconnected (elapsed time since creation: 8ms, elapsed time since send: 8ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 41 due to node 1 being disconnected (elapsed time since creation: 8ms, elapsed time since send: 8ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 41 due to node 1 being disconnected (elapsed time since creation: 8ms, elapsed time since send: 8ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 41 due to node 1 being disconnected (elapsed time since creation: 7ms, elapsed time since send: 7ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 41 due to node 1 being disconnected (elapsed time since creation: 8ms, elapsed time since send: 8ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 41 due to node 1 being disconnected (elapsed time since creation: 9ms, elapsed time since send: 9ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 41 due to node 1 being disconnected (elapsed time since creation: 7ms, elapsed time since send: 7ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 41 due to node 1 being disconnected (elapsed time since creation: 0ms, elapsed time since send: 0ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 41 due to node 1 being disconnected (elapsed time since creation: 0ms, elapsed time since send: 0ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 41 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 41 due to node 1 being disconnected (elapsed time since creation: 0ms, elapsed time since send: 0ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 41 due to node 1 being disconnected (elapsed time since creation: 3ms, elapsed time since send: 3ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 41 due to node 1 being disconnected (elapsed time since creation: 0ms, elapsed time since send: 0ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 41 due to node 1 being disconnected (elapsed time since creation: 3ms, elapsed time since send: 3ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 42 due to node 1 being disconnected (elapsed time since creation: 4ms, elapsed time since send: 4ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 42 due to node 1 being disconnected (elapsed time since creation: 0ms, elapsed time since send: 0ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 42 due to node 1 being disconnected (elapsed time since creation: 0ms, elapsed time since send: 0ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 42 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 42 due to node 1 being disconnected (elapsed time since creation: 4ms, elapsed time since send: 4ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 42 due to node 1 being disconnected (elapsed time since creation: 3ms, elapsed time since send: 3ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 42 due to node 1 being disconnected (elapsed time since creation: 0ms, elapsed time since send: 0ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 42 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 42 due to node 1 being disconnected (elapsed time since creation: 0ms, elapsed time since send: 0ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 42 due to node 1 being disconnected (elapsed time since creation: 0ms, elapsed time since send: 0ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 42 due to node 1 being disconnected (elapsed time since creation: 0ms, elapsed time since send: 0ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 42 due to node 1 being disconnected (elapsed time since creation: 0ms, elapsed time since send: 0ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 42 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 42 due to node 1 being disconnected (elapsed time since creation: 3ms, elapsed time since send: 3ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 42 due to node 1 being disconnected (elapsed time since creation: 0ms, elapsed time since send: 0ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 42 due to node 1 being disconnected (elapsed time since creation: 3ms, elapsed time since send: 3ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 42 due to node 1 being disconnected (elapsed time since creation: 5ms, elapsed time since send: 5ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 42 due to node 1 being disconnected (elapsed time since creation: 0ms, elapsed time since send: 0ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 42 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 42 due to node 1 being disconnected (elapsed time since creation: 0ms, elapsed time since send: 0ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 42 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 42 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 42 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 42 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 43 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 43 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 43 due to node 1 being disconnected (elapsed time since creation: 0ms, elapsed time since send: 0ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 43 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 43 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 43 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 43 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 43 due to node 1 being disconnected (elapsed time since creation: 0ms, elapsed time since send: 0ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 43 due to node 1 being disconnected (elapsed time since creation: 0ms, elapsed time since send: 0ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 43 due to node 1 being disconnected (elapsed time since creation: 0ms, elapsed time since send: 0ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 43 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 43 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 43 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 43 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 43 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 43 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 43 due to node 1 being disconnected (elapsed time since creation: 0ms, elapsed time since send: 0ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 43 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 43 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 43 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 43 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 43 due to node 1 being disconnected (elapsed time since creation: 0ms, elapsed time since send: 0ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 43 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 43 due to node 1 being disconnected (elapsed time since creation: 0ms, elapsed time since send: 0ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 44 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 44 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 44 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 44 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 44 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 44 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 44 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 44 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 44 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 44 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 44 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 44 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 44 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 44 due to node 1 being disconnected (elapsed time since creation: 0ms, elapsed time since send: 0ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 44 due to node 1 being disconnected (elapsed time since creation: 0ms, elapsed time since send: 0ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 44 due to node 1 being disconnected (elapsed time since creation: 0ms, elapsed time since send: 0ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 44 due to node 1 being disconnected (elapsed time since creation: 0ms, elapsed time since send: 0ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 44 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 44 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 44 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 44 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 44 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 44 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 44 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 45 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 45 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 45 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 45 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 45 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 45 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 45 due to node 1 being disconnected (elapsed time since creation: 0ms, elapsed time since send: 0ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 45 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 45 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 45 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 45 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 45 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 45 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 45 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 45 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 45 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 45 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 45 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 45 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 45 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 45 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 45 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 45 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 45 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 46 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 46 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 46 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 46 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 46 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 46 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 46 due to node 1 being disconnected (elapsed time since creation: 0ms, elapsed time since send: 0ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 46 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 46 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 46 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 46 due to node 1 being disconnected (elapsed time since creation: 0ms, elapsed time since send: 0ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 46 due to node 1 being disconnected (elapsed time since creation: 0ms, elapsed time since send: 0ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 46 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 46 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 46 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 46 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 46 due to node 1 being disconnected (elapsed time since creation: 2ms, elapsed time since send: 2ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 46 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 46 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 46 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 46 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 46 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 46 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 46 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 47 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 47 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 47 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 47 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 47 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 47 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 47 due to node 1 being disconnected (elapsed time since creation: 0ms, elapsed time since send: 0ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 47 due to node 1 being disconnected (elapsed time since creation: 0ms, elapsed time since send: 0ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 47 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 47 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 47 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 47 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 47 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 47 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 47 due to node 1 being disconnected (elapsed time since creation: 0ms, elapsed time since send: 0ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 47 due to node 1 being disconnected (elapsed time since creation: 0ms, elapsed time since send: 0ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Cancelled in-flight API_VERSIONS request with correlation id 47 due to node 1 being disconnected (elapsed time since creation: 1ms, elapsed time since send: 1ms, request timeout: 3600000ms)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - ClientCnxn                 - Opening socket connection to server localhost/0:0:0:0:0:0:0:1:2181.
INFO  - ClientCnxn                 - SASL config status: Will not attempt to authenticate using SASL (unknown error)
WARN  - ClientCnxn                 - Session 0x10009b90d4f0000 for server localhost/0:0:0:0:0:0:0:1:2181, Closing socket connection. Attempting reconnect except it is a SessionExpiredException.
java.net.ConnectException: Connection refused
	at java.base/sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)
	at java.base/sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:777)
	at org.apache.flink.shaded.zookeeper3.org.apache.zookeeper.ClientCnxnSocketNIO.doTransport(ClientCnxnSocketNIO.java:344)
	at org.apache.flink.shaded.zookeeper3.org.apache.zookeeper.ClientCnxn$SendThread.run(ClientCnxn.java:1283)
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - PermanentBlobCache         - Shutting down BLOB cache
INFO  - torLocalStateStoresManager - Shutting down TaskExecutorLocalStateStoresManager.
INFO  - TransientBlobCache         - Shutting down BLOB cache
INFO  - teChangelogStoragesManager - Shutting down TaskExecutorStateChangelogStoragesManager.
INFO  - BlobServer                 - Stopped BLOB server at 0.0.0.0:52172
INFO  - FileCache                  - removed file cache directory /tmp/temp/flink-dist-cache-0f0b7a0a-0f03-46cd-a3fc-212aab11e3af
INFO  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Node 1 disconnected.
WARN  - NetworkClient              - [AdminClient clientId=flink-enumerator-admin-client] Connection to node 1 (localhost/127.0.0.1:29092) could not be established. Broker may not be available.
INFO  - FileChannelManagerImpl     - FileChannelManager removed spill file directory /tmp/temp/flink-netty-shuffle-4e00509b-807d-4def-a026-d6b1537f3cc6
INFO  - FileChannelManagerImpl     - FileChannelManager removed spill file directory /tmp/temp/flink-io-0a6171ae-115d-46c8-b026-e3b045c9f5b5
